text,label
"cf invokes cfe_msg_init with size of <number> <section> the 3 rd parameter of <code> is supposed to indicate the actual size of the structure / buffer being initialized . in general , this must be _at least_ the size of the primary header in order to be valid . cf ( at first ) passes this as <number> , then overwrites this with the real size later on . the problem is , a size of <number> is totally invalid , and to be correct , <code> should not be writing any values into a structure that is smaller than the size of a primary header , as this is an error . writing any value into a struct of size <number> is a write - beyond - bounds error , and thus the fact that the default cfe_msg_init ( ) even allows this is a bug . <section> run cf with a proper implementation of <code> - i . e . one that verifies the size is valid . when passed a size of <number> , none of the header fields will be set ( correct behavior ) . this results in the buffer being in an indeterminate state , and the msgid will not be set . <section> the msgid needs to be set by the call to <code> <section> <url> <section> joseph hickey , vantage systems , inc .",0
"fix # <number> , update minor out - of - family naming / consistency issues in cf <section> - fixes # <number> - add event for <code> failure during initialization ( and created a new matching <allcaps> eid </allcaps> : <code> ) - in <code> : use <code> instead of <code> and use the <code> conversion macro - cf was the only app remaining to use <code> - add <code> at the beginning of the initialization routine to zero - out the global data structure ( defensive programming , and for consistency - almost all of the cfs modules / apps do this ) - remove check of the return value of <code> reporting initialization success - this is very out - of - family for cfs and also inconsistent - cf does not check the return value of any other calls to <code> - remove null check in <code> after successful call to <code> - out - of - family with cfs and also redundant ( <code> with a successful return guarantees the returned pointer to be non - <code> ) minor changes : - comment in <code> noted incorrect parameter cannot be <code> - corrected this - rename <code> to <code> - rename <code> to <code> - rename <code> to <code> - rename software bus command pipe message pointer variables from <code> to <code> - rename <code> to <code> - move ' cmd ' to end of command function names ( e . g . <code> changed to <code> ) - rename <code> to <code> - more clear and specific , and in line with vast majority of cfs incl . cfe - rename <code> to <code> <section> cf does not verify length for non - command mids received in the app pipe ( <code> and <code> ) - it would be worthwhile to rectify this at some point . cfe and the other apps are generally inconsistent on this - some do not check non - command mids , some use a single verifylength function to check all mids arriving , some use separate verifylength functions for command and non - command mids . <repeated> <section> github ci actions all passing successfully ( incl . build + run , unit / functional tests etc . ) . <section> minor changes as noted above , no significant changes to behavior . aligning aberrant naming to the predominant patterns in cfs improves usability and eases future maintenance . <section> avi weiss <user>",2
"some minor out - of - family naming / consistency issues in cf could be updated <section> cf is the only app to still use <code> to timestamp the hk packet , rather than <code> : <url> no <code> to zero - out the global data structure upon initialization . cf checks the return value of the call to <code> at the end of a successful initialization - not incorrect but unnecessary . returns from <code> are only checked a handful of times across cfs out of several thousand instances . also , cf does not check returns from this function anywhere else in the source code . <url> in <code> , there is a check for <code> _and_ for a null pointer of the buffer passed in to <code> - this is guaranteed by <code> to not be possible and is therefore unnecessary . cfe and almost all other apps do not do this . <url> some other naming inconsistencies that could be updated to match standard cfs patterns such as common variables and function / command names also exist . <section> align with cfs where appropriate - consistency makes maintenance easier , and improves usability for consumers of cfs and the open - source apps . <section> avi weiss <user>",2
"cf draco rc4 : many fiile uploads caus cf to hang or have "" gap errors "" * [x ] i performed a cursory search to see if the bug report is relevant , not redundant , nor in conflict with other tickets . <section> on <allcaps> rst wfi fsw </allcaps> , when uploading many files ( <number> - <number> files ) , the cf application either stops responding ang hangs or it responds with ' gap errors ' . this is most easily seen when uploading a large number of table files . on <allcaps> rst wfi fsw </allcaps> , this bug can be tracked under <url> <section> this bug was originally seen by the <allcaps> wfi </allcaps> simulator team when trying to upload large numbers of <allcaps> ald </allcaps> files to the <allcaps> wfi fsw </allcaps> . this bug was reproduced in the <allcaps> wfi fsw </allcaps> lab <allcaps> cots </allcaps> gr740 string by uploading <number> to <number> sets of <number> table files . from <allcaps> wfi </allcaps> - <number> : "" the script wfif_fgs_table_dump_and_load_test . prc dumps and reloads all <allcaps> fgs </allcaps> tables ( <number> ) total in sequence . once in a while the script will hang because a table was not able to upload . <allcaps> cfdp </allcaps> page will sometimes show a "" gap "" error . "" <section> the cf application should be able to handle "" large "" numbers of file uploads without hanging or producing errors . <section> - roman <allcaps> rst wpc </allcaps> , and leon4 gr740 <allcaps> cots </allcaps> - <allcaps> rtems </allcaps> <number> - cf draco rc4 ( and draco rc2 ) , <allcaps> wfi fsw </allcaps> <number> <section> add any other context about the problem here . <section> nicholas yanchik , <allcaps> nasa </allcaps> goddard space flight center , <allcaps> wfi fsw pdl </allcaps> <email>",0
"support polling with no delay <section> polling has a timer that does not support zero delay , limiting performance : <url> <url> <url> <section> there ' s already a channel enable , no need to use interval to disable the channel . update to support <number> delay to maximize throughput when using the polling directory . <section> none <section> i can not say i really understand why <number> timeout wasn ' t supported to begin with . if anyone knows i ' d be interested to hear it . in rate constrained situations unnecessary delays on file transfers are a big impact . sending small files on a fast link could waste significant bandwidth by waiting a second between polling . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"silence logic around error event broken on semaphore timeout <section> if the semaphore times out there ' s no attempt to allocate a buffer . if a buffer is not allocated and silent is false , an error event is sent claiming there was no buffer available . <url> this silent logic does not make any sense to me , since it ' s passed in as <number> from all the non - file data pdus but <number> for data . if it was intended for the allocate buffer why only non - data pdus ? i doubt it was ever intended for the semaphore timeout . <section> i saw it when waiting for the semaphore to send an eof <allcaps> pdu </allcaps> . could probably see it on the metadata send , but i initialize w / a nonzero sem count . <section> no event on semaphore timeout , this is nominal behavior for flow control . <allcaps> tbh i </allcaps> ' m not a huge fan of a possible flooding event on the failure to get a buffer . i ' d rather see a combined approach of a counter and probably a single event sent at the maximum rate of each hk cycle only when the counter increments . <section> see above . <section> ubuntu <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0
"fix # <number> , remove local error return codes in cf_validateconfigtable ( ) <section> - fixes # <number> - removed the local error return codes and replaced with one of the new <allcaps> cfe </allcaps> macros indicating validation failure . <section> github ci actions all passing successfully . <section> <code> will now return a relevant error code that is intelligible to outside functions , if they want to take action on it . the function is noticeably simpler / cleaner now . <section> avi weiss <user>",2
"decoding segments using incorrect macro ( cf_pdu_max_tlv ) <section> while checking out the most recent version of the cf repository to test with a custom file sending application , i ran into this line while trying to figure out why <allcaps> nak </allcaps> ' s were acting strangely : <url> should not it look moreso like this ? there are other lines referencing the <code> macro , but those compare against the <code> struct member . when i modified it to this in my instance of cfs , all <allcaps> cfdp </allcaps> functions worked as expected : <code>",0
"add option for padding bytes / trailer at end of <allcaps> cf pdu </allcaps> <section> some deployment scenarios for cf may require some extra platform - specific trailing data to be appended to the end of the pdus , for example a custom <allcaps> crc </allcaps> or error check / correction code . <section> to facilitate this , cf should offer an option to add extra padding bytes to the end of the <allcaps> pdu </allcaps> so that the platform may fill these bytes with the desired trailing data . <section> joseph hickey , vantage systems , inc .",2
cf backwards compatibility it possible to simply update cf app ( <number> . 4 xx ) and have that new version of cf be backwards compatible with all the other apps <allcaps> cfe </allcaps> etc ?,3
"double semicolon in <hashtag> define </hashtag> macro ? <section> does this macro expand out and result in a double - semicolon ( i . e . an empty statement ) ? <url> for example , here : <url> <section> avi weiss <user>",0
"coding style : braces around single - line statements in if / for blocks ? <section> most single - line statements ( > <percent> ) in if / for blocks are surrounded by braces , but not all . <section> if not contrary to the coding standard , no change is required , although consistency is always nice . <repeated> <section> most safety - focused coding standards require braces in call blocks , even for single - line statements ( and often even for empty statements ) . i am not sure where the cfs ( <allcaps> gsfc </allcaps> ) standard stands on this . this is due to the perceived improvement in readability and maintainability ( i . e . with braces , there is a lower risk of messing up the scope of a statement when something is either added or removed in the future ) . <section> <url> <url> a few further examples from around cfs to illustrate : <url> <url> <url> <section> avi weiss <user>",3
"<allcaps> pdu </allcaps> processing when crc_flag true * x] i reviewed the [ contributing guide <url> . * [x ] i performed a cursory search to see if the bug report is relevant , not redundant , nor in conflict with other tickets . <section> the issue involves a difference in interpretation of the <allcaps> cfdp </allcaps> specification . in particular , the format and processing of <allcaps> cfdp </allcaps> pdus when the <allcaps> pdu </allcaps> header indicates <allcaps> crc </allcaps> present . for fd pdus , the code ignores <number> bytes instead of <number> bytes for the <allcaps> crc </allcaps> at the end of the <allcaps> pdu </allcaps> ( see context ) . that will result in ignoring the last <number> bytes of file data from fd pdus encoded with a <allcaps> crc </allcaps> . if an <allcaps> eof </allcaps> or <allcaps> fin pdu </allcaps> is received with <allcaps> crc </allcaps> present , the <allcaps> crc </allcaps> at the end will ( almost always ) cause a decoding error in cf_cfdp_decodealltlv called by cf_cfdp_decodeeof / cf_cfdp_decodefin . <section> unknown . if helpful , i could provide what i believe to be valid <allcaps> cfdp </allcaps> pdus and show how their processing differs from my expectation . <section> the software could refuse pdus with crc_flag true , or , preferably , it could decrement the data_len of ( all ) pdus with crc_flag true by <number> ( bytes ) . <section> this code has the per <allcaps> pdu crc </allcaps> declaration : <url> the comments on lines <number> - <number> do not match my understanding . file data processing excerpt : <url> <section> n / a <section> unfortunately , the <allcaps> cfdp </allcaps> standard <number> <allcaps> crc procedures </allcaps> has an external reference for the <allcaps> crc </allcaps> and the reference is wrong : <number> . <number> the <allcaps> crc </allcaps> computation algorithm shall be the standard <allcaps> ccsds </allcaps> telecommand <allcaps> crc </allcaps> algorithm specified in <number> . <number> of the <allcaps> ccsds </allcaps> telecommand recommendation ( reference [ <number> ] ) . and <number> - b - <number> section <number> . <number> does not specify a <allcaps> crc </allcaps> . however , the only <allcaps> crc </allcaps> in <number> - b - <number> is defined in <number> . <number> frame error control word as a <number> octet field . <section> bob wiegand , <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0
"' <allcaps> eid </allcaps> ' should be at the end of the event id names <section> during recent updates <url> to the eids , it was noted that cf specifically has the ' <allcaps> eid </allcaps> ' component of the event id names at the beginning rather than the end for almost all the event ids . all other cfs components / apps place it at the end of the event id . <section> screenshot <number> - <number> - <number> <number> <number> <number> <img> <section> i think it is worth moving ' <allcaps> eid </allcaps> ' to the end of the cf event id names to improve consistency across the cfs apps and ease the identification of eids from cf in general . at the same time , it is probably worth moving the additional type parameter in the event id names ( <code> , <code> etc . ) to the end as well , which is also the predominant convention in cfs . <section> avi weiss <user>",2
"inconsistent event id naming <section> copy of <url> after finding that there were <number> different event ids to indicate the same thing ( invalid message id ) in <url> i scrubbed the other common commands ( e . g . task initialisation [ <allcaps> init </allcaps> ] , <allcaps> noop </allcaps> , reset counters etc . ) and found the same issue there - almost every component / app had their own variation of the event id name for the exact same event . <section> apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>",2
"temporary files possible filename conflict <section> the temporary filenames are created based on the sequence number in the <allcaps> pdu </allcaps> ( in the cf_cfdp_r_init ( ) ) . imagine that two different <allcaps> cfdp </allcaps> entities are sending a <allcaps> pdu </allcaps> with the same sequence number ( which can happen since this number is managed by each <allcaps> cfdp </allcaps> entity and it can be the same ) to the same <allcaps> cfdp </allcaps> destination entity . for instance , the sequence number in this case is ' x'. for the first <allcaps> pdu </allcaps> the cf app would create the x . tmp file and store it in the temporary folder . upon arriving the second <allcaps> pdu </allcaps> the cf app would also create a x . tmp file and then would store it in the temporary folder . this would create a conflict . would not it be better if the temporary filename is the concatenation of the source entity id and the sequence number ? this would guarantee that each temporary file would be unique since each sequence number is unique for each entity id .",0
"cf_cfdp_sendeotpkt sent with incorrect cc value * x ] i reviewed the [ contributing guide <url> . * [x ] i performed a cursory search to see if the bug report is relevant , not redundant , nor in conflict with other tickets . <section> a call to cf_cfdp_sendeotpkt ( ) was added to the cf_cfdp_resettransaction ( ) function to give feedback on successful file transmission . however , it is sent every time the transaction is discarded regardless of the cause . i believe it was the intent that the t - > history - > cc could then be used to determine if it was successful . however , it is unclear if t - > history - > cc is being correctly set on on every possible condition that calls cf_cfdp_resettransaction ( ) . particularly with the <allcaps> cfdp </allcaps> send control loop , it appears that there are cases where the the sending transaction is reset without setting t - > history - > cc which is used by cf_cfdp_sendeotpkt ( ) . i . e . the cf_eotpacket telemetry would indicate success when it in fact did not complete successfully . before cf_cfdp_sendeotpkt ( ) was added to cf_cfdp_resettransaction ( ) , it did not matter if t - > history - > cc was set before calling cf_cfdp_resettransaction ( ) since it wasn ' t used in the function before freeing the transaction . <section> steps to reproduce the behavior : example - let <allcaps> cfpd </allcaps> send t - > inactivity_timer timeout before completing the transaction . <section> t - > history - > cc must be set correctly for all possible cases before calling cf_cfdp_resettransaction ( ) . canceling a transaction or an error condition that leads to resetting the transaction must set t - > history - > cc to a value other than cf_cfdp_conditioncode_no_error . unit tests for function that have an error condition that leads to resetting the transaction should verify that t - > history - > cc is also set to an error condition . <section> void cf_cfdp_sendeotpkt ( cf_transaction_t * t ) { . <repeated> pktbuf - > eot . cc = t - > history - > cc ; . <repeated> } <section> - hardware n / a - os : centos - versions <number> <section> add any other context about the problem here . <section> nathan lynch <allcaps> jsc </allcaps> - er611",0
resolve issues building users guide with ubuntu <number> / doxygen <date> <section> doxygen <code> <section> remove unnecessary documentation <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1
"directory polling does not clean up open directory file descriptors <section> cf_cfdp_playbackdir is called by cf_cfdp_processingpollingdirectories when the interval for the cf_poll_t structure has expired . this function will attempt to reopen the directory . if the polling directory does not continuously receive new files to process , then the os_directoryopen call happens without a corresponding os_directoryclose call , exhausting the amount of available file descriptors and causing this error . <code> <section> steps to reproduce the behavior : <number> . launch cf with a configured polling directory <number> . let ticker expire and attempt to reopen directory <number> . wait until fds are exhausted and error appears <section> i expect the directory file descriptor to be cleaned up before each os_directoryopen call . <section> configuration table used : <code> <section> - sc3m , microblaze - os : linux <number> - cfs <number> , cf commit bff67f87 <section> i added a check in cf_cfdp_playbackdir <url> that looks to see if the fd is <number> . if it is not , i close the directory and reopen it . this gets rid of the problem . <section> dennis afanasev , <allcaps> nasa </allcaps> goddard code <number>",0
"disable directory polling in default configuration table <section> the default configuration table cf_def_config . c enables channel <number> directory polling on / cf / poll_dir at app startup . unless that directory already exists on the target filesystem , cf will periodically emit the error event <number> message "" cf : failed to open playback directory / cf / poll_dir , error = - <number> "" . when testing and validating the cf app running defaults , it is not ideal to have unnecessary error events being periodically reported . <section> disable all directory polling in the default configuration table . because this feature requires foreknowledge of specific directories resident on the target filesystem , it should only be configured and enabled by end users . all channels should have polling disabled and no polling settings in the cf_polldir_t structure . <section> n / a <section> n / a <section> sergio maldonado , <allcaps> nasa gsfc </allcaps> , arctic slope technical services",2
"cf build failure on systems where int32 is "" long "" <section> on a system where the <code> type is defined as <code> ( rather than <code> ) , the cf unit tests fail to build with the following error : <code> <section> build on any system where <code> is not equivalent to <code> <section> should build successfully <section> <allcaps> rtems </allcaps> <section> this is using utassert_true - problem would not exist if the <code> were used as intended . <section> joseph hickey , vantage systems , inc .",0
"fix # <number> , removes cf_config_tlm_mid from cf_msgids . h <section> - fixes # <number> <section> searched all cf child directories for <code> and found no uses of the variable . <percent> unit test coverage . <section> remove unused <code> from cf_msgids . h . <section> - ubuntu <number> <section> none <section> if included , identify any third party code and provide text file of license <section> justin figueroa , <allcaps> asrc </allcaps> federal",2
"remove config tlm packet <allcaps> mid </allcaps> <section> the cf_config_tlm_mid constant is still defined in cf_msgids . h . the corresponding packet was removed in # <number> and is no longer used . <section> remove cf_config_tlm_mid from cf_msgids . h <section> n / a <section> n / a <section> sergio maldonado , <allcaps> nasa gsfc </allcaps> , arctic slope technical services",2
enums should not be used in tlm ( portability ) <section> the end of transaction tlm message <code> uses enums which we tend to avoid due to portability issues : <url> <section> replace with fixed size types <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> reported / requested by stakeholder .,2
"numerous bugs in cf chunk processing edge cases <section> as part of resolving # <number> , numerous bugs were discovered in cf_chunk . c both with adding to the list w / <code> and computing gaps with <code> . observed chunk add errors ( covers described with non - inclusive end ) : <number> ) adding a chunk that would completely replace chunks <number> and <number> ( a combinenext case ) . starting list { offset , size } : { <number> } , { <number> , <number> } , { <number> } , { <number> } , { <number> } so it covers <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> - <number> cf_chunklistadd with { <number> } so it should completely replace chunk <number> <sad> <number> } and <number> <sad> <number> } results in { <number> } , { <number> } , { <number> } , { <number> } ( note erroneous overlap of <number> and <number> ) , expected : { <number> } , { <number> } , { <number> } , { <number> } covering <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> ) adding a chunk that combines with chunk <number> , <number> , and <number> ( prev , next , next ) . starting list { offset , size } : { <number> } , { <number> , <number> } , { <number> } , { <number> } , { <number> } so it covers <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> - <number> cf_chunklistadd with { <number> } so it should combine with chunk <number> - <number> results in { <number> } , { <number> } , { <number> } , { <number> } ( note erroneous overlap of <number> and <number> ) , expected : { <number> } , { <number> } , { <number> } covering <number> - <number> <number> - <number> <number> - <number> <number> ) adding a chunk that is a subset of chunk <number> starting list { offset , size } : { <number> } , { <number> , <number> } , { <number> } , { <number> } , { <number> } so it covers <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> - <number> cf_chunklistadd with { <number> } so it should just drop since it ' s a subset of <number> results in { <number> , <number> } , { <number> } , { <number> } , { <number> } , { <number> } ( note numerous issues ) , expected no change observed chunk gap errors ( gaps and covers described with non - inclusive end ) : <number> ) misses a leading gap . starting list { offset , size } : { <number> } , { <number> } , { <number> } covers <number> - <number> <number> - <number> <number> - <number> so gaps <number> - <number> , <number> - <number> , <number> - <number> and anything after <number> cf_chunklist_computegaps with start <number> , total <number> results in { <number> } , so it missed the <number> - <number> gap <section> see scenarios above . <section> see scenarios above . <section> cf_chunks_eraserange has problems if start = = end and the memmove size is wrong : <url> cf_chunks_combineprevious should combine whenever the offset is less than previous range ( move ret = <number> out of inner if ) : <url> cf_chunks_combinenext is overly complex and broken . <repeated> ended up refactoring completely to get it to work : <url> cf_chunks_computegaps start logic is broken . <repeated> again just refactored to straighten it out : <url> <section> ci with # <number> incorporated <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0
"clarify cmd processing success event text for cases that just initialize action <section> playback , transfer , and cancel commands just initiate the action which is then handled by the engine . event text implies otherwise : <url> <url> <url> <section> update text to indicate the action was successfully initiated <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"use generic "" cf_msgids . h "" file that uses offsets from base <allcaps> mid </allcaps> <section> currently , the example <code> file supplied with cf ( under platform_inc ) is hardcoded , e . g . : <url> this presents some challenges for the user : - at a minimum the user needs to modify this file in place ( because the build script just points to this dir , there is no selection / override currently ) - it is not really possible to use different mids on multiple instances of cf running on a multi - <allcaps> cpu </allcaps> deployment . <section> use offsets from <code> and <code> like <allcaps> cfe </allcaps> framework does . for example : <url> thus the user only needs to specify the offset from the base ( aka the "" topic id "" ) in the mission_cfg . h file ( which has global scope , not processor scope ) and each <allcaps> cpu </allcaps> will automatically get non - overlapping <allcaps> mid </allcaps> numbers . <section> the alternative is to employ the <code> cmake function to allow the user to specify this file per arch , but <allcaps> imo </allcaps> the topicid / offset approach is simpler and more logical . <section> joseph hickey , vantage systems , inc .",2
"cf_unionargs_payload_t elements dword and hword not used , union not necessary <section> dword and hword are not used in the <code> union , only byte : <url> <section> remove unnecessary union <section> <code> is somewhat out of family in that it specifies unnecessary payload elements for some of the commands . the only common benefit seems to be byte <number> which is channel , supporting all channels generically with <number> . consider untangling all the layers of abstraction and go back to simple command processing . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"cf_delete_queue_node_cc not used , expected command length for cc <number> filled in <section> command code <code> not used : <url> cc <number> expected length is set but not used : <url> <section> remove unused elements , also clean up comments when done : <url> <section> none <section> add any other context about the feature request here . <section> full name and company / organization if applicable",2
"<code> refactor broke engine initialization , blank sem_name is not an error <section> semaphore name being blank is not an error condition , it should simply skip the semaphore get by name call . the recent refactor changed this behavior which causes the engine to crash . error introduced here : <url> old code : <url> <section> initialize engine without a semaphore name defined <section> still initialize the transactions if the semaphore name is blank <section> observed from <allcaps> ctf </allcaps> testing ( on linux i assume ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0
"follow temporary file + rename pattern for all files <section> currently , there is a special case to handle situations where the <allcaps> md pdu </allcaps> arrives out of order . a temporary file is opened , and then renamed once the md packet does arrive . however , because this is only done for off - nominal cases , it is likely not as well tested as other paths ( see bug # <number> ) . <section> this pattern of using a temp file should be standard operating procedure , not just something for special cases . reasons / advantages for always doing it this way described in my comment here : <url> this improves atomicity of file updates , prevents clobbering files and avoids cases where other apps might see partial files or other bad content . <section> n / a <section> as the fix for # <number> strictly only fixed the issue described , this is a more general enhancement that would improve cf . <section> joseph hickey , vantage systems , inc .",2
"possible silent truncations of entity id and transaction sequence number <section> the types for entity id and transaction sequence number are sort of configurable ( they are in the config . h but impact packet dfns ) : <url> <url> if they are set to anything smaller than uint64 allowed by the spec , then they could get truncated silently when decoding packet headers in cf_cfdp_decodeheader : <url> although the impacts do not seem all that critical . sequence will roll over locally ( should still locally match up ) , masking off high order eid bits and still getting a match / conflict for destination or source seems unlikely , although possible . <section> check that the encoded value will fit , otherwise send an event and drop the transaction . up to <number> extra checks per header decode . <section> make these all support the spec allowed <number> bit , no longer configurable . would impact memory footprint and cmd / tlm packets . leave as is seems like an option also . avoids the extra checks on every header that would be needed to avoid something that likely has minimal impact / likelihood . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",0
"cf parameter configuration file reference incorrect in doxygen documentation <section> doxygen references non - existent file cf_def_cfg . c <url> <section> update , file name is cf_def_config . c , and probably should clarify that this is a table and that there are get / set commands . <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1
"remove design and obsolete <allcaps> vdd </allcaps> from codebase ( these are release assets ) <section> design ppt and <allcaps> vdd </allcaps> doc are binary and challenging to manage within actual codebase with little benefit . updates to either should not impact codebase hash . <section> remove from codebase , provide as release assets <section> transition design material to markdown would support better text - based management , and possibly create a pdf from it to provide as the release asset ( and that <allcaps> pdf </allcaps> could still be updated without impacting codebase hash ) . or integrate the design material into the doxygen users - guide ( or both , since doxygen can reference markdown ) , which generates a pdf as a release asset . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1
"generate diagnostics / info packet on transaction closure <section> difficult to automate follow - on actions based on transaction completion ( history queue is not automation friendly ) or maintain a record of all transactions without dumping queues . <section> send a diagnostics / info packet whenever a transaction is closed for any reason including all the relevant info ( rx / tx , channel , file source / target , status , class , etc ) <section> event could be an alternative , but harder to base automation on <section> stakeholder request <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",2
"abandon and cancel commands with invalid transaction ids are silently dropped ( not rejected ) <section> cf requirements cf5006 . <number> and cf5007 . <number> state that , if the command - specified transaction is not in progress , cf shall reject the command . requirements cf5015 . <number> and cf5017 . <number> cover "" all "" transactions and state that , if there are no transactions in progress , cf shall reject the command . cf does not reject such a command by either issuing an event message or incrementing the command failure counter . cf does not take any action other than incrementing the command counter . <section> steps to reproduce the behavior : issue the abandon or cancel command with a transaction id that is invalid and / or not currently in progress . issue the abandon or cancel command with the "" all "" specifier when no transactions are currently in progress . <section> to be consistent with other transaction based commands , cf should provide operator feedback if it fails to find the active transaction id . at the minimum , it should issue an event message and increment the command failure counter . <section> ubuntu <number> linux <number> <section> sergio maldonado , <allcaps> nasa gsfc </allcaps> , arctic slope technical services",0
cf_processmsg ( ) function incorrect description <section> the cf_processmsg ( cfe_sb_buffer_t * msg ) description in the cf_app . h header file is incorrect . it is a duplicate of the cf_init ( void ) function . <section> n / a <section> n / a <section> n / a <section> n / a <section> n / a <section> n / a,1
"new <allcaps> rx pdu </allcaps> dropped due to max rx transactions reached on channel not counted <section> there ' s a strange comment about "" no known channel "" as justification for dropping a new <allcaps> rx pdu </allcaps> without incrementing the channel dropped receive counter , yet the channel number is known since it ' s received on the channel pipe and the local <allcaps> eid </allcaps> matches . <url> <section> i ' d expect the dropped counter to increment as a way to track this condition per channel . there is not a transaction set up or a cf_cfdp_dispatchrecv called , but all the cf_cfdp_recvdrop call does is increment the dropped counter anyways . <section> maybe the received "" dropped "" counter is only intended for rx transactions that have been started . <repeated> seems like useful information though . probably also useful to track with a counter if the event gets filtered . <section> i could not find a requirement so likely derived . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"noncompliance with the concept of informative variable names <section> a style thing , but pretty obscure one character names all over . good practice to use useful names that a new reader can easily pick up on and / or easier to maintain . example use of c , q , p , and t all in one line : <url> <section> c - > chan t - > txn q - > queue_idx / q_index or whatever . p - > priority ( or whatever it is ) and so on . <section> may just be another one for the lesson ' s learned bucket . not sure how this got through code review . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"local <hashtag> defines </hashtag> in cf_cmd . c used as special values in command processing ( w / repeat dfn in tests ) <section> <code> , <code> , <code> used in command processing should not be defined in a * . c where it ' s inaccessible and somewhat hidden . the names are not great either , better to prefix w / app . <url> <section> move into cfe_msg . h and rename as <code> and similar , which would allow removal from cf_test_utils . h : <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"event id name does not match use <section> <code> is used for reporting invalid <allcaps> mid </allcaps> received , note <code> and <code> are used for actual ground command processing : <url> <section> event id names should make sense , maybe <code> or similar . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"registering <number> + event filters w / 0x0 0 0 0 values serves no purpose ( and overflows a typical filter buffer ) <section> registering event filters just to register event filters does not do anything but load the system . if an event needs to be filtered operationally , just use the add filter command . note default <code> is <number> , so the rest would get discarded and cause a filter buffer overflow event . <section> remove filter registration for those set to 0x0 0 0 0 ( all of them ! ) add operationally if / when needed , or if eventually an actual filter needs to be applied then add it . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"remove config tlm packet and associated command <section> all the configuration information is in the table ( and maintained there ) , the config packet is redundant and actually is missing all the channel data so it ' s not all that useful anyways . <url> <section> remove this functionality along with requirement cf5004 <section> none <section> as part of making more configuration channel based , this redundancy was noted . not worth the effort to maintain a tlm packet that ' s basically a repeat of the table . - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"fix # <number> , fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> adds link to new clas in pull_request_template and contributing . md <section> - fixes # <number> - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1
"update <allcaps> cla </allcaps> information <section> have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [x ] update the instructions in each app ' s contributing . md - [x ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1
"typo in <allcaps> readme </allcaps> . md <section> first section header lacks space between <code> and <code> <section> observe that "" <hashtag> core </hashtag> flight system ( cfs ) <allcaps> cfdp </allcaps> application ( cf ) "" is literal and does not look like a section header <section> "" core flight system ( cfs ) <allcaps> cfdp </allcaps> application ( cf ) "" looks like a section header <section> <url> <section> n / a <section> n / a <section> john n pham , northrop grumman",1
updating ut to work with cmake build system i am looking for a methodology or guide to build and run or convert unit tests which are based on gcov for apps which have not been updated such as : * <url> * <url> etc . the only app updated is : * <url> i have viewed the diffs between 2 a292d041a <phone> cc10344abbf0c4ecccc2 and 7 a48a8b2e8f4f5b103748685f076d9dc8b3b66fb but it is still not clear why things were shifted around . can anyone clarify,3
"<allcaps> cfdp </allcaps> backwards compatibility <section> i have a system that is running <allcaps> cfdp </allcaps> version <number> and want to interface it with a system that is running the older version of <allcaps> cfdp </allcaps> <number> . are the two versions compatible for file transfers ? <section> i would like to know if <allcaps> cfdp </allcaps> version <number> and <number> are compatible for file transfers . <section> i have looked at the documentation for <allcaps> cfdp </allcaps> available on the github page and have not seen anything suggesting they are compatible / incompatible with each other . <section> i know certain things have changed across the two versions , such as the hk telemetry messages having a different format . <section> jeff anderson",3
resolve static analysis warnings in unit tests <section> various static analysis warnings observed in unit tests ( license restricts publishing ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2
resolve static analysis warnings in fsw <section> various static analysis warnings observed ( license restricts publishing ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0
"add documentation build / deploy workflow <section> build / deploy documentation not in workflow <section> add workflow to build and deploy documentation , see nasa / cfs # <number> <section> none <section> nasa / cfs # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1
"replace codec code - compatibility macros with direct calls to the new functions <section> these were used to help transition the code from old endian dependent macros , but they obscure the fact values are being modified by taking address of the input . they also cause static analysis warnings on occasion as identified in # <number> . example : <url> <section> convert the code to use the functions directly , remove offending macros . <section> none <section> - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"replace use of <code> , coding standard violation <section> <code> violates power of ten and <allcaps> jpl </allcaps> coding standards , typically avoided in cfs code . <section> refactor <section> none <section> static analysis warning that showed up in # <number> but wasn ' t resolved as part of that issue fix <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"dynamically choose <allcaps> tlm </allcaps> or <allcaps> cmd </allcaps> message type for <allcaps> pdu </allcaps> <section> currently , the cf application uses the software bus for <allcaps> pdu </allcaps> transfer . ( this is an issue in itself , see # <number> ) . however , in the meantime , when using sb it must make the <allcaps> pdu </allcaps> messages look like the <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> messages that sb typically deals with . cf currently assumes / requires that all ingress / rx direction pdus will have a <allcaps> cmd </allcaps> header , and all egress / tx direction pdus will have a <allcaps> tlm </allcaps> header . this assumption is a barrier to configuration of having two instances of cf potentially send files to each other - in such a configuration , there must be an intermediate entity to forward the "" <allcaps> tlm </allcaps> "" - style egress <allcaps> pdu </allcaps> messages and convert them to "" <allcaps> cmd </allcaps> "" - style ingress <allcaps> pdu </allcaps> messages on the other node , in both directions . <section> to potentially make this configuration a bit easier , cf could dynamically choose which type of message header to use based on the configured msgid values . that is , if the user has configured cf to output on a msgid which ( per the <allcaps> msg </allcaps> module ) is identified as a <allcaps> cmd </allcaps> type , it should use a <allcaps> cmd </allcaps> header when assembling those egress pdus . likewise , if the user has configured cf to input on a msgid which is identified as a <allcaps> tlm </allcaps> type , then cf should strip a <allcaps> tlm </allcaps> header from that message . <section> currently if cf - cf transfer is required , an intermediate transfer agent must fulfill this role to forward the <allcaps> pdu </allcaps> to the other entity and also convert to the other type ( <allcaps> tlm </allcaps> - > <allcaps> cmd </allcaps> ) for ingest by cf . <section> while this would address one pain point of this type of configuration , it still leaves two major ones : - sb pipes have inherent buffering limits - sb pipes cannot provide backpressure to sender ( they just hit msglim and drop ) as a result the backpressure still needs to be implemented separately ( via a sync sem ) to avoid overflowing pipes . i ' d still rather fix # <number> to address all the issues inherent with using sb as a bulk data transfer mechanism - it is not designed to be that . <section> joseph hickey , vantage systems , inc .",2
"<code> in platform_inc directory <section> <code> in platform_inc directory instead of with source , causing tables to use the non - overridden cf_platform_cfg . h file instead of the one in * _defs at the top level , since the compiler prefers includes relative to the current file over include paths specified on the command line . this is also different than most other apps which define their table structs in fsw / src . workaround would be to also override cf_tbldefs . h , but the table struct is not really something that one needs to customize in the first place . <section> steps to reproduce the behavior : alter cf_num_channels in platform_cfg by copying to [ mission ] _defs / , modifying and using generate_config_includefile to override . <section> cf config table uses the updated cf_platform_cfg . h instead of the original one . <section> if applicable , add references to the software . <section> - sp0 - s - os : vxworks <number> <section> using snippets from <allcaps> jsc </allcaps> ' s modified arch_custom . cmake to override platform_cfg : <code> <section> john n pham , northrop grumman",0
"apply latest contributor license agreement links <section> applies links to the latest contributor license agreements . <section> working links <section> depends on <url> <section> justin figueroa , <allcaps> asrc </allcaps> federal",1
"resolve additional internal static analysis warnings in fsw <section> <number> "" red "" errors reported by internal static analysis ( license restricts publishing results ) <section> resolve the warnings ( uninit variable * <number> and one non - distinct identifier ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0
report mission rev in startup and noop event string <section> <code> every other app reports major . minor . rev . mission_rev ( mission_rev missing above ) <section> add mission rev to version reporting both for startup and noop . may actually need to add <code> define ( not found during quick inspection ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2
resolve cppcheck issues ( and confirm they are getting flagged correctly ) <section> style warnings when running strict cppcheck : <code> <section> confirm these are getting flagged in ci . <section> none <section> - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2
"potential acceptance of commands with invalid <allcaps> cfdp </allcaps> class <section> the check for <allcaps> cfdp </allcaps> class could let a "" class <number> "" or negative class message through the code that checks if the class is valid looks like <code> if <code> is zero or negative this check might pass and let through an invalid command . <section> n / a , have not tested yet . <section> only accept class - <number> or class - <number> . all other values should be rejected . <section> <url> <url> <section> code - only check <section> n / a <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps>",0
"apply clang - format - <number> formatting <section> was formatted w / clang - format - <number> , rest of the repos ( and ci ) still use clang - format - <number> <section> apply clang - format - <number> so ci will pass . <section> none , we can bulk update to <number> in the future . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"fix # <number> , doxygen frontpage refactor and cleanup <section> - fix # <number> <section> documentation change only , but still built and ran unit tests <section> none <section> - hardware : i5 / wsl - os : ubuntu <number> - versions : bundle main + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1
clean up old license headers <section> old headers still exist in the codebase . <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1
"add event , command code , command structure , and telemetry structure documentation <section> missing user ' s guide documentation . also some inlines in cf_utils . h missing documentation . <section> add descriptions . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1
"implement doxygen front page concept , clean up documentation , resolve doxygen warnings <section> - apply frontpage concept / documentation framework ( mainpage can not be included in larger document ) - clean up / clarify sections and apply suggested patterns - resolve warnings from building doxygen documentation <section> see above . <section> none <section> - nasa / cfe # <number> - nasa / cfe # <number> - nasa / osal # <number> - nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1
add apache <number> <allcaps> license </allcaps> file and update copyright headers <section> missing license file and out of date copyright info in file headers <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1
fix common_types . h include <section> not following standard : <url> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2
use <code> instead of <code> <section> <code> has been abstracted by <code> to avoid internal dependencies on cfe_msg_message_t <code> <section> use <code> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2
add fixed size <allcaps> ccsds </allcaps> packet option <section> some systems can not handle variable sized telemetry packets . <section> add an option to zero - fill the related <allcaps> ccsds </allcaps> packets . <section> none . <section> none <section> jacob hageman,2
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2
"cf table updates - default to cf app name to match <allcaps> gsfc </allcaps> apps , disable polling by default * x] i reviewed the [ contributing guide <url> . * x] i reviewed the [ <allcaps> cf readme </allcaps> . md file <url> to see if the feature is in the major future work . * [ x] i performed a cursory search to see if the feature request is relevant , not redundant , nor in conflict with other tickets . <section> current table name follows lab app pattern w / * _app , but <allcaps> gsfc </allcaps> apps do not have the _app . polling directory enabled by default means the warnings / errors about no polling directory existing will show up unless created by the user . prefer default behavior to not see these . <section> change cf_app to cf in table , set polling to disabled <section> users can override , so not a big deal but nice to stay consistent with apps . if we want to add * _app everywhere probably makes more sense as a bulk update . note may run into name length issues on other apps by using up the extra <number> chars . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2
"possible race condition with creation of throttle sem ( needs to exist before cf initializes ) <section> <allcaps> cfe es </allcaps> starts all applications in their own thread . therefore , conceptually at least , all apps are starting at the same time . if configured to use a throttle sem , the cf app expects that semaphore to be created _before_ it starts . during startup , it will attempt to bind to that semaphore during cf_cfdp_initengine ( ) , and if that fails , cf aborts ( see # <number> ) . problem is , if the semaphore is created by another app , whether it be ci / to or some other dedicated i / o app , there is no guarantee that the semaphore has been created before cf attempts to use it . secondary problem exists if the i / o app that owns the sem gets restarted or reloaded , the semaphore id will likely change too . this may be recoverable by disabling the engine and re - enabling it ( but have not tested that ) . <section> its a race condition , so not readily reproducible . start cf _before_ the app that creates the sem ( still not guaranteed , but increases the chance the race will be lost ) add an artificial delay during startup for the app that creates the sem ( just further increases the chance the race will be lost ) <section> should be guaranteed via sync mechanisms , or should not be a hard error ( e . g . maybe retry to bind later ? ) suggestion that cf might still start up but with the engine in a disabled state , so at least someone can correct the condition and enable the engine , rather than having cf abort / exit . adding a call to cfe_es_waitforstartupsync ( ) before starting the engine might help too . <repeated> <section> <url> <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0
"change default configuration to not use throttling semaphore <section> the default / example table source files include a semaphore name - cf_1_sem and cf_2_sem - for throttling on channel <number> and <number> , respectively . however , cf does not actually create the throttling semaphores , it expects the semaphore to be created before cf starts . if a new user is starting cf by itself with no other support apps running , this semaphore will not exist . <section> to make it simpler to build and run cf with a default configuration , the example table should have an empty string for the semaphore name - this means no throttle . <section> this will make cf at least boot up and load "" out of the box "" . <repeated> but probably any real deployment will need a throttle , so this means that we do not have an example of a throttling semaphore anymore . <section> joseph hickey , vantage systems , inc .",2
"write queue data does not truncate existing files <section> discovered when testing cf_write_queue_cc command . my test issued the command more than once , with the same target file name , but different type / queue parameters , to get the different content . noted that in cases where the second output was shorter than the first output , the old output remained in the file ( stale data ) at the end . this is because the call to os_fileopen ( ) does not use the os_file_flag_truncate flag , so the old data remains in the file , until it is actually overwritten . <section> run cf , run some transactions to get some history , then run cf_write_queue_cc with all types / all queues . then run cf_write_queue_cc again with the same output file , but a more specific type / queue parameter , so the output is smaller . observe that the old data from the first call is still at the end of the file , after the new entries - it was not truncated . <section> in general any time a write file request is done , it should truncate the file , unless the requirement is specifically to preserve old data ( i . e . append ) . this is not an append , so it should truncate , and write the file from a clean slate . <section> problematic call to os_opencreate is here ( via wrapper ) : <url> however there may be other occurrences . all calls to this function should be checked . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0
"cf no longer processes nak pdu packets <section> a recent cf change removed the decoding of received <allcaps> nak </allcaps> pdus . in cf_cfdp_s . c , function cf_cfdp_s2_nak , there should be a call to cf_cfdp_recvnak which decodes the <allcaps> pdu </allcaps> prior to processing . otherwise , the packet is not decoded , the <allcaps> pdu </allcaps> is rejected as invalid , and the event report with "" received invalid nak pdu "" is issued . <section> execute cf tests in linux that exercise receipt of <allcaps> nak </allcaps> pdus . <section> tests should pass and <allcaps> nak </allcaps> pdus should be accepted . <section> linux x86_64",0
"improve ut coverage on cf_cmdgetsetparam ( ) <section> the unit test does not individually validate all of the values that "" param_id "" may have . this did not show up in the <allcaps> lcov </allcaps> reports previously . however a recent pr changed the table lookup to a <code> block , the <allcaps> lcov </allcaps> branch coverage now shows these param_id values as untested cases in the switch . <section> should add test cases to get back to <percent> line and branch coverage . <section> note this was always the case , but it just did not show up in the <allcaps> lcov </allcaps> because of the code structure . now it does . <section> joseph hickey , vantage systems , inc .",2
"test_cf_chunks_init_setgiven_chunks_max_chunks_togiven_max_chunks creates object too large , crashes <allcaps> rtems </allcaps> <section> the "" test_cf_chunks_init_setgiven_chunks_max_chunks_togiven_max_chunks "" test fails on <allcaps> rtems </allcaps> and crashes the kernel , because it creates an absurdly large structure on the stack and then memset ( ) ' s it to <number> . this appears to blow out the stack and probably overwrites some important structures . <section> execute cf tests on <allcaps> rtems </allcaps> <section> tests should pass <section> <url> <section> <allcaps> rtems </allcaps> <number> . <number> via <allcaps> qemu </allcaps> / pc686 <section> once again , appears to be related to use of random numbers . <repeated> when using a random number to indicate the size of an object , nothing good comes from that ( see # <number> ) <section> joseph hickey , vantage systems , inc .",0
"cf_cfdp_disableengine no longer disables the engine <section> the line which actually disables the engine got mistakenly deleted in a recent pr . ( got swept up because it was grouped with the variable declarations with no whitespace between ) . <section> issue disable engine command , it does not actually disable <section> should disable the engine <section> <url> <section> n / a <section> sergio maldonado ( <user> )",0
"implementation of cf_cmdcond takes address of inline function <section> while the compiler does not complain about this , it totally defeats the purpose of making these "" inline "" functions to begin with , as by definition they will need to be compiled out - of - line in order to be able to call them via a function pointer . <section> this complexity of using a function pointer is not necessary and counterproductive . make it simple and boring : <code> not fancy , but pretty clear what the above is doing . what ' s there now just obfuscates . note that the "" cond "" is not a boolean , its the return value of a command function that returns <number> on success . so the logic is inverted . <section> existing function <url> <section> joseph hickey , vantage systems , inc .",2
"a uint16 is used for defining the input / output apids in the config table , does not support full sized message ids cf defines apid inputs / outputs as uint16 ' s , then uses these with the cfe_msg_init <allcaps> api </allcaps> which expects message id ' s of type <code> . <url>",0
"mixture of different return types , and many use "" int "" cf has a variety of different return types from its internal functions , and many are just <code> , and return <number> on success , or - <number> on failure : <url> but some , for example the "" send "" routines , have a dedicated enum : <url> these can be tricky because it is still fundamentally an <code> ( enum ) but while the success is still a value of "" <number> "" , the error codes are in positive values , not negative like the others . sometimes the return type is <code> but it indicates a size : <url> and in other cases the return type is <code> but it indicates a boolean value , where <number> is false and <number> is true : <url> this latter case is also easy to confuse with the first case , where <number> is success on many functions but a logical "" false "" here . <section> : cf should have a return code paradigm that is more consistent with <allcaps> cfe </allcaps> and other apps . - if the return value is a boolean true / false then use <code> - if the return value is a size , then use <code> - general helper functions should return a type based on <code> ( may be a typedef like <code> ) and have a set of predefined constants for use as return values , and use them consistently throughout the code .",2
remove use of message storage in cf_appdata global should this be a follow - on cleanup issue ( if it is not already ) ? _originally posted by <user> in <url> related to <url> might depend on # <number>,2
"cf updates its destination file "" in - place "" the cf application , when receiving files , will open the destination file as indicated in the metadata <allcaps> pdu </allcaps> and immediately start writing data to it , thereby overwriting any data that was previously in the file at that position . this can be dangerous , because the file transfer may not ultimately succeed . for instance , <allcaps> crc </allcaps> errors may occur , or part of the transfer might get lost . but once data has been clobbered , there is no way to "" undo "" and restore the original data - - its gone . so now the user has a situation where neither the new file nor the original file are valid - the file is just corrupt now . it is often desirable to write data to a temporary file first , let the transfer run to completion ( storing <allcaps> all </allcaps> data in the temporary file ) , and then rename the file to its final / correct filename only after the final <allcaps> crc </allcaps> and size checks have passed and the data is known to be good ( or at least to the extent that cf can verify it ) . in fact , this is the _only_ way to safely update application binary object ( . so files ) on many targets , since the text / rodata memory pages may be mmap ' ed directly to the file on disk . if these are updated in place , and the file is an actively - running application , then the running code will immediately "" see "" the modifications , and likely crash / segfault depending on what it was doing at the time . recommendation here is to <allcaps> always </allcaps> use a temporary file to store incoming data , never overwrite existing files until final validations have occurred . this will also avoid some of the special logic that only handled corner cases ( see issue # <number> ) by making that more the norm than the exception .",2
"likely issues in processing of deferred / reordered "" md "" packets there appears to be logic within cf to support a case where the metadata <allcaps> pdu </allcaps> arrives late - that is , after file data has already started . basically , the logic is as follows : - if the receiver gets <allcaps> pdu </allcaps> type is file data ( not metadata ) in the idle state ( which is for a new / unknown transaction ) , it assumes the initial metadata <allcaps> pdu </allcaps> may have been lost , and it jumps directly to the file data state . - the <allcaps> pdu </allcaps> is then re - dispatched in the context of a class <number> file data state - the cf_cfdp_r_init ( ) function , will see that this is initializing a transaction for which no metadata is known , and it will : - generate a <allcaps> nak </allcaps> for the md ( looks like this is an attempt to get the sender to regenerate it ) - populates the transaction with a generated temporary file name for the destination - if the <allcaps> md pdu </allcaps> subsequently arrives , it then kicks off the following sequence : - temporary file is closed - <code> from temporary file to file name in metadata <allcaps> pdu </allcaps> - re - open the file under its new name the problem that is immediately visible here is that this close + reopen will reset the file position , but does not reset the cached position within the state object ( <code> ) that is used during writes to determine if an "" lseek "" is necessary . so now the file pointer is back to the beginning , but the <code> likely reflects the end of the file , and as a result new data will clobber existing content . but the bigger issue is that this code is essentially duplicate / specialized logic that only handles a corner case / exception so it is unlikely to be adequately tested .",0
"cf should not require / hard - code use of the software bus for <allcaps> pdu </allcaps> transport the cf application creates a stream of data pdus during operation , which are intended to be ( somehow ) transported to the remote node . it is a point - to - point data flow . currently , cf assumes that the software bus will be used for this purpose . although this is the existing / de - facto data transport mechanism provided by the framework , it is not an ideal fit at all . ( analogy of "" when all you have is a hammer , everything looks like a nail "" applies here ) . - software bus is broadcast ( <number> : n ) where cf data flows are <number> : <number> in nature - software bus has relatively small buffers , and is designed for minimizing latency and memory efficiency , not designed for bulk throughput - software bus does not provide any sort of back - pressure capability ( e . g . if a sender like cf is sending pdus faster than the receiver can process them ) . also note that it is not really practical for it to do so either , given it is a multicast design ( <number> : n ) - in a multicast , one would not stop sending just because one subscriber is not able to keep up . - similarly , by forwarding / bridging data pdus from the os network buffers to software bus buffers , it effectively defeats any backpressure capabilities of the underlying network protocol . for example , if a <allcaps> tcp </allcaps> connection were used for node - to - node transport over the physical network , this protocol will effectively throttle the sender to the rate that the receiver actually accepts the data through the use of ack ' s and sliding windows . this is determined on the receive side by how deep the buffer is , inside the network stack . by bridging the data to sb it essentially keeps this empty , and this gives a green - light for the sender to keep blasting data in . this makes it difficult , if not impossible , to tune the system for good throughput - it means the sender must be artificially held off without any real feedback . - software bus is designed for commands and telemetry data , and all messages are assumed to be either a command or telemetry message . therefore , cf must add a fake telemetry header on the pdus it generates , and other entities must add a fake command header on the pdus it generates , in order to maintain this pattern ( or else it will break software bus apis ) . this extra header is just unnecessary baggage , because sb is not designed for bulk data ( i . e . this is where it is really contorting the problem domain to look more like a nail so the sb hammer will be able work with it ) . while there may be valid reasons to use the software bus as a backhaul , it is certainly less than ideal and should not be the only ( hard - coded , forced ) option . there should be mode to use an i / o layer and go direct to network , which will solve many of the throughput and performance tuning issues , as well as just being a far cleaner design . if anything using sb for bulk data backhaul should be the undesirable fallback option ( if nothing else better exists ) rather than the primary / only option .",2
"support for segment metadata on file data <allcaps> pdu </allcaps> according to <allcaps> ccsds </allcaps> <number> - b - <number> , table <number> - <number> , a file data <allcaps> pdu </allcaps> may have segment metadata included . this is indicated by a flag being set in the main <allcaps> pdu </allcaps> header , which means the data <allcaps> pdu </allcaps> has two extra fields as well as the specified number of segment metadata information blocks . currently cf does not even check for this bit or the presence of these fields . while it may not be required to support it , on the receive side cf should be required to check for and actively discard / reject packets for which these bits are set ( and therefore it does not understand ) . instead , as it stands right now , it will read the extra fields as part of the offset , and generally corrupt the entire file , if this flag is set by a sender . hopefully the <allcaps> crc </allcaps> check would detect the corruption , but it should not do that to begin with . current code that receives the file data header only reads a single offset field , there is no provision to check for and handle the extra fields here , just the offset : <url>",0
"command valid and rejected counters do not increment correctly for certain invalid commands cf will increment the valid counter . for certain valid commands cf will increment the invalid counter . the cf_tsnchanaction function does not appear to correctly interpret the return status from certain sub - functions that return the count of matched transactions . it assumes a non - zero return value is failure , but actually it is the count of transaction matches . this can be seen with the following command opcodes : <allcaps> abandon </allcaps> , <allcaps> cancel </allcaps> , <allcaps> suspend </allcaps> , <allcaps> resume </allcaps>",0
"<allcaps> tx file </allcaps> command does not validate channel parameter the <allcaps> tx file </allcaps> command does not validate the channel parameter value prior to execution . when specifying a channel value other than <number> or <number> , the system crashes .",0
"<allcaps> cfdp </allcaps> protocol timer configuration is not per channel ( cf5002 and cf4000 . <number> failure ) per requirement cf5002 , protocol timer configuration should be per channel . currently the values are applied to all channels .",0
"not all invalid commands send an error event message per requirement cf1004 , all invalid commands should issue an error event message . for example , the tx_file command does not send the event message when certain parameters in the command are invalid . there are several other commands that need to be dispositioned for compliance .",0
"not all validated commands send an info event message per requirement cf1003 , validated commands should issue an info event message . this is not the case for most of the cf commands . the command counter increments but no event message is sent . this applies to the following command codes but there could be more : <allcaps> abandon </allcaps> , <allcaps> cancel </allcaps> , <allcaps> enable </allcaps> / <allcaps> disable dequeue </allcaps> , <allcaps> enable </allcaps> / <allcaps> disable engine </allcaps> , <allcaps> enable </allcaps> / <allcaps> disable polldir </allcaps> , <allcaps> freeze </allcaps> , <allcaps> thaw </allcaps> , <allcaps> suspend </allcaps> , <allcaps> resume </allcaps> , <allcaps> purge </allcaps> , <allcaps> write queue </allcaps>",0
"decode procedures read header fields without checking length cf uses many variable - length fields in its header structure . this requires aggressive buffer bounds checking at each point during decode , since a bad value ( such as a bad "" length "" on an lv parameter ) can throw off the decoder which may end up reading past the end of data and into undefined behavior territory . cf really only sanity checks the length at a couple points here in the initial header receive : headers alone : <url> full <allcaps> pdu </allcaps> length field : <url> however , note that even for the first check above ( line <number> ) the code has already invoked cf_headersize here : <url> notably , the <code> function reads data from the packet header to compute header size . therefore this has already read some packet data before the length is even initially sanity checked . if the input data was very short ( such as from a <allcaps> mid </allcaps> misconfiguration ) this would potentially segfault by immediately reading beyond the buffer . furthermore , every packet type that utilizes an lv or <allcaps> tlv </allcaps> style sub - fields ( e . g . <allcaps> eof </allcaps> , <allcaps> fin </allcaps> , md ) needs to re - check the bounds at each of these entries . for example in recvmd it only confirms that the size is sufficient for fixed - size fields here : <url> but later on when copying the lv data at these places , there is no check : <url> <url> these functions only check that the length is less than <code> . <repeated> it does not check if the length has gone beyond the end of the input buffer . __recommendation__ : each and every step of encode + decode should confirm that the process is not reading or writing past the end of the buffer . particularly for variable length fields .",0
"variables declared mid - function according to many coding standards ( <allcaps> gsfc fsw </allcaps> included , <allcaps> afaik </allcaps> ) , variables should not be declared only at the top of functions , not in the middle . however , cf has many cases of this . any variables declared mid - function should be moved to the top of the function to correct this .",2
"identify cases where value is computed and only used in assert call in pr # <number> , rather than completely removing assertions in the code , this including a no - op function such that the condition is still evaluated , but not acted upon . this was done because there are a few instances where a value was computed and used only for the assert , and no other reason . if the assert is removed , then the value becomes unused and is flagged as such ( i . e . compiler warning ) . the fix in # <number> was only an interim in order to get the code to compile and run . the preferred fix would be to identify cases where a value is computed and only used in an assert , and remove them . this is likely just a matter of removing the no - op function and fixing the warnings that come up .",2
"support for alternate checksum type indicated in metadata <allcaps> pdu </allcaps> per the <allcaps> ccsds </allcaps> blue book <number> - b - <number> , section <number> . <number> - the metadata <allcaps> pdu </allcaps> has a <number> - bit "" checksum type "" field . the description says : > checksum algorithm identifier as registered in the <allcaps> sana </allcaps> checksum types registry . > value zero indicates use of the legacy modular checksum . it looks like cf only supports the legacy checksum , because it does not check this field at all , and there appears to be only one algorithm implemented . however , this is not as significant as the large file size issue (# <number> ) because it does not otherwise change the format , here the result will be a simple failure of the validation check if there is a mismatch between peers . this is an interoperability concern . if the intent is to only support legacy checksum , this should probably be documented in the release notes / version description document . if the intent is for full compliance with <allcaps> ccsds </allcaps> book <number> - b - <number> , then this is missing . interim recommendation for <allcaps> fsw </allcaps> is to at least check this field on receipt of a metadata <allcaps> pdu </allcaps> , and reject if the checksum type field is set to anything other than ' <number> ' .",2
"instantiating globals in header files ( <allcaps> fsw </allcaps> version ) the <allcaps> fsw </allcaps> has a macro called "" declare_field "" which creates a constant at global scope : <url> the constant is scoped as "" static "" so it does not create a linker error , but it still creates a _separate_ instance of this global variable for each time the header is included . confirmed by checking <code> and observing that _each_ of these <number> fields occur in the binary file <number> times : <url>",0
add format check and static - analysis workflows add format check workflow to continuous integration to ensure new commits meet style guide see <url>,2
"should not use "" hk "" packet data elements as active / runtime control values the <code> values should be used strictly for reporting housekeeping status of cf out to external entities . however , cf uses some values within this structure for some active control purposes as well . for example , the <code> member is used for checking whether the soft limit is reached yet : <url> note that these hk structures are currently marked as "" packed "" ( see # <number> ) so reading / writing from these structs is more costly than normal structures . furthermore , tracking depth using a single integer can be somewhat error prone ( it is possible to "" miss "" an increment / decrement , and it will never self - correct ) .",2
"use of globals to store ephemeral / in - transit data cf stores its current working pointers in a global variable called <code> : in particular : <code> has a pointer to the buffer last received from sb <code> has the size of that buffer ( and is actually updated during the course of processing ) <code> and <code> have the data extracted from the header of the most recent message . and so forth . <repeated> importantly : __none of these values are supposed to be carried across wakeups__ . all values are reset in their entirety on every wakeup , and in fact with each channel . all data is ephemeral and is only valid while the <allcaps> cfdp </allcaps> app is actively processing that packet . as soon as processing of the current packet completes , the data is no longer valid . when the wakeup cycle completes , only the <code> is actively cleared . all other fields will be left with whatever data was in them . also notable - there is a mixture of <allcaps> api </allcaps> calls where sometimes the pointer to the packet data is passed in directly , as it is here via the <code> argument : <url> the call to <code> also needs the packet data , but it does not pass it along . instead , this function grabs it from the global ( theoretically the same packet ) : <url> this inconsistency should be addressed . if the intent is to _always_ store the current packet in a global , then code needing to access it should _always_ retrieve it from the global . there should not be some apis which pass a pointer to the structure , mixed with others that get it directly from the global ( where they are supposed to be acting on the same data ) , as this creates the opportunity that they could diverge . for ephemeral data , it is fine to pre - allocate a buffer in a global to avoid dynamic allocation , but the pointer to this data should be passed consistently down through the <allcaps> api </allcaps> where needed . this design allows for safer evolution , permitting the use of multiple buffers or even multiple threads should that become a requirement ( e . g . create a child task per <allcaps> cfdp </allcaps> channel to make them more independent ) .",2
"inconsistent parameter passing ( chan_num vs . channel pointer ) there does not seem to be any consistency in cf as to whether identifiers passed to functions are done in the form of a number ( such as a channel number ) where the function then gets the channel pointer internally by doing a table lookup , or by passing a pointer to the structure . the cf contains both forms , and sometimes passes a pointer when the implementation really needed the number . example : <url> in this case the cf_receivemessage was ( for some reason ) declared as accepting a pointer to the channel structure , but it really needs the channel number , so it does a bit of pointer arithmetic <code> to get the number . this type of pointer manipulation can be error prone , particularly if the code evolves in such a way where the <code> pointer might not be pointing to an entry in the table , this might produce an out - of - range channel number . this can also happen during unit test where its common to pass in test values - - even if <allcaps> fsw </allcaps> never expects a value not within the table , its still possible to happen . recommendation : if channel numbers are generally always needed , pass only the channel number around . it is safer because it can be more easily range - checked if necessary . alternative : store the channel number inside the channel structure , so the <allcaps> fsw </allcaps> can more simply look it up and does not need to recompute it ( avoids assumption that the pointer is pointing to a chan table entry ) . this can avoid repetitiously looking up a chan_num to get the pointer , allowing direct pointers to be passed around . but does cost a little memory and introduces the risk that something ( e . g . a bug somewhere else ) can overwrite or change the chan_num and make it wrong .",2
"target name inconsistencies - "" cf "" vs . "" cf_app "" the name patterns used by other <allcaps> cfs </allcaps> applications do not have an "" app "" suffix . the "" sample_app "" is the only exception here , it only has this suffix to differentiate from the "" sample_lib "" . the build scripts do rely on some naming conventions - in particular the name of the directory should match the name of the main application target . since this repository is called "" cf "" ( not cf_app ) and is cloned into a directory called "" cf "" , the target name should also be "" cf "" . on the other hand , if the target is named "" cf_app "" this may problems with things like table builds and app installation , because the names in scripts will not match . recommendation is to change the cmake files to build this as a target named only <code> and drop any <code> suffix .",0
"incorrect check of status from cfe_sb_receivebuffer ( ) checking of the status return from this <allcaps> cfe api </allcaps> call is not correct / sufficient : <url> this function may fail for a number of reasons , not limited to <code> . the preferred check should be : if ( status ! = cfe_success )",0
"size is insufficient in call to cfe_sb_allocatemessagebuffer ( ) the invocation of cfe_sb_allocatemessagebuffer ( ) here only allocates for <allcaps> cf pdu </allcaps> maximum size : <url> the returned buffer is only guaranteed to be large enough for a <allcaps> cfdp pdu </allcaps> itself , not the extra sb headers / encapsulation . this needs to be a little larger to account the <allcaps> cfe sb </allcaps> headers . preferred call should be something more like : cf_appdata . engine . out . msg = cfe_sb_allocatemessagebuffer ( offsetof ( pdu_s_msg_t , ph ) + cf_max_pdu_size ) ;",0
"recieved software bus buffers must be treated as "" const "" the software bus is a broadcast mechanism and sends the same memory buffers to all subscribed applications / pipes . the intent is that the data buffer should be <code> but for backward compatibility reasons the <allcaps> api </allcaps> does not enforce this . however , cf actively writes to and modifies its received buffers , basically treating it as its own temporary storage location . if this is combined in a system with another app that subscribes to cf traffic ( e . g . data store , <allcaps> dtn </allcaps> , or some other traffic monitor ) then all other apps will see the same modifications to the data buffer , and this effectively creates a race condition / unpredictable behavior . all received software bus buffers should be qualified as <code> in application code , and they should not be written to . apps should create their own buffers for temporary storage .",0
"cf should not use bitfields use of bitfields is discouraged by many coding standards ( including <allcaps> gsfc </allcaps> ) because the c standard does not specifically dictate how they are packed into the underlying integer type . cf uses them in several internal structures , for example : <url> if these truly need to be bit fields , then they should be implemented explicitly using shifts and masks . however , initial inspection of the code would suggest they do not need to be bit fields , they can be made into separate fields . while this may increase the memory footprint somewhat ( struct is likely to be <number> bytes in the example instead of <number> ) this is probably a reasonable trade , because separate fields can be simply read / written directly rather than requiring a read - modify - write etc . note that when using bit fields , the assembly instructions to do shifts and masks will still be generated by compiler , even though the c syntax "" looks "" simple - it is hiding it all . so it may be considerably less efficient than accessing separate memory locations . this of course depends on hardware architecture , caching , optimization by the compiler , etc but in general bitfields will always be less efficient , due to the extra shifting and masking .",0
"cf should use unions to simplify code and avoid improper casting <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf should use unions to simplify code and avoid improper casting _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on wed <date> <time> <number> _original description_ : in particular this applies to the "" msg "" member of the global , in the following structs : cf \ _appdata . engine . out . msg cf \ _appdata . engine . in . msg they are currently defined as a "" <allcaps> cfe </allcaps> \ _sb \ _buffer \ _t * "" type , which is what comes to / from sb calls . however , locally it is either a "" pdu \ _s \ _msg \ _t "" or "" pdu \ _r \ _msg \ _t "" ( an extension ) depending on direction . this is then cast inline at the point of use whenever the local type is required , e . g . ret = & ( ( pdu \ _s \ _msg \ _t <wink> cf \ _appdata . engine . out . msg ) - > ph ; this is not only inelegant , but casting permits almost any type conversion , and offers no protection against a programmer mistake , such as if it was cast to a "" pdu \ _r \ _msg \ _t * "" instead of "" pdu \ _s \ _msg \ _t * "" . <repeated> that would compile just fine but cause odd memory corruption at runtime . recommend to use a union for the "" msg "" member data type , i . e . union { <allcaps> cfe </allcaps> \ _sb \ _buffer \ _t sb \ _buf ; pdu \ _r \ _msg \ _t pdu \ _r \ _msg ; }; then by taking the address of either the "" sb \ _buf "" or "" msg "" union member depending on what is being called and what it requires . in addition to being easier to read , this offers a layer of protection in that the data can only be converted into a limited set of types ( union members ) .",2
"cf use of "" static const int32 "" for return codes , not used anywhere <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf use of "" static const int32 "" for return codes , not used anywhere _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on wed <date> <time> <number> _original description_ : in the table validation function "" cf \ _validateconfigtable "" it has return values declared locally as a set of "" static const int32 "" values : static const int32 no \ _ticks \ _per \ _second = - <number> ; static const int32 crc \ _alignment = - <number> ; static const int32 outgoing \ _chunk \ _size = - <number> ; because they are local , these values are not available to code outside this function , so nothing can ever check for these status codes ( and nothing ever does ) . the validation function caller only ever checks if the value is negative , and cf only checks if the <allcaps> tbl </allcaps> call returns something other than <allcaps> cfe </allcaps> \ _success . since cf is already sending an event with the validation failure details , this error code is not necessary and not relevant . it should be remove and replaced with one of the generic cfe \ _error constants .",2
"cf code style - use of side - effects statements within "" if "" <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf code style - use of side - effects statements within "" if "" _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on wed <date> <time> <number> _original description_ : cf uses many statements such as this to check the status of a call and store in a local variable : if ( ( status = <allcaps> cfe </allcaps> \ _sb \ _createpipe ( & cf \ _appdata . cmd \ _pipe , cf \ _pipe \ _depth , cf \ _pipe \ _name ) ) ! = <allcaps> cfe </allcaps> \ _success ) most other <allcaps> cfs </allcaps> code break this out into separate statements , i . e . status = <allcaps> cfe </allcaps> \ _sb \ _createpipe ( & cf \ _appdata . cmd \ _pipe , cf \ _pipe \ _depth , cf \ _pipe \ _name ) if ( status ! = <allcaps> cfe </allcaps> \ _success ) i believe <allcaps> gsfc </allcaps> coding standards also prefer the latter form . recommend updating these statements for readability .",2
"cf tests assume "" assert "" is available but do not include assert . h <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf tests assume "" assert "" is available but do not include assert . h _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on tue <date> <time> <number> _original description_ : some cf test utility functions call "" assert "" on various items ( e . g . any \ _file \ _directive \ _t \ _except ) . several issues with this : - the "" assert . h "" system header was not included - the condition "" <allcaps> error </allcaps> \ _retrieving \ _any \ _value "" is a constant that is not even <number> , so the assert will generally pass ( it is boolean true ) . recommendation is to use the utassert \ _abort ( ) function instead .",0
"cf assertions should not be compiled in when using "" release "" buildtype <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf assertions should not be compiled in when using "" release "" buildtype _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on tue <date> <time> <number> _original description_ : see also # <number> regarding the use of "" unlikely "" in this macro . when building with <allcaps> buildtype </allcaps> = release , the <allcaps> ndebug </allcaps> macro will be set . typically this turns off assertions in the code , but in cf this is not the case , it redefines cf \ _assert to a local handler instead . typically code will disable / compile - out assertion statements when in release mode , as they should never be triggered , so they just waste cycles .",0
"cf purge queue command opcode not defined <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf purge queue command opcode not defined _originally submitted by_ : maldonado , sergio e . ( <allcaps> gsfc </allcaps> - <number> ) [ arctic slope technical services , inc . ] on fri <date> <time> <number> _original description_ : the command opcode for purge queue is not present in the cf \ _cmds enumeration in cf \ _msg . h . it should be present with a value of <number> . the command dispatch table in cf \ _cmd . c does have an entry for the command , as well as the implementation . without the opcode defined , the command cannot be verified at the functional level .",0
"cf function cf_cfdp_processplaybackdirectory has an oddly bracketed block <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf function cf_cfdp_processplaybackdirectory has an oddly bracketed block _originally submitted by_ : gibson , alan s . ( <allcaps> gsfc </allcaps> - <number> ) on wed <date> <time> <number> _original description_ : in cfdp . c the function cf \ _cfdp \ _processplaybackdirectory has a block of code with no if / while et . just a bracketed block of code that does not seem to have a reason to be bracketed .",2
"cf function cf_cfdp_issender ( transaction_t * ti ) is odd one out because it uses ti <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf function cf_cfdp_issender ( transaction_t * ti ) is odd one out because it uses ti _originally submitted by_ : gibson , alan s . ( <allcaps> gsfc </allcaps> - <number> ) on tue <date> <time> <number> _original description_ : every other function in cfdp . c that uses a transaction \ _t * as an argument names it ' t ' , but cf \ _cfdp \ _issender uses ti .",2
"cf method cf_clist_remove appears to accept bad arguments <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf method cf_clist_remove appears to accept bad arguments _originally submitted by_ : gibson , alan s . ( <allcaps> gsfc </allcaps> - <number> ) on thu <date> <time> <number> _original description_ : a bad node is passed to cf \ _clist \ _remove , but it carries on unaware . this was found because branch <number> of <code> can only be covered by a test that passes this situation , node - > next = = node , node - > prev ! = node . the issue : should a single node enter , that has a node - > next = = node ( meaning : pointing to itself ) , but a node - > prev ! = node ( meaning : <allcaps> not </allcaps> pointing to itself ) , the code continues as if this is a valid state . it may be impossible for a bad node to enter here , but that is not apparent at the unit test level for cf \ _clist \ _remove nor is the doxygen brief clear on that assumption .",2
"unused event id <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] unused event id _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on tue <date> <time> <number> _original description_ : the event <allcaps> id cf </allcaps> \ _eid \ _err \ _pdu \ _bad \ _rx \ _msg \ _size appears to be unused .",2
"cf purge command does not appear to be hooked in <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf purge command does not appear to be hooked in _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on tue <date> <time> <number> _original description_ : cf comments make reference to a purge command , and functions exist for that command . however , the command code referenced in the comments ( cf \ _purge \ _queue \ _cc ) does not appear to exist and there does not appear to be an equivalent one . _ ( link removed ) _ _ ( link removed ) _",2
"add transaction watchpoint concept for transaction complete notification <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] transaction watchpoint _originally submitted by_ : seeger , steven d . ( <allcaps> gsfc </allcaps> - <number> ) [ embedded flight systems , inc ] on thu <date> <time> <number> _original description_ : it might be useful for operators to have a concept of transaction watchpoints . this could be implemented with the spare <number> - bit per - channel register ( or the spare <number> - bit per - channel ) coupled with a ground command specifying a bit in that register to be set when a transaction is complete . the benefit here is a proc could request a watchpoint and wait for the bit to be set when the file is done . this is more useful than a file counter because polling directories being active could skew the file counter .",2
"investigate whether tx and <allcaps> rx pdu </allcaps> sizes need to be different <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] investigate whether tx and <allcaps> rx pdu </allcaps> sizes need to be different _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on mon <date> <time> <number> _original description_ : need to investigate uses cases where tx and <allcaps> rx pdu </allcaps> sizes need to be different . need to investigate the impact of making a change to allow that .",2
"improve commenting throughout cf v3 . <number> <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] improve commenting throughout cf v3 . <number> _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on mon <date> <time> <number> _original description_ : cf v3 . <number> needs improved commenting throughout . specifically : - file comments in every file describing the purpose of the file - explanations and limits for all configuration parameters - ensure that all comments are accurate",1
"cleanup cf v3 . <number> perf id handling <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cleanup cf v3 . <number> perf id handling _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on fri <date> <time> <number> _original description_ : encompasses several findings from the cf v3 . <number> code review : - remove unused perf id cf \ _dirread \ _perf \ _id - determine whether perf ids cf \ _pdu \ _rcvd \ _perf \ _id and cf \ _vcxpdusent \ _perf \ _id should be added ( currently used in stakeholder ) - ensure that <allcaps> cfe </allcaps> \ _es \ _perflogexit is called when the app exits",2
"playback directory command - timing bug related to issue # <number> the playback queue is starting to process a new file after the end - of - file ( <allcaps> eof </allcaps> ) <allcaps> pdu </allcaps> is sent for an old transaction , while the old transaction isn ’ t truly finished ( and the ‘ active transactions ’ count decremented ) until the <allcaps> ack </allcaps> - <allcaps> fin pdu </allcaps> is received . due to this , one or more transactions can still be active waiting for their <allcaps> ack </allcaps> - <allcaps> fin pdu </allcaps> to be received while the playback queue starts a new transaction . if i had to guess , this is a relic of class1 ( unacknowledged ) transactions which end after the <allcaps> eof pdu </allcaps> is sent . this issue must have gone unnoticed for so long because in most cases it is hidden , as long as your files are reasonably large and your maximum number of simultaneous transactions is greater than <number> ( ours is <number> ) . this is because as long as the file is reasonably large , it will take more time to downlink the new file than it will take for the <allcaps> ack </allcaps> - <allcaps> fin </allcaps> from the old transaction to be received and fully closed out . since the playback queue only transfers one file at a time , you ’ ll only have a maximum of two transactions active at once . with maximum number of simultaneous transactions set to <number> , if you try to download <number> small files via the playback directory command we encounter the issue ( and is the case which found this bug in the first place ) . this is because the files are so small that <number> separate files can send all of their data and hit the ‘ <allcaps> eof </allcaps> ’ phase before the first transaction receives its ‘ <allcaps> ack </allcaps> - <allcaps> fin </allcaps> ’ and fully closes out . even if the files are quite large , if i set the maximum number of simultaneous transactions to <number> the issue is encountered every time and the second file will fail to download . this is because a new transaction always attempts to start while the old transaction was between the ‘ <allcaps> eof </allcaps> sent ’ and ‘ <allcaps> ack </allcaps> - <allcaps> fin </allcaps> received ’ phases . would it be valuable for me to submit a bug fix to this repository ? unsure if this repository is monitored .",0
"use of playback directory command i ' d expect the playback directory command to function like the following . assume <number> is the maximum number of transactions that can be occurring simultaneously and that the directory we are attempting to playback has <number> files in it : - all of the files in the directory get queued . - transactions are started for <number> files , at which point the maximum number of transactions is reached . - once <number> transaction finishes , cf reads from the queue and starts a transaction for the 8 th file . - continue until the entire directory has been downlinked . however , during our testing the command is functioning like the following : - all of the files in the directory get queued . - transactions are successfully started for <number> files , at which point the maximum number of transactions is reached . - cf also attempts to start transactions for the remaining <number> files at the same time , but they error out since we are at the maximum number of transactions . the remaining files are never downlinked . i am not sure if we are misunderstanding how the command is intended to be used or if there is a bug .",1
"request for configurable transaction packet <allcaps> mid </allcaps> in our use case , we want to use <allcaps> cfdp </allcaps> to send files from cpu1 to cpu2 and from cpu1 to ground . the two cpus are connected via <allcaps> sbn </allcaps> , and the connection between cpu1 and the ground station is through to and ci . i had thought to use the <allcaps> mid </allcaps> of <allcaps> cfdp </allcaps> packets to filter which packets are let through to and <allcaps> sbn </allcaps> . by setting up cf with two input channels and two output channels , each using separate mids , i could set to to only listen for packets from one channel and <allcaps> sbn </allcaps> to listen for packets on the other cf channel . it looks like all <allcaps> cfdp </allcaps> transfer packets use the cf_trans_tlm_mid , and that ’ s not configurable . would it be possible to add a configuration value in cf_cfgtable to set <allcaps> mid </allcaps> for output channels , similar to what is done for the input channels ? alternatively , is there a more standard way to do what i am attempting ?",2
does not work by default with <allcaps> osal </allcaps> <number> . <number> official release i am using the rc - <number> . <number> branch with cfe <number> and <allcaps> osal </allcaps> <number> . <number> . it does not build without the following changes : <number> . fsw / src / cf_callbacks . c : <number> - st_size should be filesize <number> . fsw / src / cf_playback . c - all references to os_dirent_t ' s d_name entry should be changed to filename .,3
