text,label
"fix # <number> , removes extraneous boolean logic in concat command - fixes # <number> - removes boolean logic tracking file status which results in reduction of cyclomatic complexity to <number> from <number> by bundling logic in one single nested if / else according to file status . <section> - lcov - build - cert_testbed cfe_evs_concatfilescmd . json functional test successful <section> no impact to behavior <section> - os : ubuntu <number> <section> could be argued that the concat function is more readable as - is , but this way , the <allcaps> nasa </allcaps> recommendation of <number> max cyclomatic complexity per function is satisfied . <section> n / a <section> justin figueroa , vantage systems",2.0
"split header files into external and internal components configuration and header files for this app currently have mixed scope - some items apply globally ( mission ) and some only affect the internal app behavior . <section> split headers into single scope , so they contain only public / global items ( i . e . those that affect <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> / table definitions ) or they contain private / internal items . the latter would be things that are only used within the local application code and do not affect the interface . <section> similar to nasa / hs # <number> . this helps stabilize the interface , so configuration items that do change the interface are clearly marked in a separate file and the user is more aware of the impact the changes will have . it ' s also important for <allcaps> eds </allcaps> , where some of these files are generated - keeping a single scope allows for simple source selection vs . <code> s . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , convert <code> return codes and variables to <code> testing performed * * github ci actions all passing successfully . <section> no change to behavior . <code> is more expressive and improves consistency with cfe / cfs . <section> avi weiss <user>",2.0
fm <code> return codes and variables should be converted to <code> expected behavior * * use the more expressive <code> and improve consistency with cfs . <section> avi weiss <user>,2.0
"fm_childconcatcmd - cyclomatic complexity of <number> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . fm_app . c : : fm_childconcatcmd unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up fm_childconcatcmd such that it has a cyclomatic complexity of <number> or less . <section> dan knutsen <allcaps> nasa </allcaps> goddard",2.0
"use generated stubs for all internal functions fm divides its coverage test into separate units and uses stubs for all units other than the unit under test . however , this appears to be a mixture of hand - written and some generated stubs , and the hand written stubs can diverge from the implementation . <section> re - run the ut assert generate stubs script and use the generated stubs only . <section> this makes the ut stubs easier to maintain - any time a header file changes , just re - run the tool and re - commit the stubs . it is best not to modify the generated stub in any way , if it can be avoided . <section> joseph hickey , vantage systems , inc .",2.0
"internal <allcaps> api </allcaps> calls are not const - correct ( possible race condition ) functions that accept a pointer as an input only , and do not modify that structure , should be qualified as <code> . in particular , this is true of the software bus messages - these could be distributed to multiple subscribers , and these must not be modified by receivers or else race conditions are introduced . there is at least one case of fm where the buffer is modified . this should be corrected along with adding <code> to all messages . <section> possible race condition if multiple entities subscribe to the same message ( config - dependent ) <section> should not modify input . non - modified input structs should be <code> in the declarations . <section> possible case of input buffer getting modified is here : <url> <section> n / a <section> pretty much most / all of the functions in <code> should accept <code> string inputs . <section> joseph hickey , vantage systems , inc .",0.0
"move "" fm_globaldata "" back into private / local data structures the <code> object is only used within the fm app for private data storage . it should not be visible externally . however , it is currently defined here in the public <code> file : <url> <section> this should be defined in one of the internal header files , not in a public interface file . <section> public <allcaps> api </allcaps> should generally only be constants / <code> ' s , and typedefs . <allcaps> api </allcaps> calls only for libraries - apps do not have public <allcaps> api </allcaps> calls . extern data structs / globals should not be exposed in either apps or libs for a variety of reasons . <section> joseph hickey , vantage systems , inc .",2.0
"all <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> message should put content in a "" payload "" sub - structure to match the patterns used in <allcaps> cfe </allcaps> and other modules , all <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> message definitions should put the content ( non - header ) parts into a separate struct called "" payload "" . <section> separate message content into a sub structure called "" payload "" . <section> this is benefit to tooling that can use the presence of this field to identify where the actual content starts ( e . g . something like <code> would work and be correct , as opposed to checking <code> which may not actually reflect where the content starts due to possible compiler - added padding between them ) . <section> joseph hickey , vantage systems , inc .",2.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
fm should use cfe_fs_initheader fm initializes and populates the <allcaps> cfe fs </allcaps> header itself this requires fm to understand the details of the header structure and could break if that structure changes . <section> fm should instead use the cfe_fs_initheader function which is designed to do exactly this . <section> haven carlson,2.0
resolve issues building users guide with ubuntu <number> / doxygen <date> doxygen <code> <section> remove unnecessary documentation <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fm_childsizetimemode does not clear filemode on os_stat failure filemode could be uninitilized when written if there ' s an os_stat failure since it ' s not cleared : <url> <section> pass in uninitialized filemode , observe not cleared on os_stat failure . <section> should clear all values . <section> observation <section> low likelihood of ever seeing this ( maybe file deleted between directory read and os_stat ? ) , and just would write uninitialized data to the output . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"internal delete command support not in requirements , does not match description fm_delete_int_cc is out of family . fm is operator interface to the file system , not what other elements should use to delete files . also strange handling in that it updates command counters but does not send the event message , so it would break normal / simple command counter confirmation approach for ground commands . <section> deprecate and / or directly remove support of this command . other apps should use os_remove directly instead of relying on fm . goal is to reduce interdependency . <section> none <section> replaces : - # <number> - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old fm clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template a clear and concise description of what the contribution is . - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset and cfe_psp_memcpy use on addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"potential truncation of number of open files the number of open files is treated as a uint32 by <allcaps> fsw </allcaps> , but is telemetered as a uint8 such that truncation may result if the number of open files allowed by <allcaps> osal </allcaps> grows .",2.0
style warnings in strict cppcheck analysis currently fails cppcheck strict checking in static analysis workflow : <url> <code> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"either fm unit testing is incorrect or an <allcaps> osal </allcaps> enumeration is incorrect <user> commented on fri <date> <url> <section> i do not know if this an fm bug or an <allcaps> osal </allcaps> bug . i do not know what the intent on either side was . fm is failing unit tests . the first error indicates before <allcaps> osal </allcaps> <number> . <number> - bv , fm determined if a directory entry was a directory by using the s_ifdir macro directly , but had an <hashtag> if def </hashtag> that allowed it to use an <allcaps> osal </allcaps> defined macro instead . <code> with <allcaps> osal </allcaps> <number> . <number> - bv , the os_filestat_isdir macro is defined and fm is using the os_filestat_isdir macro . the unit test sets the filestatus . filemodebits to <number> ( 0x 4 0 0 0 ) , but the os_filestat_isdir tests equality against os_filestat_mode_dir ( 0x 1 0 0 0 0 ) so the unit tests fail . i do not know if the <allcaps> osal </allcaps> developer intended to use the value expected by fm ( 0x 4 0 0 0 ) , or if the fm should be : from : <code> to : <code> making the change above fixes these errors , but so does changing the enumeration from : os_filestat_mode_dir = 0x 1 0 0 0 0 to os_filestat_mode_dir = 0x 4 0 0 0 <section> steps to reproduce the behavior : <number> . build fm unit tests with the ut_assert , hooks , and stubs from cfe <number> . 0 a <number> . run fm unit tests <section> fm unit tests should pass . <section> - virtualbox - ubuntu <number> - fm <number> . <number> , <allcaps> osal </allcaps> <number> . <number> - bv , app ut_assert , hooks , and stubs from cfe <number> . 0 a <section> mathew benson windhover labs , <allcaps> llc </allcaps> <email> - - - <user> commented on mon <date> <url> <user> is this resolved with the latest fm release ?",0.0
"static analysis issues relative to flight code handful of static analysis issues in the "" red "" identified ( non - style issues ) . need to resolve these . filter : - file : elf - file : ut - file : cfe - file : os - file : cf_ - file : _lab_app . c ! ( significance : style ) should resolve and / or disposition the higher ranked ones at minimum . note license restricts publishing issues . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"fm dir list to file does not clean buffer fm get directory list to file ( fm_get_dir_file_cc ) currently is not zeroing out the buffer of dirlistdata . entryname so there can be a bunch of random stuff in there . the dirlistdata that is written currently looks like this : entryname : fm_dirlist . out \ <number> \ <number> / dev / shmw �  \ <number> \ 0 0 hw �  \ <number> \ <number> j �  \ <number> \ <number> �  \ <number> \ <number> � � � entrysize : <number> modifytime : <phone> mode : <number> when it it should look like this : entryname : fm_dirlist . out entrysize : <number> modifytime : <phone> mode : <number> the code looks like this , the commented out part is what is missing and would fix the problem . /* populate directory list file entry */ / / cfe_psp_memset ( & dirlistdata , <number> , sizeof ( fm_dirlistentry_t ) ); strncpy ( dirlistdata . entryname , os_direntry_name ( direntry ) , entrylength ) ; dirlistdata . entryname [ entrylength ] = ' \ <number> ' ; imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"ds and fm use the same default subtype ds and fm both use "" <number> "" as the default file subtype ds / fsw / platform_inc / ds_platform_cfg . h : <hashtag> define </hashtag> ds_file_hdr_subtype <number> fm / fsw / platform_inc / fm_platform_cfg . h : <hashtag> define </hashtag> fm_dir_list_file_subtype <number> imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"add signature checking command to fm stakeholder request - add a command to check the signature of a file . in the open source version of the app , this will call an empty stub in fs_lib that will always succeed ( allows external users to fill in their own implementation ) . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"add untar command to fm stakeholder requested that untar capability be added in cfe . in design discussions with the framework team , it was decided that it made sense to pull the decompress capability out of the framework and into a library , and to then add an untar command to the fm app . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
fm configuration parameter limits need clarification a number of fm configuration parameters have limits for which the reason is obscure at best . limits need to be re - evaluated and comments should give clear reasoning for the limit . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
fm return statements not needed for void function finding from code review imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"reduce redundant code in fm_cmd_utils . c most verify functions in fm_cmd_utils contain several instances of checking the filenamestate . could that code be refactored into its own function that receives the set of valid return codes , and is able to validate the return code or report the errors ( maybe a bitmap ) . this would eliminate a big portion of redundant code . or could it use switch statements ? imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"unrepeatable queue full error during fm file info command the fm main task has an internal queue to pass commands to the fm child task . most command are executed by the child task since the command execution time is unknown or variable . a stakeholder has experience two cases where an fm command somehow broke the fm main task and fm child task communication . the fm main task says the internal queue is full and the child task says it ' s waiting for the next command . in flight , this problem seemed to go away after <number> minutes and the fm child task reported the <number> queued commands had warnings . when it happened on the ground we did not wait long enough to see if it would clear up . it appears the sem give / take got confused . not sure how this can happen . observed on system using vxworks <number> , <allcaps> cfe </allcaps> <number> . <number> , fm <number> . <number> . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"fm is incompatible with recent <allcaps> osal api </allcaps> changes this is regarding <allcaps> osal </allcaps> <number> . <number> - bv . fm calls os_opendir , os_readdir , and os_closedir which were removed in favor of os_directoryopen , os_directoryread , and os_directoryclose . i expect to see other issues as i make fixes to pass unit testing . i will post them here .",0.0
"cfe <number> . <number> ( <allcaps> osal </allcaps> <number> . <number> ) comparability issues while integrating file manager app <number> . <number> with cfe <number> . <number> ( <allcaps> osal </allcaps> <number> . <number> ) i ran into an issue . fm has a command that allows users to receive a telemetry packet listing all of the open files . in order to do this fm needs to be able to query <allcaps> osal </allcaps> ' s file stream resource objects . the current <allcaps> osal </allcaps> implementation only allows a creator to query all of the resources objects by using os_foreachobject ( ) . i wrote <allcaps> osal </allcaps> ticket # <number> to recommend a more general query feature would be helpful . in opensatkit i added a new function os_queryobjecttype ( ) that allows anyone ( not restricted to the creator ) to query a resource type . the specific <allcaps> osal </allcaps> changes are below followed by the fm code that uses the function . these changes were made for openstakit <number> that can be found at <url> this ticket can only be implemented once the <allcaps> osal </allcaps> is updated with a new feature that allows fm to query the resources objects . # # osapi - os - core . h : /* * * typedef for object query <allcaps> osal </allcaps> callback functions . a query does not * * have to be performed by the object creator . all fields of the * * query_record are completed . * * * * this may be used by multiple apis */ typedef struct { const char * name_entry ; uint32 creator ; uint16 refcount ; } os_query_record_t ; typedef void ( * os_objquerycallback_t ) ( os_query_record_t * query_rec , void * callback_arg ) ; / / dcm - added for <allcaps> osk </allcaps> /* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */ /* * * <user> query an object resource type maintained by the <allcaps> osal </allcaps> * * user supplied callback is called for all active resources of a particular type * regardless of whether the caller created the object . * */ uint32 os_queryobjecttype ( uint32 obj_type , os_objquerycallback_t callback_ptr , os_query_record_t * query_rec , void * callback_arg ) ; / / dcm - added for <allcaps> osk </allcaps> # # osapi - idmap . c : /* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - * * function : os_queryobjecttype * * purpose : implemented per public <allcaps> osal api </allcaps> * see description in <allcaps> api </allcaps> and header file for detail * * - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */ uint32 os_queryobjecttype ( uint32 obj_type , os_objquerycallback_t callback_ptr , os_query_record_t * query_rec , void * callback_arg ) { uint32 obj_index ; uint32 obj_max ; uint32 obj_id ; uint32 active_obj_cnt = <number> ; os_common_record_t * obj_rec ; obj_max = os_getmaxforobjecttype ( obj_type ) ; if ( obj_max > <number> ) { os_lock_global_impl ( obj_type ) ; obj_index = os_getbaseforobjecttype ( obj_type ) ; while ( obj_max > <number> ) { obj_rec = & os_common_table [ obj_index ] ; obj_id = obj_rec - > active_id ; if ( obj_id ! = <number> ) { query_rec - > name_entry = obj_rec - > name_entry ; query_rec - > creator = obj_rec - > creator ; query_rec - > refcount = obj_rec - > refcount ; /* * handle the object - note that we must un - lock before callback . * the callback function might lock again in a different manner . */ os_unlock_global_impl ( obj_type ) ; ( * callback_ptr ) ( query_rec , callback_arg ) ; os_lock_global_impl ( obj_type ) ; + + active_obj_cnt ; } + + obj_index ; - - obj_max ; } os_unlock_global_impl ( obj_type ) ; } return active_obj_cnt ; } /* end os_queryobjecttype ( ) */ # # fm_cmd_utils . c : static uint32 open_file_cnt = <number> ; static void loadopenfiledata ( os_query_record_t * query_rec , void * callback_arg ) { fm_openfilesentry_t * openfilesdata = ( fm_openfilesentry_t <wink> callback_arg ; cfe_es_taskinfo_t taskinfo ; if ( openfilesdata ! = ( fm_openfilesentry_t <wink> <allcaps> null </allcaps> ) { /* fdtableentry . path has logical filename saved when file was opened */ strcpy ( openfilesdata [ open_file_cnt ] . logicalname , query_rec - > name_entry ) ; /* get the name of the application that opened the file */ cfe_psp_memset ( & taskinfo , <number> , sizeof ( cfe_es_taskinfo_t ) ); if ( cfe_es_gettaskinfo ( & taskinfo , query_rec - > creator ) = = cfe_success ) { strcpy ( openfilesdata [ open_file_cnt ] . appname , ( char <wink> taskinfo . appname ) ; } } + + open_file_cnt ; } /* end loadopenfiledata ( ) */ /* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */ /* */ /* fm utility function - - get open files data */ /* */ /* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */ uint32 fm_getopenfilesdata ( fm_openfilesentry_t * openfilesdata ) { os_query_record_t query_rec ; open_file_cnt = <number> ; os_queryobjecttype ( os_object_type_os_stream , loadopenfiledata , & query_rec , ( void <wink> openfilesdata ) ; return open_file_cnt ; } /* end fm_getopenfilesdata */",0.0
"cfe core services can create files fm can not delete <section> a few commands to the cfe core services , and possibly some cfs applications , are able to create files that cannot then be moved , renamed , deleted , or otherwise by fm . one example is <code> ( <code> ) . this command ( and all others that take filenames in the cfe core ) do not check the validity of a filename ; they simply pull the filename from the command and call <code> or <code> immediately . fm , on the other hand , calls <code> to check for validity of provided filenames in all commands . so , if a command like <code> is used to create a file with an invalid filename , fm cannot then access that file in any way . <section> steps to reproduce the behavior : <number> . use <code> to create a log file in <code> with a <code> in its filename . <number> . attempt to delete this file with fm . <section> i would expect that no cfe application , or cfe itself , should be able to create files with invalid filenames . my suggested fix , and how we have fixed this in our local copies of cfe and <allcaps> osal </allcaps> , is to move the <code> function into the <allcaps> osal </allcaps> , and have all <allcaps> osal </allcaps> file <allcaps> api </allcaps> functions perform the check before operating on files . this guarantees that nothing above the <allcaps> osal </allcaps> can create a file with an invalid name . <section> * <allcaps> evs </allcaps> creation of log data files without validating filename <url> * fm check on valid filenames <url> * cfs_lib filename validation <url> <section> - capella flight computer - os : freertos <number> . <number> - versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> ( plus in - house freertos port ) , cfs_lib <number> . <number> , fm <number> . <number> <section> this is another one we discovered accidentally operationally . one of our operators created an <allcaps> evs </allcaps> log with a question mark in the name , and then we realized that we could not do anything with that file with fm . we ended up patching the filename check in cfs_lib with mm so it would allow for us to delete the file . <section> mike stewart , capella space .",0.0
registration of events with 0x0 0 0 0 filters is not all that helpful <section> registration of all events with <code> filters just loads the system without actually filtering anything . also fills the event filter buffer for the app and likely drops some since default limit is <number> . <section> remove zero entries from initialization and add a filter when / if needed ( or operationally via command ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"overrun for cfe_msg_message_t <section> out - of - bounds access ( <allcaps> overrun </allcaps> ) . overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 4 0 ul . <section> fix overrun <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"check return value of cfe_sb_createpipe <section> calling cfe_sb_createpipe without checking return value ( as is done elsewhere <number> out of <number> times ) . <section> check return value of cfe_sb_createpipe . should also check return value of cfe_evs_register and cfe_sb_subscribe as seen in sample_app . <section> <url> <section> coverity : <url> <section> examples of how return value is checked for cfe_sb_createpipe : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"update cfe_msg_message_t conversions to use cfe_msg_ptr macro <section> in nasa / cfe # <number> introduces a <code> macro which converts a cmd / tlm header object to a <code> pointer , which is intended to be used rather than assuming a specific member name ( e . g . <code> ) . <section> use the macro instead of assuming <code> member name . <section> required when using generated headers , as the member name may not be "" msg "" or may be further encapsulated . <section> joseph hickey , vantage systems , inc .",2.0
"improve consistency in application of cfe_sb_msgidtovalue / valuetomsgid conversions <section> a <code> value , like other ids , is supposed to be a unique type / opaque value that identifies a message within the sb application context . although it is currently implemented using an integer ( <code> specifically ) application should not assume this . instead , a set of macros and inline conversion functions ( cfe_sb_msgidtovalue and cfe_sb_valuetomsgid ) are provided for when the application needs to interpret the value as an integer for a valid purpose . <section> add conversions where they are currently missing <section> see nasa / cfe # <number> for full info . a separate issue + pr will be submitted for each framework app . <section> joseph hickey , vantage systems , inc .",2.0
"remove references to cfe_es_registerapp <section> as part of nasa / osal # <number> and nasa / cfe # <number> the registration apis are getting fully deprecated and removed . applications no longer need to call os_taskregister , cfe_es_registerapp , or cfe_es_registerchildtask . <section> remove references to these functions . <section> will be required with nasa / osal # <number> and nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the ci_lab repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the <allcaps> osal </allcaps> repo . <section> create a contributing guide markdown file . in the guide , add a link to the ci_lab contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"applications should use all - inclusive "" cfe . h "" header <section> the <allcaps> cfe </allcaps> documentation recommends that applications use the supplied <code> header which in turn provides all <allcaps> cfe </allcaps> core , <allcaps> psp </allcaps> , and <allcaps> osal </allcaps> apis as well as mission config . because some header names are getting changed in nasa / cfe # <number> , including the headers individually becomes a problem . <section> change to using the <code> all - inclusive header , which makes ci_lab work with the new directory structure , and should avoid future issues , and it matches what the documentation recommends . <section> change <code> - > <code> <section> needed for nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for ci_lab or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing ci_lab or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / ci_lab is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / ci_lab while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"refactor ingest to utilize zero copy ( can reduce two copy to one ) <section> ci copies the data into a local buffer and then uses cfe_sb_transmitmsg ( which does a second copy into the sb buffer ) : <url> <section> could use zero copy to get a buffer , write directly to the buffer and cfe_sb_transmitbuffer ( single copy ) <section> none <section> we do not have a functional example of zero copy , just documentation . this would support user request for a working example as well as improve performance . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( from stakeholder request )",2.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add static analysis and format check <section> fix # <number> - adds static analysis and format check into github workflow , includes badges in readme <section> ci <section> basic ci works again <section> ci <section> could add release / omit_deprecated build , but this would break when / if there are cross - repo dependent changes . does get checked during merge processing as a bundle , and can be checked by pushing a test branch to cfs so it ' s debatable if it ' s worth implementing locally . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for ci_lab . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
check message length vs bytes received before publishing <section> command ingest does not verify message length ( from header ) matches bytes received . <section> verify prior to publishing to sb ( stop the error at the source ) . <section> leave as is - command sources should be sending one valid message per datagram <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"update for suggested alignment enforcement pattern ( nasa / cfe # <number> ) <section> see nasa / cfe # <number> , inconsistent pattern <section> match suggestion in nasa / cfe # <number> , use the "" raw "" message cmd / tlm types in definition . <section> none <section> nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove use of os_pack <section> os_pack should not be used . <section> remove it . <section> none <section> nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
remove dependencies on deprecated sb apis <section> sb apis deprecated in nasa / cfe # <number> <section> update to use <allcaps> msg </allcaps> module . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update ci_lab to use osal_id_t typedef <section> ci_lab is using <code> type to hold its <allcaps> osal </allcaps> socket id . <section> should use the <code> typedef instead . <section> part of ongoing effort to update all framework code to use the typedef for <allcaps> osal </allcaps> ids . <section> joseph hickey , vantage systems , inc .",2.0
"report version when responding to noop comand to match sample app template <section> the noop command response in ci_lab is currently <code> while sample app and others usually include the app version as a response . <section> use the noop response template provided in ci_lab <section> change the template so noops do not respond with the version . or create and enforce a noop <allcaps> api </allcaps> at the cfe level . <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"add build name and build number to version . h <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , remove references to <allcaps> ccsds </allcaps> types <section> replace references to <code> types with the <code> - provided type . fixes # <number> <section> build and sanity check <allcaps> cfe </allcaps> , run all unit tests <section> no impact to behavior <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"remove references to "" <allcaps> ccsds </allcaps> "" structures <section> applications should <allcaps> not </allcaps> refer to the "" <allcaps> ccsds </allcaps> "" data types and macros , as there should be no assumption of a particular message framing type at this level . <section> use the abstract types provided in <code> rather than directly using <code> types . <section> related to nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"app should treat cfe_sb_msgid_t values as opaque <section> for compatibility going forward , code should not assume that <code> is an integer . <section> when dealing with an integer , such as when printing in events / messages or for backward compatibility with <allcaps> mid </allcaps> <code> ' s , the code may use <code> and <code> conversion routines . <section> architecturally , the <code> is supposed to be an opaque / abstract value that identifies an endpoint on the software bus routing domain . the specific meaning of integer values is already different in an "" extended header "" ( <allcaps> ccsds </allcaps> v2 ) build vs . the standard header build . therefore apps should never make assumptions regarding the specific integer values , and all introspection of <code> values should be through the <allcaps> cfe sb api </allcaps> only . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , clang - format - <number> fails in travis ci <section> fix # <number> <section> ran ci <section> ci builds no more warnings in config section of travis <section> ci - ubuntu bionic <section> gerardo e . cruz - ortiz <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"clang - format - <number> fails in travis ci <section> travis ci fails with message : > the command "" sudo apt - get install clang - format - <number> "" failed and exited with <number> during . see <url> also has some warnings for deprecated tags in the <allcaps> yaml </allcaps> file : > root : deprecated key sudo ( the key <code> has no effect anymore . ) language : unexpected sequence , using the first value ( c ) root : missing os , using the default linux see <url> <section> force a run of current master branch in travis ci <section> ci finishes set up and works . no travis warnings <section> travis ci , ubuntu - bionic <section> gerardo e . cruz - ortiz <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"<allcaps> ci lab </allcaps> fails when running more than one instance on the same host <section> with a <allcaps> cfe </allcaps> project that uses more than one target ( multi - cpu ) , it is common during development to run more than one <allcaps> cfe </allcaps> core process on the same physical machine ( i . e . when simulating on native ) . but ci_lab unconditionally binds to port <number> so if more than one of those <allcaps> cfe </allcaps> core process is running ci_lab then it fails to bind because the port is in use . <section> ci_lab should at least modify its port number based on the <allcaps> cpu </allcaps> number from the <allcaps> psp </allcaps> . this would allow all cfe - core instances from the same mission to avoid conflict , and not require a custom build of ci_lab for each <allcaps> cpu </allcaps> . <section> containers would also theoretically solve this too but it is complicated to set up and also makes debugging more complex which is generally the objective of doing a native build in the first place . <section> suggest using ( base_port + cpu_number ) as the port to which ci_lab binds , so each <allcaps> cpu </allcaps> gets a different port . also suggest setting the base port to <number> instead of the current value of <number> , so that cpu1 ends up getting the same number . so this way the "" cmdutil "" still works with the same default port and will go to cpu1 . <section> joseph hickey , vantage systems , inc .",0.0
"ci_lab should put all global variables into a global structure <section> ci_lab has several global variables , which are inconsistently named . most have a <code> prefix but the prefix should at least be <code> to match the module name . <section> all globals should all be put into a single top - level global structure , similar to the way other modules isolate their global variables . this consolidates everything and also provides namespace protection . <section> joseph hickey , vantage systems , inc .",2.0
"ci_lab should split message handlers into separate functions <section> the "" process ground command "" routine in ci_lab processes some commands "" inline "" . this does not match the current / recommended style which is to put command handling into a separate function . <section> putting each command into a separate function is the preferred <allcaps> ccb </allcaps> style and it improves modularity of the code . <section> all <allcaps> cfe </allcaps> core apps the sample_app all implement the preferred pattern . ci_lab should be consistent . <section> joseph hickey , vantage systems , inc .",2.0
fails to build in raspbian <section> building ci_lab under raspbian ( a debian variant for raspberry pi <allcaps> sbc </allcaps> ' s ) fails due to alignment issues . <code> <section> build ci_lab on raspbian . <section> should build without error . <section> raspberry pi zero w <section> add any other context about the problem here . <section> <email>,0.0
"apply standard coding style <section> fixes # <number> <section> standard build / run from ic - <number> bundle ( with this change ) , confirmed ci starts up nominally <section> readability <section> - cfs dev server <number> - os : ubuntu <number> - versions : ic - <number> versions with this branch <section> first commit was auto changes 2 nd was hand cleanup for comment alignment re - applied auto format and confirmed no differences <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
apply standard coding style <section> inconsistent coding style <section> apply standard style to code ( see also # <number> for enforcement ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove <allcaps> cfdp pdu </allcaps> introspection features <section> <allcaps> cfdp pdu </allcaps> introspection is old debug code . remove to simplify ci_lab . also subject of recommended issues from lgtm : ci_lab_app . c <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"fix # <number> and release updates <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
update copyright for cfe <number> release <section> copyright update ( comment change only ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"enforce standard coding style in ci <section> inconsistent formatting <section> once <url> is in , enforce in ci <section> tried <code> but did not support editor integration settled on clang - format , requires version <number> for define alignment <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
update to use <allcaps> osal </allcaps> socket <allcaps> api </allcaps> <section> currently uses cfe supplied network_includes . h and not the abstracted <allcaps> osal </allcaps> calls <section> update to use <allcaps> osal </allcaps> <section> none <section> see osapi - os - net . h and / or <allcaps> osal api </allcaps> . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"replace deprecated cfe refs , # <number> fixes # <number> submitted by <user> , <allcaps> cla </allcaps> on file testing : - make enable_unit_tests = <allcaps> true simulation </allcaps> = native prep - built on linux with - dcfe_omit_deprecated_6_6 with no build errors - make test passed ( except osal_timer_ut which occasionally fails on linux ) - cfs executes and loads apps with no issues",2.0
remove dependencies on deprecated cfe elements with : <code> build errors : <code>,2.0
"enhanced version reporting use ci_lab_version from cfecfs_version_info . h if available and report on <allcaps> noop </allcaps> and startup ( along with classic version numbering "" classic version numbering can then just be updated on release , vs for every commit .",2.0
remove classic build support only supporting cmake build going forward .,2.0
"remove old <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",2.0
confirm valid perf_id use originated by abrown4 ( <number> on babelfish ) : cfe reserves <number> - <number> perf - ids . need to confirm ci_lab does not use these .,2.0
"split out ci_lab platform config from app header originated by abrown4 ( <number> on babelfish ) : the platform - specific config ( that i need to change for a deployment ) is in the ci_lab_app . h , and thus common to all ci_lab builds . however , i want to build and deploy multiple cfs instances , each with a ci_lab . [ it _is_ simple and handy . ] propose moving the platform - specific info into ci_lab_platform_cfg . h , like the other apps .",2.0
"<allcaps> ci lab </allcaps> "" pdumsgid "" checking depends on sb macro originated by jphickey ( <number> on babelfish ) : the <allcaps> ci lab </allcaps> application attempts to verify that the pdumsgid is within range by comparing it to the cfe_sb_highest_valid_msgid macro . unfortunately , this is a configuration macro that is specific to the sb implementation and may not be available in future builds . it makes assumptions about the way sb dispatches / handles messages that ci really should not be making . this check also does not provide any real benefit - if the msgid is out of range there is no major problem , it simply will not match any packets . to improve compatibility with future sb improvements this extra check should be removed . calling this a "" defect "" as it actually does break the build with the <allcaps> eds </allcaps> branch .",2.0
"fix # <number> , convert <code> return codes and variables to <code> testing performed * * github ci actions all passing successfully . <section> no change to behavior . <code> is more expressive and improves consistency with cfe / cfs . <section> avi weiss <user>",2.0
sc <code> return codes and variables should be converted to <code> expected behavior * * use the more expressive <code> and improve consistency with cfs . <section> avi weiss <user>,2.0
"fix # <number> , update command code underscores for consistency testing performed * * github ci actions all passing successfully ( incl . unit tests and build + run ) . <section> no change to behavior . improved consistency and clarity . note : there are similar issues with some of the sc eids lacking underscores between words : e . g . <code> <section> avi weiss <user>",2.0
command code / enum naming convention inconsistencies code snips * * <code> <code> ( should be <code> ) <code> <code> ( should be <code> ) . <repeated> and a couple more . <section> identifiers should conform to the cfs / cfe naming convention with regard to consistent use of underscores to make mnemonics clear and readable . <section> avi weiss <user>,2.0
"sc_loadats_test_atsentryoverflow unit test indexes past array bounds the <code> unit test indexes past array boundaries . there are two arrays that get indexed improperly , both in <code> : <number> . the first is a file - global variable , <code> - this array has <number> indexes ( <number> * <number> ) by default <number> . the second is local to <code> , named : <code> - this array has <number> indexes ( <number> / <number> ) by default in <code> , local variable <code> gets increased to a value of <code> . this variable is used to index into both of the above arrays . these accesses are indirect , through these pointers : - <code> - <code> also , i am not sure if i am understanding the test correctly , but it seems like <code> should be used instead of <code> , when initializing the <code> array . perhaps it would help to use more verbose variables than <code> and <code> . <section> <number> . add prints to print out the values of <code> before each <number> . run the unit tests <section> all of these out - of - bound accesses seem invalid , and should be able to be removed . this unit test should probably be revised and cleaned up anyway . for example , after the initial <code> loop , the test describes that its intending to fill the ( one ) last entry with an invalid value . however , what the actual test attempts to do is initialize two entries ( not one ) . additionally , this unit test does not do much verification of <code> to confirm that the function worked as expected . i ' d expect more than just a single <code> call . <section> <code> <section> - x86_64 - os : <allcaps> gnu </allcaps> / linux <number> - versions : draco rc4 <section> this issue only seemed to pop up when we built the linux target for a <number> - bit linux executable , with <code> . <section> keegan moore <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , squash static analysis ( codeql ) uninitialized variable warning testing performed * * github ci actions ( incl . build + run , unit tests etc . ) all passing successfully . <section> codeql ci actions now passing without errors . <section> avi weiss <user>",2.0
squash static analysis ( codeql ) uninitialized variable warning describe the bug * * <code> variable triggering codeql ( potentially ) uninitialized variable warning on some prs . codeql is apparently unable to confirm if <code> is assigned a value in all execution paths ( i . e . if the top while block will always execute at least once ) . <section> code should compile without any serious static analysis failures . <section> avi weiss <user>,2.0
"table data pointer not successfully being re - acquired in sc_managetable sc is not able to successfully send commands . <section> attempt to send a command from a sc table . <section> stored commands executes nominally . <section> uint32 * tbladdr ; switch ( type ) { case <allcaps> ats </allcaps> : tblhandle = sc_operdata . atstblhandle [ arrayindex ] ; tbladdr = sc_operdata . atstbladdr [ arrayindex ] ; break ; case <allcaps> rts </allcaps> : tblhandle = sc_operdata . rtstblhandle [ arrayindex ] ; tbladdr = sc_operdata . rtstbladdr [ arrayindex ] ; break ; case <allcaps> append </allcaps> : default : tblhandle = sc_operdata . appendtblhandle ; tbladdr = sc_operdata . appendtbladdr ; break ; } /* release table data pointer */ cfe_tbl_releaseaddress ( tblhandle ) ; /* allow cfe to manage table */ cfe_tbl_manage ( tblhandle ) ; /* re - acquire table data pointer */ result = cfe_tbl_getaddress ( ( void <wink> & tbladdr , tblhandle ) ; <section> - hardware - os : [ e . g . linux <number> ] - versions [ e . g . cfe <number> , <allcaps> osal </allcaps> <number> , <allcaps> psp </allcaps> <number> for mcp750 , any related apps ] <section> dan knutsen <allcaps> nasa </allcaps> / goddard",0.0
"fix # <number> , apply consistent event id names to common events testing performed * * only github ci actions . <section> no impact on code behavior ( no logic changes ) . consistent event id names for the events which are common to all / most cfs components and apps will improve consistency and ease make code review / debugging easier . <section> avi weiss <user>",2.0
"fix # <number> , remove unnecessary parentheses around return values . - fixes # <number> - removes parentheses in return statements in sc that return a single value / term . this aligns these return statements with the predominant style of cfs . <section> none , prior to submission of the pull request . <section> no impact on behavior . <section> <user>",2.0
resolve issues building users guide with ubuntu <number> / doxygen <date> doxygen <code> <section> remove unnecessary documentation <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fix # <number> , reorder conditions in if statements to optimize code fix # <number> , reordered conditions in if statements so less complex conditions are tested first <section> unit testing <section> no impact to behavior <section> - os : ubuntu <number> <section> haven carlson - <allcaps> nasa </allcaps>",2.0
"could simplify by just managing tables periodically vs by registering for command ( unique approach across common apps ) for the standard <number> apps , sc is the only one to use the <code> <allcaps> api </allcaps> and manage tables on command . <url> <url> <url> <section> could instead just periodically manage all the tables ( like all the rest ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"redundant conditional ( and repeated code ) for determining <allcaps> ats a </allcaps> vs b <code> is set by testing <code> against both <code> and <code> . not much point testing twice since the index is already assumed valid when used to dereference array elements . it ' s also repeated multiple times . <url> <url> <url> <section> implement logic once , and it ' s either a or b . <section> none <section> coverage issue <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old sc clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template a clear and concise description of what the contribution is . - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset use for addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"<allcaps> rts </allcaps> table file load "" failure "" event at startup misnomer causes build run workflow failure the build and run workflow checks for err | warn | fail , but sc nominally sends the following event : <code> see error here : <url> <section> really this is not a failure . it ' s just than only <number> of up to <number> <allcaps> rts </allcaps> tables were loaded automatically . maybe just change to say ' <allcaps> rts </allcaps> table files not loaded automatically at startup = <number> ' or similar . <section> could set the configuration just to load the <number> existing <allcaps> rts </allcaps> ' s . <repeated> but it may be handy to leave as somewhat larger to avoid requiring recompile to add more default <allcaps> rts </allcaps> ' s . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
strict cppcheck static analysis style warnings fails cppcheck strict static analysis workflow as seen here ( <url> <code> <section> fix the name inconsistencies . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"static analysis issues relative to flight code handful of static analysis issues in the "" red "" identified ( non - style issues ) . need to resolve these . filter : - file : elf - file : ut - file : cfe - file : os - file : cf_ - file : _lab_app . c ! ( significance : style ) should resolve and / or disposition the higher ranked ones at minimum . note license restricts publishing issues . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
remove all mentions of <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts from documentation some of our doxygen docs still reference <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts . see cfs_mm repo : fsw / src / mm_msgdefs . h : l28 imported from <allcaps> gsfccfs </allcaps> - <number>,1.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
sc : <allcaps> atp </allcaps> control block data has compiler added padding / / the below update to sc_tbldefs . h would explicitly add padding typedef struct { uint8 atpstate ; /* execution state of the <allcaps> atp </allcaps> */ uint8 atsnumber ; /* current <allcaps> ats </allcaps> running if any */ / / uint16 padding ; /* alignment padding */ uint32 cmdnumber ; /* current cmd number to run if any */ uint16 timeindexptr ; /* time index pointer for current cmd */ uint16 switchpendflag ; /* indicates that a buffer switch is waiting */ } sc_atpcontrolblock_t ; imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"use real headers and structures to define tables <allcaps> rts </allcaps> uses a relative time tag that is <number> bit native endian . current definition of tables uses a uint16 array which makes the table endian specific . could instead define a structure with the real contents ( headers and commands ) , union with an array to make it the right size , then use designated initializers . this would allow the compiler to handle the endianness . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
move table header definitions to table header sc_rtsentryheader_t and sc_atsentryheader_t are currently defined in sc_app . h : <url> <url> really should be owned by sc_tbldefs . h so that tables that use them do not need to include the entire sc_app . h . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"sc code simplification - reduce copies required to read / send sb messages sc could use significant code refactoring and simplification . it would make code more readable , but could also reduce the number of copies required to read and send the software bus messages . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
streamline sc_getnextrtscommand and sc_parserts both functions use temporary buffers and potentially unnecessary copies . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"allow rtsgrp commands to accept non - contiguous ranges currently the rtsgrp commands accept a range of rtss from start_index to end_index . instead , the command could accept a set of bytes where each bit corresponds to the <allcaps> rts </allcaps> to start . this would allow the group commands to work with a range of rtss that is non - sequential imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"add a continuertsonfailureflag to sc there is currently a "" continueatsonfailureflag "" that allows an operator to choose whether the processing of an <allcaps> ats </allcaps> should continue after an error has been encountered . there is currently no corresponding option for <allcaps> rts </allcaps> processing . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
combine loops in sc_buildtimeindextable there are two loops in sc_buildtimeindextable that appear to be easily combinable . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
sc_processatpcmd is very long - could be refactored imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"reorder conditions to optimize code in sc_processatpcmd , the following condition could be reordered : if ( ( ! sc_compareabstime ( sc_appdata . nextcmdtime [ sc_atp ] , sc_appdata . currenttime ) ) & & ( sc_appdata . nextprocnumber = = sc_atp ) & & ( sc_operdata . atsctrlblckaddr - > atpstate = = sc_executing ) ) since sc_compareabstime ( ) is more complex than the next two conditions , put it as the last one to save <allcaps> cpu </allcaps> cycles should any of the simple comparisons fail another small optimization : the "" stillprocessing = false "" condition could be moved out of the if and else blocks starting at line <number> in the sc_loadats function imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"consolidate similar functions sc_manageatstable , sc_managertstable , and sc_manageappendtable are similar enough that some consolidation may be possible . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"clarify code by making array index <number> reserved or unused the command interface to sc identifies rtss and atss starting with <number> , but the code identifies them starting with <number> . thus in each command , there is code to adjust the table number to the table index . code could be simplified by making array index <number> reserved or unused so that the conversion could be avoided . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"use os_stat to verify file existence in sc_loaddefaulttables , the os_opencreate function is used to verify that a file can be opened before any attempt is made to load a table from it . since the code as - is appears to only be checking for file existence ( and not performing any validation on the files ) , code could be streamlined by using os_stat . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"consolidate common patterns in sc could reduce lines of code by using a loop for several common patterns in sc initialization . specifically the sequence of cfe_tbl_register calls in sc_registeralltables ( ) , the sequence of cfe_tbl_getaddress calls in sc_getdumptablepointers ( ) , and the sequence of cfe_tbl_notifybymessage calls in sc_registermanagecmds ( ) . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
not updated for new cfs versions the cfs <allcaps> api </allcaps> has changed substantially since the last commit to this repo and the sc app no longer compiles with new versions of cfs .,0.0
"sc does not compile with cfs <number> hi all , i have tried to compile sc with cfs <number> . <number> and i get many errors . here are a few examples : <code> given how old the last commit in this repo is , i understand these incompatibilities . i have read <url> coming up ; when can we expect it ? fixing these errors should not take too much time , but i dont want to duplicate work , especially as you might have some <allcaps> nasa </allcaps> internal discussions , which i am not part of , about how to make these changes consistently with the other cfs repos .",0.0
"pointer precision loss casting pointer down to ( int pointer precision loss casting pointer down to ( int ) , causing segfault on <number> - bit . see : <url>",0.0
"cfe_psp_module_findbyname does not find base modules <section> <allcaps> psp </allcaps> modules can be enabled in two ways , either by adding to the <code> in targets . cmake ( for optional / platform - specific hardware access routines ) or a set of "" standard "" modules listed in <code> file under the <allcaps> psp </allcaps> . problem is that <code> only looks at the user - specified list ( from targets . cmake ) and not the list of standard modules . this is needed for hs because the <code> monitor ( for cpu utilization ) is now listed as a standard module for pc - linux <allcaps> psp </allcaps> , but this inadvertently made it un - findable . <section> run the current build of framework + hs app ( which relies on being able to locate the <code> module ) . hs does not find a module and disables <allcaps> cpu </allcaps> usage reporting . <section> hs should find the module and enable usage reporting <section> joseph hickey , vantage systems , inc .",0.0
"automate generation of integration candidate branch <section> generating the integration candidate branch is a very straightforward process , although it can be highly time consuming . automating this process can result in significant time savings . <section> use a github workflow to automatically merge a set of pull requests into the integration candidate branch and push it to github . <section> scripts can be used to simplify this process as well , but it requires setup by the person maintaining the repository and is not as portable . <section> dylan baker / <allcaps> nasa gsfc </allcaps> <number>",2.0
"add <allcaps> api </allcaps> for obtaining system health statistics <section> <allcaps> cfs </allcaps> apps ( such as hs in particular ) need to monitor and report the health of the system , in particular <allcaps> cpu </allcaps> usage . unfortunately this info can vary wildly and there is no standardized way of getting it via <allcaps> posix </allcaps> or other os apis - it is generally only obtainable via platform - specific access methods such as the <code> filesystem on linux . <section> design an <allcaps> api </allcaps> that can obtain system health statistics . initially this must support per - core <allcaps> cpu </allcaps> usage , but should be extendable to support arbitrary variables such as temperature , network + disk i / o stats , <allcaps> ram </allcaps> + swap use , etc . basically anything that is typically shown in a pc "" health monitor "" app . <section> initially the <allcaps> cpu </allcaps> usage stats would allow nasa / hs # <number> , nasa / hs # <number> , and nasa / hs # <number> to be resolved . <section> joseph hickey , vantage systems , inc .",2.0
"add example of hardware - based 1 hz signal <section> a few releases back the 1 hz configuration was changed to be initiated by <allcaps> cfe time </allcaps> itself , rather than started by the <allcaps> psp </allcaps> . this was done in order to resolve a race condition where the signal arrived before <allcaps> cfe time </allcaps> was ready to process it . however , as a result , we no longer have a good example of a "" real "" hardware - based 1 pps / 1 hz signal driving the <allcaps> cfe time </allcaps> 1 hz input , as the current example uses a software kernel timer only . <section> create an alternative to the <code> module that reads a 1 pps signal from an external reference such as a serial port - as a number of <allcaps> gps </allcaps> receivers do use a serial line to provide 1 pps along with location data . this probably still would not be directly usable but it would at least provide a ( closer ) example of how this could be achieved , that the user could modify for their particular setup . <section> there are two other ways this could be synced : <number> . use an external process like gpsd to sync the kernel clock to the 1 pps , then use <code> as - is . the result is that the 1 hz <allcaps> time </allcaps> signal will be in phase with the reference signal , but it will not occur at the same time . this phase delay may or may not acceptable depending on the application . this does have the advantage of having only a single time domain across the entire system ( kernel / os clocks and timers will all be synchronous with the <allcaps> gps </allcaps> time ) and it is totally transparent to apps - they just read time as normal . <number> . use an external sync routine ( last argument to <code> to wait for the 1 pps . this is similar to <number> but easier to implement ( no external dependencies ) however the result will be more jittery and apps must know that this timebase may not be synchronous with the os / kernel clock . <section> joseph hickey , vantage systems , inc .",2.0
"separate network logic in pc - rtems to support generic targets <section> the only non - generic implementation in pc - rtems is the network setup , which prevents use on a generic target . <section> isolate / separate network setup to support source selection or similar configuration option . consider configuring from target defs or similar to avoid changes required within psp . <section> could make an additional psp , but does not seem worth duplicating all the pc - rtems code that is not specific to pc ' s . <section> specific parts : <url> <url> might also benefit from making / mnt / eeprom a config param . <repeated> depends on how / where this is actually set up by the <allcaps> psp </allcaps> . would be nice to shift away from "" eeprom "" and use generic "" nonvol "" . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cppcheck <number> style warnings , constparameter <section> from unrelated run : <url> <html> <body> < ! - - startfragment - - > severity | location | error id | issue - - | - - | - - | - - style | fsw / pc - linux / src / cfe_psp_memory . c : <number> | constparameter | parameter ' ptrtokernelsegment ' can be declared with const style | fsw / pc - linux / src / cfe_psp_memory . c : <number> | constparameter | parameter ' sizeofkernelsegment ' can be declared with const < ! - - endfragment - - > </body> </html> <section> squash warnings <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove obsolete <code> <section> <code> is no longer used for anything . <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"wrong type of arguments to snprintf <section> function call with incorrect argument type . this argument should be of type ' unsigned int ' but is of type ' pcs_wind_tcb *'. <section> same behavior , fix error <section> <url> <section> vxworks <number> / mcp750 <section> from codeql use "" % 0 8 lx "" as the format and explicitly cast the argument as "" ( unsigned long ) "" <section> ariel adams , <allcaps> mcsg </allcaps> tech",2.0
"fix # <number> , create changelog file fixes # <number> <section> n / a <section> users can see important information on readme without changelog information . <section> ariel adams , <allcaps> mcsg </allcaps> tech",1.0
"cfe_psp_module_findbyname uses incorrect list limit / stop condition <section> the internal variable <code> is used as the limit for searching for a matching name in the <allcaps> psp </allcaps> module list here : <url> however , a while back the set of modules was split into two , so now we have separate lists : cfe_psp_base_module_list global_configdata . pspmodulelist the <code> value reflects the total number of entries ( sum ) of both lists . but the <code> function is only searching the second list ( global_configdata . pspmodulelist ) . this means that if there is no matching entry , it might read beyond the end of the list . <section> call <code> on a module name that does not actually exist in the system . the loop will segfault when it gets to the <allcaps> null </allcaps> entry that normally terminates the <code> . <section> the search should cover <code> and <code> like the init function does <section> init function uses a helper function that does each list at : <url> search function should mirror this . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc . on behalf of alan cudmore ( <allcaps> gsfc </allcaps> )",0.0
"powerpc specific include in vxworks timebase <section> there ' s a powerpc specific include in the timbase_vxworks here : <url> it would be good to make this module vxworks generic if possible . <section> i am not sure what ' s needed from that include , but if it is necessary it would be nice to abstract it out or ifdef it in only for <allcaps> ppc </allcaps> . <section> nothing particular in mind , but any method to make that module generic vxworks would work . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user>",2.0
<code> defined but not used in vxworks timebase implementation <section> defined here : <url> expected use here : <url> <section> use the define or delete it . note it ' s defined as <number> and the function returns <number> so behavior would not change . <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user>,2.0
"add psp_status_t and associated macros / wrappers / apis <section> same justification as nasa / cfe # <number> , supports clean handling / reporting of <allcaps> psp </allcaps> status . <section> add the type and wrappers , note actual use / enforcement can be later but elements need to exist in draco to maintain future compliance . <section> none . <section> - nasa / cfe # <number> - nasa / osal # <number> - nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
uninitialized variable static analysis warning <section> uninitialized variable static analysis warning observed ( license restricts publishing ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"provide example for setting processor affinity ( <allcaps> smp </allcaps> example ) <section> <allcaps> smp </allcaps> is a hot topic these days , we keep saying it ' s easy but no example provided showing how one could set a thread ' s <allcaps> cpu </allcaps> affinity . <section> provide an example for the "" simplest "" identified method for assigning threads to cores . <section> there ' s numerous approaches , this just shows one that assigns threads when created . one could manage threads from a platform specific app , do power management , fault management , etc . <section> see <url> <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
missing doxygen for function cfe_psp_setupreservedmemorymap missing the doxygen for function cfe_psp_setupreservedmemorymap <url>,1.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"remove explicit file name references in doxygen file comments to avoid warnings <section> file comment without a filename implies the comments apply to the current file . adding the file name makes doxygen try to match that file . the issue is there ' s multiple files with the same name , so doxygen gets confused unless you add full path . really it ' s just overhead since the point is to comment the current file . sample warning if you <code> from the bundle : ` ` <code> os - impl - binsem . c ' supplied as the second argument in the \ file statement matches the following input files : / home / jhageman / cfs / cfs - github / osal / src / os / posix / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / rtems / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / vxworks / src / os - impl - binsem . c please use a more specific name by including a ( larger ) part of the path ! ` ` ` <section> easiest to just remove the name since for every case the comment applies to the current file <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"module list count includes both <code> and the configurable <code> but some apis use just the latter . <section> both lists are initilized : <url> which increments the <code> : <url> but then the <allcaps> api </allcaps> ' s use <code> to limit references to just the configurable list ( and other related issues ) : <url> <section> for example if there ' s <number> entry in <code> and <number> in the additional <code> , then <code> will = = <number> . then if you call cfe_psp_module_findbyname with any module not in the <code> it ' ll actually go off the end of the <code> since it ' s limited to <number> . <repeated> and it will not find anything in the <code> . <section> a complete module list should be used for apis that includes both the built in and added . <section> see above . <section> n / a - code inspection <section> stakeholder identified issue <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"argument cannot be negative <section> tempfd is passed to a parameter that cannot be negative . function open ( "" . reservedkeyfile "" , <number> , <number> ) returns a negative number . <section> add an if statement to ensure that tempfd is not a negative number . <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"resource leak <section> handle variable filedescriptor going out of scope leaks the handle . <section> free filedescriptor or point to mmap <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"<allcaps> toctou </allcaps> bug for open <section> calling function open that uses "" <allcaps> eeprom </allcaps> . <allcaps> dat </allcaps> "" after a check function . this can cause a time - of - check , time - of - use race condition . <section> the most basic advice for <allcaps> toctou </allcaps> vulnerabilities is to not perform a check before the use . could also use the o_creat and o_excl flags of <allcaps> posix </allcaps> ' s open ( ) function . <url> <url> <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"too strict of check before calling "" init "" function of module <section> for <allcaps> psp </allcaps> modules the initialization is only called if the module type is "" <allcaps> simple </allcaps> "" - but this is not necessary to enforce , because the intent is to allow this to be extended to other module types as the mission requires . since the "" init "" function pointer is a fixed / defined entry ( so all modules have it , regardless of type ) and it is already permitted to be <allcaps> null </allcaps> if it is not needed , then there is no real reason to restrict calling it to the "" <allcaps> simple </allcaps> "" module type . <section> define an extension module type and try to use it with caelum . it will not be initialized as expected , the init call is skipped . <section> if a module provides an init function , it should be called , regardless of whether the module type is "" <allcaps> simple </allcaps> "" or something else . <section> check is here : <url> through some form of evolution it was checking specifically for <code> only , but it would be better to check that <code> instead . <section> ubuntu <section> only breaks when trying to add modules of other types ( extensions ) . could theoretically be fixed in other ways , but still , the intent of this code is only to confirm that the module structure is initialized to something before invoking a function pointer . so it is more correct to check that it is not invalid , rather than checking specifically for one value . <section> joseph hickey , vantage systems , inc .",0.0
"report actual errno / error string from c library calls <section> during startup , the <allcaps> psp </allcaps> makes several calls into c library functions , and an unexpected failure of these functions causes the system to abort / not start . however , the error messages reported do not include any detail of what went wrong . example : <url> <section> on any system call that sets the global <code> value , if that function fails , this should be included in the error that is printed to the console . at a bare minimum , could include the numeric value , but far preferable to use the system library call to print in a more human - friendly form , such as <code> or <code> if the system provides it . <section> should probably also not use <code> here due to its extra buffering , see # <number> , # <number> <section> joseph hickey , vantage systems , inc .",2.0
"add sleep ( <number> ) before exit call when printing <section> user reported os_print does not display before exit , for example : <url> <section> add sleep ( <number> ) between prints and exits to give it a chance <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"improve <allcaps> psp </allcaps> config override concept <section> historically <allcaps> psp </allcaps> ' s have been treated as clone - and - own , but to be a bit friendlier for reuse it would help to support a more general configuration override concept that would not break unit testing . example issue - if a user overrides cfe_psp_config . h for a specific target , it ends up getting used by unit test for the other psps that rely on unique / conflicting cfe_psp_config . h elements . this can be avoided by conditionally <allcaps> not </allcaps> pulling in a cfe_psp_config . h override for native or when enable_unit_tests = <number> unless trying to unit test the system it applies to but this really is not pretty if it ' s a multi - build and you really do want to coverage test using overridden configs . basically a user had an override to the linux <allcaps> psp </allcaps> config , but unit tests build for vxworks coverage and they tried to use the linux <allcaps> psp </allcaps> coverage override . <section> allow for easily disabling <allcaps> psp </allcaps> unit tests for the non - target psps . likely a good thing for <allcaps> osal </allcaps> also . really users only need to test what they are using , just the open source bundle needs to test them all . also would help to transition to the <allcaps> osal </allcaps> pattern for setting cmake variables , and use those to set the defines with default backups . the built configs could then easily override just what they want , and the common - across - psp settings would be portable . maybe the config headers should have unique names associated with the implementation vs all being called cfe_psp_config . h since really they are not portable . or separate the unique and portable settings . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , from conversation with <user>",2.0
"fix # <number> , rename doc to docs <section> this is a simple rename of the <code> subdirectory , for consistency with other modules . fixes # <number> <section> build cfe documentation <section> none , but may affect scripts / tools that look for / link to a specific "" doc "" directory name ( none found for <allcaps> psp </allcaps> based on my initial checks , but there could potentially be some links hidden elsewhere ) . <section> ubuntu <section> joseph hickey , vantage systems , inc .",1.0
"rename "" doc "" to "" docs "" for consistency <section> most other cfs modules put the documentation in a <code> subdirectory , except <allcaps> osal </allcaps> and <allcaps> psp </allcaps> , which put it in <code> <section> be consistent , use <code> since this is what cfe and the majority of cfs apps use . <section> inconsistent naming means over complicated scripts and tools , that have to look in multiple different possible names / locations <section> joseph hickey , vantage systems , inc .",2.0
"cfe_psp_memvalidaterange ( ) always fails on <number> - bit targets <section> when attempting to telemeter memory pool stats , <allcaps> cfe es </allcaps> calls <code> on the address of the pool data . however on <number> bit linux this function ends up always returning an error , because the internal table is not set up for <number> bit address <section> run <allcaps> cfe </allcaps> on a <number> - bit pc - linux platform , then issue <allcaps> cfe es </allcaps> command code <code> ( <number> ) with a valid pool id . this always fails and says invalid handle , even though the handle is actually fine , because it is not passing the <code> check . <section> check should pass . <section> if applicable , add references to the software . <section> ubuntu <number> ( <number> - bit ) <section> this table is still using <code> sizes . it must have been missed in the previous updates that changed much of this to <code> . <section> joseph hickey , vantage systems , inc .",0.0
"remove "" global_psp_configdata "" object <section> this global / constant structure object was originally added to facilitate modular linking , but is not really necessary anymore , and was never really used . as it stands today , only the <allcaps> psp </allcaps> has it , which makes it a bit of an anomaly in the system context . <section> clean it up , remove this extra global object . <section> in contrast the similar object <code> object _is_ used , as it facilitates getting <allcaps> psp </allcaps> access to constants defined in <allcaps> cfe </allcaps> at link time , without <allcaps> psp </allcaps> having to directly <code> the header that defines it at compile time ( as this would create a backwards dependency ) . the <code> object is the same idea but was for <allcaps> psp </allcaps> constants , however there is not the same dependency structure here , so it was never really needed . only the version info was ever used externally by <allcaps> cfe </allcaps> , and now that is replaced by an <allcaps> api </allcaps> call to get the info , ( recent prs nasa / psp # <number> and nasa / cfe # <number> ) so there is no need for this global at all anymore . <section> joseph hickey , vantage systems , inc .",2.0
"add missing "" cfe_psp_version . c "" to source list <section> the <code> file was not included in the <allcaps> psp </allcaps> source list as it should have been . <section> referencing any version info call results in linker error . <section> link should succeed <section> ubuntu <number> <section> this was supposed to be part of previous pr # <number> . somehow it got missed / omitted from that pr . ( too much stuff going on at once maybe . <repeated> ) <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> psp </allcaps> headers need a scrub / cleanup <section> the <code> header file puts its comments / description _after_ the function declaration and does not use doxygen style . it also contains at least a few functions that are not used by <allcaps> cfe </allcaps> and also may not even be implemented <section> cleanup . at least fixup comments to be more readable - put before declaration and ideally also add some doxygen markup . at least the <code> function appears to be not implemented at all - recommend removing this prototype . <section> other functions which are inconsistently implemented or too hardware specific to be useful , might be targets for deprecation / removal ( these are not used by <allcaps> cfe </allcaps> , either ) : - <code> - why an init but no read / write / mount / etc ? seems like a thought that was never completed . - <code> - note this is different than <code> - <code> - not well defined what this value really is , so not really usable in portable apps . these are referenced but have some issues : - <code> - the definition is inconsistent , sometimes it maps to a real clock and sometimes its more of an interval timer with an arbitrary wrap point , needs more info / definition at least because it is generally hard to use __correctly__ . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the <allcaps> psp </allcaps> repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the <allcaps> psp </allcaps> repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"should not use os_getlocaltime ( ) for <allcaps> psp </allcaps> timebase <section> the <allcaps> psp </allcaps> timebase ( returned via <code> ) is used by <allcaps> cfe </allcaps> performance monitoring and it is important that this time is stable and does not get reset . but depending on the implementation of <allcaps> osal </allcaps> , it may be possible to reset / change the <allcaps> osal </allcaps> "" local time "" . at least there is an <code> function defined - whether it works or not depends on what kernel resource was used to implement this . <section> on pc - linux and other <allcaps> posix </allcaps> - like systems this should use <code> with clock_monotonic directly , instead of calling <allcaps> osal </allcaps> . furthermore this function can be split into a separate module and therefore used on any system that provides <code> <section> see nasa / osal # <number> - <code> may be redefined / clarified to indeed refer to "" real "" time , which would make it less suitable for this purpose used here . <section> joseph hickey , vantage systems , inc .",2.0
"scrub for include < > vs "" "" use ( < > should be system only ) <section> < > used on non - system header includes . example : <url> <section> full scrub / fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"make <allcaps> psp </allcaps> more modular <section> it is currently not easy to override items in the "" shared "" directory even for platforms which it does not apply . for example , in the "" cfe_psp_ram . c "" and "" cfe_psp_port . c "" files this contains code that directly writes to physical memory addresses , which may work on mcp750 , but will likely segfault on an pc - linux system . the code should be better structured as modules so the "" correct "" implementation can be used for each system without breaking the other system . <section> most of the code in <code> should be modularized so it can be selectable per - platform . each platform ( mcp750 , pc - linux , pc - rtems , plus whatever others users might have ) then becomes just a collection of modules . <section> there really should not be much in the <code> directory ( the existence of such a directory implies its not platform - specific , but yet its in the <allcaps> psp </allcaps> ) . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for <allcaps> psp </allcaps> or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing <allcaps> psp </allcaps> or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / <allcaps> psp </allcaps> is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / <allcaps> psp </allcaps> while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"static analysis : ' unsigned int ' but is of type ' pcs_wind_tcb * ' <section> see < <url> detected in <code> not sure we might want to dismiss it <section> run codeql <section> < img width = "" <number> "" alt = "" screen shot <number> - <number> - <number> at <number> <number> <number> pm "" src = "" <url>",0.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
c + + comment style and commented out code violations <section> c + + comment style and commented out code violates style guidelines <url> <section> clean up <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
version string not reported correctly <user> commented on fri <date> <url> <section> <code> note missing <code> for psp <section> add <code> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for <allcaps> psp </allcaps> . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"re - add static code analysis for pull requests <section> the travis ci runner ran cppcheck which we do not have anymore <section> submit pull request , notice that travis ci does not run anymore . <section> a success or failure report of a cppcheck run . <section> check from travis . yml <code> <section> n / a <section> part of ongoing travisci to github actions migration",0.0
"add workflow timeouts and format check <section> - no timeout in workflow ( default is <number> minutes ) could consume allocations - missing format check - remove old travis configuration - update badges <section> add timeout and format check <section> none <section> similar to transition in nasa / cfs <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <allcaps> edit </allcaps> - was general workflow ticket ( duplicate of # <number> ) , made specific for remaining changes",2.0
"update <allcaps> psp </allcaps> to use os time conversion / access methods <section> <allcaps> psp </allcaps> is directly accessing specific fields within <code> which will break when the struct definition changes . <section> instead of directly accessing the <code> and <code> fields within <code> , use the accessor functions to convert / extract the relevant info from the value instead . <section> see nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
"remove obsolete reference to os_taskregister <section> obsolete comment ( in each psp , but sample below ) : <url> <section> remove obsolete comment <section> none . <section> nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update unit test stubs to use size_t <section> as part of nasa / osal # <number> the unit test routines were updated to use <code> rather than <code> for object sizes . <section> <allcaps> psp </allcaps> stub implementations need to use <code> instead of <code> to avoid a compiler type mismatch error on some platforms . <section> this needs to go with / dependency on pr nasa / osal # <number> . this issue is only for stubs as it will cause a build issue without it . there will be a separate change / to - do item to fix <allcaps> psp fsw </allcaps> apis that are still using uint32 . <section> joseph hickey , vantage systems , inc .",2.0
"graceful shutdown for vxworks / mcp750 <section> when the <allcaps> cfe </allcaps> "" restart "" command is executed , it calls <code> . in the mcp750 implementation , this ultimately just invokes the <code> kernel <allcaps> api </allcaps> . this is rather extreme - - all apps / tasks are still running when this command comes in , and this just suddenly reboots the <allcaps> cpu </allcaps> with no notice . those tasks could have been doing something important when they suddenly get the carpet ripped out from underneath . <section> should do some sort of graceful shutdown like linux does with <allcaps> ctrl </allcaps> + c handling . cancel or suspend all running tasks first so that when the "" reboot ( ) "" is called there should not be any other activity going on . <section> <section> during <allcaps> cfe </allcaps> <number> testing there was some occasional spurious exceptions observed when issuing the <allcaps> cfe </allcaps> restart command - causing it to effectively execute a <allcaps> processor </allcaps> restart instead of the intended <allcaps> poweron </allcaps> reset . i was not able to reproduce that with the core framework distro , but my hypothesis is that there were possibly some apps running and doing something when the reboot was initiated and this set the stage for indeterminate behavior . <section> joseph hickey , vantage systems , inc .",2.0
refactor ut_setforcefail describe the bug ut_setforcefail was refactored to ut_setdefaultreturnvalue for <url> it needs to have its name changed here as well . expected behavior change ut_setforcefail to ut_setdefaultreturnvalue additional context part of <url> reporter info alex campbell,2.0
"apply standard formatting <section> various formatting styles in codebase <section> apply standard formatting , if it ' s an improvement then submit for fasttrack ( minimize impacts to open work ) . if standard format requires hand mods , update such that application of standard format in the future does not require repeat modification . <section> leave as - is if not an improvement . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> psp </allcaps> coverage tests fail to build on the mcp750 / vxworks <number> target <section> when building for mcp750 with all unit / coverage tests enabled , an error occurs : <code> <section> prepare using <code> and sample_defs config then run <code> <section> build should succeed <section> <code> build machine with mcp750 target <section> joseph hickey , vantage systems , inc .",0.0
"errors printed using os_printf may never appear <section> os_printf uses an additional output buffer with a low priority task to move the data from the buffer to the console . in the case of fatal errors which cause the process to exit as a result , the output may not get transferred before the process exits and the task is killed . <section> see # <number> of a case where ( for other reasons ) shmget failed but no error message was shown . <section> error messages should be shown <section> this is particularly an issue for errors which cause an immediate process exit . so long as the process keeps running and the output task is not immediately cancelled , there should not be an issue . recommendation is to use <code> for fatal error messages , as even the stdout stream might have some line buffering in the c library , but the stderr stream should be ( relatively ) unbuffered . <section> joseph hickey , vantage systems , inc . ( based on previous report in # <number> )",0.0
"update <allcaps> psp </allcaps> to use osal_id_t type instead of uint32 <section> the <code> typedef was recently added to <allcaps> osal </allcaps> to differentiate <allcaps> osal </allcaps> ids from simple integers . <section> <allcaps> psp </allcaps> should use this type , instead of <code> , for all the places where an id is stored . <section> using the typedef helps future - proof the code for possible id type changes . <section> joseph hickey , vantage systems , inc .",2.0
"set thread name on pc - linux <section> <allcaps> osal </allcaps> currently does not inform the os kernel of the actual thread names , because this is not a standard <allcaps> posix </allcaps> feature . but linux has this capability and it helps with debugging to see real thread names . <section> use the <allcaps> osal </allcaps> callback framework introduced in nasa / osal # <number> to set the thread name at the kernel level when using the <code> <allcaps> psp </allcaps> . <section> originally suggested in nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
"add support for <allcaps> rtems </allcaps> <number> - cmake updates and pc - rtems <allcaps> psp </allcaps> readme updates <section> the cfs bundle currently supports <allcaps> rtems </allcaps> <number> . now that <allcaps> rtems </allcaps> <number> has been released , i would like to update the necessary components to support <allcaps> rtems </allcaps> <number> on the pc - rtems platform . this involves minor modifications to the cfe repository , the <allcaps> psp </allcaps> repository , and the <allcaps> osal </allcaps> repository . these changes can be done in such a way that preserves the current <allcaps> rtems </allcaps> <number> support and adds <allcaps> rtems </allcaps> <number> support . <section> i would like to add support for <allcaps> rtems </allcaps> <number> while maintaining compatibility with the existing <allcaps> rtems </allcaps> <number> support . for the <allcaps> psp </allcaps> repository there are a few minor changes needed to allow support of <allcaps> rtems </allcaps> <number> and <allcaps> rtems </allcaps> <number> : - minor changes in the <allcaps> psp </allcaps> cmake / modules / platform / <allcaps> rtems </allcaps> . cmake file - changes to the pc - rtems readme and the addition of an <allcaps> rtems </allcaps> <number> specific readme <section> alternatives include : - not supporting newer versions of <allcaps> rtems </allcaps> , but several projects will depend on <allcaps> rtems </allcaps> <number> support . - dropping <allcaps> rtems </allcaps> <number> support and just making the changes needed for <allcaps> rtems </allcaps> <number> , but there may be projects that depend on <allcaps> rtems </allcaps> <number> . we can consider dropping <allcaps> rtems </allcaps> <number> support on a future release . <section> <section> alan cudmore / <allcaps> nasa gsfc </allcaps> code <number>",2.0
"fix # <number> , install unit test to target directories <section> fix # <number> , install unit test to target directories <section> make unit tests , install , observe they install in correct directory <section> correct install directory <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"coverage test not installed in correct directory <section> coverage test not installed in correct directory - see nasa / cfe # <number> <section> make unit tests , make install , observe unit test in build directory . <section> should go in target directory ( build / exe / cpu1 for sample config ) <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , add cfe_psp_getprocessorname <section> fix # <number> - add cfe_psp_getprocessorname <section> added test code in sample_app to output <allcaps> sc id </allcaps> , <allcaps> cpu id </allcaps> , and <allcaps> cpu name </allcaps> build and ran ( pc - linux only ) , tested with both default options and <code> , confirmed expected output <section> now provides get processor name <allcaps> api </allcaps> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this change . <section> nasa / cfe # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , set stub spacecraft id to historical value ( 0x 4 2 ) <section> fix # <number> - set the stub config data spacecraft id to historical value 0x 4 2 , was <number> . <section> nominal build / test , passed . <section> anything using the stub config data will now get the default . the point is really to reduce confusion the mismatch could cause . nothing should actually be using this stub data directly . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this change <section> nasa / cfe # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"hardcode of spacecraft id to <number> in psp unit test stub <section> likely should be 0x 4 2 since that ' s the historical sample setting . not critical since this is just stub data , but easier to understand intent if the settings are consistent . <section> default spacecraft id to the historical setting . <section> some random value , or use cfe_spacecraft_id_value <section> nasa / cfe # <number> , nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , remove classic make artifacts <section> fix # <number> - removes classic make artifacts <section> <code> ( passed ) <section> none , these files are no longer used anywhere <section> - hardware : cfs dev server - os : ubuntu <number> - versions : main bundle ( main cfe / osal since they were not in sync ) + this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use a changelog to keep track of changes instead of having them in the readme <section> the version history in the readme file clutters useful information <section> move the "" version history "" from <code> to <code> and start following this spec : <url> <section> move changelog section in the readme to a section at the very bottom of the file <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
vxworks build broken - missing include path for net / uio . h <section> <code> <section> steps to reproduce the behavior : <number> . set tgt1_system to ppc - vxworks6 . <number> and try to build for mcp750 <section> should build <section> old includes : <url> current : <url> <section> - cfs vxworks host - os : building for vxworks6 . <number> - versions : current bundle <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
add replacement for deprecated <allcaps> osal </allcaps> - os_intlock and os_intunlock <section> os_intlock and os_intunlock were deprecated from <allcaps> osal </allcaps> since there wasn ' t a platform independent way to implement the actual intent . <section> need a replacement implemented where possible to support the concept of executing a uninterrupted block of code . <section> non - portable implementation of uninterruptible code ? <section> memory manager has a load memory with interrupts disabled command . perhaps operationally could be done differently ? * <allcaps> note </allcaps> * - priority to come up with a solution to support upcoming mm release . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,3.0
"increase exception action choices in <allcaps> psp </allcaps> handler <section> if , during * application development * , a task fails and raises a kernel exception , the <allcaps> psp </allcaps> handler can only choose between processor reset ( zero ) or restart the application ( non - zero value ) . when that happens , all the information about the exception are lost during the memory reset . <section> add extra options to the exception action field in the startup script to “ do nothing ” in case of exception , and therefore keep memory intact for task autopsy . maybe if exception action is below zero ignore . <section> <section> i can see this easily expanded to handle special cases where we want to recover data from the failed task , or communicate to another task / application this information . <section> claudio olmi <allcaps> nasa </allcaps> - <allcaps> jsc </allcaps> doyle mills <allcaps> nasa </allcaps> - <allcaps> jsc </allcaps>",2.0
"add build name and build number to version . h <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , set exception context size <section> store the size of the stored data into the exception record on mcp750 - vxworks platform . fixes # <number> <section> build and sanity test <allcaps> cfe </allcaps> . unit testing via <allcaps> psp </allcaps> coverage tests ( separately in issue # <number> ) <section> the exception context stored on mcp750 has a valid size . <section> ubuntu <number> running coverage tests for mcp750 . <section> joseph hickey , vantage systems , inc .",0.0
"mcp750 should set up a timebase like other psps do <section> mcp750 currently uses a ( very inaccurate ) infinite loop with an <code> to mimic a 1 hz callback . this is inaccurate as it drifts over time and not the best way to create a 1 hz tick . <section> in pc - linux and pc - rtems this just sets up a timebase object so cfe_time ( or anything else ) can register their own 1 hz timer and have it by synchronized to the <allcaps> psp </allcaps> time source . recommend to use this on mcp750 too . <section> infinite loops with no exit condition are also bad for unit testing . this code to set up a <allcaps> psp </allcaps> timebase using kernel timer could be modularized , as the implementation is already abstracted in <allcaps> osal </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"mcp750 needs to set context size on exception handling <section> mcp750 is not storing the context size , which results in the size being <number> and therefore no extended data is saved to the log file even though its in memory . <section> found in unit testing with new <allcaps> psp </allcaps> coverage tests ( not yet merged ) <section> the <code> function should set the <code> field to the amount of data it has actually stored in the buffer . this is then used later if a file dump is requested to write the exception data to a file . <section> ubuntu <number> running <allcaps> psp </allcaps> coverage tests . <section> joseph hickey , vantage systems , inc .",0.0
"build <allcaps> psp </allcaps> components as a separate targets <section> as part of coverage testing that is being introduced in # <number> , it will require rebuilding the <allcaps> psp </allcaps> code more than once , to make a variant that include coverage instrumentation . this requires a bit of restructuring to support . <section> build components ( e . g . shared directory ) as separate targets so they can be added more than once with different configurations . define all target names using a separate re - definable string such as <code> rather than <code> to avoid target name conflicts . <section> prerequisite to # <number> , isolated to separate issue because it affects <allcaps> fsw </allcaps> headers and build scripts , not just unit test , and therefore warrants separate review . <section> joseph hickey , vantage systems , inc .",2.0
"create <allcaps> psp </allcaps> unit test framework and example <section> need to provide example of <allcaps> psp </allcaps> unit tests . coverage and functional testing are required but require a different approach . this issue will focus on the coverage test portion . <section> provide a framework and example to perform <allcaps> psp </allcaps> coverage test . <section> using mcp750 as a proof - of - concept . <section> joseph hickey , vantage systems , inc .",2.0
"add cfe_psp_getprocessorname ( ) <allcaps> api </allcaps> <section> the build configuration specifies a spacecraft id , <allcaps> cpu </allcaps> / processor id , and a <allcaps> cpu </allcaps> / processor name , but the <allcaps> psp api </allcaps> only gives runtime access to two of the three : <code> <section> should add : <code> <section> continue to offer incomplete information from <allcaps> psp api </allcaps> . <section> related to nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , reference generic <allcaps> osal bsp </allcaps> <section> the change in nasa / osal # <number> makes the <allcaps> bsp </allcaps> modules more generic and changes the name . this changes the <allcaps> psp </allcaps> reference to be compatible . <section> build for all platforms and sanity check <allcaps> cfe </allcaps> operation <section> no change to behavior . <section> ubuntu <number> ( native ) <allcaps> rtems </allcaps> <number> on pc686 / <allcaps> qemu </allcaps> vxworks <number> on mcp750 <section> makes build compatible with nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , remove os_volumetable <section> removes all references to the os_volumetable in all psps . replace with call to os_filesysaddfixedmap ( ) for the fs_based entries . other types are already handled at runtime anyway . fix # <number> <section> build and sanity check <allcaps> cfe </allcaps> on all supported platforms ( vxworks , linux , rtems ) <section> no impact to behavior . <section> ubuntu <number> ( native ) <allcaps> rtems </allcaps> <number> on pc686 / <allcaps> qemu </allcaps> vxworks <number> on mcp750 <section> makes code compatible wtih nasa / osal # <number> which deprecates the os_volumetable <section> joseph hickey , vantage systems , inc .",2.0
"reference the generic <allcaps> osal </allcaps> bsps <section> recent <allcaps> osal </allcaps> changes make the <allcaps> bsp </allcaps> layer more generic for vxworks and linux . in nasa / osal # <number> this changes the name from mcp750 - vxworks to generic - vxworks , and from pc - linux to generic - linux , respectively . <section> change the <allcaps> psp </allcaps> references to match the <allcaps> osal bsp </allcaps> name . <section> joseph hickey , vantage systems , inc .",2.0
"deprecate definition / use of os_volumetable <section> <allcaps> osal </allcaps> has an <allcaps> api </allcaps> where volume table mappings can be added during the startup code , rendering the static <code> object unnecessary . <section> use the <allcaps> osal api </allcaps> to register the fs_based file system mappings , and remove os_volumetable . <section> joseph hickey , vantage systems , inc .",2.0
"implement exception logging / capture in <allcaps> psp </allcaps> <section> exception handling in <allcaps> cfe </allcaps> is not possible due to race conditions and differences between platforms , so the <allcaps> psp </allcaps> needs to take a greater role in handling these events . <section> <allcaps> psp </allcaps> should capture exception contexts locally , and provide a more abstract <allcaps> api </allcaps> for <allcaps> cfe </allcaps> to poll and retrieve them rather than pushing direct . <section> related to nasa / cfe # <number> , nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , termination on strncpy <section> fix possible non - termination of strings in command line option parsing . these generated warnings in gcc9 . fixes # <number> <section> build code with default config , <allcaps> simulation </allcaps> = native <allcaps> buildtype </allcaps> = release on <allcaps> gcc </allcaps> <number> . <number> . confirm successful build with no warning . <section> no impact to behavior <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> joseph hickey , vantage systems , inc .",0.0
"inconsistent default <allcaps> cpu id </allcaps> / spacecraft id between pc - linux and other platforms <section> the <allcaps> cpu id </allcaps> / spacecraft id on linux differs from the vxworks build due to the linux build deriving the value from the targets . cmake and other platforms deriving it from the value of [ target name ] _platform_cfg . h and [ mission name ] _mission_cfg . h <section> set cfe_mission_spacecraft_id in [ mission name ] _mission_cfg . h different than spacecraft_id in targets . cmake . do same for cfe_platform_cpu_id and the <x> value in <allcaps> tgt </allcaps> <x> . build for linux and a vxworks target . <allcaps> cpu </allcaps> ids will be different when attempting to run <allcaps> sbn </allcaps> <section> the same default <allcaps> cpu </allcaps> ids should show up across both platforms . <section> it appears this is due to the linux <allcaps> psp </allcaps> using global_configdata in <allcaps> cfe </allcaps> ' s target_config . c and the other platforms using cfe_mission_spacecraft_id and cfe_platform_cpu_id directly . <section> - os : [ e . g . linux <number> ] - versions cfe <date> , <allcaps> psp </allcaps> <number> for mcp750 , linux , sp0 <section> add any other context about the problem here . <section> john pham , northrop grumman",2.0
"fix # <number> , update doxygen comments to fix warnings <section> fixes # <number> resolve doxygen warnings <section> steps taken to test the contribution : <number> . corrected lines that generated warnings <number> . rebuilt documentation with <code> <number> . observed no warnings generated <number> . viewed relevant page ( s ) to verify correctness <section> changes to documentation only ; no code impact <section> leor bleier , <allcaps> nasa </allcaps> \ <allcaps> gsfc </allcaps>",1.0
"fix doxygen warnings <section> warnings are generated when compiling the documentation <section> <number> . build documentation using <code> <number> . observe warnings in <code> <section> no warnings should be generated <section> leor bleier , <allcaps> gsfc </allcaps> \ <number>",0.0
"<allcaps> rtems </allcaps> cmake module does not define all required outputs <section> when building with <allcaps> cfe </allcaps> , this ultimately triggers a ( seemingly ) unrelated error : <code> <section> build software for i686 - rtems4 . <number> per <allcaps> readme </allcaps> instructions and example toolchain <section> build should succeed without warnings or errors <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( build host ) building for i686 - rtems4 . <number> <section> this regression was introduced when <allcaps> cfe </allcaps> added logic to inspect the variable <code> and use the same flags for the <code> option on the link line . normally <code> is exported by the platform module , but not in the locally - provided <allcaps> rtems </allcaps> module . <allcaps> rtems </allcaps> uses the compiler to perform linking ( gcc ) and as such it needs the <code> prefix . it may also benefit from <code> anyway so it is a good idea to include this . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , resolve ci config warnings <section> resolves ci configuration warnings fix # <number> <section> steps taken to test the contribution : <number> . ci ( ci change only ) <section> no travis ci configuration warnings <section> - hardware : ci - os : ubuntu <number> - versions : this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix travis - ci config warnings <section> build config validation ( from travis - ci ) - root : deprecated key sudo ( the key <code> has no effect anymore . ) language : unexpected sequence , using the first value ( c ) root : missing os , using the default linux <section> see <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , compiler warnings on mcp750 <allcaps> psp </allcaps> <section> fix # <number> patches for the mcp750 <allcaps> psp </allcaps> to avoid some compiler warnings that show up when building with strict flags . <section> build for mcp750 using default config and procedure , confirm warnings are fixed ( others still exist in other modules , however ) . <section> no impact to behavior . only fixes warnings . <section> - <allcaps> gsfc </allcaps> build host ( gs582w - cfelnx ) <section> joseph hickey , vantage systems , inc .",0.0
"mcp750 <allcaps> psp </allcaps> fails to build <section> building the current "" master "" branch for mcp750 yields the following build error : <code> <section> build "" master "" using standard procedure and default config . <section> build should succeed . <section> - <allcaps> gsfc </allcaps> mcp750 build machine ( gs582w - cfelnx ) <section> this is an error now due to the inclusion of <code> in the default build . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , remove local mcp750 header file <section> removed in favor of using cross - compiler provided header fix # <number> <section> steps taken to test the contribution : <number> . diff ' ed local file with cross - compiler version and they were identical <number> . switched to ppc - vxworks6 . <number> toolchain and built with cross compiler , no issues <section> none <section> - hardware : cfs cross - compiler pc - os : linux <number> - versions : master bundle w / this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove mcpx750 . h <section> mcpx750 . h does not belong in open source release . <section> remove file , real version gets picked up as part of include path for this platform cross - compiler toolset . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"allow out - of - tree psp paths <section> requiring a <allcaps> psp </allcaps> to always be defined inside the <allcaps> psp </allcaps> repository means holding a set of patches on top of the upstream version . this adds friction when updating to latest version . <section> at least initially , <code> should be introduced . it should be configurable and it should allow arbitrary paths to <allcaps> psp </allcaps> files .",2.0
"deprecated multiple "" success "" code responses <section> <allcaps> api </allcaps> ' s with multiple "" success "" codes are frequently mishandled <section> single success response , unique information should be passed back in parameters <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"parameter commanddata hides a global variable with the same name . [ lgtm ] <section> cfe_psp_start . c <code> <section> steps to reproduce the behavior : <number> . build against lgtm <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"improve consistency and reduce duplication in <allcaps> psp bsp </allcaps> implementation <section> see <url> where this ticket is to address item <number> to reduce code duplication in the <allcaps> psp </allcaps> ' s . <section> the <allcaps> cfe psp </allcaps> should be an extension of the <allcaps> osal bsp </allcaps> , not a replacement for it . the <allcaps> psp </allcaps> already defines a cfe_psp_main ( ) entry point for itself , and this can be invoked as a second - stage after os_application_startup to do the additional startup tasks required for <allcaps> cfe </allcaps> . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add travis . yml for cppcheck on psp / fsw <section> add cppcheck for fsw <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"<allcaps> psp </allcaps> cppcheck warning stricter flag <section> [ psp / fsw / mcp750 - vxworks / src / cfe_psp_exception . c : <number> ] - > psp / fsw / mcp750 - vxworks / src / cfe_psp_exception . c : <number> <url> inconclusive ) function ' cfe_psp_exceptionhook ' argument <number> names different : declaration ' pesf ' definition ' vpesf ' . [ psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> ] - > psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> <url> variable ' return_code ' is reassigned a value before the old one has been used . [ psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> ] - > psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> <url> variable ' return_code ' is reassigned a value before the old one has been used . [ psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> ] - > psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> <url> variable ' return_code ' is reassigned a value before the old one has been used . [ psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> ] - > psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> <url> variable ' return_code ' is reassigned a value before the old one has been used . [ psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> ] - > psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> <url> variable ' return_code ' is reassigned a value before the old one has been used . [ psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> ] - > psp / fsw / pc - linux / src / cfe_psp_memory . c : <number> <url> variable ' return_code ' is reassigned a value before the old one has been used . psp / fsw / pc - rtems / src / cfe_psp_exception . c : <number> <url> inconclusive ) the buffer ' taskname ' may not be null - terminated after the call to strncpy ( ) . psp / fsw / modules / eeprom_mmap_file / cfe_psp_eeprom_mmap_file . c : <number> <url> variable ' status ' is assigned a value that is never used . [ psp / fsw / shared / cfe_psp_module . h : <number> ] - > psp / fsw / shared / cfe_psp_module . c : <number> <url> inconclusive ) function ' cfe_psp_module_findbyname ' argument <number> names different : declaration ' modulename ' definition ' drivername ' . psp / fsw / mcp750 - vxworks / src / bsp - integration / cfesupport . c : <number> <url> the scope of the variable ' i ' can be reduced . psp / fsw / mcp750 - vxworks / src / bsp - integration / cfesupport . c : <number> <url> the scope of the variable ' cfnamefound ' can be reduced . psp / fsw / mcp750 - vxworks / src / bsp - integration / cfesupport . c : <number> <url> the scope of the variable ' tempfd ' can be reduced . psp / fsw / mcp750 - vxworks / src / bsp - integration / cfesupport . c : <number> <url> the scope of the variable ' compactflashname ' can be reduced . psp / fsw / shared / cfe_psp_module . c : <number> <url> the scope of the variable ' apiptr ' can be reduced . <section> resolve warning <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"cfe_psp_start timer race condition , leading to undef memory writes hi i am working with cfe in the context of <allcaps> nasa </allcaps> ' s icarus codebase we think we found an issue , in psp / fsw / pc - linux / src / cfe_psp_start . c , a timer is setup with this line : setitimer ( itimer_real , & timer , <allcaps> null </allcaps> ); the timer event ultimately calls cfe_es_perflogadd after 2 5 0 ms which starts making assignments on the perf object like so : perf - > metadata . invalidmarkerreported = <allcaps> true </allcaps> ; the problem is there is a time race condition in that cfe_es_main_function ’ s call to cfe_es_setupperfvariables has not yet initialized the perf object , depending on your execution speed . this is unlikely but if you are adding initialization code after setitimer it will likely lead to undefined behavior <section> steps to reproduce the behavior : after setitimer ( itimer_real , & timer , <allcaps> null </allcaps> ); add sleep ( <number> ); and undefined behavior will happen ( or nothing observable ) . it was crashing our lengthy <allcaps> dll </allcaps> initialization that we were running in the place of sleep ( <number> ); <section> no crash <section> n / a <section> - <number> bit intel - os : vmware workstation <number> running ubuntu <number> vm , host is windows <number> - versions current <section> n / a <section> reachable at <email> . this is not currently an issue for us but is probably worth reporting",0.0
"doxygen warning <section> psp / fsw / inc / cfe_psp_configdata . h : <number> : warning : the name ` cfe_psp_config . h ' supplied as the second argument in the \ file statement is not an input file <section> steps to reproduce the behavior : <number> . make usersguide <number> . see error <section> - hardware - ubuntu <number> - doxygen <date> , rc - <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"mcp750 - vxworks <allcaps> psp </allcaps> hardcodes core as "" cfe - core . o "" <section> cfe_psp_getcfetextsegmentinfo fails if cfe_module_name does not match what was run , currently hardcoded to "" cfe - core . o "" . could make lookup more general so it would not require hardcoded name . <section> steps to reproduce the behavior : <number> . build for vxworks , use core name other than cfe - core . o ( cfe - core . exe ) <number> . execute <number> . checksum of text segment will report as 0 xffff due to failed modulefindbyname on hardcoded cfe - core . o <section> checksum should work <section> see fsw / mcp750 - vxworks / src / cfe_psp_memory . c lines related to cfe_module_name <section> - hardware : mcp750 - os : vxworks6 . <number> - versions <number> bundle <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"update <allcaps> psp </allcaps> build options files to use add_definitions these had been setting the "" osal_c_flags "" variable and relied on <allcaps> osal </allcaps> preserving this value . however after [ cfs_osal : <number> ] this no longer gets preserved ( necessary because ut and real code may have different bsps / flags ) . using the cmake <code> mechanism is more appropriate and more reliable as it does not depend on the behavior of the <allcaps> osal </allcaps> build procedure .",0.0
"remove references to osalbool / boolean the c99 "" bool "" and related true / false identifiers should be used instead . this is related to [ cfs_osal : <number> ]",0.0
"update mcp750 - vxworks <allcaps> psp </allcaps> for cmake in order to build the vxworks image using cmake , a platform module and other various bits need to be added . this <allcaps> psp </allcaps> was previously only buildable with classic makefile .",0.0
"mcp750 uncommanded reset at startup an uncommanded reset periodically occurs ( ~ <number> in <number> startups ) at startup on the mcp750 using vxworks6 . <number> . this bug has likely been around for a long time ( <number> years or more ) , is only seen on a "" processor reset "" , and is likely related to something corrupted in memory that gets reused . reset type is based on a register , and after the reset , a "" power - on reset "" is performed and is always successful ( formats / clears the corrupted memory before use ) .",0.0
"remove "" enhanced_build "" macro the classic build is being deprecated , so the "" enhanced_build "" switch that indicated a cmake - based build is no longer required , as it is always the case . this is related to [ cfs_cfe : <number> ] in <allcaps> cfe </allcaps> .",0.0
"wrap / remove old backwards compatibility in cfe_psp_start comments say cfe_platform_cfg . h include is only for old makefiles , can this be removed now that classic build is deprecated ? remove backward compatibility for old <allcaps> osal </allcaps> - cfe_psp_setuplocal1hz and associated call .",0.0
wrap cfe_psp_subminor_version in deprecated ifndef fsw / pc - rtems / inc / psp_version . h has cfe_psp_subminor_version marked as only for backward compatibility .,0.0
"consistent cfe_psp_main implementation <allcaps> rtems psp </allcaps> hardcodes "" / cf / cfe_es_startup . scr "" , but mcp750 and pc - linux both use the cfe_platform_es_nonvol_startup_file . inconsistent implementations . from # <number> ( solved here ) : cfe_psp_start . c for mcp750 vxworks has startupfilepath as an input parameter to cfe_psp_main , but calls cfe_es_main with cfe_platform_es_nonvol_startup_file . confusing implementation . <repeated> looks like at least the pc - linux <allcaps> psp </allcaps> only uses cfe_platform_es_nonvol_startup_file ( but a different prototype ) .",2.0
"mcp750 <allcaps> psp </allcaps> ignores startupfilepath cfe_psp_start . c for mcp750 vxworks has startupfilepath as an input parameter to cfe_psp_main , but calls cfe_es_main with cfe_platform_es_nonvol_startup_file . confusing implementation . <repeated> looks like at least the pc - linux <allcaps> psp </allcaps> only uses cfe_platform_es_nonvol_startup_file ( but a different prototype ) .",2.0
"remove old <allcaps> mks </allcaps> flags in comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",0.0
update vxworks <allcaps> psp </allcaps> name ( no longer <number> ),0.0
"<allcaps> psp </allcaps> must not use os_printf ( ) before os_api_init in particular this is important when the "" utility task "" is in use ( soon to be standard ) . if <code> has not been called yet , then the data buffer to which <code> writes is not valid . the <allcaps> osal </allcaps> implementation does protect against this and it should drop the data , but <allcaps> psp </allcaps> should not be calling this function before the initialization . ( it happened to be ok if os_printf was just a wrapper around printf , but if os_printf is anything more , then it does not work ) . just use <code> or native c library calls before os_api_init ( ) .",0.0
update copyright and license info for end - of - summer release,0.0
resolve klocwork issues found in <number> . <number> see attached spreadsheet .,0.0
"add "" ramdisk startup script "" module this module adds a simple way for a <allcaps> psp </allcaps> to create the startup script file in a <allcaps> ramdisk </allcaps> , using embedded data linked at build time with <allcaps> cfe </allcaps> . intended for use on systems that have no persistent storage to hold this file .",2.0
add top level readme for open source release applies to both psp - <number> . 0 a and development branch .,2.0
update copyright and license for open source cfs framework release <number> . 0 a need to update / add copyright and license to apache <number> for open source release of <number> . 0 a .,0.0
remove tools directory directory clean - up,2.0
"remove non - <allcaps> ccb </allcaps> controlled psps sp0 and grut699 are not <allcaps> ccb </allcaps> controlled psps , remove them from development branch . note techdev branches were created to store the work ( both have diverged from current dev )",2.0
"improper strncpy to resettype in pc - linux <allcaps> psp </allcaps> static analysis noted that the following strncpy in <code> is potentially a problem : { { { strncpy ( commanddata - > resettype , "" po "" , <number> ); } } } this is because the string is a constant two character literal and the fixed copy size of "" <number> "" means that the null terminating byte will never get copied to the output buffer . in the <allcaps> psp </allcaps> , because the buffer had been zeroed out by an earlier memset ( ) call , the code still worked ok . still , this should be fixed , as the prior path to get to this function might not always be identical to the way it is today .",0.0
"cfe_psp_writetocds input buffer should be const the cfe_psp_writetocds ( ) <allcaps> api </allcaps> is not currently const - correct . the input buffer should be qualified as "" const "" but it is not currently so . the <allcaps> api </allcaps> prototype : { { { int32 cfe_psp_writetocds ( void * ptrtodatatowrite , uint32 cdsoffset , uint32 numbytes ) } } } should become : { { { int32 cfe_psp_writetocds ( const void * ptrtodatatowrite , uint32 cdsoffset , uint32 numbytes ) } } } in particular , this incorrect definition can cause a spurious compiler warning any time the data being written is "" const "" . in certain places , <allcaps> cfe </allcaps> calls this function with string literals , which trigger compiler warnings on some platforms / configurations .",0.0
"( pc - linux ) psp should not use signals ( 1 hz timer ) the <allcaps> psp </allcaps> 1 hz timer uses <allcaps> sigalarm </allcaps> and setitimer . there is a proposal ticket : <number> to use timer_create ( ) instead . this still has the problem of using asynchronous signal delivery . asynchronous signal delivery does not belong in realtime applications . we should remove this and instead us timerfd_create ( ) and create a thread to wait on the timer event . this tracks overruns as well as removes the danger of calling thread - unsafe functions in signal handlers ( which pc - linux does . ) in order to avoid the race condition specified in ticket : <number> the <allcaps> psp api </allcaps> should be changed for the user to register a callback rather than depeding on an external dependency from <allcaps> time </allcaps> . this would allow <allcaps> psp </allcaps> to start the timer relative to "" bootup "" and it would allow the user to avoid the race condition by registering itself with the timer . if we made it a blocking call the user could call from their own thread , it also would let the user control the priority of the thread receiving the timer event . i believe the point of the 1 hz timer is for platforms where there is a hardware timer that can be used with better granulatiry than os timers . if that is no longer true , then we should just get rid of this and use an os timer .",0.0
<allcaps> psp </allcaps> for sp0 - vxworks6 . <number> needs update for cfe v6 . <number>,0.0
"pc - linux64 create a <allcaps> psp </allcaps> for x86_64 on linux . this can serve as a development platform for code targeting the <allcaps> arm </allcaps> cortex - a53 , for example .",2.0
"update pc - rtems to support released <allcaps> rtems </allcaps> <number> the <code> <allcaps> psp </allcaps> was initially developed for <allcaps> cfe </allcaps> <number> using the development <allcaps> rtems </allcaps> branch ( pre - <number> ) . since then , <allcaps> rtems </allcaps> <number> has been released and upstream <allcaps> rtems </allcaps> development has moved on to <number> . there are some changes between the pre - release and final versions of <allcaps> rtems </allcaps> <number> . some functions being used were marked as deprecated . as part of testing <allcaps> cfe </allcaps> <number> release the <code> was re - validated against the latest <allcaps> rtems </allcaps> <number> . <number> official release . this ticket contains the necessary updates to pc - rtems <allcaps> psp </allcaps> to run with <allcaps> rtems </allcaps> <number> . <number> .",0.0
"fix <allcaps> psp </allcaps> to use updated names for macros and symbols <allcaps> cfe </allcaps> <number> addresses a number of naming convention inconsistencies , and many of the symbol names are updated to be clearer about the intent and purpose of the symbol . as part of <allcaps> cfe </allcaps> <number> a backward - compatibility mapping is also provided . this ticket is to do the corresponding updates to the <allcaps> psp </allcaps> to use the correct new - style name , and not rely on the backward compatibility macro anymore . this will need to be done before the compatibility names can be turned off .",0.0
"include <allcaps> psp </allcaps> unit test stub functions per the ut assert framework design , each component should include basic stubs for the same public <allcaps> api </allcaps> calls provided by the component . this adds those stubs for the <allcaps> psp </allcaps> .",2.0
<allcaps> psp api </allcaps> prototype fixes for warning cleanup some <allcaps> psp api </allcaps> calls were missing a <code> qualifier from their prototypes ( e . g . the memcpy wrapper ) which means that it triggered a compiler warning any time application code used these functions with a value that was correctly qualified as <code> . the prototype and all definitions of the function should be fixed .,0.0
"include <allcaps> psp api </allcaps> unit testing stubs in <allcaps> psp </allcaps> in the distributed ut assert framework , unit testing stubs for <allcaps> psp </allcaps> functions should be included with the <allcaps> psp </allcaps> .",2.0
"use timer_create ( ) instead of setitimer ( ) for pc - linux <allcaps> psp </allcaps> uses setitemer ( ) to call cfe_psp_timerhandler at 4 hz . setitemer ( ) does this by sending <allcaps> sigalrm </allcaps> to the process every <number> / 4 s . <allcaps> sigalrm </allcaps> ( and signals in general ) have no mechanism for distinguishing who created the signal , and handling the signal is tricky in multi - threaded environments . i would like to integrate a library but it also uses <allcaps> sigalrm </allcaps> ( also for timing ) and the two uses conflict . additionally , "" <allcaps> posix </allcaps> . <date> marks getitimer ( ) and setitimer ( ) obsolete "" and also has a number of issues regarding multiple timers and accuracy of the timers under load . see <url> i propose using timer_create ( ) and sigaction ( ) as demonstrated in the manual page : <url>",2.0
"( re ) create macosx <allcaps> psp </allcaps> the wiki includes <allcaps> osx </allcaps> as one of the target <allcaps> psp </allcaps> ' s , but it was removed a while ago . it should be re - created / updated .",2.0
"missing <allcaps> psp api </allcaps> document an <allcaps> api </allcaps> reference document is needed and should be provided . see <allcaps> osal api </allcaps> document for reference however , it is highly recommended to create this document via doxygen .",1.0
"mcp750 causes ces1702 . <number> and ces1703 . <number> requirement failures on vxworks <number> although the mcp750 vxworks <allcaps> psp </allcaps> directory is named "" mcp750 - vxworks6 . <number> "" , this implementation should support all <number> . x versions of vxworks . it was found the cfe_psp_setdefaultexceptionenvironment function defined in cfe_psp_exception . c does not set all the required flags in order to produce a task restart following a <allcaps> cpu </allcaps> or float point exception produced via task running under <number> . the recoverable interrupt flag ( _ppc_msr_ri ) is missing in the call to vxmsrset . it was recommended by windriver to update how we setup the default exception environment using the vxmsrget call . the following code will resolve the issue in vxworks <number> and will also not affect <number> from producing the desired behavior : vxmsrset ( vxmsrget ( ) | _ppc_msr_fe0 | _ppc_msr_fe1 | _ppc_msr_ee | _ppc_msr_fp | _ppc_msr_me | _ppc_msr_dr ) ; vxfpscrset ( vxfpscrget ( ) | _ppc_fpscr_ve | _ppc_fpscr_oe | _ppc_fpscr_ni | _ppc_fpscr_ze ) ; vxfpscrset ( vxfpscrget ( ) | _ppc_fpscr_xe | _ppc_fpscr_ue );",2.0
"cfe_psp_gettime loses resolution in conversion to microseconds ( <allcaps> gsfc dcr </allcaps> <number> ) there ' s a ' bug ' in the implementation of the mcp750 / vxworks <allcaps> psp </allcaps> which causes the loss of timing resolution in the function cfe_psp_gettime ( ) . for example : { { { void cfe_psp_gettime ( os_time_t * localtime ) { uint32 deccount ; /* reads the time from the hardware register , then converts it * into usable seconds and microseconds */ syspciread32 ( 0 xfc0011c0 , ( uint32 *)( & deccount ) ); deccount = deccount & 0x 7 fffffff ; deccount = ( ( uint32 ) 0x0 d6937e5 ) - deccount ; localtime - > seconds = deccount / <number> ; deccount = deccount % <number> ; localtime - > microsecs = ( deccount / <number> ) * <number> ; }/* end cfe_psp_getlocaltime */ } } } in this case , ( deccount / <number> ) * <number> is performed as an integer calculation ( as deccount and localtime - > microsecs are integers ) , basically reducing resolution from microseconds ( which this function can calculated from fractions of microseconds ) to miliseconds . <allcaps> note </allcaps> : <allcaps> gsfc </allcaps> ' s rad750 version has a similar calculation ( ( deccount / <number> ) * <number> ) should this be changed to something like ( for mcp750 ) : { { { localtime - > microsecs = ( uint32 ) ( ( ( ( double ) deccount ) / <number> ) * <number> ); } } }",0.0
add cfe_psp_getlocalmet and cfe_psp_setlocalmet <allcaps> api </allcaps> functions ( <allcaps> gsfc dcr </allcaps> <number> ) these functions are called by the cfe / <allcaps> time </allcaps> subsystem and were never implemented .,2.0
"add c + + support in <allcaps> psp </allcaps> header files ( <allcaps> gsfc dcr </allcaps> <number> ) to support c + + based applications , the <allcaps> psp </allcaps> header files need to have the following code : in the beginning of each header file : <hashtag> if def </hashtag> __cplusplus extern "" c "" { <hashtag> end if </hashtag> at the end of each header file : <hashtag> if def </hashtag> __cplusplus } <hashtag> end if </hashtag>",2.0
add <allcaps> psp api </allcaps> to return startup path of cfe ( <allcaps> gsfc dcr </allcaps> <number> ) <allcaps> apl </allcaps> has requested a <allcaps> psp api </allcaps> function to return the startup path of the cfe . this will allow them to load tables and applications from the same location the cfe was loaded from without having to use absolute / full paths . <allcaps> apl </allcaps> has prototyped this and is considering its use on solar probe plus . overall description of the changes : cfe_psp_start . c : new function void cfe_psp_parseandsavestartuppath ( char * startfilepath ) ; add storage for strings : startup file full path and filename startup path startup filename ( excluding path ) in cfe_psp_main ( ) call new function with the string used to pass into cfe_es_main ( ) inc / cfe_psp . h new <allcaps> api </allcaps> prototype uint32 cfe_psp_getstaruppath ( char * path ) cfe_psp_support . c new <allcaps> api </allcaps> definition,2.0
"consider adding the vxworks <allcaps> rtp </allcaps> / memory protected <allcaps> psp </allcaps> ( <allcaps> gsfc dcr </allcaps> <number> ) add the <allcaps> psp </allcaps> and startup manager code for the vxworks <allcaps> rtp </allcaps> implementation . this was used in an <allcaps> apl </allcaps> / <allcaps> gsfc irad </allcaps> to run the cfe within a memory protected process . using the startup manager , more than one instance of the cfe can be run on the same processor . at a minimum this should be added to the "" <allcaps> psp </allcaps> technology "" branch .",2.0
"preserve reserved memory on a soft power - on reset ( <allcaps> gsfc dcr </allcaps> <number> ) the default action on all <allcaps> psp </allcaps> implementations is to clear the reserved memory on a soft power - on reset . this is where the cfe stores the exception and reset log information . on both the <allcaps> gpm </allcaps> and <allcaps> mms </allcaps> missions , the <allcaps> psp </allcaps> ' s were customized to preserve the reserved memory on most soft power - on resets . the <allcaps> psp </allcaps> implementations should be changed to preserve this memory where possible . this may not be possible for all <allcaps> psp </allcaps> , but at a minimum could be done for the mcp750 target . attached is a sample of how the <allcaps> psp </allcaps> was changed on <allcaps> gpm </allcaps> for their rad750 target .",2.0
"add <allcaps> api </allcaps> to return <allcaps> eeprom </allcaps> write enable / disable status ( <allcaps> gsfc dcr </allcaps> <number> ) the <allcaps> psp </allcaps> should provide an <allcaps> api </allcaps> to allow a caller to retrieve the write enable / disable status of a selected bank of <allcaps> eeprom </allcaps> ( or alternatively , the status of all available banks ) . this would allow this information to be made available in telemetry .",2.0
"move <allcaps> psp </allcaps> timer init earlier , prior to module initialization <allcaps> psp </allcaps> modules may require timers . to support this , the <allcaps> psp </allcaps> timer initialization should be prior to initialization of the module list .",2.0
pass module id as parameter to <allcaps> psp </allcaps> module init function some modules can benefit from having a unique identifier they can use to allocate resources . this is a simple change to add .,2.0
"pc - <allcaps> rtems </allcaps> fixes from psp - <number> / cfe - <number> testing during testing of psp - <number> / cfe - <number> candidate , found a few things in need of attention in the pc - rtems <allcaps> psp </allcaps> .",0.0
"use ( foo ) , not & ( foo [ <number> ] ) , where appropriate in a number of places , code jumps through extra hoops to take the address of the first element of an array , rather than just allowing the array name to gracefully decay into the pointer . where just using the array name is more correct , we should simplify the code to use it .",2.0
"mcp750 - vxworks - memory variables should be "" cpuaddr "" type there are several variable instances in the cfe_psp_memory . c source file in the mcp750 - vxworks implementation that define memory address variables as a uint32 type . these definitions need to be updated to use the platform defined "" cpuaddr "" type .",0.0
printf format codes vs argument types resolve a number of mismatches between printf format string conversions and the data types of the parameters . from cppcheck : { { { psp / fsw / grut699 - vxworks6 / src / cfe_psp_start . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c : <number> : warning : %x in format string ( no . <number> ) requires ' unsigned int ' but the argument type is ' unsigned long ' . } } },0.0
"<allcaps> psp </allcaps> build fails for mcp750 greg limes reports the following errors he got with "" make - k "" and notes because some files do not compile , the build does not attempt to build some others , so this may not be a complete list of all the actual errors : ( none of this is *hard* to fix . <repeated> just frustating when i only get short snips of time to push on this issue . <repeated> ) psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_start . c : <number> : error : conflicting types for ' cfe_psp_main ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_main ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_start . c : <number> : error : conflicting types for ' cfe_psp_main ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_main ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getresetarea ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getresetarea ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getresetarea ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getresetarea ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getuserreservedarea ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getuserreservedarea ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getuserreservedarea ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getuserreservedarea ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getvolatilediskmem ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getvolatilediskmem ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getvolatilediskmem ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getvolatilediskmem ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getkerneltextsegmentinfo ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getkerneltextsegmentinfo ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getkerneltextsegmentinfo ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getkerneltextsegmentinfo ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getcfetextsegmentinfo ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getcfetextsegmentinfo ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getcfetextsegmentinfo ' psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getcfetextsegmentinfo ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_exception . c : <number> : error : conflicting types for ' cfe_es_processcoreexception ' cfe / fsw / cfe - core / src / inc / cfe_es . h : <number> : error : previous declaration of ' cfe_es_processcoreexception ' was here psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_exception . c : <number> : error : conflicting types for ' cfe_es_processcoreexception ' cfe / fsw / cfe - core / src / inc / cfe_es . h : <number> : error : previous declaration of ' cfe_es_processcoreexception ' was here also matt grubb reports the following problems / fixes that were made in his environment to get the mcp750 build to compile : <number> . psp_version . h needed updated with the _impl definitions as i found in pc - linux <number> . cfe_psp_exception . c , cfe_psp_memory . c , and cfe_psp_start . c all needed updates for new function definitions in cfe_psp . h <number> . the version . cmake file creates a "" version . h "" file when building . this is a filename required by vxworks , so i renamed the file in the script to cmakeversion . h and changed the target_config to include cmakeversion . h <number> . added a build_options . cmake file to the mcp750 <allcaps> psp </allcaps> <number> . created a toolchain file for the mcp750 on vxworks <number> in proj_defs",0.0
n2x <allcaps> psp </allcaps> development branch for the n2x quad leon4 development board need to branch off trac - <number> - ut699 - improvements since it has all of the ut699 updates plus a good linux psp from trac - <number>,2.0
fix sp0 <allcaps> psp </allcaps>,0.0
"additional ut699 changes from trac - <number> ticket for the purpose of building a change set , for review , from the existing trac - <number> ticket .",0.0
"<allcaps> psp </allcaps> build fails for grut699 steve duran reports that he is encountering errors in the <allcaps> grut </allcaps> - <number> <allcaps> psp </allcaps> as follows : { noformat } / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getresetarea ' / home / sduran / cop_cfs_workspace / psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getresetarea ' was here / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : in function ' cfe_psp_getresetarea ' : / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : warning : cast increases required alignment of target type / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : at top level : / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getuserreservedarea ' / home / sduran / cop_cfs_workspace / psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getuserreservedarea ' was here / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : in function ' cfe_psp_getuserreservedarea ' : / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : warning : cast increases required alignment of target type / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : at top level : / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getvolatilediskmem ' / home / sduran / cop_cfs_workspace / psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getvolatilediskmem ' was here / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : in function ' cfe_psp_getvolatilediskmem ' : / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : warning : cast increases required alignment of target type / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : at top level : / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getkerneltextsegmentinfo ' / home / sduran / cop_cfs_workspace / psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getkerneltextsegmentinfo ' was here / home / sduran / cop_cfs_workspace / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c : <number> : error : conflicting types for ' cfe_psp_getcfetextsegmentinfo ' / home / sduran / cop_cfs_workspace / psp / fsw / inc / cfe_psp . h : <number> : error : previous declaration of ' cfe_psp_getcfetextsegmentinfo ' was here { noformat } these appear to be due to the changes to some of the <allcaps> psp </allcaps> functions , to go from using <code> to indicate where to store a pointer , to using <code> which is slightly better . i have a place i am currently building <allcaps> grut </allcaps> - <number> vxworks images , so i should be able to make this change and verify that it builds . this should be able to get done , tested , and integrated in time to be part of the next <allcaps> psp </allcaps> release ( <allcaps> psp </allcaps> <number> ) .",0.0
trick <allcaps> psp </allcaps> there is growing interest in being able to use the trick <allcaps> osal </allcaps> / <allcaps> psp </allcaps> so that a <allcaps> cfs </allcaps> build can be executed within a trick simulation - basically allowing developers to fly unmodified <allcaps> fsw </allcaps> within an all sw simulation environment on their desktop . the approach was used extensively and successfully on the morpheus project . the trick <allcaps> osal </allcaps> / <allcaps> psp </allcaps> were developed a few years ago . some work will be necessary to get them up and running again with the latest <allcaps> cfs </allcaps> .,2.0
"apexsim for arinc653 posix simulator effort has been made at <allcaps> jsc </allcaps> to build an "" apexsim "" which is a arinc653 os simulator that runs in <allcaps> posix </allcaps> . the tool was development by guy de carufel and mathew benson . it is not complete , but should be a good starting point for arinc653 development . the arinc modules that have been implemented are fully tested . it can be a good resource for any arinc653 <allcaps> osal </allcaps> development . the arinc653 <allcaps> osal </allcaps> timer has been tested with this tool . eventually , this could be adapted into a <allcaps> psp </allcaps> layer . here are things missing : - add partition scheduling for multi - partition build - add missing modules ( queuing port , events , error handler , blackboard ) - <allcaps> xml </allcaps> parsing tool to turn <allcaps> xml </allcaps> config file into apexsim tables - documentation - develop a <allcaps> psp </allcaps> layer",2.0
"volume table requires user modification the volume table definition is source file that is included with each <allcaps> psp </allcaps> implementation . the implementation source code files are not intended to be modified . the volume table however , requires user modification to specify the volumes and their physical locations specific to a project / mission . adding a volume table macro is a simple solution to allow volume information to be specified at build time .",0.0
"allow c99 code in <allcaps> psp </allcaps> . update compiler flags to allow c99 code to be used everywhere in <allcaps> psp </allcaps> . just removing <code> tells <allcaps> gcc </allcaps> to allow <allcaps> gnu </allcaps> extensions in the source code , which gets us most of what we want from c99 but not actually everythying . using <code> tells <allcaps> gcc </allcaps> that the code is expected to be <allcaps> incits iso </allcaps> / <allcaps> iec </allcaps> <number> <time> <number> ( aka c99 ) , and any other extensions as explicitly requested in the code .",0.0
update <allcaps> psp </allcaps> version number for <number> . <number> release all <allcaps> psp </allcaps> version . h header files need to be updated from version <number> . <number> to <number> . <number> for the release . note : this will be the last release that uses the old versioning scheme where all <allcaps> psp </allcaps> implementation version header files are updated with the same version number and no version exists for the shared code or <allcaps> api </allcaps> ' s .,2.0
standardize version numbering ( in <allcaps> psp </allcaps> ) bring version number management within <allcaps> osal </allcaps> into line with the cfs standards documented at <url>,0.0
"update mcp750 - vxworks6 . <number> cfesupport . c to enforce cf name the cf device is a rawfs device for the first part of the disk that contains the <allcaps> mbr </allcaps> and some unused space . mounting the device via vxworks <number> resulted in the device name of cf : <number> . this behavior has changed with newer versions of vxworks where the device name may result in cf : <number> or cf : <number> depending on where the device partition is made . a device name of cf : <number> will require the default <allcaps> psp </allcaps> volume table to be updated . to avoid changes to the <allcaps> psp </allcaps> volume table the attached kernel code make an update to the cfe_psp_initflashdisk function to look for a valid cf <kiss> ( where x is <number> - <number> ) and then if it finds one that is not <number> , it will create another device for <number> . this wastes a small amount of ram but is otherwise harmless . also the disk is mounted in buffered mode instead of sync mode .",2.0
"rename "" mcp750 - vxworks6 . <number> "" folder the mcp750 - vxworks6 . <number> implementation is not specific to vxworks version <number> . this implementation will work with other vxworks <number> versions up to vxworks <number> . the folder should be renamed to mcp750 - vxworks6 to avoid any confusion .",0.0
"should <allcaps> psp </allcaps> have byte - swapping utilities for endian conversions ? we are constantly running into code needing to swap bytes in <number> - and <number> - bit data for big - endian data on little - endian platforms and i think it might be a convenience if <allcaps> cfs </allcaps> provided byte - swapping utilities . ( theoretically , some platforms may have the ability to perform byte swaps more efficiently using <allcaps> cpu </allcaps> instructions or the like . ) this may be more appropriately housed in <allcaps> osal </allcaps> or elsewhere . <allcaps> cfs </allcaps> code should be reviewed for redundancies such as the fs code has cfe_fs_byteswapuint32 that could utilize a more generic function . ( i can take on writing the patch once i receive concurrence that this is a wise update and the right location to house the code . )",2.0
"simplify function pointer manipulations there are a number of places within the <allcaps> cfs </allcaps> projects where the usage of function pointers is somewhat obfuscated by the inclusion of redundant operators . removing those operators can improve the clarity of the code . the redundancies are based on code that , when written , did not properly base itself on the following aspects of function pointers in the c programming language . <number> . function names decay into function pointers in the same way that array names decay into pointers to their first elements , which means that an <code> operator is redundant when setting a pointer to point at a function . for the classical example of this , see most <code> examples , where no <code> is applied to the comparison function when passing it as the last argument , which has type ' ' pointer to function . <repeated> ' ' <number> . the function call operator <code> ' ' args ' ' <code> operates on a function pointer - - so every function call you see actually is invoking the above decay semantics . this means that the <code> operator is ' ' not ' ' needed when calling a function via a function pointer . happily , this also often means that you also do not need an extra level ( or two ? ! <repeated> ) of parentheses to asure that the <code> is applied to the function pointer and not to the return value . <number> . calling a function pointed to by a structure member is a very common operation , and with the above in mind , note that there is no parsing or evaluation order ambiguity ; no extra parentheses are required to assure that <code> and <code> and the function call operator are evaluated in the proper order . my task - - embodied in this ticket - - is to seek out cases in the <allcaps> psp </allcaps> source code where redundant operations are applied to function pointers ( at assignment sites ' ' and ' ' at call sites ) , and provide recommended changes to improve clarity . specific examples will accumulate in the comments below . ticket to be closed when my scan of the project is complete , and all call sites have been resolved ( whether the resolution is to improve them now , file a ticket for later improvement , or where we will be leaving the code unchanged ) . ' ' ( this also makes the code robust against the rare but troublesome case where an external function changed from a function to a function pointer . <repeated> we may never do this , but it is always good to foster good code hygene . ) ' '",2.0
"<allcaps> sparc </allcaps> leon3 memory alignment sensitivity and handling in our cfs_tst / ut699_vxworks6 . <number> build , i have noted that there are still cfe / osal / psp build warnings ( <number> ) . on ut699 / vxworks , they are almost all memory alignment warnings . "" warning : cast increases required alignment of target type "" i understand why we are getting theses , and only on this processor ( not linux or <allcaps> ppc </allcaps> - based processors - for these ones , either the processor or compiler will compensate for unaligned accesses ) . the <allcaps> sparc </allcaps> processor is sensitive to memory alignment ( in fact neither the processor or compiler will align for you , it just will crash and generate a memory alignment exception ) . it is a trade between hardware and compiler complexity and performance . i enabled the mem align warning in the compiler options . i have not looked at every single one of these warning cases , but most are something like char * ptr to a buffer or just a char buf [ <number> ] , then later there is code that casts a uint32 pointer to the buffer to access it - this is where you get the warning . the char * or char buf could end up on an odd address , the compiler does not guarantee allocation to an even address . however , in all of these cases , it has to currently be allocating to even , <number> - bit aligned addresses ( which is most efficient for memory access ) . we need to look at these warning cases ( these exit not only in the <allcaps> psp </allcaps> but in the cfe and <allcaps> osal </allcaps> ) and see if there is a better way to implement . the other and probably better option is to develop an exception handler that would trap the alignment exception and then still perform the access , there is a small performance hit if / when this occurs , but it beats crashing any day .",2.0
"change * to * * in cfe_psp_memory . c for improved efficiency consider changing 1 st argument to be a double pointer of type void , and not a single pointer of type void . then a straight assignment can be used in place of memcpy ( used to copy <number> bytes ) . this will be an <allcaps> api </allcaps> change . { { { int32 cfe_psp_writetocds ( void * ptrtodatatowrite , uint32 cdsoffset , uint32 numbytes ) } } } to { { { int32 cfe_psp_writetocds ( void * * ptrtodatatowrite , uint32 cdsoffset , uint32 numbytes ) } } } need to assess this proposed change . why was it implemented the way it was originally ?",2.0
"use more accurate return codes in cfe_psp_memory . c , original code returns os_error ( - <number> ) error code , modified at some point to return cfe_psp_error ( - <number> ) , but really should more acurratley use cfe_psp_invalid_pointer ( - <number> ) . however , this would basically change the <allcaps> api </allcaps> though by returning - <number> instead of - <number> . need to determine not sure how well any calling code checks return value and assess the impacts of this potential change .",2.0
"unld <allcaps> psp </allcaps> core unit test causes a processor exception load and run test , then unload , and load again to run test a 2 nd time and redirect output to a file results in an exception on the 2 nd load . this issue is only see in the way the unit tests were trying to be run . it is not any sort of system runtime issue . - > unld "" core_ut . o "" value = <number> = 0x0 - > ld < core_ut . o grlib > run <number> iu in error mode ( tt = 0x 2 b ) 6 5 2 c35f8 8 0 a06063 cmp % g1 , <number> grlib > hist <phone> ahb read , mst = <number> , size = <number> [ 6 1 1 7 d400 <number> ] <phone> ahb read , mst = <number> , size = <number> [ <number> <number> ] <phone> ahb read , mst = <number> , size = <number> [ <number> 0 0 0 0 0 0 8 e ] <phone> ahb write , mst = <number> , size = <number> [ <number> 0 0 0 0 0 0 ae ] <phone> ahb read , mst = <number> , size = <number> [ <number> <number> ] <phone> 6 5 2 c35d8 ld [ % g1 ] , % g1 [ <number> ] <phone> 6 5 2 c35dc add % g1 , <number> , % g2 [ <number> ] <phone> 6 5 2 c35e0 sethi % hi ( 0x0 ) , % g1 [ <number> ] <phone> 6 5 2 c35e4 or % g1 , % g1 [ <number> ] <phone> ahb write , mst = <number> , size = <number> [ <number> 0 0 0 0 0 0 ee ] <phone> 6 5 2 c35e8 st % g2 , [ % g1 ] [ <number> <number> ] <phone> 6 5 2 c35ec sethi % hi ( 0x0 ) , % g1 [ <number> ] <phone> 6 5 2 c35f0 or % g1 , % g1 [ <number> ] <phone> ahb write , mst = <number> , size = <number> [ <number> <number> ] <phone> 6 5 2 c35f4 ld [ % g1 ] , % g1 [ <number> ] <phone> ahb read , mst = <number> , size = <number> [ 6 5 2 c3600 <number> ] <phone> ahb read , mst = <number> , size = <number> [ 6 5 2 c3604 <number> ] <phone> 6 5 2 c35f8 cmp % g1 , <number> [ trapped ] grlib > reg <allcaps> ins locals outs globals </allcaps> <number> : <number> f3401fc4 6 1 2 3 e878 <number> <number> : <number> 6 5 2 c35c8 6 1 2 3 eb10 <number> <number> : 6 1 2 3 eb10 6 5 2 c35cc <number> <number> <number> : 0 0 0 0 0 0 0 a <number> <number> <number> <number> : 6 5 2 c7fc8 <number> <number> <number> <number> : 0 0 0 0 0 0 0 a <number> <number> <number> <number> : <number> 6 1 1 b88b8 6 1 1 7 5 0 e8 <number> <number> : 6 0 1 3 fb3c 6 0 1 cc000 6 0 0 acee4 <number> psr : f3401fe4 wim : <number> tbr : <number> y : <number> pc : 6 5 2 c35f8 cmp % g1 , <number> npc : 6 5 2 c35fc ble 0x 6 5 2 c363c",0.0
"update grut699 - vxworks6 cfe_psp_start . c per white box unit testing results during white box testing the following issue was identified with the grut699 - vxworks6 version of cfe_psp_start . c * in cfe_psp_getrestarttype , the input pointer is not checked for <allcaps> null </allcaps> prior to dereferencing it . issue identified during # <number> white box testing , commit : [ changeset : ad4e7c5f ]",0.0
update grut699 - vxworks6 cfe_psp_timer . c per white box unit testing results during white box testing the following issue was identified with the grut699 - vxworks6 version of cfe_psp_timer . c * cfe_psp_get_timebase - possible divide by zero in the calculation : lower /= systimestampfreq ( ) / 1 0 0 0 0 0 0 ul if systimestampfreq ( ) returns a number less than 1 0 0 0 0 0 0 ul . issue identified during # <number> white box testing commit : [ changeset : eade737 ],0.0
"limit the calculated results in cfe_psp_watchdogset cfe_psp_watchdogset computes a new value to set the watchdog timer to , but does not limit the results to the specified min and max values ( cfe_psp_watchdog_min and cfe_psp_watchdog_max ) . the calculation is also not protected from overflowing the possible range , so it is possible to get a much different result than expected . issues identified during # <number> white box testing commit <sad> changeset : 9 9 8 ebe4a ]",0.0
"cfe_psp_memrangeset ( ) description error cfe_psp_memrangeset ( ) in cfe_psp_memrange . c has a comment error on the memorytype argument that could be misleading . cfe_psp_memrangeset ( ) validates against cfe_psp_mem_ram and cfe_psp_mem_eeprom types and errors out with any other type . ( this is consistent with the cfe_psp_memvalidaterange ( ) implementation . ) but the source file comments for cfe_psp_memrangeset ( ) have ( cfe_psp_memrange . c , line <number> <sad> { { { < . <repeated> snip . <repeated> > * * * * parameters : * * rangenum - - a <number> bit integer ( starting with <number> ) specifying the memorytable entry . * * memorytype - - the memory type to validate : cfe_psp_mem_ram , cfe_psp_mrm_eeprom , or cfe_psp_mem_any * * address - - a <number> bit starting address of the memory range < . <repeated> snip . <repeated> > } } } that last "" or cfe_psp_mem_any "" is incorrect .",0.0
"update grut699 - vxworks6 cfe_psp_memory . c per white box unit testing results during white box testing a number of functions were identified which return cfe_psp_error rather than cfe_psp_invalid_pointer for <allcaps> null </allcaps> pointers . functions include : cfe_psp_getcdssize cfe_psp_writetocds cfe_psp_readfromcds cfe_psp_getresetarea cfe_psp_getuserreservedarea cfe_psp_getvolatilediskmem cfe_psp_getkerneltextsegmentinfo cfe_psp_getcfetextsegmentinfo other issues : several functions take two pointer arguments , but only check if one is a <allcaps> null </allcaps> pointer . should check calling functions to see if changes to the return values may potentially cause issues . issues identified during # <number> white box testing commit : [ changeset : 6 1 2 f00f3 ]",0.0
"cfe_psp_memcpy does not handle overlapping ranges <section> in cfe_psp_memutils . c does not contain any logic for handling the case where the source and destination memory regions overlap . the current grut699 - vxworks6 implementation currently calls the c memcpy ( ) , which is documented to have undefined behavior in this case .",0.0
"cfe_psp_memcpy / set not checking for <allcaps> null </allcaps> pointer args in the psp / fsw / shared / cfe_psp_memutils . c , the <section> do not check for null pointer arguments . if a null pointer is passed then a segfault occurs . both function signatures already have a return value for an error code . <section> <section> where none of them check the return value . it appears that either the <allcaps> psp </allcaps> return value was added later than most of the client development or client developers just assumed a c - like behavior with no return values .",0.0
"cfe_psp_memread / write ( ) not checking for <allcaps> null </allcaps> pointer args in the psp / fsw / shared / cfe_psp_ram . c , we have cfe_psp_memread8 / <number> / <number> and cfe_psp_memwrite8 / <number> / <number> functions . they all take memory addresses as uint32 values and the * read functions take a pointer . all of these addresses & pointers are happily dereferenced without checking for a null pointer . ( the - <number> and - <number> read / write functions do check for alignment and error out . ) some spot - checks revealed a larger problem : some clients that call these functions do not look at the return value . cfe_psp_memread8 ( <sad> the <allcaps> cfs </allcaps> <section> does not check the status . cfe_psp_memwrite8 ( <sad> the <allcaps> cfs </allcaps> <section> does not check the return value in <number> call sites ( mm_load . c and mm_mem8 . c ) . similar results for cfe_psp_memread16 ( ) , cfe_psp_memwrite16 ( ) , cfe_psp_memread32 ( ) , and cfe_psp_memwrite32 ( ) . recommendation : since these return an error code already , these functions should check for null pointers / addresses . but es and mm should be fixed to properly check the return codes first .",0.0
"<allcaps> psp api </allcaps> for onboard devices this has been split off from # <number> <allcaps> psp </allcaps> needs to define some common <allcaps> api </allcaps> / framework for communication with onboard devices . this would present a consistent <allcaps> api </allcaps> so <allcaps> cfs </allcaps> code can be better abstracted from the hardware implementation details . for instance , if a serial controller device is present on the board , it would speak the same protocol regardless of whether the physical devices is connected over rs232 , rs485 , an <allcaps> lvds </allcaps> link , or some other link . however the configuration <allcaps> api </allcaps> and the means to communicate over these different types of interfaces differs . some boards might have dedicated hardware channels , others might "" bit bang "" with <allcaps> gpio </allcaps> , etc . the <allcaps> psp </allcaps> should abstract this difference and present a similar <allcaps> api </allcaps> so the <allcaps> cfs </allcaps> code that talks to these devices can be portable . the standardization work being performed by the <allcaps> ccsds sois </allcaps> working group may be relevant here as well .",2.0
"add sp0 <allcaps> psp </allcaps> add the aitech sp0 <allcaps> psp </allcaps> developed at <allcaps> jsc </allcaps> . it is still under development , but the basics appear to work . - watchdog and exception handling code not done yet",2.0
"fix "" utbsp . h "" not found failure when building on some platforms testing on other platforms revealed an issue regarding the include path for the utassert header files . in particular , the latest ubuntu ( <number> ) failed to build due to "" utbsp . h "" not being found . ( this may be related to the more recent cmake v3 . <number> )",0.0
"update "" beaglebone - linux "" <allcaps> psp </allcaps> larc is contributing a beagle bone linux <allcaps> psp </allcaps> , which is based on the <allcaps> cfs </allcaps> <number> . <number> version of the pc - linux <allcaps> psp </allcaps> . it is now present in the cfs_psp project tree under the "" ic - larc - beaglebone - linux "" branch on babelfish , based at the <number> . <number> release . this <allcaps> psp </allcaps> does not yet have the following updates to bring it up to match the development versions of the other psps : # <number> enhanced build script # <number> - change uint32 to cpuaddr # <number> - dependency management # <number> compatibility with <allcaps> cfe </allcaps> "" const "" <allcaps> api </allcaps> # <number> - clean up build macros",2.0
"outdated license ( ? ) many files in the <allcaps> psp </allcaps> ( and one in the <allcaps> cfs </allcaps> ) contain a file license header that seems to be outdated ? it does not reference the <allcaps> nosa </allcaps> , and seems to include restrictions that are in conflict with the <allcaps> nosa </allcaps> ( see the 2 nd paragraph ) . note , working with the sourceforge cfe release . an example : { { { * * copyright ( c ) <number> - <number> , united states government as represented by the * * administrator of the national aeronautics space administration . * * all rights reserved . this software ( cfe ) was created at <allcaps> nasa </allcaps> goddard * * space flight center pursuant to government contracts . * * * * this software may be used only pursuant to a united states government * * sponsored project and the united states government may not be charged * * for use thereof . } } } a quick grep showed these files : { { { find . - type f - exec grep - li "" this software may be used only "" { } \; . / <allcaps> cfs </allcaps> / hs / fsw / unit_test / cfe_psp_timer . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / inc / psp_version . h . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / inc / cfe_psp_config . h . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_support . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_start . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_ssr . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_voltab . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_exception . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_watchdog . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_timer . c . / cfe / psp / fsw / mcp750 - vxworks6 . <number> / src / cfe_psp_memory . c . / cfe / psp / fsw / inc / cfe_psp . h . / cfe / psp / fsw / arm - linux / inc / psp_version . h . / cfe / psp / fsw / arm - linux / inc / cfe_psp_config . h . / cfe / psp / fsw / arm - linux / src / cfe_psp_support . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_start . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_ssr . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_voltab . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_exception . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_watchdog . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_timer . c . / cfe / psp / fsw / arm - linux / src / cfe_psp_memory . c . / cfe / psp / fsw / pc - cygwin / inc / psp_version . h . / cfe / psp / fsw / pc - cygwin / inc / cfe_psp_config . h . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_support . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_start . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_ssr . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_voltab . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_exception . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_watchdog . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_timer . c . / cfe / psp / fsw / pc - cygwin / src / cfe_psp_memory . c . / cfe / psp / fsw / mac - osx / inc / psp_version . h . / cfe / psp / fsw / mac - osx / inc / cfe_psp_config . h . / cfe / psp / fsw / mac - osx / src / cfe_psp_support . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_start . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_ssr . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_voltab . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_exception . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_watchdog . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_timer . c . / cfe / psp / fsw / mac - osx / src / cfe_psp_memory . c . / cfe / psp / fsw / pc - linux / inc / psp_version . h . / cfe / psp / fsw / pc - linux / inc / cfe_psp_config . h . / cfe / psp / fsw / pc - linux / src / cfe_psp_support . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_start . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_ssr . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_voltab . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_exception . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_watchdog . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_timer . c . / cfe / psp / fsw / pc - linux / src / cfe_psp_memory . c . / cfe / psp / fsw / grut699 - vxworks6 / inc / psp_version . h . / cfe / psp / fsw / grut699 - vxworks6 / inc / cfe_psp_config . h . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_support . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_start . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_ssr . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_voltab . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_exception . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_watchdog . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_timer . c . / cfe / psp / fsw / grut699 - vxworks6 / src / cfe_psp_memory . c . / cfe / psp / fsw / mcf5235 - rtems / inc / psp_version . h . / cfe / psp / fsw / mcf5235 - rtems / inc / cfe_psp_config . h . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_support . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_start . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_ssr . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_voltab . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_exception . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_watchdog . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_timer . c . / cfe / psp / fsw / mcf5235 - rtems / src / cfe_psp_memory . c } } }",0.0
"<allcaps> psp </allcaps> startup code should confirm that os_api_init worked if the { { { os_api_init ( ) } } } call fails for some reason , it means that the <allcaps> osal </allcaps> services are not available . this can result in some very strange and hard - to - debug situations , if it gets so far as to use underlying os primitives that have not been initialized . proceeding to call <allcaps> cfe </allcaps> main after a os_api_init failure is undefined and almost certain to deadlock the process . it would be preferable to call the <allcaps> psp </allcaps> panic function to make the initialization failure obvious .",0.0
"race condition : <allcaps> psp </allcaps> timer callbacks are set up and started before cfe_time is running this was the point brought up by chris monaco during today ' s <allcaps> ccb </allcaps> meeting while discussing the <allcaps> cfe </allcaps> core app startup dependencies the reference tickets in cfe : [ <url> and [ <url> the problem is that the <allcaps> psp </allcaps> actually starts the timer before calling cfe_es_main ( ) . depending on how long it takes to reach the initialization for cfe_time , the timer may fire and call the 1 hz function before the semaphore is created or the 1 hz task is started . <section> : this issue actually becomes moot when the latest { { { posix - ng } } } or { { { rtems - ng } } } <allcaps> osal </allcaps> is used . with this version a mutex id of <number> is never valid , and attempting to "" give "" that mutex will fail in a benign manner and do nothing . although it is not an ideal fix , there is no chance of problems occurring due to this when using these osals . <section> : delaying the start of the 1 hz tick may not be an option because this means scheduling will not work until cfe_es_main ( ) returns , which may be considerably delayed if apps have long startup sequences , or if they actually depend on the 1 hz signal in order to start properly .",0.0
"small fixes pc - rtems <allcaps> bsp </allcaps> this fixes a number of small issues found when testing the "" pc - rtems "" <allcaps> psp </allcaps> : * when compiling with - pedantic , gcc complains about the old - style initializer syntax * move the shell init call earlier in the main process , this is more logical placement and allows for a working console in the event that the <allcaps> cfe </allcaps> main function has a problem . * utilize the os_api_wait call implemented in the newest <allcaps> osal </allcaps> * remove conditional compiles around timer setups ( it is not expected this <allcaps> psp </allcaps> will be used with earlier <allcaps> osal </allcaps> versions )",0.0
"fix pc - linux <allcaps> psp </allcaps> for the latest <allcaps> osal </allcaps> several items in the pc - linux <allcaps> psp </allcaps> can be removed / cleaned up when using the newest revisions of <allcaps> osal </allcaps> : * the hack to use { { { - m32 } } } can be removed as the latest osal works with <number> bit natively * the installation subdirectory should be "" cf "" rather than "" eeprom1 "" * the task priority modifications done in main ( ) ( cfe_psp_start . c ) are now integrated into os_api_init and os_api_wait so these can be removed .",0.0
enforce strict <allcaps> ascii </allcaps> replace all non - <allcaps> ascii </allcaps> characters ( i . e . copyright symbol ) with <allcaps> ascii </allcaps> equivalent .,0.0
"fix inclusion of <allcaps> psp </allcaps> internal headers from within public headers the <allcaps> psp </allcaps> public { { { cfe_psp . h } } } file includes configuration and version information from another file which is located in the <allcaps> psp </allcaps> platform - specific ( internal ) subdirectory . specifically , these headers are platform - specific and therefore must only be used within <allcaps> psp </allcaps> itself : * cfe_psp_config . h * psp_version . h access to the values within these platform - specific includes should go through the public <allcaps> api </allcaps> rather than direct inclusion .",0.0
add xenomai <allcaps> b <elongated> psp </allcaps> add xenomai <allcaps> b <elongated> </allcaps> ( beagle bone black ) <allcaps> psp </allcaps> v1 . <number> as delivered from matt benson / odyssey space research on <date>,2.0
"clean up "" - d "" compile time macros used in pc - linux build the "" pc - linux "" <allcaps> psp </allcaps> defines the following to be added to the compiler <allcaps> cflags </allcaps> for __all__ files in the mission : { { { - d_el - <allcaps> dendian </allcaps> = _el - dsoftware_little_bit_order - d__ix86__ - d_ix86_ - dposix - <sad> 8 6 pc - d_reentrant - d_embed_ - dos_debug_level = <number> } } } these were brought into the cmake build from the original build scripts in order to be consistent just in case any code required it . however , they are unnecessary , many are not even used anywhere in <allcaps> cfe </allcaps> / <allcaps> osal </allcaps> , and potentially even wrong . the reality is that with linux , the "" pc - linux "" is a general purpose <allcaps> psp </allcaps> that can most likely be used on __any__ general - purpose development machine that runs linux . it is not limited to only x86 pc ' s , and in fact works just fine on <allcaps> arm </allcaps> , powerpc , and microblaze targets too . i have successfully used the ( unmodified ) pc - linux <allcaps> psp </allcaps> to execute <allcaps> cfe </allcaps> on a beaglebone black ( <allcaps> arm </allcaps> ) as well as an emulated powerpc <number> based development machine . in all these cases , the "" x86 "" macros are wrong , and on the powerpc , the el / <allcaps> endian </allcaps> / software_little_bit_order are wrong too . to summarize - i recommend removing <section> of these macros from the pc - linux build when using the cmake scripts ( the old makefiles can stay as - is ) .",0.0
"<allcaps> psp </allcaps> modifications for const - correct <allcaps> cfe api </allcaps> for context , see trac <number> in the <allcaps> cfe </allcaps> repository : [ <url> the <allcaps> cfe api </allcaps> has been updated such that the pointer arguments in functions called via the <allcaps> psp </allcaps> are now declared "" const "" . this helps in several ways , but the most important reason is so they can be safely supplied from a data structure in <allcaps> rom </allcaps> rather than requiring that the data structure be copied to <allcaps> ram </allcaps> first .",0.0
implement continuous integration tests of cfs <allcaps> psp </allcaps> tree need to construct a ci plan that builds everything that can be built in <code> and runs all of the local test programs that are suitable for fast turnaround automatic test cycles .,2.0
consider adding psps developed at <allcaps> jsc jsc </allcaps> has developed a number of psps as listed in the attachment . consider adding some or all to repo .,2.0
"provide grut699 - vxworks6 <allcaps> psp </allcaps> updates <allcaps> jsc </allcaps> developed grut699 - vxworks6 <allcaps> psp </allcaps> from <allcaps> jsc </allcaps> ' s subversion repo rev <number> was provided to <allcaps> gsfc </allcaps> and released with cfe <number> . since its release , changes have been made that need to be push to the main repo . <allcaps> jsc </allcaps> redmine issue # <number> <number> fixes get time base issue in grut699 <allcaps> psp </allcaps> as currently implemented , cfe_psp_get_timebase ( ) does not set tbu and tbl correctly , based on from cfe_es_perf . c : : cfe_es_perflogadd ( ) /* time is stored as <number> <number> bit integers , ( timerlower32 , timerupper32 ) : / / timerlower32 is the curent value of the hardware timer register . / / timerupper32 is the number of times the timer has rolled over . / / / / time is stored as a absolute time instead of a relative time between log / / entries . this will yield better accuracy since storing relative time between / / entries will accumulate ( rounding / sampling ) errors over time . it also is / / faster since the time does not need to be calculated . for this board , since upper is seconds and the <number> - bit timer register is reset to <number> ( basically rolled over ) every second that exactly fits this definition . upper = g_nsecondscount ; < - - upper is correct lower needs to be changed <allcaps> from </allcaps> lower = systimestamplock ( ); lower /= systimestampfreq ( ) / 1 0 0 0 0 0 0 ul ; to lower = systimestamplock ( ); when using using the <number> - bit <allcaps> tbr </allcaps> on <allcaps> ppc </allcaps> processors , this definition still fits , because the upper <number> - bits increments each time the lower <number> - bits rolls over at <number> ^ <number> . also , in cfe_psp_timer . c , i am pretty sure that cfe_psp_timer_low32_rollover should be <number> instead of <number> . it rolls over each second at <number> ticks . <number> means it rolls over at its max ( <number> ^ <number> ) value , which in this case it does not . <allcaps> note </allcaps> : this only impacts the correctness of performance log data time tags . no other code in <allcaps> cfs </allcaps> uses this function . <allcaps> jsc </allcaps> redmine issue <number> <number> <allcaps> psp </allcaps> updates for cfe <number> . x compatibility in compiler - opts . mak , changed <allcaps> from </allcaps> : $( cfe_tools ) / elf2cfetbl / elf2cfetbl to table_bin = elf2cfetbl also , changed <allcaps> psp </allcaps> rev to <number>",0.0
"add pc - rtems <allcaps> psp </allcaps> "" pc - rtems "" is a <allcaps> psp </allcaps> implemented for running <allcaps> cfe </allcaps> on standard pc hardware using the <allcaps> rtems os </allcaps> . it is mainly targeted at debugging or proof - of - concept validation using <allcaps> qemu </allcaps> as an emulator to provide a virtual pc hardware . it can also potentially be used as a build target for bamboo builds to ensure that all code builds , links , and runs properly using <allcaps> rtems </allcaps> .",2.0
document available psps in trac wiki it would be helpful to construct a small wiki page corresponding to each platform support package giving a quick overview of the platform for which support is being provided . i suggest including hotlinks on each such page back into the <code> subtree of the specific <allcaps> psp </allcaps> for extended documentation - - as clones will obtain the content of the project sources but do not clone the trac wiki .,0.0
"add pc - rtems <allcaps> psp </allcaps> "" pc - rtems "" is a <allcaps> psp </allcaps> implemented for running <allcaps> cfe </allcaps> on standard pc hardware using the <allcaps> rtems os </allcaps> . it is mainly targeted at debugging or proof - of - concept validation using <allcaps> qemu </allcaps> as an emulator to provide a virtual pc hardware . it can also potentially be used as a build target for bamboo builds to ensure that all code builds , links , and runs properly using <allcaps> rtems </allcaps> .",2.0
"<allcaps> psp </allcaps> needs unit tests this project has no unit tests that can be run as part of an automatic build - and - test cycle to assure that a change has not broken fundamental behaviors . we need central portable unit tests that can be run against any <allcaps> psp </allcaps> that check the basic behaviors required of every <allcaps> psp </allcaps> , and a way for individual psps to provide additional unit tests that verify any <allcaps> psp </allcaps> - specific required behaviors .",2.0
"<allcaps> psp </allcaps> memory , port , and <allcaps> eeprom </allcaps> functions assume direct - mapped access the <allcaps> psp </allcaps> currently provides a number of access functions such as cfe_psp_memwrite8 / <number> / <number> , cfe_psp_portread8 / <number> / <number> , etc . these functions all assume that the memory is directly accessible to the current process by simply casting the address as a pointer and directly reading / writing from it . unfortunately this is often <section> the case . * i / o port access in the x86 / intel world is never memory mapped and requires different instructions ( inline asm or kernel syscalls ) in order to get to it . * when using virtual memory , physical memory addresses are not directly accessible to the running process until the memory is mapped into the current virtual memory space . * many <allcaps> eeprom </allcaps> devices are actually connected via a serial bus such as <allcaps> spi </allcaps> or <allcaps> twi </allcaps> and therefore would not be memory mapped . with the way it is structured right now , cfe_psp_ram . c , cfe_psp_port . c , and ( to a lesser degree ) cfe_psp_eeprom . c only provide slow performance - robbing function calls to simply cast a pointer . furthermore , it is arguable whether direct i / o port or physical memory access even belongs in the <allcaps> psp </allcaps> at all ; the <allcaps> api </allcaps> this provides to the application layer remains far too hardware - specific to provide any useful abstraction . any <allcaps> cfs </allcaps> application performing direct i / o is already unlikely to be portable to any other platform , since ( by definition ) this would be accessing a specific hardware device at a specific location . proposed changes : * stop compiling cfe_psp_ram . c , cfe_psp_port . c , and cfe_psp_eeprom . c from the "" shared "" code by default ; what these currently implement is more of an exception than the general rule . these can be renamed or moved to indicate they are not always used . * deprecate / discourage future use of the <allcaps> ram </allcaps> / port access functions . instead , a "" driver "" architecture should be used so the hardware device can be better abstracted ( see # <number> this also allows easier simulation of the hardware , and the resulting <allcaps> cfs </allcaps> application will be much more portable / reusable . * on the <allcaps> psp </allcaps> ' s for which direct memory access / / is / / valid , they can continue to compile - in the current implementations to maintain backward compatibility . * on the <allcaps> psp </allcaps> ' s for which direct memory access / / is not / / valid , either customized functions can be provided or simply return the not_implemented error .",2.0
"remove references to "" cfe_platform_cfg . h "" from <allcaps> psp </allcaps> for maximum portability and the simplest build process , the <allcaps> psp </allcaps> library should be completely independent of the specific <allcaps> cfe </allcaps> configuration that is running on top of it . the <allcaps> psp </allcaps> ' s behavior should be dictated entirely by the capabilities / capacities of the platform it is supporting , not the application using it . as such , it should not need to directly "" compile - in "" any values or definitions from the application layer ( cfe ) . * the "" reset types "" returned by the <allcaps> psp </allcaps> functions use a definition that comes directly from the <allcaps> cfe es </allcaps> core application . since the hardware platform is what actually defines the different reset types , the definition of these types really belongs in the <allcaps> psp </allcaps> . * for memory area sizes , a better differentiation should be made between the size of memory that the hardware provides ( capacities ) and the sizes that cfe needs in order to operate ( requirements ) . currently only one value is defined for both which is not really accurate ; the cfe_platform_cfg . h defines the cfe requirements but the capacities are fixed by the physical hardware available .",0.0
"fix all <allcaps> psp </allcaps> memory functions that use a uint32 for memory addresses many functions within the <allcaps> psp </allcaps> code use a uint32 to store a memory address . this practice reduces code portability , most importantly it completely breaks on <number> - bit processors . reference [ <url> at a minimum the uint32 should be replaced with an integer type guaranteed to be wide enough for memory addresses on the local <allcaps> cpu </allcaps> . note that this change depends on having an <allcaps> osal </allcaps> that offers the "" cpuaddr "" type for this purpose .",0.0
"clean up shared <allcaps> eeprom </allcaps> read / write implementation the code in "" cfe_psp_eeprom . c "" is far more complicated than it needs to be . the objective of this code appears to be to accomplish basic read / writes of <number> , <number> , or <number> bit values to a memory device that only supports <number> bit access . therefore for words less than <number> bits it performs a read - modify - write sequence . it has a completely separate implementations for big endian vs little endian . the code could be easily made endian - neutral and <allcaps> much </allcaps> simpler by first reading the <number> bit value into a union and then performing simple byte / word access to update the value , then write it back . all <hashtag> if defs </hashtag> would become unnecessary and the code would be much more straightforward .",2.0
"<allcaps> psp </allcaps> modular build enhancements currently , in order to support a different variant of a board , such as one that has the same processor but different set of peripherals , one must "" clone "" the entire <allcaps> psp </allcaps> of the board and modify it to support the new board . the problem with this approach is that as usage becomes more widespread we will end up with a large number of similar - but - different psps needing maintenance . any change to the <allcaps> cfe </allcaps> that requires <allcaps> psp </allcaps> support will require updating <allcaps> all variants </allcaps> of the <allcaps> psp </allcaps> which will become increasingly difficult . the cmake build system introduced in ticket # <number> as the ability to / / statically / / link in a set of extra mission - defined code modules into the <allcaps> psp </allcaps> library . with this system in place , <allcaps> cfs </allcaps> applications can bind to specific "" <allcaps> psp </allcaps> drivers "" at runtime . this is analogous to statically linking driver modules into the linux kernel depending on the hardware configuration . as long as the interface is the same ( e . g . "" / dev / ttys *"") , the application need not know what hardware is actually providing the interface . this allows code re - use in many ways : * a single <allcaps> psp </allcaps> can support multiple physical board variations by loading a different module set . * multiple <allcaps> psp </allcaps> ' s can leverage the same drivers where appropriate ( e . g . an <allcaps> adc </allcaps> driver that communicates over a serial bus can work equally well on <allcaps> arm </allcaps> , x86 , or <allcaps> ppc </allcaps> as long as it has a compatible serial bus ) . * as long as all similar - function <allcaps> psp </allcaps> modules provide the same application - facing <allcaps> api </allcaps> , any <allcaps> cfs </allcaps> application implementing "" business logic "" can operate in a completely hardware - independent manner . the driver module can be replaced with a different module and the <allcaps> cfs </allcaps> application does not need to change ( or even be recompiled ) to work with alternate hardware . this framework should help avoid the need to "" clone - and - own "" a <allcaps> psp </allcaps> for a particular project . this is especially true for linux psps which are already very generic ( e . g . pc - linux easily runs on <allcaps> arm </allcaps> linux or <allcaps> ppc </allcaps> linux ) . the framework is a very simple extension to the <allcaps> psp </allcaps> and does not change existing <allcaps> psp </allcaps> apis so it will not interfere with existing code .",2.0
enhanced build system for cfs this ticket is for the <allcaps> psp </allcaps> portion of the enhanced build system pushed out under the corresponding cfs ticket : [ <url>,2.0
"fix # <number> , adds checkstatus helper functions <section> - fixes # <number> , this improvement reduces the cyclomatic complexity of the main ( ) function from <number> to <number> which is less than the recommended <number> cyclomatic complexity upper limit . the change accomplishes this improvement by adding two new status - checking helper functions . <section> ci <section> - no impact to behavior . this change distributes complexity to newly created helper functions . <section> - os : ubuntu <number> <section> * note , that this improvement does not reduce the overall complexity of the elf2cfetbl program . it just distributes the complexity across the two new helper functions which each have <number> cyclomatic complexity , potentially making the code easier to understand and maintain . * also note that the multiple <code> statements are replaced with <code> via the two new helper functions . calling <code> from main ( ) when no other non - daemon threads are running , will have the same effect as calling <code> . it will terminate the process . i chose to use <code> to make use of the new helper functions since elf2cfetbl does not appear to use multi - threading . <section> n / a <section> justin figueroa , vantage systems",2.0
"fix # <number> , reduce cyclomatic complexity of getelfheader <section> - fixes # <number> this change reduces the cyclomatic complexity by <number> . the changes specifically condense extraneous "" verbose "" if statements for printing header as well as extraneous status assignments when checking the elf magic number . <section> none <section> no expected impact to behavior . <section> - os : ubuntu <number> <section> the cyclomatic complexity for this function still remains above the recommended <number> , however the code is relatively clean and follows a pretty straightforward process . if desired , further reduction of cylomatic complexity by <number> can be achieved by creating new functions for the processor class type ] ( <url> verification and [ data encoding type <url> verification switch / case . <section> n / a <section> justin figueroa , vantage systems",2.0
"main - cyclomatic complexity of <number> <section> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . elf2cfetbl . c : : main <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up main such that it has a cyclomatic complexity of <number> or less . <section> leave as - is <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> justin figueroa , vantage systems",2.0
"locateandreaduserobject - cyclomatic complexity of <number> <section> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . elf2cfetbl . c : : locateandreaduserobject <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up getelfheader such that it has a cyclomatic complexity of <number> or less . <section> leave as - is <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> justin figueroa , vantage systems",2.0
"getsectionheader - cyclomatic complexity of <number> <section> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . elf2cfetbl . c : : getsectionheader <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up getelfheader such that it has a cyclomatic complexity of <number> or less . <section> leave as - is <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> justin figueroa , vantage systems",2.0
"getelfheader - cyclomatic complexity of <number> <section> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . elf2cfetbl . c : : getelfheader <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up getelfheader such that it has a cyclomatic complexity of <number> or less . <section> leave as - is <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> justin figueroa , vantage systems",2.0
"processcmdlineoptions - cyclomatic complexity of <number> <section> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . elf2cfetbl . c : : processcmdlineoptions <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up processcmdlineoptions such that it has a cyclomatic complexity of <number> or less . <section> leave as - is <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> justin figueroa , vantage systems",2.0
uninitialized variable static analysis warning <section> uninitialized variable static analysis warning observed ( license restricts publishing warnings ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"remove explicit file name references in doxygen file comments to avoid warnings <section> file comment without a filename implies the comments apply to the current file . adding the file name makes doxygen try to match that file . the issue is there ' s multiple files with the same name , so doxygen gets confused unless you add full path . really it ' s just overhead since the point is to comment the current file . sample warning if you <code> from the bundle : ` ` <code> os - impl - binsem . c ' supplied as the second argument in the \ file statement matches the following input files : / home / jhageman / cfs / cfs - github / osal / src / os / posix / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / rtems / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / vxworks / src / os - impl - binsem . c please use a more specific name by including a ( larger ) part of the path ! ` ` ` <section> easiest to just remove the name since for every case the comment applies to the current file <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"tainted expression get_sh_entsize ( sectionheader ) <section> using tainted expression get_sh_entsize ( sectionheader ) as the divisor in get_sh_size ( sectionheader ) / get_sh_entsize ( sectionheader ) . <section> check that get_sh_entsize ( sectionheader ) does not equal to <number> so get_sh_entsize ( sectionheader ) is not divided by <number> . <section> <url> <section> coverity : <url> <section> untrusted divisor ( tainted_scalar ) <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"should error if output name does not match input name <section> the cfe build scripts assume that the file name of the output of <code> matches the input basename but with a <code> extension added . in reality , this tool uses the output name specified in the source file . if this does not match , an obscure installation error occurs because the "" expected "" binary file will be missing . <section> elf2cfetbl should error out if the input name does not match the output name . <section> alternatively , the tool could have a new command line option added to directly control the output name and override whatever was in the source file . this would be a more substantial change , however . <section> this can create confusion when the multiple table feature in nasa / cfe # <number> is used . if the source file internal definition does not match the expected name the error occurs later at install time , not when elf2cfetbl runs , so it can be confusing . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the elf2cfetbl repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the elf2cfetbl repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for elf2cfetbl under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing elf2cfetbl undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / elf2cfetbl is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / elf2cfetbl while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
c + + comment style and commented out code violations <section> c + + comment style and commented out code violates style guidelines <url> <section> clean up <section> none <section> alex campbell <allcaps> gsfc </allcaps>,0.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for elf2cfetbl . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , deconflict global and local parameters <section> fix # <number> - deconflicts global / local parameters <section> built and executed cfs , loaded tables as expected <section> none , squashed warning <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
<allcaps> lgtm </allcaps> warning - local parameter hides global variable with the same name <section> <code> <section> deconflict . <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix # <number> , replace ctime with ctime_r <section> fix # <number> - replace ctime ( which generates <allcaps> lgtm </allcaps> warning ) with ctime_r <section> built and ran code in verbose mode , confirmed time output <section> eliminate <allcaps> lgtm </allcaps> warning <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
<allcaps> lgtm </allcaps> issue - replace call to ctime with ctime_r <section> <code> <section> <allcaps> lgtm </allcaps> recommends replace with ctime_r <section> strftime <section> split from # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix # <number> , squash int comparison warning <section> fix # <number> - squash int comparison warning <section> build and ran cfe ( uses tables built by elf2cfetbl ) , no issues . <section> no longer produce the <allcaps> lgtm </allcaps> warning . no behavior change . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this change . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> lgtm </allcaps> issue - comparison between int16 and int <section> <code> <section> i is an iterator , no need to be fixed size . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , restrict destination file permissions <section> fix # <number> - restricts destination file permissions <section> built and ran elf2cfetbl , confirmed file permissions restricted ( checked w / verbose ) <section> created file not writable by group or other . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> <allcaps> cwe </allcaps> - <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
move content from <allcaps> readme </allcaps> . txt to readme . md <section> having two files named readme is confusing . making users click over to a second file when they might expect readme . md to have a thorough description of the tool is inefficient . <section> absorb readme . txt into readme . md <section> have full blown documentation folder using doxygen or similar <section> none <section> gerardo e . cruz - ortiz,1.0
"use a changelog to keep track of changes instead of having them in the readme <section> the version history in the readme file clutters useful information <section> move the "" version history "" from <code> to <code> and start following this spec : <url> <section> move changelog section in the readme to a section at the very bottom of the file <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"add build name and number <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , string table identification . <section> support <allcaps> elf </allcaps> files that have all strings , including <allcaps> elf </allcaps> section names , in one single "" . strtab "" section in the <allcaps> elf </allcaps> file . this gives preferential treatment to a section named "" . strtab "" as this should always be the section which contains the names for the "" . symtab "" section . this should also be true of <allcaps> elf </allcaps> files that contain other strtab sections , such as a "" . dynstr "" section . fixes # <number> <section> confirmed that normal table files built using <allcaps> gcc </allcaps> ( e . g . those in the sample framework configuration ) are identical , before and after this change is applied . confirmed that this is now able to also correctly parse an <allcaps> elf </allcaps> file from <code> which has all strings in a single <code> section . <section> now correctly parses <allcaps> elf </allcaps> files that do _not_ have a separate <code> and <code> section . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"elf2cfetbl does not handle files without a separate "" . shstrtab "" section <section> in <allcaps> elf </allcaps> files all strings are put into string table sections ( <code> type ) . many tools dedicate a separate <allcaps> strtab </allcaps> section specifically for the section names , with the number of this section indicated in the main <allcaps> elf </allcaps> header <code> field . however there is no requirement to put these strings in a separate table section . some compilers generate a single <allcaps> strtab </allcaps> section containing all strings , section names and symbol names . in this case the <allcaps> elf </allcaps> header <code> field points to this unified section . <section> pass an <allcaps> elf </allcaps> table object file generated from <code> compiler to <code> - it fails to identify the symbol names correctly , and it therefore fails to find the <code> symbol . <section> elf2cfetbl should work with these <allcaps> elf </allcaps> files and produce an output . <section> ubuntu <number> ( build host ) <section> note that <allcaps> elf </allcaps> also does not say any maximum number of string table sections either . there could be just one ( this bug ) or there could be more than two . as best i can tell , the string table used for the <code> section should always be named <code> - so this is probably a better way to identify the right section . <section> joseph hickey , vantage systems , inc .",0.0
"srcfilename and dstfilename not ensured to be null - terminated <section> elf2cfetbl uses strncpy to load the srcfilename and dstfilename strings , but does not ensure that the strings are null - terminated . <section> this is related to <url> <section> <email>",0.0
input file description / tablename without terminator causes segfault <section> segfault at : <url> likely also an issue with tablename : <url> <section> steps to reproduce the behavior : <number> . create a table input file with a <number> byte description ( no null terminator ) <number> . run elf2cfetbl <section> error or warn / truncate . <section> see above <section> - versions : master bundle <section> identified by <allcaps> jsc </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix # <number> , apply standard code style <section> whitespace changes only . fix # <number> <section> ci - <url> <section> none <section> - hardware : ci - os : ubuntu <number> - versions : bundle w / all whitespace change commits <section> note - not enforcing , just a single cleanup since there ' s no pending activity in this repo . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix typos hey , this tiny pr will fix : - <number> typo in <code> - <number> typo in <code> best ! : robot :",1.0
"fix # <number> , termination on strncpy <section> fix possible non - termination of strings within command line parsing . this generated a warning in gcc9 . fixes # <number> <section> build code with default config , <allcaps> simulation </allcaps> = native <allcaps> buildtype </allcaps> = release on <allcaps> gcc </allcaps> <number> . <number> . confirm successful build with no warning . <section> no impact to behavior <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> joseph hickey , vantage systems , inc .",0.0
"string truncation warnings with newer <allcaps> gcc </allcaps> <section> ubuntu has released <number> <allcaps> lts </allcaps> which includes <allcaps> gcc </allcaps> <number> . <number> . when using this compiler it implements a much stricter ( and often over - zealous ) checking of string ops . for instance : <code> <section> build code with default config using <allcaps> gcc </allcaps> <number> . <number> , with optimization enabled and full warnings . <section> code should build cleanly . <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , resolve print format mismatches on <number> - bit host <section> casts where needed for print formatting on <number> - bit host fix # <number> <section> steps taken to test the contribution : <number> . ci - see <url> <number> . also built for vxworks on <number> - bit host <section> builds for vxworks w / <number> - bit host <section> - hardware : ci , cross compiled for vxworks <number> mcp750 on <number> - bit linux host - os : ubuntu <number> , vxworks <number> , redhat <number> - versions : bundle + this commit <section> none ( this is not the only issue on vxworks , but have not written them up yet ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"if you get a path_max undefined issue . <repeated> the inclusion of the path_max has introduced a compilation error when compiling on linux systems . while this is a little confusing , the path_max definition is located in < linux / limits . h > not < limits . h > which is currently included here <url> . steps to reproduce the behavior : <number> . pull the latest build of the <allcaps> cfs </allcaps> that uses this tool ( as of commit b7dcc71360467ce2443dff27ea6314199f5c3ef0 ) <number> . attempt to build using the sample cmake <section> no compilation errors . <section> - os : ubuntu <number> . <number> <allcaps> lts </allcaps> - versions : cfe <date> , <allcaps> osal </allcaps> <date> , <allcaps> psp </allcaps> <number> . <number> for linux",3.0
"fails to build under raspbian and vxworks <section> building elf2cfetbl under raspbian ( the debian variant released for the popular raspberry pi <allcaps> sbc </allcaps> ' s by the raspberry pi organization ) it fails with a long laundry list of printf type mismatch errors . <code> <section> build elf2cfetbl under raspbian . <section> should be casting types to what printf expects . <section> if applicable , add references to the software . <section> raspberry pi zero w . <section> add any other context about the problem here . <section> <email>",0.0
apply standard code style <section> inconstant style <section> see <url> and <url> <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"non - constant format string in sprintf call , lgtm warning <section> recommended issues from lgtm : elf2cfetbl . c <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"simplify header inclusion and cmake list <section> complex cmakelist . txt header logic should not be needed any more <section> include the now "" external "" headers for tables <section> none <section> related to <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add validation for returncode and fix bracket to standard <section> build with options : - wall - std =c 9 9 - pedantic - wstrict - prototypes - wwrite - strings two warning appear : / media / sf_share / cfs / tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : missing braces around initializer [ - wmissing - braces ] union elf_shdr sectionheaderstringtable = { <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> }; ^ { } / media / sf_share / cfs / tools / elf2cfetbl / elf2cfetbl . c : in function ‘ opensrcfile ’ : / media / sf_share / cfs / tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : variable ‘ rtncode ’ set but not used [ - wunused - but - set - variable ] int rtncode ; ^ ~ ~ ~ ~ ~ ~ <section> first issues , add second bracket : union elf_shdr sectionheaderstringtable = { { <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> , <number> }}; second issue : add validation for return code . <section> anh van , <allcaps> nasa </allcaps> goddard",0.0
"tutorial on using elf2cfetbl <section> no <section> a guide on how to use elf2cfetbl to create an table file <section> none <section> none <section> anh van , nasa goddard",1.0
# <number> replace deprecated defines fixes # <number> work submitted by <user> <allcaps> cla </allcaps> on file .,2.0
"<number> bit support and machine additions , # <number> fixes # <number> note already reviewed and approved by community <allcaps> ccb </allcaps> on babelfish . submitting pull request to follow github process for merging to master . work performed by <user> - other - james",2.0
"remove dependencies on deprecated elements building with cfe_omit_deprecated_6_6 fails , needs to be fixed .",0.0
bring in <number> bit support and machine additions from babelfish see <url>,2.0
"create version header file , update to x . x . <number> , report on execution",2.0
elf2cfetbl internal filename / path length dependency on <allcaps> osal </allcaps> questionable originated by abrown4 ( <number> on babelfish ) : the internal filename / path length for the table files produced do <allcaps> not </allcaps> have to depend upon the <allcaps> osal </allcaps> . the <allcaps> osal </allcaps> os_max_file_name limit is too restrictive . need to use the path_max from linux / limits . h that is appropriate for the host . jh - suggest possibly checking size against <allcaps> osal </allcaps> and notify user when limit exceeded ( but still allow to run as long as it meets path_max ) .,0.0
"elf2cfetbl classic build include path order issues originated by abrown ( <number> on babelfish ) : elf2cfetbl makefile does not include paths in the correct order ( classic build ) using cfe <number> . 0 a with the "" classic "" makefile system : the tools / elf2cfetbl / for_build / makefile has include paths in the wrong order such that it always picks up config files from the defined source first , rather than what is in your actual mission or local build directory . ex : you change os_max_file_name in your flight build and there is a table header mismatch with elf2cfetbl .",0.0
"elf2cfetbl crashes when destination file not found originated by thadeus ( <number> on babelfish ) : when the destination filename cannot be found in the table object file , the destination object file is not opened . however , the freememoryallocations function unconditionally calls fclose on its pointer , which segfaults when it is <allcaps> null </allcaps> . initializing both file pointers to <allcaps> null </allcaps> and checking them before calling fclose prevents the segfault . <number> - prevent - a - segfault - in - elf2cfetbl . txt <url>",0.0
"printf format string vs data type mismatches we have some lingering mismatches between printf format string conversions and the parameter data types ; all but one of them are in elf2cfetbl so pinning this bug on elf2cfetbl ( will fix cmdutil in passing ) : tools / cmdutil / cmdutil . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' long int ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' uint32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' uint32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' %x ' expects argument of type ' unsigned int ' , but argument <number> has type ' time_t ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' %x ' expects argument of type ' unsigned int ' , but argument <number> has type ' long unsigned int ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' %x ' expects argument of type ' unsigned int ' , but argument <number> has type ' long unsigned int ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' long int ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' %x ' expects argument of type ' unsigned int ' , but argument <number> has type ' long unsigned int ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' uint32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : format ' %x ' expects argument of type ' unsigned int ' , but argument <number> has type ' uint32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' char * ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' int32 ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> : <number> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' long int ' [ - wformat <happy> tools / elf2cfetbl / elf2cfetbl . c : <number> <time> : warning : format ' % d ' expects argument of type ' int ' , but argument <number> has type ' uint32 ' [ - wformat <happy> attachments ( <number> )",0.0
"updated <allcaps> mat </allcaps> table assumes "" commandheader "" first member name depending on where the message definitions came from , and the type of <allcaps> hdr </allcaps> implementation used , the first element of a structure may or may not be named <code> . this is controlled by the specific msghdr implementation that was chosen . <section> build the <allcaps> mat </allcaps> using <allcaps> eds </allcaps> - generated structs - in these ( unfortunately ) there is an extra layer of nesting , so this fails . the first element still is ultimately a command header . <section> the <allcaps> tbl </allcaps> message definitions are defined by a combination of <allcaps> tbl </allcaps> itself and the <allcaps> msg hdr </allcaps> module selection . no assumptions in hs should be made about its structure . <section> <url> specifically the "" . commandheader "" part . <section> debian <section> should be able to just remove this part of the designated initializer . normally i would recommend use of designated initializers , but in this context it introduces a dependency / assumption that may not be correct . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , remove <code> - related macros testing performed * * github ci actions all passing successfully . <section> no change . <section> avi weiss <user>",2.0
"add <allcaps> eds </allcaps> file for hs application an electronic data sheet ( <allcaps> eds </allcaps> ) file provides a standardized machine - readable <allcaps> xml </allcaps> description of the interfaces for an application . having this documented externally from the code allows many new features and capabilities . <section> every <allcaps> cfs </allcaps> app should include an <allcaps> eds </allcaps> file . <section> <allcaps> cfe </allcaps> core modules already have these files . <section> joseph hickey , vantage systems , inc .",2.0
"use generated stubs hs unit testing currently uses a set of stubs for its internal units that are not generated by the tool <section> use the generated stubs directly whenever possible , as this makes future maintenance easier - when an <allcaps> api </allcaps> changes , just re - run the generator tool to update the stubs . <section> this requires some additional separation of items - global variable stubs should be in a separate compilation unit , as the tool does not generate these . <section> joseph hickey , vantage systems , inc .",2.0
"cppcheck unread variable errors in hs_monitor . c cppcheck is currently reporting the following style issues : | severity | location | error id | issue | | - - - | - - - | - - - | - - - | | style | fsw / src / hs_monitors . c : <number> | unreadvariable | variable ' entryresult ' is assigned a value that is never used . | | style | fsw / src / hs_monitors . c : <number> | unreadvariable | variable ' resourcetype ' is assigned a value that is never used . | | style | fsw / src / hs_monitors . c : <number> | unreadvariable | variable ' nullterm ' is assigned a value that is never used . | <section> run cppcheck workflow <section> should run clean <section> github hosted runner <section> joseph hickey , vantage systems , inc .",0.0
"appmonstatusrefresh tests appear to check the wrong output the <code> <allcaps> api </allcaps> call updates a field called <code> in the global data structure . declared here : <url> value is updated in the function here : <url> called from unit test here ( among others ) : <url> however - the unit tests then check the similarly - named field within the hk packet here : <url> note that this is _not the same member_ - - one is directly inside the global , the other is inside the hk packet . <section> test should verify the fields it was supposed to update . <section> note the tests is passing , this suggests the test might not be sufficient , because it is checking a different value than was set . the test conditions could have simply been written to pass without actually verifying expected output . <section> joseph hickey , vantage systems , inc .",0.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
"use cfe_msg_cmd_hdr_init macro in message action table implementation current raw buffer / command implementation in <allcaps> mat </allcaps> table is not portable across different endian systems and is somewhat challenging / messy to implement . <section> similar to nasa / sc # <number> , the message action table could use the <code> macro and real command types to simplify table implementation . suggestion : typedef a union that contains each of the message types in the table , then define the array w / the <allcaps> mat </allcaps> info and unioned element <code> <section> none <section> similar possible approach with <allcaps> sch </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove stray terminators <url> <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"hs_idletask has no cancellation point the default <code> has no cancellation point , so hangs up on linux for cntrl - c . <section> add a cancellation point <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",0.0
"uncovered condition for while loop in hs_custom . c there will always be room within the diagvalue / count array here , so it ' ll match before j >= the limit . the conditions are not independent : <url> <section> refactor <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsf </allcaps>",2.0
refactor config dependent conditional in hs_custom . c can not cover branch when hs_util_calls_per_mark is <number> ( since the counter is static local ) : <url> <section> use the custom global to store config such that it can be set to get full coverage . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"simplify message action logic to avoid unreachable branch branch can not be covered since there ' s no way to get to this decision with a actiontype <= hs_amt_act_last_nonmsg : <url> this is due to actiontype already being checked here : <url> all other cases of current implementation are handled . only way to exercise this decision as false would be to introduce a bug . <section> slight refactor to simplify and allow full coverage - remove the <allcaps> noact </allcaps> case since it can never happen : <url> also swap the logic to calculate msgactsindex first and just check the result for in - range . <section> could do enabled check first , but it ' s already <number> levels deep . better to save that for # <number> to really clean up duplicated logic . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old hs clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template . md and contributing . md - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset use on addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add functional verification of hs8006 and hs8006 . <number> hs8006 : upon any initialization , hs shall wait until the cfe startup synch has been received indicating all applications have started . hs8006 . <number> : if the startup - synch is not received in <platform_defined> seconds , hs shall begin processing . these are difficult to verify in <allcaps> cft </allcaps> , so they need to be verified in unit test by ensuring cfe_es_waitforstartupsync is called with a platform defined timeout . <section> add verification in the unit tests . <section> none <section> test case : <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
hs idle task only executes once and exits . <repeated> reports <allcaps> cpu </allcaps> hogging all the time hs idle task used to have a while loop ( from <number> . <number> tag ) : <url> now just runs once : <url> <section> running cfs with hs reports hogging every time . <repeated> <code> <section> task should run in a loop and realistic margin should be getting reported <section> - os : linux - versions : <number> . <number> + <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"static analysis workflow failures due to style warnings strict cppcheck fails in static analysis workflow , see <url> ' ' ' fsw / src / hs_cmds . c : <number> ] - > [ fsw / src / hs_cmds . c : <number> <url> variable ' status ' is reassigned a value before the old one has been used . fsw / src / hs_custom . c : <number> ] - > [ fsw / src / hs_custom . c : <number> <url> variable ' status ' is reassigned a value before the old one has been used . ' ' ' <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove all mentions of <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts from documentation some of our doxygen docs still reference <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts . see cfs_mm repo : fsw / src / mm_msgdefs . h : l28 imported from <allcaps> gsfccfs </allcaps> - <number>,1.0
"health and safety has extraneous code <allcaps> ivv </allcaps> severity : <number> issue category : code issue type : extraneous code count : <number> description : the health and safety app init function includes the extraneous assignment of status to cfe_success [ <number> : line <number> ]; however , this value is never used again before the value of status is reassigned [ <number> : line <number> ] . recommended actions : the assignment statement for status can be removed . impact : defect impacting maintainability on current mission or reuse on future missions . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"scrub configuration file for items that do not change suggest removing non - project configuration items from this file . would help to limit this list to only items that projects should expect to manage . examples of things i would not consider for project configuration - app name , wakeup pipe depth , table names , etc . note open ticket on <allcaps> cpu </allcaps> utilization / idle task so avoiding comments on those parameters since i expect this implementation to change . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"recommended refactoring in hs_monitorevent hs_monitorevent recommendation : refactor common action logic for the different monitors into one function , and pass in unique info . would avoid repeated logic for the same action from a different trigger . finding from code review imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
hs idle task consumes <percent> <allcaps> cpu </allcaps> on <allcaps> posix </allcaps> systems imported from <allcaps> gsfccfs </allcaps> - <number>,0.0
hs telemetry reporting per - core <allcaps> cpu </allcaps> utilization on <allcaps> smp </allcaps> idle task needs to be updated for <allcaps> smp </allcaps> so that utilization can be determined for each core . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"older versions of make do not support "" abspath "" <section> the table build procedure uses the <allcaps> gnu </allcaps> make function <code> as documented here : <url> however , older versions of make ( e . g . <number> ) appear to not support this function as described - although make itself does not throw an error about this function , the result is an empty string . this in turn causes the command being executed to fail because its missing the argument , which is supposed to be a file name . <section> build the software using an older version of <allcaps> gnu </allcaps> make , an error such as this occurs : <code> <section> there should be a library filename between the "" x "" and the object filename . <section> the command in the makefile here is : <url> note that the <code> evaluated to the empty string . whereas on <allcaps> gnu </allcaps> make <number> . x this works as described in the documentation . <section> vxworks <number> , which ships a binary version of <allcaps> gnu </allcaps> make v3 . <number> . <section> joseph hickey , vantage systems , inc .",0.0
"occasional table build failures with parallel builds ( - j ) <section> when using the - j option to <code> , occasionally some table builds may fail . <section> depends on a configuration that uses a lot of table files ( > <number> ) . repeatedly do clean builds followed by <code> where x is a number greater than <number> or so . occasionally an error will occur due to a missing object . <section> should succeed <section> debian <section> initial analysis of a failed build seems to suggest it was trying to build the same intermediate table library twice , at the same time . as such either the <code> or <code> actions failed because one of them stepped on the files from the other parallel build . <section> joseph hickey , vantage systems , inc .",0.0
"table build logic is assuming "" . o "" extension for object files <section> the new scripts that are used to build table files assume a "" . o "" extension on object files . this is not always the case , as some other systems use "" . obj "" . <section> build using the vxworks <number> toolchain combined with the vxworks platform module - this sets up for an "" . obj "" extension . table file generation will fail due to a missing . o file . <section> should build successfully . <section> vxworks <number> ( <allcaps> gsfc </allcaps> build machine ) <section> the variable <code> should be used here . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , cfe functional test <number> fixes # <number> - cfe functional test <number> failing if the cfe functional tests are executed multiple times in a row , because of differences in pre - test log messages - cfe_es_writetosyslog can return cfe_es_err_sys_log_truncated during execution of cfe test <number> . functional test <number> was updated to allow for the cfe_es_err_sys_log_truncated return value - as that is an acceptable / nominal condition . <section> successfully executed functional tests multiple times in a row . <section> cfe functional test <number> should no longer intermittently fail . <section> dan knutsen <allcaps> nasa </allcaps> goddard",0.0
es functional test : test write to sys log failing intermittently <section> cfe functional test <number> ( test write to sys log ) is failing intermittently . <section> execute functional tests multiple times . <section> test should consistently pass if there is no anomalous config / behavior . <section> dan knutsen <allcaps> nasa </allcaps> goddard,0.0
"add source - routing feature to software bus <section> normally , software bus messages are fully assembled by clients , then passed to the software bus via e . g . <code> for delivery to subscribers . this routing to subscribers is currently done based on the <code> value that is present in the message - that is , the msgid is looked up in the routing table , which is in turn translated to a list of destinations ( subscribers ) to deliver that message to . <section> add an alternative <allcaps> api </allcaps> that allows the message to be routed to destination ( s ) that are are given explicitly in the <allcaps> api </allcaps> call . that is , allow the caller to specify the <code> that sb should use to route and deliver the message . specifically - this passed - in <code> for routing may be different than the msgid value contained in the message . <section> n / a <section> the use - case for this feature has to do with complex systems with distributed software bus services across many instances of <allcaps> cfe </allcaps> . in this context the destination may not be directly reachable from the source , but reachable through some sort of intermediate hop . this feature gives the needed flexibility to work with such an architecture , by allowing messages to be routed to an intermediate delivery assistant app that may not be the final destination of the message . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , adds utassert message descriptions to readme_functionaltes … - fixes # <number> - adds descriptions of each utassert message to the functional test readme markdown file for easier readability . <section> previewed markdown file <section> no impact to behavior . <section> - os : ubuntu <number> <section> description content resourced from : <url> <section> n / a <section> justin figueroa , vantage systems",1.0
"update readme_functionaltest . md to include <allcaps> utassert </allcaps> message descriptions <section> the cfe functional tests include assert messages that can be further clarified in the <allcaps> readme </allcaps> . <section> include and describe each enumerated assert message in the readme . <section> n / a <section> n / a <section> justin figueroa , vantage systems",1.0
update readme_functionaltest . md to include sample_app in startup script <section> the cfe functional tests are dependent on the inclusion of sample_app for the successful execution of all tests . <section> include sample_app in the example startup script and explain that there is a dependency . <section> dan knutsen <allcaps> nasa </allcaps> goddard,1.0
make the shared table used in the cfe functional tests configurable <section> projects typically will remove sample_app from their build . this creates an issue because the cfe functional tests are dependent on it such that tests will fail after removal . need a mechanism to easily swap out the sample_app table used in the functional tests such that projects can still run the tests as part of their ci / cd once sample_app is removed . <section> make the name of the table used in the cfe functional tests configurable such that projects can easily swap out the sample_app table with a table in their project specific build . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
counters included in cfe functional test summary does not add up to total test count <section> cfe functional test summary does does not contain information on all counters that increase the total test case count . this results in the appearance of missing tests when the results are read . <section> add an information statement that includes the test counters for the remaining tests that increase the total test count . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
"reorganize include files for <allcaps> cfe </allcaps> <section> a recommendation for header file naming and scoping was documented in # <number> and pr # <number> . however , that pr was just a document , <allcaps> cfe </allcaps> itself does not ( yet ) adhere to this convention <section> split the current "" cfe_mission_cfg . h "" and "" cfe_platform_cfg . h "" into module - specific chunks ( es , sb , evs , tbl , time ) . and organize the names and contents of those chunks according to the documented convention in <url> <section> n / a <section> this is important going forward as some files ( in particular , those that define the interfaces ) may be generated from a tool . it is therefore important to separate the file content according to the convention . this allows headers that are generated by the tool to be "" source - selected "" accordingly ; we do not want to have those definitions mixed with other types of unrelated definitions . currently , the <allcaps> cfe </allcaps> platform and mission config files contain a mixture of definitions - all of the core apps are mixed together , and some of the definitions affect the interfaces , and some do not . <section> joseph hickey , vantage systems , inc .",2.0
"new cfe_locate_implementation_file ( ) includes fallback file in results even if override found <section> when using a "" fallback_file "" option , this is put at the last priority when using the "" allow_list "" option , this function returns <allcaps> all </allcaps> files found that match the pattern being searched for . when those two options are used together , it means that the fallback file will be included in the result list , along with the user - supplied files . this is not the intent ; the fallback file should only be returned if _no_ user - supplied files were found . the result of including both is that one gets duplicate defs and / or unexpected values . the "" generate_include_configfile ( ) "" uses it in this way , and thus gets both copies . <section> use "" generate_config_includefile "" with a file that has been overridden by the user . the generated include file will get both the default and the user - supplied copy . <section> only the user - supplied copy should be used . <section> joseph hickey , vantage systems , inc .",0.0
"update <allcaps> eds </allcaps> based on latest compatibility testing <section> the <allcaps> ctf </allcaps> / <allcaps> ccdd json </allcaps> files produced by the <allcaps> eds </allcaps> tool from the <allcaps> xml </allcaps> files ( see nasa / edslib # <number> ) do not exactly match the current scripts . <section> generate <allcaps> json </allcaps> products from <allcaps> eds </allcaps> , then run <allcaps> ctf </allcaps> - based tests using those <allcaps> json </allcaps> files , observe mismatch errors <section> should run cleanly - the generated <allcaps> json </allcaps> files should be fully compatible with the existing <allcaps> json </allcaps> files . <section> test / validation vm <section> this means there are a few cases where the <allcaps> eds </allcaps> file does not exactly match how it is currently implemented . things like missing "" spare "" bits , or a different width type , etc . <section> joseph hickey , vantage systems , inc .",0.0
"document recommended file naming conventions and expected content <section> the <allcaps> cfs </allcaps> apps still vary quite a bit in terms of the content and structure of the source files , even though many do share similar file names in their source trees , the content is not always aligned . for example , <code> and <code> apps both have <code> files ( draco - rc4 tag linked here ) : <url> <url> <url> <url> but the content of the file between these two apps is quite different ; in "" hs "" the <code> file contains only some <code> statements associated with table definitions , whereas in "" hk "" this has the complete table definition structures . in contrast , the "" hs "" app puts the complete table structure definitions in <code> , but this same file has only a <code> in hk . <section> improve consistency not only in file naming but also the content and scope / usage of those files , which starts by documenting the recommended patterns so developers have a guide to follow , as opposed to assumptions . <section> this is extra misleading in <allcaps> cfs </allcaps> because files _do_ have similar - looking names , which suggests similar usage and content , but the latter is not actually the case . having the appearance / veil of consistency without actual consistency within the file is worse than having no appearance of consistency at all . <section> joseph hickey , vantage systems , inc .",2.0
<allcaps> tbl ut </allcaps> failure when max table size is increased <section> <allcaps> tbl </allcaps> unit tests do not always initialize a memory pool large enough for table load buffers prior to unit test execution . <section> increase the size of the max allowable table sizes and run unit test . example : <hashtag> define </hashtag> cfe_platform_tbl_max_dbl_table_size <number> <hashtag> define </hashtag> cfe_platform_tbl_max_sngl_table_size <number> <hashtag> define </hashtag> cfe_platform_tbl_buf_memory_bytes ( <number> * <number> ) <hashtag> define </hashtag> cfe_platform_tbl_max_simultaneous_loads <number> <section> dan knutsen <allcaps> nasa gsfc </allcaps>,0.0
"automate generation of integration candidate branch <section> generating the integration candidate branch is a very straightforward process , although it can be highly time consuming . automating this process can result in significant time savings . <section> use a github workflow to automatically merge a set of pull requests into the integration candidate branch and push it to github . <section> scripts can be used to simplify this process as well , but it requires setup by the person maintaining the repository and is not as portable . <section> dylan baker / <allcaps> nasa gsfc </allcaps> <number>",2.0
"inconsisent search paths used for mission - provided files <section> the cmake build system allows the user to provide customized versions of particular files by creating a file of the same name in the <code> configuration directory . specifically this feature is important for configuration header files and table files that are intended to be customized by the user . the problem is that the search paths / patterns used for the cmake <code> function ( for table files ) and the <code> function ( for headers ) are not related at all , which is confusing . <section> the search patterns and search order / priority levels between two functions should be more consistent , ideally use a common file finding function under the hood to implement the search , so the patterns and order will be the same . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , move no_such_table_err_eid into findtableinregistry and make optional testing performed * * github ci actions all passing successfully . local tests with cfs suite confirm no net loss of coverage . note : quite a few tests had to have an event count incremented up one because <number> functions in <code> were calling <code> but were not sending an event on failure ( like those from <code> were ) . so any unit tests calling these functions ( including downstream ) with intentional failures to find the table now issue an event , where they did not do so previously . <section> event reports of <code> are now all issued from within <code> and can be optionally switched on or off from within the platform config file . <section> intel ( r ) celeron ( r ) n4100 <allcaps> cpu </allcaps> @ <number> . 1 0 ghz x86_64 debian <allcaps> gnu </allcaps> / linux <number> ( bullseye ) current main branch of cfs . <section> avi weiss <user>",2.0
"move cmd pipe processing into separate dispatch file <section> currently the "" taskpipe "" function is comprised of a couple big switch statements based on msgid and fcncode , along with length validation and potentially other structural checks . if / when migrating to <allcaps> eds </allcaps> some of that logic can be handled by common code that check against constraints defined in <allcaps> eds </allcaps> . <section> the current "" taskpipe "" function and the supporting logic around it should be moved to a separate "" dispatch "" source unit . this improves organization in general , but also makes for an easier switch to different logic in the future , should that come to be needed . <section> the alternative is to add <code> blocks if validation logic needs to be switched . <section> the recommended solution of moving this logic to a separate source unit permits source - selection in cmake at configuration time rather than relying on preprocessor - based option selection . this is generally cleaner , and permits all options to be verified in a single unit test build , as opposed to only being able to test the selected option . <section> joseph hickey , vantage systems , inc .",2.0
"cfe_sb line / branch coverage not <percent> <section> currently cfe_sb is not seeing full code coverage during the unit tests . there are two conditions that seem to be causing this : <number> . in various functions there are checks for - pendingeventid ! = <number> and status = cfe_success . however , both of these variables are being changed together , such that conditions are mutually exclusive . the end results is that there is no path for pendingevent to still be non - <number> if the status does not equal cfe_success . example ( cfe_sb_api . c line <number> <sad> if ( status = = cfe_success ) { cfe_sb_pipedescsetfree ( pipedscptr ) ; - - cfe_sb_global . stattlmmsg . payload . pipesinuse ; } else if ( pendingeventid ! = <number> ) { cfe_sb_global . hktlmmsg . payload . createpipeerrorcounter + + ; } <number> . another issue that is occurring is in all usages of switch statements . without a default case capturing an unknown event id , sb assumes that the case will always fall within the defined eids - which causes an issue with gcov coverage statistics . example : switch ( pendingeventid ) { case cfe_sb_del_pipe_err1_eid : cfe_evs_sendeventwithappid ( cfe_sb_del_pipe_err1_eid , cfe_evs_eventtype_error , cfe_sb_global . appid , "" pipe delete error : bad argument , pipedid % ld , requestor %s "" , cfe_resourceid_to_ulong ( pipeid ) , fullname ) ; break ; case cfe_sb_del_pipe_err2_eid : cfe_evs_sendeventwithappid ( cfe_sb_del_pipe_err2_eid , cfe_evs_eventtype_error , cfe_sb_global . appid , "" pipe delete error : caller ( %s ) is not the owner of pipe % ld "" , fullname , cfe_resourceid_to_ulong ( pipeid ) ); break ; } <section> i believe these were already adjudicated as part of the coverage analysis . however , they were pointed out by <allcaps> jsc sa </allcaps> and it is likely the non100 % coverage statistics will keep coming up such that it would be worthwhile to revisit / fix or document why we think the branch coverage meets requirements . further , we may want to audit our branch coverage for the other core apps as well . <section> dan knutsen <allcaps> nasa gsfc </allcaps>",2.0
"add "" workflow_dispatch "" for any workflow that depends on an external action <section> currently , the existing github workflows are only triggered by pull request and push events . however , many of them use external workflows , mainly those defined in <code> bundle repo , and some 3 rd party ones . problem is , when merging new code to the cfs bundle repo main branch , there is no way to re - run the cfe workflows against the updated main branch of cfs . clicking the "" re - run "" button on the previous run does not work ; it runs with the same bundle commitid as the original did . we need a way to run against the updated <code> branch of the cfs repo , even when the cfe repo may not have changed at all . currently the only way to trigger this is to make a bogus push to a fork , which will trigger the actions to run and will use the latest version . <section> add "" workflow_dispatch "" as an option to workflows - especially for anything that references an external workflow or action in the <code> branch that can in turn be updated outside the merge cycle of the local repo . <section> this provides a simpler , cleaner method to re - validate the cfe workflows are still functioning after a change to the cfs repo . <section> joseph hickey , vantage systems , inc .",2.0
"add abstract target for documentation dependencies <section> both the <allcaps> cfe </allcaps> documentation as well as the <allcaps> cfs </allcaps> app documentation builds require certain generated files to exist before they can run . currently the <allcaps> cfe </allcaps> itself solved this with a direct dependency on <code> but this is not ideal , because it is referring to a very specific <allcaps> osal </allcaps> target , which is based on the way <allcaps> osal </allcaps> documentation is currently implemented , but may not be so in the future . furthermore , the <allcaps> cfs </allcaps> app doc workflows do not have this , and thus the workflow fails . <section> add an abstract target for documentation , correlating to the existing <code> for source files , such as <code> . this can in turn depend on the specific targets that are needed to be created in order to build documentation . this allows all submodules to also add dependencies onto this target , in case they have an artifact that needs to be generated prior to building documentation . <section> joseph hickey , vantage systems , inc .",2.0
"cppcheck errors reported using latest workflow update <section> the latest version of ubuntu ( with cppcheck v2 . <number> ) is reporting the following errors in the cfe repo : | severity | file | line | issue | | - - - | - - - | - - - | - - - | | error | / home / runner / work / cfs / cfs / source / cfe / modules / tbl / ut - coverage / tbl_ut . c | <number> | uninitialized variable : file . tblheader | | error | / home / runner / work / cfs / cfs / source / cfe / modules / tbl / ut - coverage / tbl_ut . c | <number> | uninitialized variable : file . tblheader | <section> run latest version of static analysis workflow ( depends on nasa / cfs # <number> ) <section> should run cleanly <section> ubuntu <number> , with cppcheck v2 . <number> <section> summary from workflow run <url> <section> joseph hickey , vantage systems , inc .",0.0
"remove changelog from cfs documentation action <section> related to <url> the cfs documentation and guides workflow is failing due to an error in <allcaps> psp </allcaps> ' s changelog . <section> remove the changelog <section> keep as is . <section> ariel adams , <allcaps> mcsg </allcaps> tech",1.0
"recursion and side effects in boolean expressions <section> side effect in a boolean expression and use of recursion in several cfe files . avoiding recursion allows tools and people to better analyze the program . this ticket is for side effects in boolean expressions that also fixes recursion issues . <section> same behavior <section> one example : <url> <section> caught by codeql . can either dismiss as will not fix , false positive , or used in tests ( some are test files ) or fix these alerts . <section> ariel adams , <allcaps> mcsg </allcaps> tech",2.0
"automate changelog for <allcaps> readme </allcaps> <section> when merging an integration candidate branch into main , the author must manually update the changelog for the <allcaps> readme </allcaps> . md file . this can be automated to reduce time and possible missed pull requests . <section> automate the creation of a changelog and use it to replace / update the existing <allcaps> readme </allcaps> . md file . an example can be found in cfs , <url> but it will need to be tweaked so that only merged prs are included . <section> keep as is . <section> can use github actions or github cli like gh . <section> ariel adams , <allcaps> mcsg </allcaps> tech",1.0
"resolve issues building users guide with ubuntu <number> / doxygen <date> <section> automatic generation of doxygen documentation fails at latex make step , hangs up at <code> error prompts . <section> resolve via simplifying the dox source files <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"uninitialized variable static analysis warnings <section> <number> new warnings identified , <number> in ut and <number> in op code . note op code issue is just to squash the warning , no real operational issue identified . <section> squash <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_es_getpoolbuf ( ) return value is confusing on error , cfe_es_getpoolbuf ( ) returns a status code , but on success , it returns the size allocated ( which is actually the size input parameter , so the return value is redundant . ) i suggest either make the size parameter an in / out parameter , or just return a <allcaps> cfe </allcaps> status and the caller can assume cfe_success means the memory size requested was allocated . <url>",2.0
"only the first item passed to add_cfe_app_dependency ( ) function is actually registered <section> the add_cfe_app_dependency ( ) function in the build system is intended to register when one module depends on another module . it is supposed to accept a list of modules , but only the first item actually gets registered . if attempting to register more than one , the second item ( and anything beyond that ) do not have an effect . <section> attempting to change the "" bp "" app to depend on the bplib library as well as a input / output layer called "" iodriver "" , i changed : <code> to <code> however this did not have any effect , i did not get the iodriver public include path as expected - it did nothing . <section> all listed dependencies should be registered and public include paths of all dependencies should be added to the app target . <section> ubuntu <number> <section> this is caused by the wrong variable in the loop . there _is_ a loop to handle all the listed dependencies , but it registers the first one multiple times , because the wrong variable is referenced inside the loop . <section> joseph hickey , vantage systems , inc .",0.0
"abort on restart after maximum resets ( linux w / mismatched restart request / restart type ) <section> after exceeding the maximum number of unplanned resets allowed per cfe_platform_es_max_processor_resets , the system attempts to perform a <allcaps> por </allcaps> instead of a <allcaps> processor </allcaps> reset . unfortunately this orderly reset fails due to an apparent deadlock and the system eventually times out and calls abort . note that this does not occur when using cfe_es_resetcfe , only with cfe_psp_restart ( cfe_psp_rst_type_processor ) . <section> steps to reproduce the behavior : modify any app to call cfe_psp_restart ( cfe_psp_rst_type_processor ) on command - i used sample app ' s noop command issue the command to trigger the restart and then re - spawn the executable repeat the restart until the system falls back to a <allcaps> por </allcaps> reset <section> expect a clean <allcaps> por </allcaps> restart without the <number> second timeout and abort <section> <section> - hardware intel i7 - 1 0 8 7 0 h <number> <allcaps> gb ram </allcaps> - os : [ e . g . linux <number> ] linux - - - - - - - - <date> - <number> - generic # <number> ~ <phone> ~ <number> ~ 7 d5e891 <allcaps> smp </allcaps> preempt_dynamic fri j x86_64 x86_64 x86_64 <allcaps> gnu </allcaps> / linux - versions [ e . g . cfe <number> , <allcaps> osal </allcaps> <number> , <allcaps> psp </allcaps> <number> for mcp750 , any related apps ] latest cfs distribution as of <date> , modification to sample_app to call cfe_psp_restart . <section> stack trace from running threads at the time of the abort <code> <section> lorn miller red canyon engineering & software",0.0
remove stray <allcaps> todo </allcaps> <section> <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"shift overflow compiler warning in endian macros <section> <code> from : <url> <section> mask , then shift . <section> none <section> - # <number> or really transition to serializer / deserializaer concepts . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
update wrong comment regarding the value of cfe_sb_invalid_msg_id <section> cfe_sb_invalid_msg_id value is no longer the maximum representable number of type cfe_sb_msgid_t . comment needs to be updated . <section> link to lines of code <url> <section> jose f . martinez pedraza / <allcaps> gsfc </allcaps> <number>,1.0
add cfe_status_t conversion macros / functions <section> various issues / complexities relative to cfe_status_t handling : - # <number> - # <number> - # <number> but there are no conversion wrappers / apis . <section> add cfe_status_c and cfe_statustostring to support future enhancements to error handling . matches <allcaps> osal </allcaps> pattern ( except <allcaps> osal </allcaps> does not have osal_statustostring yet ) . <section> see linked issues . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"stopping an <allcaps> app </allcaps> that has a locked mutex using cfe_es_stopappcmd <allcaps> bug </allcaps> <section> an <allcaps> app </allcaps> cannot be correctly stopped by cfe_es if the <code> is sent in the same moment that the <allcaps> app </allcaps> has a mutex locked . although the app is terminated ( with errors ) , when we try to restart it , it does not work . <section> steps to reproduce the behavior : <number> . create a mutex in sample_app using <code> <number> . take the mutex in the sample_app runloop using <code> <number> . perform cfe_es <allcaps> cmd </allcaps> <code> using "" sample_app "" as target <number> . see error <code> <section> <number> . cfe_es should be able to unlock the mutexes in a target <allcaps> app </allcaps> in order to close all its resources . <number> . in case cfe_es behavior can not do that , how can we handle apps that have mutexes and may be closed in the exactly same moment that its mutex is locked ( "" taken "" ) ? <section> - ubuntu <number> <allcaps> lts </allcaps> - version : cfs caelum release candidate <number> ] ( <url> ( also tested with [ aquila ] ( <url> and [ cfs bootes release candidate <number> <url> <section> an example : image <img> <section> igor luppi",0.0
"<allcaps> url </allcaps> to "" cfe users guide "" in the top - level <allcaps> readme </allcaps> . md returns a <number> <section> this is the <allcaps> url </allcaps> to the <code> given on the front page <allcaps> readme </allcaps> . md : <url> the <allcaps> url </allcaps> returns a <number> . <section> steps to reproduce the behavior : <number> . go to <url> <number> . follow the link given by : > the detailed cfe user ' s guide can be viewed at <url> <number> . click the link and see the <number> . <section> the document should exist at the given <allcaps> url </allcaps> . <section> alex carrillo",1.0
resolve uninitialized variable warnings in fsw when compiling unit tests <section> static analysis warnings observed relative to fsw when compiling the unit tests based on how the stubs are implemented . <section> fix since it also makes the code more robust to underlying <allcaps> api </allcaps> changes . not marking as bug since non unit test analysis does not identify issues . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"automatic suppression of flooding events <section> we have observed that overly verbose event messages can take down a processor , especially if the generation of events can induce the production of more events due to increased sb / sbng traffic . some ability to rate - limit events regardless of filter state seems to be desirable , as the default for many apps is often unfiltered , and during an event storm it may not be possible to command an event to be filtered . in addition , there are concerns about critical event messages being lost amongst a flood of less critical events , especially when not commandable due to being in a temporary loss - of - signal state . there ' s also the desire to automatically re - enable an event if it is no longer flooding , and the proposed solution would have that characteristic . this is important if the event notifying that the filter has been activated gets lost due to flooding . events could still be permanently suppressed w / the existing binary filters . <section> a filter that is applied per - app , per event type ( priority ) . a token counter for ( app , event type ) is incremented every time an event message arrives for ( app , event type ) . meanwhile , the token counter is decremented at a fixed rate . if the token counter exceeds a certain threshold , incrementing stops and all incoming events for that ( app , event type ) are discarded until the counter is below a threshold ( could be the same as the suppress threshold , then it ' ll effectively rate limit after allowing a small burst ) . <section> to simplify the implementation , this could be done globally for all events instead of on a per - app basis . there would be the problem of a misbehaved app flooding out another app sending more critical event messages , but this could be mitigated somewhat by doing this per - event type or prioritizing by event type . a more granular solution would filter only excessively verbose events by ( app event id ) but this would probably require registration of all events and enforcement . it appears that not all apps register all events w / <allcaps> evs </allcaps> ( i . e . sbng ) . another solution that only addresses the auto - reenabling of formerly flooding events would be to add another filter type besides binary filter that uses the above mentioned token scheme . this does not help too much since the filter type is set by the app during registration , if events are registered at all . <section> initial driver was sbng does not come w / default filters for floodable events , and one of our other apps also sends off a lot of events on startup . obvious solution is to modify these apps to setup default filters , but this does not address reenabling the events automatically when the transients go away , nor does it address unexpectedly flooding messages due to unforeseen edge cases . <section> john n pham , northrop grumman",2.0
"default to <number> bit memory address / offset for all io ( cmd / tlm / tbl / binary dumps ) <section> cfe_es_memaddress_t / cfe_es_memaddress_c and cfe_es_memoffset_t / cfe_es_memoffset_c are used to convert cpuaddr into a fixed size for cmd / tlm / tbl / binary output . currently they are both hard - coded to uint32 : <url> problem is this basically is just wasted space on <number> bit and also requires querying a separate element to know if these values are valid . also ends up reducing functionality ( and not supporting some requirements on certain apps ) . <url> there ' s also cases where validity is not actually indicated within the element as in tbl tlm : <url> note mm , cs , and md also all have memory addresses in io . <section> default to <number> bit everywhere and reorganize io to avoid implicit padding where possible based on the change . this is a breaking change ( io change ) so probably appropriate to either provide backwards compatibility or target a major release . this does waste space on <number> - bit systems , but makes it such that the values are always valid ( no longer need a special flag as long as the underlying functionality is still valid ) . none of the uses are in what would typically be high rate telemetry so should be minimal impact . if really need we could support configurability , or projects could locally modify if really needed . <section> none <section> discussed at <number> <allcaps> ccb </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"convert mission / platform cfe configuration to cmake to support source selection <section> many configuration options involve conditionally compiled code which is discouraged in various coding standards and makes unit testing multiple configurations require separate builds . <section> switch to the <allcaps> osal </allcaps> pattern of defining configuration via cmake file ( s ) , which then could be used to source select during the prep . also all units could then be tested / covered regardless of the actual selection to ensure code is not rotting . functional testing would still require a separate build , but at least this would show the code still compiles in the unit test setup . <section> add multiple unit test builds <section> # <number> as a specific example of a related issue . note <allcaps> msg </allcaps> already uses cmake variables for source selection , which should be added to the config . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use document generation reusable workflow <section> updates to make documentation more consistent for # <number> requires an update to the documentation generation workflow , so also switching to use reusable workflow added by nasa / cfs # <number> . <section> use reusable workflow added by nasa / cfs # <number> <section> none <section> depends on nasa / cfs # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"use consistent documentation generation directories / names to support matrix actions from cfs <section> naming is not consistent , osal - apiguide uses osalguide directory , mission - doc generates a detaildesign directory but the warning file gets put in the docs directory instead of subdir , etc . <section> make behavior consistent . <section> none <section> cleaning up top level nasa / cfs # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"build failure with cfe_platform_time_cfg_src_time = = true <section> build failures when enabling time source configuration . <code> <section> - set <code> true - set <code> true - set <code> false <section> should build and run . <section> see warning above , note <number> instances of the old reference . <section> - hardware : i5 / wsl - os : ubuntu <number> - versions : bundle main <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"sb housekeeping internalerrorcounter increments for nominal conditions <section> sb housekeeping internalerrorcounter increments for nominal conditions such as <code> or <code> <section> have apps running that poll a pipe or block w / timeout <section> internalerrorcounter only increments on actual errors <section> <url> <section> - sp0 - os : vxworks <number> - versions : <allcaps> cfe </allcaps> 9 c86dd4020327e52d894f1266d7b98d32dc6d34a <section> add any other context about the problem here . <section> john n pham , northrop grumman",0.0
"use osal common config to resolve <allcaps> osal </allcaps> doxygen references and provide default settings <section> path dependencies in cfe on <allcaps> osal </allcaps> <section> use the osal - common . doxygen instead , removes cfe dependency on <allcaps> osal </allcaps> paths <section> none <section> depends on nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"cfe_es_waitforstartupsync ( ) - - behavior if timeout reached ? i am a little confused by the cfe_es_waitforstartupsync ( ) timeout , there ' s no way to determine if the timeout was reached ( except looking at wall clock time elapsed ) and what should the application do if the timeout is reached ( if anything ) ? i am guessing that the caller should just proceed assuming startup has completed even if the timeout was reached , but perhaps this can be made clear in the documentation for this function ? i plan to use this for <allcaps> sbn </allcaps> but perhaps i should be using cfe_es_waitforsystemstate ( ) instead ? the comments imply cfe_es_waitforstartupsync ( ) is a convenience and may be deprecated ? <url>",3.0
"nonmonotonicity with cfe_time_gettime <section> the time returned by cfe_time_gettime ( ) is not monotonically increasing . <section> steps to reproduce the behavior : create a new app ( add the appropriate configuration to startup script and targets . cmake ) with the following files : runner . c : <code> analyze_time / cmakelists . txt : <code> <section> there should never be any case when a timestamp has the same seconds but lower subseconds field than an earlier timestamp . <section> see above <section> - os : <number> . <number> - <number> - generic ubuntu <section> the frequency with which the time discrepancy is printed decreases when the input to the usleep ( ) function is increased . still , there is always one timestamp discrepancy printed regardless of the input to usleep ( ) . we first noticed the behavior while trying to read data from an <allcaps> imu </allcaps> sending values at roughly 1 2 5 hz .",3.0
update app dev guide and unit tests to use <code> instead of <code> <section> <code> still used in ut and docs where <code> should be used to avoid dependency on internal cfe_msg_message_t elements . <section> replace with <code> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"doxygen <code> if needed should not contain unique content , just references <section> currently <code> has content , and since only one <code> can exist in a doxygen document other documents can not include this unique information . <section> doxygen will set up document in order , so could just replace <code> with a front page and <code> the front page first . <section> make ' mainpage ' just a reference to other pages . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> per project request .",1.0
"link error when building with mission_msgid_v2 = <allcaps> true </allcaps> <section> cfe compiles ( with warnings about implicit function declarations ) , but linking the cfe_core executable errors out with undefined references to symbols <code> and <code> . <section> steps to reproduce the behavior : <number> . create a mission configuration . modify global_build_options . cmake by adding the following two lines : set ( mission_include_ccsdsext_header <allcaps> true </allcaps> ) set ( mission_msgid_v2 <allcaps> true </allcaps> ) <number> . build cfs . the following warnings will be issued when compiling cfe_msg_msgid_v2 . c : [ <percent> ] building c object msg / cmakefiles / msg . dir / fsw / src / cfe_msg_msgid_v2 . c . o / home / dsa / lpnt_ws / dsa_lpnt_fsw / fsw / cfs / cfe / modules / msg / fsw / src / cfe_msg_msgid_v2 . c : in function ‘ cfe_msg_getmsgid ’ : / home / dsa / lpnt_ws / dsa_lpnt_fsw / fsw / cfs / cfe / modules / msg / fsw / src / cfe_msg_msgid_v2 . c : <number> <time> : warning : implicit declaration of function ‘ cfe_sb_valuetomsgid ’ [ - wimplicit - function - declaration ] <number> | * msgid = cfe_sb_valuetomsgid ( msgidval ) ; | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ / home / dsa / lpnt_ws / dsa_lpnt_fsw / fsw / cfs / cfe / modules / msg / fsw / src / cfe_msg_msgid_v2 . c : in function ‘ cfe_msg_setmsgid ’ : / home / dsa / lpnt_ws / dsa_lpnt_fsw / fsw / cfs / cfe / modules / msg / fsw / src / cfe_msg_msgid_v2 . c : <number> <time> : warning : implicit declaration of function ‘ cfe_sb_msgidtovalue ’ [ - wimplicit - function - declaration ] <number> | cfe_sb_msgid_atom_t msgidval = cfe_sb_msgidtovalue ( msgid ) ; | ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ the following error will be reported at the link phase : [ <percent> ] linking c executable core - cpu1 / usr / bin / ld : . <repeated> / msg / libmsg . a ( cfe_msg_msgid_v2 . c . o ) : in function <code> cfe_sb_valuetomsgid ' / usr / bin / ld : . <repeated> / msg / libmsg . a ( cfe_msg_msgid_v2 . c . o ) : in function <code> cfe_sb_msgidtovalue ' collect2 : error : ld returned <number> exit status make11 <url> [ cpu1 / cmakefiles / core - cpu1 . dir / build . make : <number> : cpu1 / core - cpu1 ] error <number> <number> . the bug occurs because the two functions are defined as ' static inline ' in cfe_sb . h , which is not referenced in cfe_msg_msgid_v2 . c , and because the c language prior to the c99 standard implicitly defines functions as <code> . simply adding <code> fixes the problem . <section> core - cpu1 should compile and link cleanly . <section> see attached patch file . msg_v2_link_error_patch . txt <url> <section> - hardware : virtualbox <date> emulation of a generic x86 - <number> system on macos <number> . <number> - os : ubuntu <number> - compiler : <allcaps> gcc </allcaps> <number> . <number> - versions : cfe tag v7 . <number> - rc4 , <allcaps> osal </allcaps> tag v6 . <number> - rc4 , <allcaps> psp </allcaps> tag v1 . <number> - rc4 <section> <section> chuck fry , <allcaps> qts </allcaps> inc . , subcontractor to <allcaps> kbr </allcaps> wyle on the isrds3 contract , at <allcaps> nasa arc </allcaps> code ti <email>",0.0
"resolve detailed design doxygen generation warnings from <code> and enforce in ci <section> <code> produces warnings <section> fix issues to resolve warnings , enforce in ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"remove explicit file name references in doxygen file comments to avoid warnings <section> file comment without a filename implies the comments apply to the current file . adding the file name makes doxygen try to match that file . the issue is there ' s multiple files with the same name , so doxygen gets confused unless you add full path . really it ' s just overhead since the point is to comment the current file . sample warning if you <code> from the bundle : ` ` <code> os - impl - binsem . c ' supplied as the second argument in the \ file statement matches the following input files : / home / jhageman / cfs / cfs - github / osal / src / os / posix / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / rtems / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / vxworks / src / os - impl - binsem . c please use a more specific name by including a ( larger ) part of the path ! ` ` ` <section> easiest to just remove the name since for every case the comment applies to the current file <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , remove redundant word <section> - fix # <number> a clear and concise description of what the contribution is . - removes redundant word in the application developer ' s guide in order to make documentation clearer <section> a clear and concise description of how this contribution will change behavior and level of impact . - no impact to behavior <section> personal - hugo valente",1.0
"<code> handler default behavior fails if return not set <section> any ut not setting the return for <code> will see the call fail in the unit under test : <url> <section> < ore helpful to test against cfe_sb_invalid_msg_id if the return is not set . <section> none <section> just test against invalid , since max is configurable and ut ' s should not rely on it . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"replace cfe_sb_valuetomsgid ( <number> ) with cfe_sb_invalid_msg_id <section> using zero explicitly is not great , for the most part all cases should be replace with just using the invalid macro : <code> <section> replace with cfe_sb_invalid_msg_id <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"implement message dispatch table within sb for unified validation and invocation of handler <section> most ( but not all ! ) applications use a big <code> statement to interpret the <allcaps> mid </allcaps> and command code , and invoke a handler . problem is : - still done very inconsistently . styles of this <code> vary significantly in terms of where the checks are done , and the type of validation that is done ( some apps still do not do length checks before casting ) - fundamentally still requires interpretation of msgid as integer value , because a <code> in c only works on integer values . ideally apps should treat msgid as opaque , not do any local interpretation of the value . - some apps do not use the <code> approach at all , implementing a dispatch table instead . notable examples are <allcaps> tbl </allcaps> services , and the cf app . while these both use the general concept of a table lookup to a function pointer , they are implemented pretty differently . <section> the dispatch table is a cleaner design , since it allows the application code to be more agnostic to how mids work . notably , the part that interprets / matches the mids can be put into sb , thereby no longer requiring the _app itself_ to interpret / match the mids . but rather than letting every app individually migrate to this pattern and have each one done differently , the framework should preemptively add a generic dispatch routine within sb . the generic function should : - validate the initial message <allcaps> mid </allcaps> coming in ( does it match any known <allcaps> mid </allcaps> in the table ) - interpret and validate the command code , if the msg has one ( does it match any known cc in the table ) - confirm that the length of the message is correct - cast the message to the correct "" real "" type and invoke the handler function that was provided from the app . <section> see <allcaps> tbl </allcaps> services and cf app , its the same idea . <section> framework needs to add this alternative method of dispatching first , but apps would not be required to use it ( backward compatible ) . the framework apps in draco could all be converted to a dispatch table . but <allcaps> gsfc </allcaps> and other external <allcaps> cfs </allcaps> apps would continue using their existing methods in order to remain "" caelum - compatible "" but could be updated over time to the unified dispatched as warranted , if / when changed for other reasons . <repeated> this is also somewhat related to / part of # <number> . <repeated> it would cover one of the items listed in there ( generic length check ) <section> joseph hickey , vantage systems , inc .",2.0
"revert app info structure modification (# <number> , # <number> ) , relative to draco development cycle <section> <code> is public so the change in # <number> /# <number> is breaking . should not have been included in draco . makes cs non - portable between caelum and draco . <section> revert . <section> could add accessor functions or some sort of abstraction / layer or back - port , but the change really is very low priority . could be considered in a future major update cycle if there ' s some actual benefit from the additional structure . could make cs adapt also ( conditional compilation or whatever ) , but i do not think it ' s worth it for this sort of change or carrying that option . <section> need to decide if we want to reopen # <number> as future work or leave closed . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add cfe_es_appinfo_t element documentation <section> - fix # <number> <section> documentation only / ci <section> none <section> - hardware : ci only - os : ubuntu <number> - versions : bundle main + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
add app info structure element descriptions back in <section> element descriptions were dropped in # <number> <url> <url> <section> add element descriptions <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"<allcaps> es perf </allcaps> array size calculation assumes "" uint32 "" array base type <section> the es perf code uses macros to determine the array length based on the overall array size ( via <code> ) . problem is , these calculations hard - code a <code> type as the divisor ( element size ) which may not always be true . <section> change the definition of the masks in <allcaps> tlm </allcaps> to be e . g . uint8 - based instead of uint32 - based . array lengths are now calculated incorrectly , because it divides by <code> which would now be wrong . <section> should use <code> to get the actual type of the element , this makes the calculation future - proof , as it does not assume / repeat the array element type ( adheres to <allcaps> dry </allcaps> principle ) <section> <url> <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
initialize <allcaps> cds </allcaps> block data in es unit testing to avoid uninit var warnings from valgrind <section> block data is used uninitialized in unit test : <url> <url> <url> <section> initialize . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
limit <allcaps> sbr </allcaps> message id loops for reasonable test times <section> loops over cfe_platfor_sb_highest_valid_msgid can take a long time on some systems ( many minutes ) . unit tests that cover the full range for the default setting is sufficient to show proper operation . <url> <url> <url> <section> limit the loops . <section> none <section> none <section> jacob hageman <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>,2.0
username change i changed my username from ( at ) pavll to <user> . the problem is that someone else claimed my old name an now he ' s mentioned every time ( at ) pavll was used ( mostly prs ) . do i have to state this change somewhere for my nasa opensource contribs ( because github does not redirect @ mentions to new usernames ) ?,3.0
"compiling in external libraries hi , i am currently trying to run the core flight executive on a freertos environment . i am currently using a community port based on an older version and am running into some difficulties during the linking stage . my main issue i believe is due to the fact that i am trying to link an externally compiled library that contains freertos and all of the device drivers generated by my <allcaps> ide </allcaps> . however , when i insert the following lines into the cmakelists . txt file in the osal folder : add_library ( libfreertros <allcaps> static imported </allcaps> ) set_target_properties ( libfreertos <allcaps> properties </allcaps> imported_location "" / home / user1 / projects / cfs / bsp / libfreertos . a "" ) i get an error : set_target_properties can not find target to add properties to : libfreertos please let me know if this is the appropriate place to post this :",3.0
"fix # <number> , cfe application developers guide . md : specify language for improved code highlighting <section> fixes # <number> specify the language to improve the code highlighting . <section> none . <section> no impact to behavior or <allcaps> api </allcaps> .",1.0
"inttypes . h - style printf format strings for common types <section> for message id ' s , cfs generally use 0x % 0 8 x but sometimes it ' s printed with 0x % 0 8 x ( lowercase a - f ) , or without the 0x , or even as % d or % u . ( although i do not know if that ' s used anymore . ) <section> per <url> c99 added printf format string macros for int types and it would be keen to follow this practice . i suggest prixmsg or pridmsg for printing ( generally , sending an event message ) a message id in hex or decimal ( defined as <code> and <code> for unsigned integer ( <number> - bit ) msgids . so instead of : <code> it would be : <code> <section> leave well enough alone . <repeated> <laugh> <section> add any other context about the feature request here . <section> <email>",2.0
"cfe application developers guide . md shows use of deprecated binary filter constant name <section> cfe_evs_binary_filter appears in the guide , but the current usage is cfe_evs_eventfilter_binary . <section> n / a <section> update guide to show use of cfe_evs_eventfilter_binary . <section> there are <number> locations : line <number> <url> line <number> <url> line <number> <url> <section> n / a <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",1.0
cfe application developers guide . md showing use of deprecated event message constants <section> developer ' s guide is still showing the old event message type names . <section> n / a <section> all uses of event message types should be updated to the currently used names in the guide . <section> main listing of event type values : line <number> <url> examples of cfe_evs_error use within the guide : line <number> <url> line <number> <url> <section> n / a <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>,1.0
"add delayed responses to command verification documentation related to command codes <section> missing documentation on delayed responses . for example , cfe_es_stop_app_cc is a "" request "" which when initiated creates the cfe_es_stop_dbg_eid ( documented ) , but when the request is actually completed a cfe_es_stop_inf_eid is sent ( not documented ) . <url> <url> <section> scrub "" request "" class of commands for complete verification documentation and add where missing . confirm these events are checked in test . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_platform_endian - - not used ? . <repeated> # <number> removed definitions for ccsds_ { <allcaps> big </allcaps> | <allcaps> little </allcaps> } _endian . in cfe / sample_defs / cpu1_platform_cfg . h , there is a definition for cfe_platform_endian but it is defined as ccsds_little_endian but that is not defined anywhere . also the comments mention that the valid values for cfe_platform_endian are "" <number> "" or "" <number> "" .",2.0
"mismatched foreach in cmake function the endforeach args do not match the foreach args foreach ( <allcaps> app </allcaps> ${ mission_deps } ) list ( <allcaps> append varlist </allcaps> "" ${ <allcaps> app </allcaps> } _mission_dir "" ) endforeach ( <allcaps> app </allcaps> ${< section > } ) <url>",2.0
"overrun warning false alarm for cfe_sb_buffer_t <section> overrunning struct type cfe_sb_buffer_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument msgsize ( which evaluates to <number> ) . <section> fix overrun <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"incrementing componentptr when pointing at componentterm goes out of bounds ( but is not accessed ) <section> using componentptr as an array . this might corrupt or misinterpret adjacent memory locations . <section> fix out - of - bounds access bug <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"overrun warnings false alarm for cfe_msg_message_t <section> out - of - bounds access ( <allcaps> overrun </allcaps> ) <section> fix overruns <section> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 1 6 0 ul . <url> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 4 8 ul . <url> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 3 2 ul . <url> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 4 4 ul . <url> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 3 0 0 ul . <url> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 2 8 ul . <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"unsigned compared against <number> always true <section> this greater - than - or - equal - to - zero comparison of an unsigned value is always true . cmdptr - > triggermode >= cfe_es_perf_trigger_start . <section> fix the if statement . <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"dereference null return value warning false alarm <section> dereferencing bucketptr , which is known to be <allcaps> null </allcaps> . <section> check if bucketptr is not <allcaps> null </allcaps> before dereferencing . <section> <url> <section> coverity : <url> <section> full name and company / organization if applicable",2.0
"check return value of cfe_es_putpoolbuf <section> calling cfe_es_putpoolbuf without checking return value ( as is done elsewhere <number> out of <number> times ) . <section> check return value of cfe_es_putpoolbuf as seen elsewhere . <section> <url> <section> coverity : <url> <section> examples of return value being checked for cfe_es_putpoolbuf <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"strict aliasing build errors in unit test code <section> when using strict aliasing in combination with tests ( i . e . enable_unit_tests = true ) , additional aliasing warnings are produced by <allcaps> gcc </allcaps> <number> . <section> build <allcaps> cfe </allcaps> with tests enabled along with strict aliasing compiler settings ( <code> ) , build will fail with errors such as : <code> <section> should build cleanly <section> ubuntu <number> ( w / gcc <number> ) <section> most of these are related to <code> casts , which is easily resolved by making another local <code> variable to temporarily hold the pointer . <section> joseph hickey , vantage systems , inc .",0.0
"build errors when using extended headers <section> in caelum when setting <code> to use extended headers , i get a build error due to duplicate typedef of the <allcaps> msg </allcaps> types : <code> <section> enable extended headers in caelum config , and build . <section> build should succeed . <section> this is because the "" typedef "" cannot be in both places . in contrast , the standard header ( non - extended ) defines only the union / struct , not typedef ' ed : <url> whereas the extended header version has a typedef : <url> <section> ubuntu <section> joseph hickey , vantage systems , inc .",0.0
"cfe_sb_getuserdata needs functional test <section> this function uses an overly simplistic method to determine the location of the payload structure : <number> . it uses cfe_msg calls to determine if its is <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> ( assuming it has been initialized with a proper msgid ) <number> . it adds the size of the corresponding header to the base pointer . problem is , this does not take into account compiler - added padding , which might be present depending on the size of the header and the alignment requirements of the payload member . <section> deprecate this function ? would need to come up with a solution for the places its used in <allcaps> cfs </allcaps> apps . <section> move logic to cfe_msg , where it knows details ( alignment ) of the header but that is unfortunately not really going to help , since its the alignment of the payload that is the issue here . that is not known anywhere in a generic <allcaps> api </allcaps> . <section> in <allcaps> eds </allcaps> it could actually be made to work properly , because with this tool one knows the layout of the structures and whether or not padding exists - so it can get the real offset of the payload member . without <allcaps> eds </allcaps> , there is not much way to fix this , other than to ensure both <allcaps> tlm </allcaps> and <allcaps> cmd </allcaps> headers have explicit padding added to make them multiples of the worst - case payload alignment . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , implement abstract config registry module <section> adds a new module called "" config "" that tracks simple key / value pairs . all values are const . as a proof of concept , all version information is mirrored into this key store , and es is updated to use this instead of the global_configdata when generating events . fixes # <number> <section> build and sanity check <allcaps> cfe </allcaps> , run all tests . <section> slightly different version display during startup ( module names are all_caps , mainly ) . otherwise pretty transparent . <section> ubuntu <section> this attempts to balance the advantages / disadvantages of having a string - based key / value store and an integer - based key / value store . in this implementation , the table is primarily indexed by an integer , which is assigned at compile time , so its fast ( direct lookup from key to table entry ) . but the downside to this is that it creates a compile - time dependency on the assigned integer ids . so , the keys also have string names associated with them , such that an app can find a key by name , to avoid having a hard compile - time dependency on a particular configuration item , such as if its an optional component . this also has the side effect of improving branch / line coverage in es where it was reading the "" const "" configdata objects . due to the fact that configdata is declared "" const "" , it means that coverage test can also only run with one copy . therefore , it could not cover all the branches as a result . <section> joseph hickey , vantage systems , inc .",2.0
"implement generic runtime configuration registry for <allcaps> cfe </allcaps> <section> rather than compiling - in various values ( e . g . via <code> or <code> ) it would be more flexible and more useful to put many of these configuration items into some type of simple runtime registry . the registry would be a simple key / value store , where the key is the configurable item id , and the value is either an integer or a pointer to a global data object ( ideally const , to avoid sharing / concurrent access issues ) . the registry can be somewhat dynamic , allowing registry items to be easily added / extended . default values and text - based descriptions can also be potentially included . <section> user <allcaps> api </allcaps> that works something like : - <code> - <code> <section> this would reduce dependency on <code> and <code> for keeping this type of value , and also provide a place for the version info currently in <code> . thereby consolidating the current bunch of different types of info with different access methods into one generic registry with a common , simple access method . similar model exists in <allcaps> unix </allcaps> / <allcaps> posix </allcaps> in the <code> facility - so certain platform - specific values do not need to be compiled into binaries , thereby improving binary portability ( i . e . compile once for a <allcaps> cpu </allcaps> arch , run anywhere that has that arch ) . this would make the long - desired feature of separate <allcaps> cfe </allcaps> core and app builds closer to reality . of course windows has its well - known registry , which is huge and unwieldy - this should _not_ turn into that . more like <allcaps> unix </allcaps> sysconf , but with pointers / strings also supported , not just integers . other issues with <code> - ed config values : - value is effectively compiled - into the binary , so if the value ever changes , modular binaries become incompatible ( but this is _not_ actively detected - its a subtle , silent incompatibility ) . - works ok for integers , but not as well for strings , even less well for structured data - requires that the <code> / <code> be kept in sync with the source code . new variables added in new builds must be manually propagated to the user build . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , functional requirements grammar cleanup <section> - fix # <number> grammar cleanup only , no actual change to meaning . <section> none , doc change only <section> none <section> n / a <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
grammatical cleanup of requirements <section> many grammatical issues identified in functional requirements . <section> fix them <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"possible alias warning on certain compiler versions <section> when getting the address of a memory pool buffer directly as a <code> type , it may trigger an alias warning in certain compilers / configurations . example when using <code> on <allcaps> gcc </allcaps> <number> : <code> <section> should build clean <section> using a local <code> intermediate value should avoid this . <section> joseph hickey , vantage systems , inc .",2.0
"making and mounting a file system from cfe functional caused a reformat of <allcaps> ram </allcaps> on mcp750 <section> see # <number> . note # <number> worked around the issue by just using existing ram , but os_mkfs / os_mount should have no impact on the existing drive ( s ) . <section> run the old fs test that creates the additional mount and observe the reformat on mcp750 . <url> <section> should not cause a reformat . <repeated> <section> - hardware : mcp750 - os : vxworks <number> - versions : bundle main ( pre # <number> merge ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"header structure name assumptions limit <allcaps> msg </allcaps> abstraction capability <section> the <allcaps> msg </allcaps> library is supposed to offer a complete abstraction of the header format , but in practice there are still some direct references to header structure members in caelum which limit this capability . in particular , when converting a local message buffer to a <code> pointer , when passing into any cfe_sb <allcaps> api </allcaps> , the code references a sub - member , such as : <url> while this was nice in that it is fully type - safe , it limits the header abstraction in two important ways : <number> . it assumes / requires that the buffer itself contains a <code> member . <number> . it assumes / requires that the <code> structure , in turn , contains a <code> member . for item ( <number> ) above , the <allcaps> tlm </allcaps> header is a structure controlled / defined by the cfe_msg module , and there is no guarantee that a "" msg "" member exists . this will be a problem if an alternate <allcaps> msg </allcaps> module is used , where the <code> member is not called "" msg "" . ( the whole point of <allcaps> msg </allcaps> is to make these structures free - form , and no assumptions should be made as to their internal structure , so this reference somewhat defeats that purpose ) . <section> - convert this to a cast instead , e . g . <code> - have cfe_msg provide a macro / inline function to implement this conversion / cast <section> just document what the names need to be , and make it a requirement to name things in this manner . major issues with that - mainly that it is not friendly to automated tools which might be used to generate these headers / structures from a <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> database . <section> there is no real convention to the names that exist today . it would be more viable to do that if a specific convention / reasoning was followed , such as the <code> member being called <code> ( i . e . without the cfe_msg_ prefix or _t suffix ) . this way a tool would know what name to call things in the generated files . but as it is , there is simply no naming consistency in these members , a tool would have to hard - code "" special "" member names for each structure , for no good reason other than that ' s what a human had used for an abbreviation at one point . but furthermore , even if a name convention was follwed prevents an additional layer of headers to be added . for example , the "" tlmheader "" is assumed contain a "" msg "" member directly . however in some implementations a user might want an intermediate header , where it would become <code> instead . there is no way to accommodate a third layer with the current assumptions in the code . _regarding suggested casts_ - - by casting , it can be converted without knowing what the member is specifically named , nor knowing how deep within the structure the message structure lies . this is not as bad as it sounds , and not really going back to being type - unsafe , because it is being cast to a <code> , not a <code> as previous <allcaps> cfe </allcaps> versions had done here . because of this , and the fact that <allcaps> cfe </allcaps> is compiled with strict aliasing rules enabled , it will trigger an alias violation if the structure is not actually cast - able to a <code> type . while this is not quite as robust as the current type safety , it is much more flexible , and user errors / mismatches should still be caught . <section> joseph hickey , vantage systems , inc .",2.0
"potential for recursive loop if event <allcaps> tlm </allcaps> msgid is incorrect <section> if the software bus <code> fails to send a message due to a validation failure , it will send an event through <allcaps> evs </allcaps> . event services , in turn , generates a message ( longeventtlm / shorteventtlm ) which is broadcast via software bus . however if the event telemetry <allcaps> mid </allcaps> value ( <code> ) is not set correctly ( or some other <allcaps> evs </allcaps> config is bad ) such that <allcaps> evs </allcaps> tries to send event messages which do not validate , a recursive loop ensues and the software eventually segfaults . <section> ( mis ) configure <code> to a value which will not pass the cfe_sb_transmitmsgvalidate tests . run <allcaps> cfe </allcaps> , it will get in a recursive loop and eventually segfault / crash as soon as any app sends an event . <section> should not do a recursive loop <section> ubuntu <section> should be protection against recursive event loops like this , where if an event fails to send , it should not cause another event to be sent . this protection appears this is not working correctly right now , at least not for <allcaps> evs </allcaps> messages . __note__ : to be absolutely clear - the issue described here is a mis - configuration issue . it will not happen in a properly configured system , so long as <allcaps> evs </allcaps> generates messages which are "" transmittable "" . <allcaps> but </allcaps> - there are other events that might be triggered by a cfe_sb_transmitmsg call , such as a msglim error , and its not clear of a similar recursive loop might be possible there ( have not tested / investigated ) . <section> joseph hickey , vantage systems , inc .",0.0
"mismatch between <allcaps> msg api </allcaps> and test case in "" testmsgid "" functional test <section> there is a test case in the "" testmsgid "" set which passes in <code> to <code> , and expects <code> return value : <url> however : - the <allcaps> api </allcaps> does not document that it returns cfe_msg_bad_argument in response to an invalid msgid value ( in fact it does not say anything about validating the input msgid at all ) - the implementation is not actually checking if its a valid msgid anyway . it is checking if it is <code> , which is a different concept . although this is currently "" passing "" - it is only by chance , because cfe_sb_invalid_msg_id has the value of - <number> , which when converted to an unsigned int , will be greater than <code> ( unless the latter is set to 0 xffffffff ) . <section> run this test against an alternate <allcaps> msg </allcaps> module implementation ( i . e . one that has different criteria ) and / or change the sb definition of "" cfe_sb_invalid_msg_id "" . the test will now fail . <section> test case should still pass , even when run against an alternate <allcaps> msg </allcaps> implementation . should not depend on "" chance "" values that it does not control . <section> actual implementation is here ( same basic check in v1 / v2 ) : <url> <section> ubuntu <section> the important concept is nowhere does the documentation say that the <code> constant must be greater than the <code> . in fact , the latter may not even exist in all implementations . - if the intent was to reject an invalid msgid value , the proper function to use is <code> , and the <allcaps> api </allcaps> documentation should state that cfe_msg_bad_argument will be returned in response to an invalid msgid ( it does not currently say this ) . - however , in general the <allcaps> msg </allcaps> module is just supposed to be a getter / setter , not a validator , in its role . so in that sense , validating the msgid is superfluous here , and the check against "" highest "" msgid should be removed . <section> joseph hickey , vantage systems , inc .",0.0
fix broken link in app developers guide fix broken link,1.0
"typos in documentation , print statements , and comments <section> found multiple typos throughout the codebase <section> correct grammar and spelling errors <section> none <section> retroactive issue for # <number>",2.0
"improve consistency in application of cfe_sb_msgidtovalue / valuetomsgid conversions <section> a <code> value , like other ids , is supposed to be a unique type / opaque value that identifies a message within the sb application context . although it is currently implemented using an integer ( <code> specifically ) application should not assume this . instead , a set of macros and inline conversion functions ( cfe_sb_msgidtovalue and cfe_sb_valuetomsgid ) are provided for when the application needs to interpret the value as an integer for a valid purpose . however , since use of this conversion is not currently enforced - there is no config option that makes msgid into a strict type , as there is for resourceid - so much of the newly - added code such as tests and apps , did not completely apply it . <section> add conversions where they are currently missing <section> preferably , the <allcaps> mid </allcaps> constants should be defined directly as a <code> type value , which would eliminate the need for conversions all over the runtime code . however , this breaks the switch / case paradigm used when dispatching - a <code> label needs to be an integer value . so although this would yield cleaner code it does have a bigger backward compatibility impact which is why it was avoided for caelum . <section> joseph hickey , vantage systems , inc .",2.0
"use <number> as cfe_sb_invalid_msg_id <section> currently the value for an "" invalid "" <allcaps> msg id </allcaps> is - <number> , as defined here : <url> the pattern used in other modules ( which is preferred ) is to use <number> as the invalid value , for several reasons : - local variables / structures which are explicitly memset to <number> before use ( common / recommended practice ) will get automatically set to the <allcaps> invalid </allcaps> value - global data structures in <allcaps> bss </allcaps> section get automatically memset to <number> by the loader - uninitialized members of a partially initialized data structure will be automatically memset to <number> so , its much safer to embrace <number> as the reserved / invalid / placeholder value , due to all the different ways memory is cleared to <number> both implicitly and explicitly . <section> change the definition of <code> to be <number> , rather than - <number> . <section> standard headers ( historical / v1 ) are safe because any valid msgid always has the "" secondary header "" flag set ( bit <number> ) . so any valid msgid is already guaranteed to be nonzero . should be trivial to change in this config . will require a check / confirmation of the extended headers ( v2 ) configuration , to ensure that the msgid value <number> does not correlate to a valid address . since one assumes that 0 xffffffff ( - <number> ) already does not correlate to a valid address , it may be as simple as just flipping the bits or adding <number> , if that ' s an issue . note that most other resource types ( appid , taskid , <allcaps> osal </allcaps> ids , memhandle , etc ) already use <number> as the invalid / reserved value for the same reason . msgid and tableid are still outliers that do not do this . for consistency and reliability reasons they should both be updated . ( tableid can be fixed under a separate ticket , possibly as part of a more complete refactor of <allcaps> tbl </allcaps> services ) <section> joseph hickey , vantage systems , inc .",2.0
"missing some dependency include files in public <allcaps> api </allcaps> headers <section> as a general rule of thumb , all header files should directly include whatever dependencies they require in order to provide the types / declarations they intend to provide . however in the <allcaps> cfe </allcaps> headers there remain a couple omissions / mistakes in this regard : - <code> declares the function <code> which accepts a resource id input , so this depends on <code> , but it does not directly include this dependency - <code> defines a <code> type , which in turn has a member sized to <code> , which is provided by <code> , but it does not directly include this dependency . in both cases the current framework sample builds do compile successfully , because the dependent header gets included implicitly ( i . e . by some header before it ) in all the current use cases , but this could change in other use cases . <section> use header files in contexts beyond what the current framework does , such as 3 rd party code only including "" cfe_es . h "" or "" cfe_tbl_api_typedefs . h "" directly . <section> headers should work ( compile w / o errors or warnings ) when included individually , they should include all dependencies directly rather than relying on inclusion ordering . <section> ubuntu <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> # <number> , update dev guide for <allcaps> msg </allcaps> and <allcaps> sbr </allcaps> <section> - fix # <number> - fix # <number> updates the application developer ' s guide for <allcaps> msg </allcaps> and <allcaps> sbr </allcaps> updates . <section> none , doc only . <section> none <section> na <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"es missing branch coverage in cfe_es_runperflogdump , condition not possible <section> there ' s no way for the current state to not be < cfe_es_perfdumpstate_cleanup : <code> here : <url> <section> maybe this is an artifact of a previous implementation ? really could just set the pending state to cleanup . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update sb / <allcaps> msg </allcaps> tests to verify not implemented functions <section> functional tests fail if project is using custom cfe_msg functions that return cfe_sb_not_implemented . <section> in functional test , verify that function to be tested is implemented before running the tests . <section> none . <section> jose f . martinez pedraza / <allcaps> nasa gsfc </allcaps>",2.0
"es branch missing coverage in cfe_es_genpoolrecyclepoolblock and cfe_esgenpoolcreatepoolblock , <allcaps> null </allcaps> pointer check <section> the <allcaps> null </allcaps> pointer check in cfe_es_genpoolrecyclepoolblock would require either exposing this internal routine or getting really lucky corrupting the record from a separate task since it ' s valid from the calling function . <code> here : <url> same pattern in cfe_es_genpoolcreatepoolblock : <code> here <url> <section> questionable usefulness , since it can likely only be hit if a pool without a mutex is shared between tasks and access is not serialized ( <allcaps> bad </allcaps> ! ) . if the check does remain , could just expose the internal function to force the failure . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es missing branch in cfe_es_registercdsex , overwrite success check does not make sense <section> i suspect there were code changes that made the check redundant / pointless since regupdatestatus only gets set if status = = cfe_success before this point , so there ' s no way for it to not be success and for status to also not be success . <code> here : <url> <section> really collapses back down into just one status . <repeated> no point for two . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es missing branch coverage in cfe_es_registercdsex , isnewentry can not be true without isnewoffset being true <section> branches are not independent , since a new entry will always have a new offset ( can not hit false isnewoffset with true isnewentry ) : <code> here : <url> <section> could just test against isnewoffset . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es missing branch coverage in cfe_es_registercdsex , conditions not independent ( already checked ) <section> the following check for cfe_success is not independent from the <allcaps> null </allcaps> pointer test in cfe_es_registercdsex : <number> [ + + <sad> <number> : if ( regrecptr ! = <allcaps> null </allcaps> ) <number> : : { <number> : : /* account for the extra header which will be added */ <number> : <number> : newblocksize = userblocksize ; <number> : <number> : newblocksize + = sizeof ( cfe_es_cds_blockheader_t ) ; <number> : : <number> : : /* if a reallocation is needed , the old block may need to be freed first */ <number> [ + - ] [ + + <sad> <number> : if ( status = = cfe_success & & regrecptr - > blockoffset ! = <number> & & newblocksize ! = regrecptr - > blocksize ) [ + + ] here : <url> <section> recommend just checking for cfe_success instead of <allcaps> null </allcaps> pointer check since it ' s already tested . we do not have a requirement to check for a <allcaps> null </allcaps> pointer within internal functions where it can not be <allcaps> null </allcaps> . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es uncovered branch in cfe_es_taskentrypoint , conditions not independent ( defensive code ) <section> uncovered branch since realentryfunc always ! = <allcaps> null </allcaps> when cfe_es_gettaskfunction returns cfe_success : <code> here : <url> <section> if cfe_es_gettaskfunction was stubbed this could be exercised ( or alternate implementation ) . these are both internal functions so really does not require a <allcaps> null </allcaps> check . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , remove extra word in comment <section> remove extra word ( and ) in comment fixes # <number> <section> build and sanity check <section> none <section> ubuntu <section> joseph hickey , vantage systems , inc .",1.0
"cannot specify custom <allcaps> psp </allcaps> directory using psp_mission_dir <section> originally discussed in # <number> by <user> - hbr cannot specify "" non - standard "" psp source directory via the environment variable $ cfs_app_path or the cmake variable ${ psp_search_path } . > the cfe cmake build infrastructure uses the environment / cmake variable $ cfs_app_path as well as the cmake meta - variable pattern ${ ${ <allcaps> app </allcaps> } _search_path } to locate apps and other modules ( such as psp ) , and subsequently sets the variable pattern ${ ${ <allcaps> app </allcaps> } _mission_dir } ( see mission_build . cmake lines <number> - <number> ) . <url> > however , the resulting variable ${ psp_mission_dir } is not used in process_arch ( ) in arch_build . cmake line <number> when including a target platform ' s build_options . cmake file . this causes a cmake configuration failure when trying to use a non - standard psp location . <url> <section> build with psp in non - standard location , with the cfs_app_path environment variable set <section> ${ psp_mission_dir } is used in process_arch ( ) in arch_build . cmake for a successful build <section> system ( s ) tested on hardware : pc os : ubuntu <number> versions : cfe v6 . <number> - rc1 + dev933 <section> <user> - hbr",2.0
"sb missing coverage in cfe_sb_appinit , alternate config but suggested refactor / redesign <section> uncovered code since it would require an alternate config where cfe_platform_evs_max_event_filters is less than the defined number of filters : <code> here : <url> <section> consider refactor of self - filtering , unfriendly to ground management of filters . generated events should not spam to begin with , and be useful vs requiring self - filtering . or if this pattern is retained the silent misconfiguration is not great , could better utilize <allcaps> evs </allcaps> registration error reporting . either way this design is not great . could get coverage by modifying config , but really it ' d just be broken ( have user fix config vs silently not doing what the user requested ) . <section> see above . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"comment about mission_global_applist is confusing <section> the first sentence for the description of mission_global_applist in <code> does not make sense . ' the "" mission_global_applist "" is a set of apps / libs that will be built for every defined and target . ' specifically ' defined and target ' does not provide clarity as to the intent here . removing the ' and ' would have it make sense , but was something else meant to be imparted here ? <section> n / a <section> n / a <section> <url> <section> n / a <section> n / a <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",1.0
"make fails under macos <section> when following the instructions in the <allcaps> readme </allcaps> on a mac ( either intel or apple silicon <allcaps> arm </allcaps> ) , the first make fails with <code> this looks like a regression or maybe an untested case of # <number> . steps to reproduce the behavior : on a mac , follow the instructions in the <allcaps> readme </allcaps> to clone the project and then start the first make : <code> so far so good <code> fails with first error message to console : <code> the cmakeerror . log file says : <code> but that may be a secondary cascade error . i would expect it to compile without error . this is observed on both a macbook m1 and a mac pro ( intel ) , both with latest macos ( <number> . <number> ) and toolchain ( xcode <number> . <number> ; cmake <number> . <number> ; appleclang <number> . <number> ) . zsh shell ( but same result under bash ) . output of make attached : make_output . txt <url> cmakeerror . log <url> cmakeoutput . log <url>",2.0
"update <allcaps> time </allcaps> tests to use bitmask check macros <section> with nasa / osal # <number> , utassert now provides a better macro for testing bit fields / masks . the updated macro provides better / more concise information in the test log . <section> replace the utassert_uint32_eq checks with the new macros - utassert_bitmask_set / utassert_bitmask_unset . <section> depends on nasa / osal # <number> and nasa / cfe # <number> ( both currently in ic but not in main , as of this writing ) . <section> joseph hickey , vantage systems , inc .",2.0
"relax cmake directory expectations for elf2cfetbl <section> see conversation in < <url> > from a dependency / scope standpoint , the cfe_add_tables ( ) function really wants to be defined along with the table tool sources themselves . then , after finding the table source directory , the cfe cmake infrastructure could import implementations of those cmake functions which are tool - specific . then cfe and table generation can be decoupled via the cfe_add_tables ( ) interface . in that way , different implementations for cfe_add_tables ( ) can be used depending on the mission config . <section> create a modifiable <allcaps> cmake </allcaps> parameter for the location of elf2cfetbl so users can design custom directory structures <section> long - term , let users define custom toolchain compositions using tools other than elf2cfetbl <section> see above",2.0
"fix # <number> , update directory diagrams in app developer guide <section> fixes # <number> <section> used tree to provide a tree view of cfs , cfe , build , and apps . <section> did not add cs directory . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , incorrect <allcaps> osal </allcaps> format in users guide reference <section> fixes # <number> <section> users know where to find autogenerated documents and other documents . <section> did not keep the table in case files change names , location , or documents are added / removed . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"<allcaps> tbl </allcaps> missing branch coverage of run - time endian logic ( and sometimes line ) <section> <allcaps> tbl </allcaps> suffers from the unfortunate pattern of run time checks for endian ( and associated logic ) , which leads to uncovered branches and possibly uncovered code ( depending on endian of platform ) . <code> <url> same pattern in : <url> <section> complete coverage is possible if run on each system , but should be resolved in the future . possibly in concert with # <number> and related abstraction such that this code does not care ( whatever underlying <allcaps> api </allcaps> / implementation that handles raw data should do the appropriate conversion ) . <section> none <section> same as # <number> for fs <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> tbl </allcaps> unreachable branch in cfe_tbl_getworkingbuffer and cfe_tbl_updateinternal ( memcpy overlap avoidance ) <section> can not hit ever hit the second false condition below since it only sets the buffer to inactive or a working buffer ( never the same as active ) : <code> <url> same pattern in cfe_tbl_updateinternal <code> <url> <section> trade "" defensive "" programming ( avoids memcpy overlap which is undefined behavior ) w / removing the impossible condition check since the only way to reach it would be to introduce a bug . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"caelum non - tested <allcaps> tbl </allcaps> apis <section> the following <allcaps> tbl </allcaps> apis are not being exercised in the functional test : cases requiring a second / companion app without access to the test table : <code> other special registration cases that may require an intermediate reboot to achieve : <code> cases requiring a transient state outside control of the test : <code> <section> document for caelum , eventually add a second test app and / or more sophisticated tests that can exercise these . <section> identified as part of scrub in # <number> some cases depend on having second test app per # <number> <section> joseph hickey , vantage systems , inc .",2.0
"caelum non - tested es apis <section> the following es apis are not being exercised in the functional test : related to <allcaps> cfe </allcaps> itself ( cannot reboot <allcaps> cfe </allcaps> in the middle of a test , could be done by parent script though ) : <code> related to app / <allcaps> cfe </allcaps> management ( these require a second test app that can be reloaded / restarted ) : <code> related to <allcaps> cds </allcaps> implementation ( or lack thereof ; all current targets _do_ implement <allcaps> cds </allcaps> , even though documentation allows it to return this code if it is not implemented ) : <code> related to syslog ( depends on having runtime mode set to "" discard "" rather than "" overwrite "" , which is not currently under test control : <code> <section> document for caelum , eventually add a second test app and / or more sophisticated tests that can exercise these . <section> identified as part of scrub in # <number> some cases depend on having second test app per # <number> <section> joseph hickey , vantage systems , inc .",2.0
"missing test cases for table services <allcaps> api </allcaps> parameter / return combinations <section> the following parameter / return code combinations are not exercised by the table services functional test : <code> <section> solve each missing case in one of three ways : <number> . add a test case covering that option <number> . update the <allcaps> api </allcaps> documentation <number> . add a <code> tag if the combination can only be reasonably achieved in a coverage environment <section> part of / related to # <number> ( each subsystem will be handled separately ) <section> joseph hickey , vantage systems , inc .",2.0
"missing test cases for file services <allcaps> api </allcaps> parameter / return combinations <section> the following parameter / return code combinations are not exercised by the file services functional test : <code> <section> solve each missing case in one of three ways : <number> . add a test case covering that option <number> . update the <allcaps> api </allcaps> documentation <number> . add a <code> tag if the combination can only be reasonably achieved in a coverage environment <section> part of / related to # <number> ( each subsystem will be handled separately ) <section> joseph hickey , vantage systems , inc .",2.0
"missing test cases for executive services <allcaps> api </allcaps> parameter / return combinations <section> the following parameter / return code combinations are not exercised by the executive services functional test : <code> <section> solve each missing case in one of three ways : <number> . add a test case covering that option <number> . update the <allcaps> api </allcaps> documentation <number> . add a <code> tag if the combination can only be reasonably achieved in a coverage environment <section> part of / related to # <number> ( each subsystem will be handled separately ) <section> joseph hickey , vantage systems , inc .",2.0
remove comment referencing cfe_tbl_err_file_not_found <section> reference to deprecated error code in comments > should remove it from here as well > > <url> _originally posted by <user> in <url> <section> inspect <code> <section> no references to deleted items <section> see above <section> source code coment <section> see # <number> <section> <user>,1.0
"cfe_tbl_load returns cfe_success when initially loading an incomplete image file ( cfe_tbl_warn_short_file internally ) <section> during a <code> call , the function is expected to return an error code if the loaded file was not complete ( i . e . does not result in a complete image in memory ) . in this case , if the image started at offset <number> , but had fewer bytes than required for a complete table ) , it triggers the <code> status internally inside cfe_tbl_loadfromfile , but then this gets overwritten to cfe_success in cfe_tbl_load , making the return value to the user seem like the table was fully loaded / valid . <section> call <code> on a table which has not been initially loaded with a partial data file . <section> should return an error not <code> , because the table image is only half loaded . <section> ubuntu <section> found as part of scrub in # <number> <section> joseph hickey , vantage systems , inc .",0.0
"cfe_tbl_err_file_not_found error defined but not used <section> this is documented as a return code from <code> however this function actually returns <code> when it cannot open the file . this "" file not found "" status code is not used - and it cannot be used - because os_opencreate does not really differentiate between the file not existing and existing but not having permission to open it . <section> remove unused status code <section> found as part of scrub in # <number> <section> joseph hickey , vantage systems , inc .",2.0
"search and replace error in syslog message inside cfe_es_poolcreateex <section> interesting word ended up in this syslog : <url> likely because the code was copied from library stuff , and "" lib "" was replaced with "" mempool "" , and this used the full word "" library "" . <repeated> <section> should say "" mem pool "" <section> joseph hickey , vantage systems , inc .",2.0
"cfe_tbl_err_bad_app_id error defined but not used <section> this error code was added at one point as a return value from various <allcaps> tbl api </allcaps> calls when they were called from a context which was not a <allcaps> cfe app </allcaps> . however , in the current code , the status code from the call to <code> is just passed through : <url> as a result , nothing actually returns <code> in the current code . <section> remove value from cfe_error . h and remove any remaining references to it . as the value is passed through from <code> , the actual return code when called from a bad context is <code> . <section> noted as part of scrub in # <number> <section> joseph hickey , vantage systems , inc .",2.0
"cfe_es_pool_bounds_error defined but not used <section> this error code was added at one point as a return value from <code> when there was an issue that caused the pool to go beyond the allocated size . however now the code validates the size before even starting to create the pool , and returns cfe_es_bad_argument if it is too small . so now the <code> has become stale , nothing uses this error anymore . <section> remove value from cfe_error . h and remove any remaining references to it . <section> noted as part of scrub in # <number> <section> joseph hickey , vantage systems , inc .",2.0
"enable strict resource id types with omit_deprecated build option <section> the build system has an "" omit_deprecated "" option which currently turns off all legacy - compatibility code and switches to only providing the new / preferred methods for any <allcaps> api </allcaps> elements that have been changed in recent versions . <section> as part of the omit_deprecated option , we should enable <code> mode . this mode uses type - safe definitions for all the different resource types , and prevents users from "" crossing "" different id types ( tasks , apps , etc ) at compile time rather than compiling successfully but not running correctly . <section> ci is already testing with omit_deprecated on and off so it seems like a good fit to enable strict resource id types too , the code will be tested in both backward - compatible mode and preferred / new mode . this was prompted by having two independent prs both breaking code by mixing id with other values ( one status code - id mixup , and one a tableid - <allcaps> cds id </allcaps> mixup ) in the same merge cycle . this strict build option catches both . <section> joseph hickey , vantage systems , inc .",2.0
cfe_resourceid_findnext can seg fault <section> if you pass a null for the checkfunc argument then cfe_resourceid_findnext will segmentation fault . also the comments in the c file mention how it is an internal function which it currently is not . <section> there should be a null check . a functional test for that null check . update the header file for the new return code <section> new functional test should plan with <url> <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"update name of macros / functions added to "" cfe_assert "" <section> per the naming convention , any symbols provided by a given app / lib should be prefixed with the name of that module . for "" cfe_assert "" library , this would be <code> prefix . but the new macros that were directly lifted from the coverage test are using a <code> prefix . <section> search and replace the <code> prefix with <code> to be consistent . <section> this came from migrating the macros in haste ; the extra "" ut "" that does not really belong wasn ' t caught during initial implementation or review . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , consolidate msg get / set doxygen group <section> fix # <number> makes one group for sb message characteristics ( get / set combined ) . note the setter name was also out of family ( did not include sb ) . <section> ci - doc only <section> none <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"combine sb set / get message characteristics group <section> get message and set message characteristics grouping out - of - family ( no other separate getters / setters ) <section> make a single group , makes more sense for test grouping also ( test setter with getter ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , group <allcaps> msg </allcaps> apis documentation by header type <section> fix # <number> improves <allcaps> msg api </allcaps> grouping in documentation <section> ci - documentation change only <section> none <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"improve <allcaps> msg api </allcaps> grouping in documentation - general , primary , secondary , extended <section> <allcaps> msg </allcaps> apis are all in one group , but affect different parts of the msg header and some are not applicable based on configuration ( extended headers enabled or not ) . <section> group in doxygen and add group description . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"missing test cases for event services <allcaps> api </allcaps> parameter / return status combinations <section> the following parameter / return combinations are not exercised by the event services functional test : <code> <section> ideally should be tested , but this may be difficult with the current cfe_testcase app because it uses event services to report test results . <section> document why these cannot be tested in the current caelum release , and rely on coverage testing to test these responses ( which is already implemented ) <section> part of / related to # <number> ( each subsystem will be handled separately ) these should generally not be marked as <code> in the doxygen because they ( theoretically ) _can_ be tested in a functional test , its just that the cfe_testcase app uses and registers with event services before starting tests , so any interference with this would prevent / conflict with normal test reporting . this is true for all calls to <code> ( because its already registered ) , and all items that return <code> or <code> ( which is really everything in the above list ) . these would all need a _separate_ app / task that is not registered with <allcaps> evs </allcaps> to accomplish . <section> joseph hickey , vantage systems , inc .",2.0
"add cfe_utassert macros to support tests where status is not predictable <section> the typical method of using <code> to validate the result of a <allcaps> cfe </allcaps> call will both invoke the function and check the result in a single macro . however , this requires advance knowledge of what the result is _supposed to be_ , before the call is made . in some functional test circumstances , particularly where the test is not being run in a clean / isolated environment , it may not always be feasible to predict the "" correct "" return code from an <allcaps> api </allcaps> call before it is made . for instance , there may be cases where a set of return values are acceptable , or the correct value depends on another aspect of system state that is not known beforehand . a test case may handle this currently by using a stack variable , for instance : <code> while this works , the test log entry will only show the check for <code> , it will not show the full function call that was tested here ( <code> ) . to make the logs most useful , this should show the full function call that was made , and that it was cfe_success ( the fact that the assertion was retroactive does not really matter ) . of course this can be done with the free - form <code> macro , but that requires the programmer to repeat the text of the function call , and is subject to getting stale / incorrect or cut / paste errors as any "" repeated "" info always is . <section> implement <allcaps> cfe </allcaps> utassert macros that decouple the function call from the expected return status value , so the test case can call the function and then retroactively / separately determine what the correct result should have been . the <allcaps> cfe </allcaps> utassert library can temporarily hold the status in a temp variable . this makes it simpler for the programmer to use , avoids issues with repeating the info , keeping things honest . the use pattern would be : <code> with this pattern , the assert library holds the full text of the function between the store and assert , so it can be logged in the same format as utassert_int32_eq does , and not require the programmer to repeat it , or jump through other hoops to make sure that the call gets into the test log as it should . <section> leave as is , but this imposes burdens on the programmer for corner cases ( by repeating info unnecessarily , and having to be explicitly concerned with writing it to the test log to make the test count ) and / or makes tests more fragile by repeating info ( after cut / paste / move the text of the copy can get out of sync with the real call ) . having a false / incorrect log is often worse than not having a log at all . <section> joseph hickey , vantage systems , inc .",2.0
"missing test cases for software bus <allcaps> api </allcaps> parameter / return combinations <section> the following parameter / return code combinations are not exercised by the software bus functional test : <code> <section> solve each missing case in one of three ways : <number> . add a test case covering that option <number> . update the <allcaps> api </allcaps> documentation <number> . add a <code> tag if the combination can only be reasonably achieved in a coverage environment <section> part of / related to # <number> ( each subsystem will be handled separately ) <section> joseph hickey , vantage systems , inc .",2.0
"default configuration does not permit max - size sb message buffer to be allocated <section> all messages need to be wrapped in a software bus message descriptor while in transit , and the software bus should be capable of accepting + passing messages up to <code> ( configurable ) . however , the default pool configuration does not allow this . calling <code> retuns <allcaps> null </allcaps> due to this . <section> build with default configuration , and call <code> - returns <allcaps> null </allcaps> . <section> should return non - <allcaps> null </allcaps> , as <code> is the upper limit that should be acceptable . <section> ubuntu <section> this is because in the default sb pool configuration , there is not enough extra space in the maximum size pool block . it is defined here : <url> the hardcoded "" + <number> "" bytes is not quite enough for the descriptor on a <number> - bit <allcaps> cpu </allcaps> ( it might work on <number> - bit , did not test ) <section> joseph hickey , vantage systems , inc .",0.0
"adding note on sb undefined behavior with sb_pend_forever and cfe_sb_deletepipe ( ) <section> this adds affirmative documentation regarding the discussion in # <number> and # <number> <section> documentation only . <section> documentation only . <section> - none <section> see discussion in # <number> <section> no third party code included . <section> jonathan bohren , honeybee robotics",1.0
"fix # <number> , update cfe_es_runloop documentation <section> add better description of the runstatus input / output parameter . fixes # <number> <section> build and check <allcaps> cfe </allcaps> , run all tests <section> none , documentation only <section> ubuntu <section> joseph hickey , vantage systems , inc .",1.0
"cfe_sb_receivebuffer does not return when the provided pipe is destroyed <section> if a pipe is destroyed while <code> is waiting with <code> , <code> either blocks indefinitely or returns <code> ( non - deterministically ) . this behavior is demonstrated in the proposed test case in pr # <number> . this is situation is only realizable in a multi - task context . the functional tests included in # <number> / # <number> do not test this behavior because they do not create multiple tasks in which one task is waiting on a blocking call to <code> while the pipe provided to it is deleted . <section> see test case in pr # <number> <section> the expectation ( albeit not documented ) is that if a pipe is deleted while waiting on <code> , that <code> would return immediately with an error code . <section> see pr # <number> <section> see pr # <number> <section> see pr # <number> <section> jonathan bohren , honeybee robotics",2.0
"make global test table setup in functional tests reusable i actually prefer the idea of making a "" setup "" function here that does this init , then it can be passed as the setup function as part of the uttest_add for any test that uses this table struct . that being said , its ok as is , i would not hold this up . _originally posted by <user> in <url>",2.0
"port "" cfe_utassert_successcheck "" and related macros from coverage test to functional test <section> the <allcaps> cfe </allcaps> coverage test has a number of useful test macros : - cfe_utassert_setup - cfe_utassert_teardown - cfe_utassert_success - cfe_utassert_msgid_eq - cfe_utassert_resourceid_eq - cfe_utassert_memoffset_eq however , these are only accessible / usable from the coverage test environment . it would be helpful if equivalent macros / functions existed in the functional test environment . <section> define the same basic set of macros in <code> so they can be used by any functional test . <section> due to the considerable differences in the application linkage , there currently is no ( real ) library that is common between the coverage test and functional test environments , aside from utassert itself . unfortunately this means there is no easy way to use the exact same definition of these macros , but as they are just wrappers around utassert functions so it is not that bad to duplicate them . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> rtems </allcaps> cfe_ft_global build failure <section> <allcaps> rtems ci </allcaps> fails due to "" multiple definitions "" of <code> ` ` <code> cfe_ft_global ' ; cmakefiles / cfe_testcase . dir / src / cfe_test_table . c . <surprise> ( . data + 0x0 ) : first defined here / root / rtems - <number> / bin / i386 - rtems5 - ld : cmakefiles / cfe_testcase . dir / src / tbl_content_access_test . c . <surprise> ( . bss + 0x0 ) : multiple definition of <code> cfe_ft_global ' ; cmakefiles / cfe_testcase . dir / src / cfe_test_table . c . <surprise> ( . data + 0x0 ) : first defined here / root / rtems - <number> / bin / i386 - rtems5 - ld : cmakefiles / cfe_testcase . dir / src / tbl_information_test . c . <surprise> ( . bss + 0x0 ) : multiple definition of <code> cfe_ft_global ' ; cmakefiles / cfe_testcase . dir / src / cfe_test_table . c . <surprise> ( . data + 0x0 ) : first defined here ` ` <code> 8 7 1 a2d7 <code> modules / cfe_testcase / src / cfe_test_table . c <code> ` <code> ` ` <section> ci build of <allcaps> rtems </allcaps> <number> and <number> <section> found during ic : <number> - <number> - <number> process . see <url> and <url>",2.0
"add syslog for cfe_es_deleteapp and cfe_es_reloadapp id failures <section> cfe_es_deleteapp is required to log a bad id ( es : delete application - reject undefined , ces1309 . <number> ) , and cfe_es_restartapp has a requirement and does syslog . cfe_es_reloadapp does not have an associated requirement , but should be consistent . <section> add syslog for cfe_es_deleteapp and cfe_es_reloadapp <section> remove syslog write from the requirements and remove from cfe_es_restartapp . <repeated> <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"confirm / add system log write verification explicitly documented in requirements <section> a handful of the error handling requirements include system log writes . need to confirm verification in the associated test . <code> <section> confirm there ' s a check for the system log entry , and where required a check of the return code . if the verification is missing from the coverage check , add it . if it ' s not implemented , reconsider requirement ( is the system log write really necessary ? ) <section> none . need to verify requirements , and system log writes are easiest to verify from a stub call check in coverage code . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"update end child task error requirement ( can not return error code from void function ) <section> calling cfe_es_exitchildtask from a main application task is a bug / error , but it ' s a void call so impossible to fully meet the es : end child task - error if application main task , ces1314 . <number> as written since an error code can not be returned : <url> <section> remove the error code return language . <section> add a return code . really it ' s a bug so there ' s no use case to logically handle a return code when called from a main app context . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"delete / exit / create child task additional error codes need to be documented in <allcaps> api </allcaps> and tested ( related to requirements ) <section> we have got requirements to error if <code> or <code> relate to the main app task : <url> <url> also <code> can not be called from a child task : <url> <section> document in the <allcaps> api </allcaps> and exercise these cases and test for return codes : <code> <code> note <code> is a void so no error code to check but should not exit from a main app , exercise from main test app task to confirm <section> none <section> hopefully this would be caught by the upcoming <allcaps> api </allcaps> scrub ( <user> ) , but documenting explicitly since it ' s a requirement verification issue . not sure if it ' s easier to fix now or with the rest of the updates . <repeated> open to whatever is easiest . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"remove create child task error reporting requirement , out of family and over - constrains implementation <section> es : create child task - report error , ces1311 . <number> over - constrains the design / implementation . parameter errors like <allcaps> null </allcaps> pointers are not reported in the log for any parameter checking . no other apis have this sort of error handling related requirement . strict interpretations would mean the failing the requirement as written . <section> delete <section> changing the implementation would make it inconsistent with all other handling , changing the requirement really just turns the requirement into design . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"printf test logs missing last character <section> in the <allcaps> cfe </allcaps> coverage tests , assertions for "" printf "" include the message format string being checked for , but it truncates the last character . for example : <code> <section> run es coverage test , view logs <section> should include the full string , not cut off the last char . <section> ubuntu <section> off by one error in the string processing <section> joseph hickey , vantage systems , inc .",0.0
"cfe_es_runloop runstatus parameter is in / out , documented as in <section> documented as in : <url> but set : <url> <section> update <allcaps> api </allcaps> documentation . description is also somewhat incomplete , since it ' s also a way for the app to self exit for the typical case where it ' s a condition in the while loop . <section> a clear and concise description of any alternative solutions or features you have considered . <section> add any other context about the feature request here . <section> full name and company / organization if applicable",1.0
"add a companion test app for additional <allcaps> api </allcaps> coverage and lab app independence <section> currently the functional test ( see # <number> ) relies on sample_app running to test the table share <allcaps> api </allcaps> , there ' s also other apis that would be easier or could be more fully covered if there was another app owned by the functional test ( app control , cfe_es_exitapp , etc ) . <section> add support / logic and initial implementation ( the table case is a good place to start ) . does not actually need to be a full - blown app and / or could be a bunch of very trivial , single - use objects . could likely still just do all the asserts from the main functional app , and could use cfe_es_reloadapp if different logic is needed for the specific test . still not really easy since there is no <allcaps> api </allcaps> to load an app ( could send a command to es though , either from the functional test app or as another command from the ground ) , and you can not reload an app that is not running ( if it exits it ' s done ) . <section> a child task could do some of it , but would not be able to cover cfe_es_exitapp . cfe_es_exitapp or cfe_es_deleteapp would need care if taking the cfe_es_reloadapp approach ( do at the end , or use command to es to start again , etc ) . could also just require sample_app be loaded to run the test since that ' s not really much different than requiring an additional test app ( although the test app would be controlled with the rest of the functional logic , so more self - contained ) . definitely open to other ideas . <repeated> <section> worth a trade of what ' s "" good enough "" , since <allcaps> api </allcaps> testing does not really prove a distribution ' s use of the <allcaps> api </allcaps> will work . in <allcaps> osal </allcaps> the apis are functionally tested within the context of separate executables so testing the cfe <allcaps> api </allcaps> works within a test configuration ( with sample_app ) is analogous . distributions are still expected to test their functionality vs requirements , system test , and scenario test which really shows whatever apis they are using behave as required . there ' s also the challenges related to custom configuration which could cause the functional test to fail ( even as currently implemented ) . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
cfe_msg_gettypefrommsgid not handling all invalid inputs <section> cfe_msg_gettypefrommsgid calls cfe_msg_setmsgid and cfe_msg_gettype but ignores those return calls . they can return fail status codes so cfe_msg_gettypefrommsgid should handle that . <section> cfe_msg_gettypefrommsgid should check for failing status codes and return them if they happen . <section> alex campbell <allcaps> gsfc </allcaps>,0.0
"improve consistency when working with <allcaps> osal </allcaps> status codes <section> quite often in the <allcaps> cfe </allcaps> implementation , <allcaps> osal </allcaps> status codes are mixed with <allcaps> cfe </allcaps> status codes , often times sharing a single stack variable to hold either one , and even switching back and forth . to improve clarity and consistency , <allcaps> osal </allcaps> status codes should be stored in a _separate_ stack variable from the <allcaps> cfe </allcaps> status codes . ideally , in the future , these should also migrate to a separate type ( e . g . <code> , as in nasa / osal # <number> , or <code> , as in nasa / cfe # <number> ) . <section> - anywhere that an <allcaps> osal </allcaps> status code is stored on the stack , make a _separate_ variable . - always use a consistent name for that variable , e . g . <code> ( as opposed to "" status "" or "" returncode "" etc , which are vague ) . - avoid intermixing <allcaps> cfe </allcaps> status codes and <allcaps> osal </allcaps> status codes whenever possible ( there will still be some times its necessary , when calling generic functions ) . when it is necessary , make conversions between these types explicit / obvious via comments and / or type casting . - when printing <allcaps> osal </allcaps> status codes in a log or event message , print it as long decimal ( % ld ) , not as hex as the <allcaps> cfe </allcaps> status codes are . this is because <allcaps> osal </allcaps> defines its status codes as decimal numbers , so logs / events should match this . <section> this can be considered a prerequisite to nasa / cfe # <number> ( cannot introduce a unique <code> type until it is no longer being used to store <allcaps> osal </allcaps> codes ) . this would be a fix for next release ( not <number> . <number> ) . <section> joseph hickey , vantage systems , inc .",2.0
"no null pointer check on tblhandles in cfe_tbl_getaddresses and cfe_tbl_releaseaddresses <section> cfe_tbl_getaddresses does not check that the array of tblhandles is not <allcaps> null </allcaps> and will cause a segmentation fault . a similar issue appears to also exist in cfe_tbl_releaseaddresses . <section> steps to reproduce the behavior : <number> . the following line from my fork for # <number> will cause a segmentation fault instead of gracefully returning a cfe_tbl_bad_argument <code> whereas when the input tblptrs is <allcaps> null </allcaps> , cfe_tbl_bad_argument is correctly returned . <number> . similarly the following line will cause a segmentation fault from cfe_tbl_releaseaddresses <code> <section> * cfe_tbl_getaddresses should return cfe_tbl_bad_argument when the pointer tblhandles is <allcaps> null </allcaps> . * cfe_tbl_releaseaddresses should return cfe_tbl_bad_argument when the pointer tblhandles is <allcaps> null </allcaps> . <section> - hardware : pc - os : ubuntu <number> <section> niall mullane - <allcaps> gsfc </allcaps> <number> intern",2.0
"cfe_tbl_load does not reset loadinprogress when called on a locked table <section> when calling cfe_tbl_load on a table that is locked it correctly returns the status cfe_tbl_info_table_locked . <url> however , this branch skips over the function cfe_tbl_notifytblusersofupdate which resets the variable <code> . without this variable being reset to <code> , all future calls to cfe_tbl_load will fail . <url> once the table address is correctly released , all subsequent calls to cfe_tbl_load will still fail and return cfe_tbl_err_load_in_progress even though the last load failed when the table was locked . <url> this can be fixed by calling cfe_tbl_manage before trying to load data . <section> on my fork for # <number> the test <code> in the file <code> requires a call to cfe_tbl_manage before we can load data to the table after releasing the address for it . the following code snippet is from this file . <code> <section> after a failed table load because the table was locked , i should be able to release the address of a table and then call cfe_tbl_load without needing to call cfe_tbl_manage in between . <section> - hardware : pc - os : ubuntu <number> <section> niall mullane - <allcaps> gsfc </allcaps> <number> intern",0.0
cfe_evs_register not validating inputs first <section> inside <allcaps> evs </allcaps> register it clears the appdata record before it validates all the inputs . if some of the inputs are invalid that then causes the app to crash . <section> validate inputs first before anything else . <section> <url> <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"transition <allcaps> cfe </allcaps> tests to use utassert macros ( moved from <allcaps> cfe </allcaps> ) <section> in pull request nasa / osal # <number> , a number of <allcaps> cfe </allcaps> coverage assert macros and generic functions were ported into the base utassert library . usage of the macro is equivalent . <section> after merging that pr , remove the local <allcaps> cfe </allcaps> definitions of the macros and functions , and search / replace all references to use the utassert version instead . <section> leave duplicate <section> requires nasa / osal # <number> to be merged first ( or at the same time ) <section> joseph hickey , vantage systems , inc .",2.0
"remove sb : last message sender info , csb4309 requirement ( removed <allcaps> api </allcaps> ) <section> support for getting the last message sender was removed in the caelum development cycle , need to remove the requirement <section> remove csb4309 - sb : last message sender info requirement <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"add ( unsigned int ) cast to <allcaps> mir </allcaps> prints in time_ut . c <section> <allcaps> mir </allcaps> prints in time_ut . c break the <allcaps> rtems </allcaps> build because % u expects ( unsigned int ) , but uint32 in <allcaps> rtems </allcaps> is an unsigned long . <section> add ( unsigned int ) cast to <allcaps> mir </allcaps> prints in time_ut . c <section> jose f . martinez pedraza / <allcaps> nasa gsfc </allcaps>",0.0
"move "" count "" global to test global struct <section> should not have random global variables around , particularly variables with simple / common names , as it may silently overwrite an existing variable ( i . e . if any other app / lib makes a global called "" count "" some os ' s will just happily bind to the existing variable , not make a separate instance , when dynamic refs are resolved after loading ) . <url> <section> now that we have a proper global struct , <code> - this should be moved into it . <section> joseph hickey , vantage systems , inc .",0.0
"explicitly document / test file offset behavior in relation to fs file read / write apis <section> it ' s not clear from the <allcaps> api </allcaps> where the file offset is left after using any of the fs apis that access the file : cfe_fs_readheader cfe_fs_writeheader cfe_fs_settimestamp <section> right now , at least some apps in the wild depend on current behavior so preferred fix for caelum is just to document current behavior ( success and error ) . error can be undefined , but success should be consistent / explicit . also worth adding a functional check to confirm this behavior ( if it ' s not already checked ) . <section> could explicitly be undefined , or change behavior to reset to the start of the file but that would ripple through all the apps . <section> from an app code review , currently undocumented behavior means apps should all lseek but rather than change every app it ' s likely better to document the current behavior explicitly in the <allcaps> api </allcaps> . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , ping <user>",1.0
"fix # <number> , mistakes in some copyright headers <section> - fixes # <number> <section> - no behavior changes paul oberosler , individual",1.0
"some source code files have mistakes in the copyright headers . <section> the source files have their file names in their headers , but some have just copied the text from another file , so the file names in their headers do not match that of the file . <section> example where this is a mistake . <url> <section> it ' s just a quick fix , not necessary for the program ' s features .",1.0
"datatocopy argument of cfe_es_copytocds should be "" const "" <section> this pointer argument is read - only , the data is passed to <allcaps> psp </allcaps> which is ( correctly ) a <code> <section> prototype should be : cfe_status_t cfe_es_copytocds ( cfe_es_cdshandle_t handle , const void * datatocopy ) <section> should not cause any issue for existing code ( ok to pass non - const to const , just not the other way ) . making const - correct avoids issue / warning if called from an app using <code> data . <section> joseph hickey , vantage systems , inc .",2.0
"scrub for discrepancies between implementation return codes and documentation <section> need to perform a general scrub of <allcaps> api </allcaps> documentation for parameters , error checking , and and return codes , as was done for <allcaps> osal </allcaps> . <section> - confirm that all return / status codes which are _directly_ generated by an implementation appear in the documentation for that function as a <code> clause . - confirm that all return codes specified by a <code> clause also have a test case that covers them - confirm that parameter documentation is appropriately marked <code> or <code> where applicable - confirm that there is a test case that violates above rule to test function response w / bad input - confirm that coverage tests are not "" overloaded "" ( i . e . violate only one rule at a time when confirming status code response ) . <section> see nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",1.0
"incomplete <allcaps> osal </allcaps> error conversion in cfe_es_reloadapp <section> the cfe_es_reloadapp function uses the function os_stat to perform its work . the error handling in cfe_es_reloadapp assumes any failure in os_stat is due to a file io issue . this may not be the case because if a null pointer is passed in as the file name os_stat will return an os_invalid_pointer , but this specific error code will be ignored and cfe_es_reloadapp will just output cfe_es_file_io_err instead of a cfe_es_bad_argument . <section> steps to reproduce the behavior : <number> . call cfe_es_reloadapp with a null pointer for filename . it will return a cfe_es_file_io_err when the real issue was a bad argument . <section> cfe_es_reloadapp could include a null check itself to provide a more specific error message or the os_invalid_pointer returned by os_stat could be converted to a specific <allcaps> cfe </allcaps> error code . <section> see # <number> for a similar error conversion issue <section> niall mullane - <allcaps> gsfc </allcaps> <number> intern",2.0
no null pointer check in cfe_es_taskid_toindex <section> cfe_es_taskid_toindex does not check if the input index pointer is null and will cause a segmentation fault if it is null . <section> steps to reproduce the behavior : <number> . this <url> line in the functional unit tests on my fork will result in a segmentation fault if it is uncommented . <number> . build <allcaps> cfe </allcaps> and run functional unit tests to view the error . <section> cfe_es_taskid_toindex should return a cfe_es_bad_argument if the index pointer is null . <section> - hardware : pc - os : ubuntu <number> <section> niall mullane - <allcaps> gsfc </allcaps> <number> intern,2.0
"requirements scrub for caelum development cycle <section> caelum development included <allcaps> api </allcaps> additions , need updated requirements . <section> update : es : report task and application name , ces1305 - > es : get task information new : es : get library information , ces1344 es : delete memory pool , ces1345 es : get generic counter name , ces1346 fs : filename auto - complete , ces1605 fs : background file dump , ces1606 sb : delete pipe , csb4302 sb : set packet type , csb4346 sb : get header field , csb4347 sb : set header field , csb4348 sb : get sequence count , csb4349 sb : set sequence count , csb4350 sb : get next sequence count , csb4351 sb : get type from msgid , csb4352 <section> none <section> note - resource id apis and * _toindex apis were categorized as "" design "" so they are not associated directly with requirements ( a different implementation may not require these ) . of similar note , the message implementation supports user defined header fields , so the requirement is generic where there is not internal dependencies on the field . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
remove get message checksum requirement <section> as part of the message module refactor the cfe_sb_getchecksum external <allcaps> api </allcaps> was determined to have no use case . <section> remove associated requirement : csb4326 - sb : get checksum <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"remove requirements for message initialization "" clear "" vs "" no - clear "" options <section> cfe_msg_init no longer supports "" clear "" vs "" no - clear "" options due to abstraction incompatibilities . csb4315 . <number> - sb : initialize message - clear csb4315 . <number> - sb : initialize message - no clear <section> remove these "" special option "" requirements . the requirement is that it initializes the packet ( csb4315 ) , the design / implementation describes the exact behavior ( there are many possible compliant implementations by design ) . ambiguous options that can not be abstracted should be avoided in the <allcaps> api </allcaps> . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"most commands only generate <allcaps> debug </allcaps> event for successful completion <section> most commands will increment the command counter for the application and send a debug event after they are processed . however , in the default / sample config , debug events are filtered out , so these will <allcaps> not </allcaps> be visible to the operator . as such there is really no way to confirm a specific command was accepted - since _any_ command will increment the command counter ( including noop , etc ) the counter by itself is not a reliable means to check if a particular command was accepted . <section> generally , the fact that a command was accepted and processed is useful and necessary information for operators , so it should not be classified only as "" <allcaps> debug </allcaps> "" . consider making all these events to be of type <code> . note that some commands , such as no - op , already send an <allcaps> information </allcaps> event ( so not fully consistent as it is ) . <section> noted when reviewing command documentation in # <number> . for caelum will just document the <allcaps> eid </allcaps> that is currently being generated ( debug or information ) but will not change it . for next release should try to make this more consistent . <section> joseph hickey , vantage systems , inc .",2.0
"renumber requirements based on category <section> requirements have evolved such that the numbering is no longer consistent . makes it harder to quickly check implementation linkage to at least the correct category ( cfe_es_writetosyslog links to ces1014 which is typically the command / message group ) examples : ces1014 and associated is all about the system log , but in what is typically the command section ces1017 is the exception reset log ces1022 is for performance analyzer <allcaps> api </allcaps> ces1600 is fs , but is under es ( should be all under <allcaps> api </allcaps> ' s and / or functional ) . <repeated> and so on <section> x0 xx - commands / messages and behavior ( upon receipt of a command / message and x0 xx . x for additional behavior ) x3 xx - <allcaps> api </allcaps> ' s and behavior ( upon receipt of a request ) x5xx - reset behavior x7xx - functional / performance behavior fs should be split out from es ( 1 6 xx ) <section> none , although renumbering should always use <allcaps> new </allcaps> numbers to avoid confusion and helpful to have a comment with the old number ( or other way to identify in a search ) . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"remove application / child task registration <allcaps> api </allcaps> requirements <section> apis were removed in # <number> , registration handled by es and no longer requires <allcaps> api </allcaps> . ces1300 and <section> remove associated requirements , ces1300 - es : register application and ces1313 - es : register child task <section> none <section> # <number> , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"implicit padding in <code> <section> implicit padding , as well as the issues detailed in # <number> ( configurable sized elements early in the packet ) in <code> . there ' s <number> bytes being added after <code> . <url> noticed when debugging memory handle info reporting commands in es . discovered the table pool handle was being interpreted incorrectly in cfs - groundsystem due to the implicit padding . <section> likely addressed as part of the transition to the cmd / tlm structures being generated / delivered from a more complete data description . <section> could quick fix . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"correct return code mismatches in <allcaps> cfe </allcaps> <section> in several places across <allcaps> cfe </allcaps> , a function is documented as returning a <allcaps> cfe </allcaps> status ( e . g . cfe_success ) but checked against either os_success or cfe_psp_success , or vice versa . <section> functions documented as returning <allcaps> cfe </allcaps> status should check for <code> , where functions documented as returning an <allcaps> osal </allcaps> status should check for <code> , and functions returning a <allcaps> psp </allcaps> status should check for <code> . <section> similar to # <number> , but found in more places . since the definition of all these symbols is <number> , this is no change in practice , but should be fixed for correctness sake . <section> joseph hickey , vantage systems , inc .",2.0
"correct notes on cfe_fs_backgroundfiledumprequest <section> the notes for this <allcaps> api </allcaps> say "" not on heap "" when it really should say "" not on stack "" <section> if buffer is allocated on the stack and object goes out of scope before background job finishes , random unpredictable behavior occurs , as in pr # <number> . <section> correct comment . <section> ci <section> fundamental requirement is that object must persist for the time the background job runs . so stack is likely a problem , heap is ok as long as it is not freed before task is done . <section> joseph hickey , vantage systems , inc .",1.0
"re - add cfe_sb_deletepipe requirement <section> the requirement for the <code> <allcaps> api </allcaps> , csb4302 was mistakenly deleted in # <number> . <section> re - add . <section> none <section> got mistakenly cancelled in <allcaps> jira </allcaps> , un - cancelled . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"incorrect returncode check in cfe_es_createobjects <section> the <code> returns a <allcaps> cfe </allcaps> status . however , when checking the the return code , it is compared to <code> , rather than <code> . <url> <section> check against <code> <section> n / a <section> this is just a minor / pedantic correctness issue , since in practice os_success and cfe_success are the same value ( <number> ) . however when scrubbing for type correctness this shows up . <section> joseph hickey , vantage systems , inc .",2.0
"update doxygen groupnames to match cfs naming conventions # # description the doxygen "" groupnames "" do not have any separators and are difficult to read , see <code> in code snippet below . <url> see short discussion in <url> # # proposed solution have the group name match the updated directory structure after the modules update , for example - <code> cfe_es_entryexit # # alternatives leave names as is but introduce underscores <code> .",1.0
"es missing coverage in cfe_es_apps . c , cfe_es_cleanuptaskresources <section> <code> function contains a hard to reach line ( <number> below ) that remains untested , preventing us from reaching <percent> coverage in file . <code> <section> add coverage for line to complete <percent> coverage in file . <section> it ' s really difficult to recreate a case were cleanstate . foundobjects is greater than <number> since it always gets set to <number> in while ( <number> ) <url> <section> jose f . martinez pedraza / <allcaps> nasa gsfc </allcaps>",2.0
"correct syslog message in ut_bsp_unlock <section> the log message in <code> has the wrong function name ( os_mutsemtake ) . appears to be a copy / paste error from ut_bsp_lock above . <section> n / a ( does not fail in normal operation ) <section> log message should have <code> , not <code> <section> <url> <section> ubuntu <section> mismatch noted as part of review for # <number> <section> joseph hickey , vantage systems , inc .",0.0
"improve separation / distinction between <allcaps> osal </allcaps> and <allcaps> cfe </allcaps> error codes <section> application code should not conflate / intermix these two sets of error / status code values . <allcaps> osal </allcaps> and <allcaps> cfe </allcaps> differ in how their error codes are defined . for <allcaps> osal </allcaps> , in <code> , the codes are in signed decimal format ( e . g . <code> ) . for <allcaps> cfe </allcaps> , in <code> , the codes are in hexadecimal format ( e . g . <code> ) with bits having certain meanings . <section> - when storing an error code in a local stack variable , applications should create a _separate_ variable for storing an <allcaps> osal </allcaps> status code from a <allcaps> cfe </allcaps> status code . - the correct typedef should be used , e . g . <code> for <allcaps> cfe </allcaps> codes , and ( ideally ) <code> for <allcaps> osal </allcaps> codes ( which does not exist yet , but see issue nasa / osal # <number> ) . - when logging / printing or sending events , use the correct conversion specifier such that the format is consistent with how it is defined . this means <code> for <allcaps> osal </allcaps> codes , and <code> for <allcaps> cfe </allcaps> codes . ( in many cases , <allcaps> osal </allcaps> error codes are printed using the <code> conversion currently ) . <section> for caelum , the approach will be to document the functions / cases where <allcaps> osal </allcaps> and <allcaps> cfe </allcaps> status codes are conflated ( see issue # <number> ) but ideally for better code modularity , the two sets of status codes should not be intermixed at all . while issue # <number> will just document where this is a problem , this issue should be to fix those problem areas and keep things isolated . also note that <allcaps> psp </allcaps> also has a few of its own status codes , which also should be kept separate . <section> joseph hickey , vantage systems , inc .",2.0
"implement separate log / event for <allcaps> cfe fs </allcaps> filename validation failure <section> filename validation ( from commands , scripts , etc ) now happens at both <allcaps> cfe fs </allcaps> level ( via <code> ) and inside <allcaps> osal </allcaps> ( via <code> or <code> etc ) . however , in most code paths where this is done , the results are currently combined . that is - failure of either function is reported via the same event / log message . doing this ultimately requires putting the error code into the same "" int32 "" value ( thereby mixing <allcaps> osal </allcaps> and <allcaps> cfe </allcaps> error codes ) . <section> should have a separate event / log message for failures at the <allcaps> cfe fs </allcaps> level vs . failures at the <allcaps> osal </allcaps> level . the log message should clearly indicate whether the failure came from <code> or <code> ( or whatever other function was called ) . <section> note that the preferred format for printing / logging error codes is also different - to match the values in the osapi - error . h file and cfe_error . h files , <allcaps> osal </allcaps> codes should be printed as decimal , whereas <allcaps> cfe </allcaps> codes should be hex . when combining error codes into a single log , it requires choosing one format , which will be wrong for half of them ( it is still able to be decoded at least , because error numbers do not overlap , but not ideal ) . <section> joseph hickey , vantage systems , inc .",2.0
"incomplete <allcaps> osal </allcaps> error conversion in cfe_es_gettaskname <section> the cfe_es_gettaskname function uses an <allcaps> osal api </allcaps> to perform its work . however , its error handling path is not complete , it assumes any underlying <allcaps> osal </allcaps> failure is due to the resource id not being valid : <url> although a bad id is a _likely_ cause for failure , it is not the only possible cause of failure - for example , if the name is too large to fit in the buffer , <allcaps> osal </allcaps> may return <code> . <section> call <code> with a valid task id and string buffer size of <number> ( such that the task name is too long to fit in the buffer ) . the function will return <code> status , even though the real error was that the buffer was too short . <section> should do better error conversion - only <code> should translate to <code> , and other potential / foreseeable <allcaps> osal </allcaps> errors converted to the nearest <allcaps> cfe es </allcaps> error , or the generic catch - all <code> can be returned for other unexpected / unhandled errors . <section> see # <number> , for caelum will document the existing behavior , but a future release should correct this . <section> joseph hickey , vantage systems , inc .",0.0
"sb unreachable code in cfe_sb_appinit <section> the following conditional is never reachable with the default config : <url> to reach this would require that the code is built with a config where <code> ( from platform config , defaults to <number> ) is less than <code> ( hardcoded to <number> ) . <section> build code with default config and run coverage report . <section> code could be cleaned up to not have unreachable lines in any config , or at least convert the check such that it can be evaluated at compile time ( if <code> >= <code> then the code becomes unreachable ) . <section> ubuntu <section> somewhat related to # <number> , if this is fixed hopefully it would get both of these <section> joseph hickey , vantage systems , inc .",2.0
"cfe_sb_msghdrsize returns size_t but still attempts to return <allcaps> cfe </allcaps> status code <section> the <code> function returns a <code> value . therefore , there is no provision / possibility for an error to be returned . however , if passed a <allcaps> null </allcaps> argument , this still attempts to return <code> which will be implicitly converted to a <code> value - which is platform - defined . notably , since <code> is unsigned , the result is always positive ( success range ) and will not be correctly interpreted by the caller . <section> call <code> with a <allcaps> null </allcaps> <code> argument . <section> this function should probably return <number> instead of <code> in this case . cannot return <allcaps> cfe </allcaps> status codes from a function that does not return <code> ( or <code> ) . <section> <url> <section> ubuntu <section> this line was also not being covered by the coverage test (# <number> ) and the return type mismatch prevents this from being covered properly . <section> joseph hickey , vantage systems , inc .",0.0
revert <code> default file extension addition <section> added default extension is causing issues w / <number> character limit and confusion among users / testers <section> for generic files ( log / data / etc ) where there is not a required extension just leave the file name as requested by the user . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe application developer ' s guide hardware servicing app section out of date <section> cfe application developers guide . md has references to generic <allcaps> isr </allcaps> apis and other functionality that is not supported . <section> update <url> section <number> . <number> "" hardware servicing "" application <section> none <section> nasa / cfs # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"add missing <allcaps> api </allcaps> ' s to user guide <section> in section <number> of the user guide , it lists all the apis , and some are missing from that list . cfe resource <allcaps> id api </allcaps> ' s – cfe_es_appid_toindex – cfe_es_libid_toindex – cfe_es_taskid_toindex – cfe_es_counterid_toindex cfe fs file utility apis – cfe_fs_getdefaultmountpoint – cfe_fs_getdefaultextension – cfe_fs_parseinputfilenameex – cfe_fs_parseinputfilename – cfe_fs_backgroundfiledumprequest – cfe_fs_backgroundfiledumpispending <section> should be listed in section <number> . <section> the details of the functions are in there correct place later in the guide . <section> full name and company / organization if applicable",1.0
remove unused function <code> in cfe_es_syslog . c <section> this function is not used . we also do not have ut for this function . <section> simply remove the code . <section> keep it and add the unit tests . <section> jose f martinez pedraza / <allcaps> nasa gsfc </allcaps>,2.0
"update the ci functional test to use the unit test report file <section> ci functional test currently tee ' s the console output and waits for a string , which is subject to flushing and not very robust . <section> # <number> added a test log file , ci in functional test can now just wait until this file exists to know when the test is complete ( vs tee on console output ) . that log file is then the artifact and can be checked for summary success / failure . <section> none . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
fix documentation workflow warning . log archive <section> the documentation ci workflow has a typo in the directory for the usersguide - warnings . log output file . <section> see < <url> <section> workflow runs successfully and reports and archives warnings <section> <url> <section> this popped up after the update to the documentation build and i missed it when fixing up the ic,2.0
"es uncovered code cfe_es_api . c , cfe_es_exitapp infinite loop ( spins until deleted ) <section> missing coverage for cfe_es_exitapp function that contains an infinite loop . <url> <section> add coverage tests to include part of the function that is currently not being tested . <section> none . <section> jose f . martinez pedraza / <allcaps> nasa gsfc </allcaps>",2.0
"consistency in <allcaps> cfe </allcaps> coverage test helper macros <section> the following helper macros are defined in <code> and used in sb_ut . c , with the intent of applying to other modules : - <allcaps> setup </allcaps> - <allcaps> assert </allcaps> - assert_eq - assert_true - <allcaps> evtcnt </allcaps> - <allcaps> evtsent </allcaps> these macros are all specific to / tuned toward <allcaps> cfe </allcaps> coverage testing ( i . e . they are not generic ) because they embed certain <allcaps> cfe </allcaps> patterns / assumptions , i . e . <allcaps> setup </allcaps> and <allcaps> teardown </allcaps> check for cfe_success , the "" <allcaps> event </allcaps> "" macros deal with the ut stub event capture logic , etc . <section> the genuinely <allcaps> cfe </allcaps> - specific macros should be updated with a <code> prefix to indicate that they are assertion statements that are specific to <allcaps> cfe </allcaps> . for macros which are actually generic , such as "" assert_eq "" , consider replacing this with the existing generic <code> macro . also for wider coverage test applicability and consistency of logging output , should also add the following : - <code> macro to consistently log functions that do not have a return value , but still want to include the full text of what was called - <code> macro to check for equality between resource id values ( int32_eq is not sufficient here because one should not assume that ids are integers ) <section> discussed in <allcaps> ccb </allcaps> <number> - <number> - <number> , as part of issue # <number> and improving the test log output <section> joseph hickey , vantage systems , inc .",2.0
"add feature to <allcaps> cfe </allcaps> assert to write output to log file <section> the <allcaps> cfe </allcaps> functional tests executed via the cfe_assert helper app currently report test cases as events . problem is : - events are ( by default ) limited to <number> chars , and assert strings tend to be long - ish , so these are likely to get truncated - makes it difficult to write test analyzing tools - either need to somehow subscribe to those event ids ( non - trivial w / current script capabilities ) , or pipe the entire terminal log to a file ( os dependent ) . and in both cases , still subject to text truncation . <section> the cfe_assert app should have a feature to internally "" tee "" the results to a log file . this would alleviate the need ( and os dependency ) on trying to "" tee "" the output externally , and the output would contain <allcaps> only </allcaps> test logs i . e . not mixed with other syslog messages . <section> see # <number> , this would make ci tests more reliable <section> joseph hickey , vantage systems , inc .",2.0
"cfe_es_query_one_cc not performing as expected <section> within the cfe_es_app_tlm_mid packet - the following items are not behaving as expected : <number> . bssize <elongated> , codesize , and datasize always report <number> for a given app . <number> . startaddress for a given app changes whenever the software reset . <section> <number> . start <allcaps> fsw </allcaps> <number> . send the cfe_es_query_one_cc for a given app <number> . verify that the bssize <elongated> , codesize , and datasize always report <number> + startaddress is not fixed ( this may be by design . <repeated> i am thinking that it should only change if the software is re - compiled ) . <section> oracle vm virtualbox os : ubuntu - <number> versions : cfe v6 . <number> - rc1 + dev218 , osal v5 . <number> - rc1 + dev109 , psp v1 . <number> - rc142 <section> dan knutsen <allcaps> nasa </allcaps> / goddard",3.0
"add compile time assert that platform config sizes are < mission config sizes <section> a stakeholder bumped up cfe_platform_sb_max_pipes to <number> but left cfe_mission_sb_max_pipes as <number> , which is a broken config since tlm for pipedepthstats is sized using cfe_mission_sb_max_pipes . <section> add a compile time assert that cfe_platform_ * is < cfe_mission_ * <section> charge more to fix user errors . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , ping <user>",2.0
"incorrect osal <allcaps> api </allcaps> guide format in users guide reference the <allcaps> api </allcaps> is no longer a * . doc , it ' s generated and deployed from doxygen as a pdf , and it goes in a separate branch . right now it ' s in the cfs repo at <url> _originally posted by <user> in <url>",1.0
"standardize on "" docs "" subdirectory for documentation <section> in nasa / osal # <number> and nasa / psp # <number> , the <code> subdirectories will be renamed to <code> , to be consistent . going forward , documentation should be in a <code> subdirectory on all submodules / components . <section> places where <allcaps> cfe </allcaps> build system is using / referring to a <code> subdirectory ( e . g . refs into <allcaps> osal </allcaps> ) should be changed to <code> <section> needed for compatibility with / dependency on nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
cfe_es_getpoolbufinfo header has incorrect return description <section> the return in the header says it returns execution status but it actually returns the buffer size or error code . <section> header file should be changed to match the implementation . <section> the code that does this has a comment saying it ' s not workable so we could also change the implementation <url> <section> alex campbell <allcaps> gsfc </allcaps>,1.0
"clean up version header and standardize reporting <section> unnecessary macros ( coding standard ) , strange line splits , various event formats . <section> i will provide a suggested cleanup . if people like it , keep it and consider applying the pattern across repos . <repeated> if not , toss it . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , update version description per current design <section> fix # <number> - cleanup of version description , biggest fix is mission revision definition location ( not in config files ) . also deleted template section which just duplicated an outdated version of cfe_version . h . <section> ci - documentation only <section> none <section> ci - documentation only <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , document cfe_tbl_unregister use - case <section> fix # <number> - documents cfe_tbl_unregister on shared table use case vs use by owning task . <section> ci - documentation only <section> none <section> ci <section> # <number> documents potential races , global table handles often are not protected so care needs to be taken when using shared tables . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , document cfe_es_runloop increment task counter behavior <section> fix # <number> - updated documentation <section> ci - documentation only <section> none <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"update <allcaps> api </allcaps> / error code documentation relative to osreturncode cases <section> there are multiple cfe <allcaps> api </allcaps> ' s that can return osreturncodes ( cfe_fs_readheader , cfe_fs_writeheader , etc ) . this is not explicitly documented in the <allcaps> api </allcaps> or as part of cfereturncodes . <section> add documentation . they do not conflict due to the severity bits / service bits . <section> convert all return codes to the <allcaps> cfe </allcaps> set , but probably not worth it and could obscure source of error . <section> spawned from requested change in # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , updated fs read / writeheader <allcaps> api </allcaps> return documentation <section> fix # <number> - updated return documentation for cfe_fs_readheader and cfe_fs_writeheader to state they return bytes read / written or error code . left as cfe_status_t since they do return error codes , although overloaded . it is confusing since <number> actually indicates the data wasn ' t read or written , but that would require an <allcaps> api </allcaps> change . related issue is # <number> . <section> ci - documentation only <section> none , documentation only <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"unify / standardize method for writing files , multiple patterns currently implemented <section> some files are still written directly from the command handler ( main task ) , see <code> for example . some request the write from a background task using <code> and cfe_fs_background * routines , see <code> . then there ' s also the unique <code> with it ' s own run function that does not utilize <code> . side note - <code> does not check for cfe_fs_writeheader valid size ( just >= <number> ) <section> scrub all file writes and implement a single pattern . this should standardize events , error handling , scheduling work , dump deconfliction , etc . note there ' s multiple issues with overloaded eids in reporting errors , etc . avoid additional complexity from "" backwards compatible "" event messages , etc . <section> if these really require different handling , summarize file write handling and document . current design is challenging to analyze for file write timing impacts without in - depth knowledge of implementation . <section> # <number> documents some of the eventid issues <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"provide ut_bsp_lock / unlock in <allcaps> cfe </allcaps> assert app <section> in nasa / osal # <number> it adds a ut_bsp_lock / ut_bsp_unlock routine to protect the utassert global data structures . however for cfe_assert app the utbsp . c file is not used , it provides its own routines . therefore these routines need to be added . <section> add ut_bsp_lock / unlock wrappers in <allcaps> cfe </allcaps> assert ( this already has a mutex ) . <section> joseph hickey , vantage systems , inc .",2.0
"unique warn_logfile for documentation builds <section> <code> is set the same for both cfe documentation builds since it ' s set in cfe - common . doxyfile . in . potential conflict during a parallel build . <section> set unique warning file names for usersguide and doc build . <section> none <section> # <number> would also deconflict , but would deconflict ci artifacts ( no longer would need to rename in related action ) . this was mentioned in # <number> , but updated to make specific to the undocumented warnings . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"same event id used in multiple locations ( <allcaps> overloaded </allcaps> ) , should be unique <section> as part of <allcaps> eid </allcaps> scrub , identified the following cases where an eventid was used in multiple locations ( intent is for eids to be unique ) . cfe_es_syslog2_err_eid : <url> <url> cfe_es_erlog2_err_eid : <url> <url> cfe_es_perf_log_err_eid : <url> <url> cfe_es_filewrite_err_eid : <url> <url> cfe_es_creating_cds_dump_err_eid : <url> <url> # <number> documents overload cfe_sb_snd_rtg_eid and cfe_sb_snd_rtg_err1_eid cfe_sb_bad_cmd_code_eid : <url> <url> cfe_sb_getpipename_id_err_eid : <url> <url> cfe_sb_getpipeidbyname_name_err_eid - note the message also is not all that useful . <url> <url> cfe_evs_err_crlogfile_eid : <url> <url> cfe_evs_err_evtidnoregs_eid ( might benefit from being common code ) : <url> <url> <url> cfe_evs_err_appnoregs_eid , cfe_evs_err_illappidrange_eid , cfe_evs_err_noappidfound_eid - used in <number> locations , refactor ! cfe_evs_err_crdatfile_eid : <url> <url> cfe_evs_err_invalid_bitmask_eid used in <number> different places for different bitmasks , refactor candidate . cfe_tbl_load_success_inf_eid : <url> <url> cfe_tbl_validation_inf_eid : <url> <url> cfe_tbl_file_access_err_eid : note - gave up here . based on the number of these and no near - term solution it ' s likely explicitly recording every duplicate use of event ids will be out of date by the time this is addressed . may note as "" <allcaps> overloaded </allcaps> "" in event documentation but that is not all that reliable either . suggest scripted verification . <section> create unique eids <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"erroneous time behavior <section> time is jumping to an erroneous value after sending the cfe_time_sub_1hz_adjustment_cc command . i am not clear if the erroneous behavior is isolated only to the cfe_time_sub_1hz_adjustment_cc command - the error was just noticed when testing a script that sends that command . <section> steps to reproduce the behavior : <number> . set the <allcaps> stcf </allcaps> to a known value <number> . send add 1 hz adjustment ( in my attached test report i did <number> sec per sec to demonstrate behavior ) <number> . send sub1hz adjustment ( in my attached test report i did <number> sec per sec to demonstrate behavior ) <number> . observe an anomalous time jump ( lines <number> - <number> in my attached report ) <section> oracle vm virtualbox os : ubuntu - <number> versions : cfe v6 . <number> - rc1 + dev218 , osal v5 . <number> - rc1 + dev109 , psp v1 . <number> - rc142 . <section> dan knutsen <allcaps> nasa </allcaps> / goddard erroneoustimebehavior . txt <url>",0.0
"cfe_es_calculatecrc header has incorrect return description <section> the return in the header of cfe_es_calculatecrc says it returns error codes but it does not . when things go wrong it returns either the input crc or <number> depending on how it went wrong , <section> header should correctly explain what cfe_es_calculatecrc can return . <section> if typecrc is a non - implemented type then it returns <number> . if dataptr is null or datalength is zero it returns the input crc <section> alex campbell <allcaps> gsfc </allcaps>",1.0
"order event id ' s and fix duplicates <section> the whole "" <allcaps> max eid </allcaps> "" concept for avoiding conflicts is poorly followed , out of order <allcaps> eid </allcaps> ' s then lead to collisions . just one example shown here ( there are multiple ) : <url> <url> <section> order <allcaps> eid </allcaps> ' s by number . put new ones at the end . remove the unused <allcaps> max eid </allcaps> value which is fragile anyways . <section> none <section> # <number> - incorrect max <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"streamline change history in readme <section> the changelog history clutters the readme . <section> move all change history to a new <allcaps> changelog </allcaps> . md . replace "" history "" section on readme with a "" changes in latest build "" section that contains the latest entry in the changelog . <section> automatically generating the changelog . stop including the change summary in the readme . <section> none",1.0
"protect from eventid collisions with <code> <section> <allcaps> evs </allcaps> uses <code> to mark slots in the filter table as free : <url> since <code> is of type <code> , this ends up colliding with 0 xffff which is not documented in the <allcaps> api </allcaps> ' s as being "" reserved "" . leads to some very strange asserts in the coverage tests where - <number> eventid returns cfe_success where it should be rejected : <url> <section> <code> should be documented as an invalid eventid ( expose ) , and reject in apis / commands that take eventid . <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"convert or remove "" cfe requirements . docx "" <section> <code> is not easily readable since it requires both a download and the user to have ms word or equivalent installed . the document ' s purpose is ambiguous given the existence of <code> . i have also seen some "" tbds "" in the document hinting that there is some more work needed . <section> various options add a readme to the docs directory that explains the different files . additionally , replace <code> with markdown or <allcaps> pdf </allcaps> <section> none <section> none",1.0
remove unused <code> <section> unused error code . unsubscribe returns <code> from an unsubscribe call when there are no subscribers . <section> remove <section> none <section> # <number> updated the documentation <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove <allcaps> osal api </allcaps> guide from <allcaps> cfe </allcaps> <section> in nasa / osal # <number> the scripts for generating the <allcaps> osal api </allcaps> guide are now included in the <allcaps> osal </allcaps> repo , based on what <allcaps> cfe </allcaps> had here . with this , it should not be necessary to include the <allcaps> osal </allcaps> documentation in the <allcaps> cfe </allcaps> repo any longer . <section> remove the <allcaps> osal api </allcaps> guide config / templates from <allcaps> cfe </allcaps> , and call the <allcaps> osal </allcaps> script as a subdirectory to build the <allcaps> osal api </allcaps> documentation . <section> depends on nasa / osal # <number> being merged first ( or at the same time ) <section> joseph hickey , vantage systems , inc .",1.0
"move <code> internal ( no longer an <allcaps> api </allcaps> ) <section> since it ' s set up and registered by the <allcaps> time </allcaps> service via <code> , it no longer needs to be exposed . <section> move prototype internal <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add doxygen aliases for <allcaps> osal </allcaps> parameter / retvals <section> adds "" nonnull "" , "" nonzero "" , and "" covtest "" tags to mark parameters and return values in documentation . this info is helpful when auditing the test cases . fixes # <number> <section> build osalguide documentation , confirm output in the generated <allcaps> html </allcaps> <section> documentation only , no <allcaps> fsw </allcaps> . doxygen parameters and retvals can now be marked accordingly <section> ubuntu <section> this markup will be required for some of the <allcaps> osal </allcaps> return value verifications <section> joseph hickey , vantage systems , inc .",1.0
"documentation tag to indicate return vals that are not tested in functional test <section> the pattern employed in <allcaps> osal </allcaps> ( and <allcaps> cfe </allcaps> ) is that functions should list all directly - generated return values from an implementation as <code> tags in doxygen markup . these are then cross referenced between the test logs to ensure that all documented return value are tested , and all tested return values are documented . coverage test should be able to exercise all values all the time , but functional test may not be able to exercise all of them . in particular the ones which depend on a failure of the underlying system call are not likely to be trigger - able from a functional test environment . <section> these return codes should be marked in the doxygen as being "" coverage test only "" . this will capture the fact that this has been checked / examined and the functional test is not expected to reproduce this value . <section> the retval statements could be entirely removed if they are not trigger - able in a functional test environment . ( many are pass - through values from the low level impl , but probably not all of them ) <section> this info is valuable not only for this test / documentation round but also any future audits of these test cases by projects and / or future releases . <section> joseph hickey , vantage systems , inc .",1.0
"small typos in developers guide <section> "" definition "" and "" negligible "" are misspelled in the developers guide .",2.0
"cfe_*_verify <censored> . h files are not included anywhere , so error checks are not being applied <section> <code> <code> <section> can also test by providing an invalid parameter . i set : <code> which should have triggered : <url> <section> verifications should be performed <section> na <section> - hardware : docker on laptop - os : ubuntu <number> - versions : bundle main <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"<code> , sample platform and sample mission headers require stdbool . h to appropriately evaluate <code> and <code> <section> without stdbool . h included , both true and false evaluate to <number> for the preprocessor , so tests in <code> will fail to check for exclusive settings . <section> <code> results in : <code> <section> should only fail if both <code> and <code> are defined as <code> <section> <url> <section> - hardware : docker on laptop - os : ubuntu <number> - versions : bundle main <section> note fairly hidden , since <code> is included in osal / src / os / inc / common_types . h . only observable if these headers are included from a file that does not already include osal standard headers . also <code> is not actually included anywhere (# <number> ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
use <code> in cmd / tlm and handling <section> defined as int16 even though a type is available : <url> <url> <url> <url> <url> <url> <url> <url> <url> <url> <url> <section> use <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
factor out duplicate code in <code> by using <code> <section> duplicated code : cfe_time_calculateutc <section> <allcaps> utc </allcaps> = <allcaps> tai </allcaps> - leapseconds . use the utility function instead of duplicating logic to get <allcaps> tai </allcaps> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"improve <code> error handling <section> hard coding retry count to <number> is a bit "" magic "" , not clear how much margin this has , not clear statistically how may conflicts are occurring , no error reporting , no way for the calling routine to take action or track , not clear even if these values are always required to be in sync or what happens if they are not , not obvious what is intended here . <section> clarify design , track / monitor / report performance / errors . if there ' s uses where it ' s critical , may need to deconflict ( protect query from update ) . maybe provide <allcaps> api </allcaps> that ' s slower but always correct , vs faster but possibly invalid if that ' s really a need . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<code> misnomer <section> <code> actually reads in and sets variables , so "" query "" is not a great verb to use . <section> rename ( maybe <code> or similar ) <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"time sync callbacks only called when the tone is marked as good <section> time sync callbacks may be desired even if <code> . <section> consider optional notification regardless of tone "" goodness "" <section> not really clear on the use case where <code> but the synch callback is desired . it ' s really just a check if it ' s within the <number> hz tolerance , which should be true even if it ' s virtual . if configured as a server and virtual , the tone should always be good . if not virtual and there ' s an external sync , should only call if the 1 hz is within tolerance . if not virtual and no external sync , then the <allcaps> isr </allcaps> would not get called anyways , so it would not call <code> , so not clear why changing the internal check against <code> would matter . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <allcaps> note </allcaps> - requested more information from commenter .",2.0
combine <hashtag> if </hashtag> / <hashtag> end if </hashtag> directives into <hashtag> if </hashtag> / <hashtag> else </hashtag> / <hashtag> end if </hashtag> in <code> <section> mutually exclusive logic : <url> <section> use <hashtag> if </hashtag> / <hashtag> else </hashtag> / <hashtag> end if </hashtag> <section> # <number> would likely make this obsolete <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove "" return ; "" from last line of void functions <section> "" return ; "" at last line in void function is redundant . <section> remove <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove empty <code> / <code> blocks in <allcaps> time </allcaps> for tone is / was , comment is sufficient <section> pointless empty block , comment is enough : <url> <url> <section> remove , also indent comments ( if autoformatting does not conflict ) . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"support multiple / alternative table definitions <section> some users have requested the ability to generate multiple different table files / configurations as part of the build , to represent different hardware configurations . this way , they can choose the active configuration at install time ( by choosing which file gets copied to the target ) or at run time , by loading a different table file . <section> currently the "" add_cfe_tables "" does not directly support this , but with a little work it should be able to . this requires adding an "" install "" hook so the user has a proper place to call this function to generate customized table files . <section> while this is possible to some degree with the current build system , all decisions are made at build time . for instance the c preprocessor can be used ( via e . g . add_definitions ) to select different table values based on build - time configurations . alternatively , the user can write their own script to compile a c file and call <code> on it , but it can be difficult to determine the proper include paths and compile definitions . <section> joseph hickey , vantage systems , inc .",2.0
"replace hardcoded message limits in <allcaps> time </allcaps> services <section> hard coded as <number> , although if there ' s <number> messages in the pipe that ' d be an issue . <repeated> <url> <url> <url> <section> the default subscriptions just use <code> so could just use it to keep subscriptions the same , even though <number> would be bad it ' s likely handled by the related verification logic . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"factor out duplicate logic in <code> and <code> <section> <code> and <code> duplicate logic . <section> refactor . <section> <code> seems overly restrictive . since it ' s a single entry per app , could just set it as <code> . note <code> does set it to <code> without restrictions . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor or replace <allcaps> api </allcaps> ' s related to <code> <section> <code> , <code> , <code> , <code> , <code> all just call <code> . <section> could just expose and use cfe_time_getreference . <section> if the structure needs to stay internal , consider factoring out common logic . <section> code review . related to # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
replace if ' s with table and loop in <code> <section> <code> could just be a table / loop instead of individual <code> ' s: <url> <section> simplify with table / loop <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
declare leap seconds as unsigned <section> <code> type used for <code> in command payload : <url> also in hk : <url> <allcaps> api </allcaps> ' s: <url> <section> convert to <code> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"define and apply naming standard for event id definitions <section> some services include the error type as part of the name of the <allcaps> eid </allcaps> / eventid / event id , others do not : <url> <url> <section> define and apply standard naming pattern . suggest append either _info_eid , debug_eid , err_eid , or crit_eid to the name . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , typos in developer guide <section> this commit fixes a few minor typos in the developer guide . please let me know if i need to file issues for such trivial changes , too <happy> <section> none . <section> none . <section> none . <section> none . <section> none . * individual <allcaps> cla </allcaps> is on file *",1.0
"simplify <allcaps> tbl </allcaps> <code> indication , and possibly the buffered table concept in general <section> strange indexing / math for double buffered vs non - double buffered tables for <code> : <url> really the whole "" double buffered "" table concept is a bit strange / limited . <section> separate into explicit shared buffer index and table buffer index or other method to deconflict meaning . <section> really "" double buffered "" is the capability to have <number> versions of a table in memory and be able to switch . could generalize to define the number of tables in memory , and be able to load to any of them , activate whichever one is request , etc . if the selected table to load to is active , then use a shared buffer and if not just directly load . design collapses and unique logic for "" double buffering "" goes away ( for just <number> table in memory it ' s the "" single buffer "" use case , more than <number> is an enhanced version of "" double buffer "" but still allows user to load to whatever index they want ) . could have an option to "" disallow "" loads to active table ( single buffer would reject reloads , multiple would prevent loading active index ) . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add option to send <code> event from <code> <section> repeated pattern in <allcaps> tbl </allcaps> to find a table and if not found send the same event : <url> <url> <url> <url> <url> <url> <section> optionally ( if needed ) send event in <code> <section> other refactoring as suggested in # <number> <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"implement single pattern for command handler returns <section> - es ignores command handler returns , just returns cfe_succss ( increments counters within handler ) - <allcaps> evs </allcaps> captures the return and increments appropriate counter as part of the main command processing routine - <allcaps> tbl </allcaps> defines <code> but does not use it consistently , example : <url> <url> <section> utilize a consistent pattern . suggest using cfe_status_t and defined error types . this allows command handlers to use apis and not need to convert error codes . <section> none <section> code review , also related to issue # <number> to consistently use <code> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> tbl </allcaps> owner app id logic should utilize id utilities / defines <section> <allcaps> tbl </allcaps> services defines <code> as <code> and then tests for equality , just ends up mixing concepts . the relation is not obvious and it ' s not clear cfe_tbl_not_owned is actually an ( undefined ) id . <section> keep it simple , just use the valid id macros and associated definition for undefined if it ' s not owned . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"overloaded internal return codes in <allcaps> tbl </allcaps> service <section> multiple return codes are defined as <code> , this defeats the purpose of named codes and does not allow for unique handling , checking the error code is also not actually testing that the expected incorrect code was returned . <url> <url> note there ' s at least one cases where an index is initialized to one of these error codes , which is especially fragile (# <number> ) <section> defined unique error codes , if they every get passed out an <allcaps> api </allcaps> really they should be defined in cfe_error . h <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"printf format issue on <allcaps> rtems </allcaps> <section> when compiling the test app under <allcaps> rtems </allcaps> , a build failure occurs : <code> <section> build system for <allcaps> rtems </allcaps> <number> with unit tests enabled , and <code> will fail to build . <section> build should succeed . <section> <allcaps> rtems </allcaps> <number> <section> joseph hickey , vantage systems , inc .",2.0
"<code> translates a positive return from the validation function to an error ( - <number> ) <section> although it ' s documented in the <allcaps> api </allcaps> that a positive return is considered an error ( and overwrites the return status ) , this is out - of - family with the rest of cfe . <url> <url> also hardcoding as - <number> is not all that helpful , probably worth a unique error code ( if this error is kept ) . <section> seems like the code is trying to do too much . if ! = success just send the error event and return the status ( it ' s the apps problem to handle it ) , if it does not comply w / cfs error code standards it ' s outside the scope of cfe to do something special with it . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor <code> to unmix error codes with indexes and simplify loop <section> mixes error codes ( at least by name ) with an index : <url> also the do / while loop is unnecessarily complex in how it exits ( has to check for last entry twice ) . <section> consider a simpler while or for loop with a break , do not mix index w / a command code . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<code> misnomer <section> <code> just marks the table as updated , does not "" notify "" <section> clarify name to reflect what is actually done <section> none <section> code review - just an internal naming change <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
consistent loop implementation in <code> and <code> <section> loops could be the same but are not : <url> <url> <section> consistent implementation <section> none <section> code review - note this is style suggestion only <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove local / duplicate file name length check from <code> <section> filename length is checked by os_opencreate , does not need a local check : <url> <section> use <code> return code to report the appropriate error <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove unnecessary <code> in <code> <section> memset followed by writing everything except last char : <url> <section> just do the <code> then <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"use <allcaps> xor </allcaps> for ping - pong buffer in <allcaps> tbl </allcaps> <section> current pattern use for the active / inactive buffer index is not as obvious / common ( <code> ) , examples but needs full scrub : <url> <url> <section> <code> <section> current implementation works , this is just style <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"implement <allcaps> jpl </allcaps> rules in codeql <section> codeql does not use <allcaps> jpl </allcaps> rules , which is used in the upcoming coding standard . <section> implement <allcaps> jpl </allcaps> rules for codeql . continue using the security queries , but keep them separate from the <allcaps> jpl </allcaps> results . can use two different workflows , one for the coding standard and one for the security queries . <section> might be able to use one workflow , as long as the results can be easily identified as a coding standard issue or security issue . <section> <allcaps> jpl </allcaps> queries are found here : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"convert to static array sizes for string parameters - <code> and scrub string handling <section> many apis and even internal functions require specific minimum string sizes to avoid a potential buffer overrun , yet take simple pointers , i . e . <code> . some tools complain about strcpy / sprintf / etc , but the sized versions are not any safer if the passed in string is too short . example case : <url> <section> leverage c99 checks on sized parameter arrays , which also will protect at compile time from <allcaps> null </allcaps> inputs . once minimum sizes are guaranteed , then revisit string comparison / manipulation calls to avoid buffer overruns based on these enforced minimums . note not backwards compatible where pointers are passed in vs the array . also would <allcaps> require </allcaps> the removal of all <allcaps> null </allcaps> pointer test cases and checks ( would cause compile errors or dead code respectively ) . <section> none <section> code review , related to # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
write <code> errors to syslog <section> multiple errors are not written to the syslog : <url> <url> <url> <url> <section> report errors <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"possible race conditions in table sharing if sharing / unsharing / unregistering while managing / updating / accessing <section> related to # <number> , no built in protection from possible race conditions with global table data if tables are shared / unshared / unregistered currently with other management functions from multiple tasks . <code> example : <url> <code> example : <url> note , looks avoidable if <code> and <code> happen at startup and shared tables do not <code> . but still need to keep in mind blocking related to management and how updates work . <section> via inspection . <repeated> <section> no race . add locks or disallow <allcaps> api </allcaps> use in certain system states . consider if simplification is possible based on actual use cases . <section> see above <section> na - inspection <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"<code> not processor specific ( comment clarification ) <section> multiple locations refer to <code> as "" processor specific "" , which does not make sense since it ' s just appname . tablename . even if the table is processor specific , it should likely have a non - processor specific name such that apps are portable . examples : <url> <url> <url> <url> <url> <url> note <code> is described as <code> which is somewhat circular , but this could be addressed as part of # <number> ( similar to # <number> ) . suggestions - fullname , qualifiedname , resourcename . <repeated> <section> remove processor specific language <section> none <section> # <number> is similar wrt <allcaps> cds </allcaps> names # <number> is a general issue related to resource naming <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"use <code> in <allcaps> tbl </allcaps> reporting when available <section> inconsistent reporting of table "" context "" throughout <code> ( and likely others ) . just ' name ' ( no app ) example : <url> no table context at all : <url> re - assembled name : <url> actual <code> use : <url> <section> just use <code> , it ' s assembled right at the start . consistent syslog format ( see also # <number> ) of "" function : tblname - message "" or similar . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
""" <allcaps> null </allcaps> "" entry no longer supported for libraries in startup script <section> set sample_lib entry point to <allcaps> null </allcaps> : <code> <section> see above . <section> <allcaps> null </allcaps> should skip the symbol lookup and load . note it does skip if the field is just left empty , as in : <code> <section> only skips if empty string : <url> probably could just convert "" <allcaps> null </allcaps> "" to empty in the cfs_lib processing section . <section> - hardware : docker - os : ubuntu <number> - versions : bundle main <section> found by <user> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"refactor <allcaps> tbl </allcaps> to reduce complexity , improve maintainability , reduce technical debt <section> <allcaps> tbl </allcaps> functions are complex and utilize many modes . complex enough that minor maintenance is avoided due to the high likelihood of breaking something . other code review notes to address as part of the refactor : - if block could go inside else at line <number> <url> - free handle is consumed even if status is already an error ( and not returned to the pool ) <url> - similar logic in <code> for single and double buffered tables , factor out duplication - may be able to shorten lock in <code> to just the resource allocation parts ( although since it ' s typically just part of startup should not be an issue ) - multiple returns in <code> should be refactored out - <code> loop could be a do / while and only loop if additional management required , although really the only two things that could be done in one manage are validate and dump ( if an update is scheduled it ' s first and exits loop ) , although these are globals so it seems like a validate could run before an update . <repeated> related to # <number> - consider using <code> from <code> - <code> should use <code> <section> break down large complex functions . <section> note grouped all the suggested refactor changes here , could break out smaller tasks and implement one by one but that may result in extra work . <section> code review , related to # <number> in that sharing is not clearly defined <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"consolidate command payload base types <section> many services define a service specific no - arg payload . there ' s also many filename only commands with repeated definitions , and numerous others . <section> consolidate , define a common set and standardize parameter names . still can utilize unique payload / message names , but just typedef the generic ones . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
use <code> for <code> in <allcaps> tbl </allcaps> <section> <code> not using expected type : <url> <url> <section> use <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update time format to support negative time or unify with <allcaps> osal </allcaps> time <section> unsigned <number> bit used for seconds in cfe . requires unique handing for rollover and avoiding negative time . <section> signed <number> bit seconds , or unify with <allcaps> osal </allcaps> time format and provide the necessary conversions . consider typedef of seconds and subseconds to support strict checking ( if there ' s still any functions left that take individual elements ) <section> none <section> code review , note backwards compatibility issues <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove <code> and <code> <section> no need to support getting the individual fields , just use <code> . avoids misuse , since individual fields are not in sync ( subseconds could roll between calls , etc ) . <section> remove / deprecate these extra apis ( confirm against requirements ) <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove / replace <code> macro <section> the stated purpose ( copy across different structures with second / subsecond fields ) really is better avoided by using a common time structure . <section> remove <code> , use cfe_time_systime_t which enables simple assignment (x = y ) , or replace with more type - safe / inline function . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"define table maximum object name length <section> hardcoded length : <url> <section> add a local define for reference for cases where sizeoff ( objectname ) is not appropriate . note elf2cfetbl just uses sizeof , so size is not duplicated anywhere currently . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use <code> instead of individual seconds / subseconds <section> inconsistent use / definition of time structure vs individual sec / subsecs , benefits from common structure : <url> <section> use <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove <code> and <code> apis <section> these two apis are out of family , no others take arrays of handles . not a significant benefit to maintain this capability . <section> remove these two apis <section> could provide handle array <allcaps> api </allcaps> ' s for all the standard <allcaps> tbl </allcaps> calls ( register , manage , etc ) , but really needs a use case since it ' s rare to see the existing apis used in the wild . this is not really all that great since it does not allow for individual error handling . maybe "" all or nothing "" sort of error handling is ok , but should be considered in the trade . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"embed table modification response actions / notification in <code> <section> <code> <allcaps> api </allcaps> that notifies table services the table has been modified could be replaced by an additional parameter to <code> , which might help with table sharing / synchronization since required actions could be completed prior to release . <section> perform "" modification "" response actions as part of <code> . <section> consider as part of design review related to # <number> <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"comments / document cleanup relative to <allcaps> tbl </allcaps> / <allcaps> time </allcaps> review <section> <code> , <code> , and <code> are all performed by <code> if there ' s a pending request . clarify in <allcaps> api </allcaps> documentation for all <number> ( missing completely from <code> ) . s / addresses / address , this should cross reference , not self reference : <url> add short description of spacecraft time , it ' s number of seconds since the epoch as set in mission configuration <url> self reference does not make sense : <url> there is no <allcaps> api </allcaps> to set or adjust leap seconds or <allcaps> sctf </allcaps> , this should be done by ground command only : <url> <url> now called by a timer , not <allcaps> psp </allcaps> : <url> hk command handler also sends the table registry packet ( if requested ) and dumps "" dump - only tables "" that are pending , document : <url> s / issued / issues : <url> remove commented out verification check using sizeof from cfe_tbl_verify . h : <url> remove pointless comment : <url> <section> fix <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"clarify acceptable actions on a shared table along with expected patterns and add functional tests <section> currently table sharing management requires careful design or restricting the design space to avoid block / priority concerns . - there is not a "" read only "" way to get a table address to restrict capability for management to a single "" owner "" - since update / management can be done by any app with shared access , blocking / priority has to be managed - not immediately clear how the locking / sharing is all intended to work together <section> should clarify the sharing design documentation , there ' s currently "" hints "" in the apis and a very short section in the cfe application developer ' s guide but there are not functional tests that actually implement / exercise all the sharing patterns or a full description of how it ' s intended to work . - clearly describe how unregistering a shared table is expected to work ( or not ) <url> <section> consider additions / simplification to the sharing model like read only access , etc . need to tie to requirements , funding , use cases , etc and trade against the additional complexity . <section> code review , see also # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , correctly format code block section terminator <section> - a code block wasn ' t terminated terminate properly , causing the markdown to not render correctly on github . fix # <number> <section> <number> . view on github <section> - no impact to behavior <section> - n / a <section> n / a <section> n / a <section> full name and company / organization / center of all contributors ( "" personal "" if individual work ) - company <allcaps> cla </allcaps> from honeybee robotics on file .",1.0
"add ${ <allcaps> argn </allcaps> } to add_cfe_coverage_test in arch_build . cmake <section> trying to build cf unit tests with additional libraries through add_cfe_coverage_test does not work because <allcaps> argn </allcaps> is not added in the target_link_libraries call . <section> add <code> into target_link_libraries call in add_cfe_coverage_test so that additional libraries can be given where necessary . <section> writing my own coverage test addition for my use case , but just adding the ${ <allcaps> argn </allcaps> } in add_cfe_coverage_test works , so why re - invent ? <section> the addition should be transparent to any other calls currently in use ; it is opt in only . <allcaps> argn </allcaps> should be empty in current use cases ( it could not be , but that is unlikely ) . <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",2.0
"remove suppression of files checked by cppcheck in action to allow visual confirmation it worked <section> the "" all "" static analysis check suppresses standard output with <code> , so can not see that it actually did anything <section> remove <code> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove travis - ci script <section> the travis - ci script is currently broken and duplicates what ' s now covered by github actions <section> delete <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_es_poolcreateex numblocksizes error handling <section> in the header file of cfe_es_poolcreateex , for parameter numblocksizes it says "" if set equal to zero or if greater than <number> , then default block sizes are used . "" in the code though if numblocksizes is greater than cfe_platform_es_pool_max_buckets ( which is set to <number> ) then it returns error code cfe_es_bad_argument . <section> the header and functionality should match . <section> alex campbell <allcaps> gsfc </allcaps>",1.0
add a ci action to build and execute the cfe coverage tests <section> ci does not build and execute the cfe coverage tests <section> add <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
fs header functional tests <section> the functional test currently only test the base cases of the <allcaps> api </allcaps> functions . more in depth tests still need to be written . <section> write tests for all the possible cases <section> follow up to # <number> <section> alex campbell,2.0
<allcaps> es cds </allcaps> functional tests <section> the functional test currently only test the base cases of the <allcaps> api </allcaps> functions . more in depth tests still need to be written . <section> write tests for all the possible cases <section> follow up to # <number> <section> alex campbell,2.0
cfe es child task <allcaps> api </allcaps> functional tests <section> the functional test currently only test the base cases of the <allcaps> api </allcaps> functions . more in depth tests still need to be written . <section> write tests for all the possible cases <section> follow up to # <number> <section> alex campbell,2.0
use <code> for <code> in <code> <section> not using <code> : <url> <section> a clear and concise description of what you want to happen . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"make invalid id a generic define and use ( always <number> ) <section> hardcoded zero instead of <code> used by <code> : <url> <section> define a generic cfe_invalid_id <happy> <number> ) , and confirm it ' s used everywhere . <section> at minimum replace this specific use with define . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> api </allcaps> prototype / implementation mismatch scrub <section> example from <code> , <code> vs int32 : <url> <url> note numerous others , some noted in <allcaps> tbl </allcaps> . <section> general scrub , prototypes across all the headers should match implementation . also could remove <code> per # <number> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add helper for <code> to implement common logic <section> repeated logic / pattern in <code> , <code> , and <code> . <section> put common logic in a helper , pass in info . <section> might even be able to make a generic function in # <number> for all apps / services to use since it ' s likely a very common pattern . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
replace loop with single <code> in <code> <section> loop not needed <url> <section> just <code> the sizeof*count <censored> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"improve <code> naming <section> <code> , <code> and <code> have very similar names , but are of different type and from different causes . easy to confuse / typo or mix up the difference . <section> replace with more descriptive names , one suggested pattern is to also embed the type in the name . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
create array and loop for software bus subscriptions <section> repeated logic / pattern in subscriptions : <url> <section> create array and loop . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add service "" health "" parameter to hk ( and provide a suggested pattern for apps to follow ) <section> historically syslog or events are used to report issues , and telemetry status reporting is likely scattered and / or inconsistent . not easy to really be sure everything is "" healthy "" at a glance . example issue is with system startup synchronization , there is not an easy way to tell ( especially if there ' s spotty com ) that startup synchronization was successful . there ' s also other cases where operation continues "" best effort "" in failure conditions , since there is not anything that can really be done from within the system . <section> add an app / service health summary parameter to hk , <number> is healthy and nonzero bits could indicate specific issues have been encountered . latch on condition , but clear with the a reset command . proper synchronization is an easy first condition to add , but scrub for others to include in the summary . with this addition , reduces the dependency on syslog / events for a monitoring system ( like hs or an "" external "" monitor ) or the ground to take appropriate action . additionally many of the <allcaps> cds </allcaps> "" errors "" are simply written to the system log ( or not ) and initialization continues . when these things fail there is something wrong or something got corrupted , needs to be more obvious ( examples ) : <url> <url> <url> <section> none <section> # <number> would allow apps to add the sync status , note also # <number> would provide the syslog . spawned from issues discussed at code review . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use a statically constructed table for sb filter initialization <section> no need to store filter settings in global or individually process : <url> <section> statically construct the table and use it for initialization , can loop through it for size test . <section> not sure how consistent this pattern is , but another candidate for # <number> and use for all the services ( available for apps if they want it ) . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"report cfe_es_waitforsystemstate timeouts <section> timeouts are not reported when using <code> . <url> <section> syslog from within the <allcaps> api </allcaps> . <section> note the syslog from within the <allcaps> api </allcaps> provides the minimal amount of notification only , expectation is apps / services would handle the return for any local / additional actions that may be required ( like system heath / synchronization status reporting ) <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <allcaps> edit </allcaps> - updated possible solutions .",2.0
"add status output to <code> <section> <code> does not return status , so unique / local timeout responses can not be handled by the caller . <section> pass the return from <code> through <code> back to the caller so timeouts can be handled if needed from within the app context . note # <number> adds a syslog on timeout from underlying <code> . so handling would be anything extra , like app health reporting , aborting hazardous ops , etc . <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use sized char array for <code> parameter and limit print <section> <code> takes a char pointer <code> without an associated size . relies on user to size the buffer correctly for the sprintf : <url> <url> <section> related to # <number> , explicitly size as an array and use snprintf to print to limit appropriately . note # <number> suggests moving this to a generic utility ( out of sb scope ) , maybe <allcaps> es api </allcaps> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"replace magic number in <code> <section> the <code> limit on an <code> does not seem to make sense , looks like int16 max instead of uint16 max ? <url> <section> use a defined max , add a comment if the max choice is not obvious . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
reduce scope of lock to within <code> statement in <code> <section> locks outside if : <url> <section> move inside <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"combine mostly duplicated logic in <code> <section> duplicated logic : <url> <section> factor out , make an else with shared logic and internal if for the unique logic <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"improve documentation in sb subscription apis wrt non - priority based delivery <section> although they do document order of delivery ( last is first ) , it ' s not obvious the relation to priority and how a higher priority task could be blocked . related to lack of actual <allcaps> qos </allcaps> options . note duplicated info in each api , should just define once and reference . <section> provide details and example for out of order priority scheduling . <repeated> really tasks where it matters should probably not pend on the same message , and understand how sb works . <section> implement <allcaps> qos </allcaps> / priority delivery <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"factor out construction of fullname in sb event messages <section> <code> is called in virtually every <allcaps> api </allcaps> event message , example : <url> note for the special case in <code> it currently overloads fullname with caller and owner . really should report both if there is not a match . also fullname is referenced before initialized below , but not used . <repeated> : <url> <section> construct fullname outside switch and use it . <section> really there ' s inconsistent reporting in apis ( sometimes system log , sometimes events , unique message formats all over with differing info ) , would benefit from an overhaul . see also # <number> and related issues (# <number> , etc ) to fix . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"define a const global for <code> and use it <section> <code> and similar is defined hardcoded as size <code> , example : <url> <section> create a const global and use it . <section> may make sense to actually scrub reporting in apis to use consistent reporting style / technique . suspect there ' s either repetition or variation across the services . candidate for generic utility function - # <number> <section> code review . note fullname in sb is actually appname . taskname . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<code> typedef implies a callback , but it ' s callback arguments <section> name used in typedef misleading : <url> <section> <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add tag to <code> structure and use it instead of <code> for <code> and <code> <section> void pointers used in <code> : <url> <section> defining a tag and use in pointer definitions <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
keep local subscription status with subscription info so only one unsubscribe <allcaps> api </allcaps> is needed <section> do not need a special unsubscribe if the setting is available : <url> <section> store local setting so single unsubscribe <allcaps> api </allcaps> can just do the right thing based on the setting . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove / replace / rework <code> related macros <section> the <code> , <code> , <code> , <code> are all only used within cfe for avoiding recursion in sb , all just once except <code> <section> remove unnecessary macro , clearer to just use the expression vs an abstraction like everywhere else bits are set , cleared , tested . coding standards encourage avoiding overuse of macros . <section> could replace with inline functions and provide as a general utility ( sb scope is not all that intuitive ) , and use it more consistently . these are not thread safe , if they are maintained consider atomic bit ops . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"comments / document cleanup relative to sb / <allcaps> msg </allcaps> / <allcaps> sbr </allcaps> review ( and # <number> ) <section> clarify <allcaps> ccsds </allcaps> comment , just note <allcaps> ccsds </allcaps> maximum is <number> bigger than int16 : <url> add link to options in documentation : <url> clarify comments to eliminate implied coupling ( <allcaps> sbn </allcaps> is an example use ) : <url> mention cfe_sb_releasemessagebuffer for the case when a message is not transmitted in <code> : <url> extra <code> in comment : <url> comment in <code> about cfe_success status should be brought up to the <code> level , everything is success and explicitly mention in <allcaps> api </allcaps> documentation : <url> s / bush / bus : <url> fix comment , does not pad to boundary , instead pads to be divisible by <number> so compiler will not add padding if payload structure requires <number> bit alignment : <url> <url> <section> fix <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
remove duplicate status check in <code> <section> checking for status and outputing command handler debug event here : <url> could output event within the first check here : <url> <section> move event . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"refactor enable and disable command handlers to use common code w / boolean <section> duplicated logic in many enable / disable command handlers , example : <url> <url> <section> factor out common code . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
simplify logoverflowcounter increment logic <section> the cfe_evs_global . evs_logptr - > logoverflowcounter gets incremented in two locations and is done based on the logfullflag : <url> <section> pull up higher and change the if / else statement to : <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"both enums ( index ) and defines ( mask ) exist for event type <section> having both the mask and the index requires keeping them in sync . event type bitmasks : <url> event type enum : <url> <section> collapse to one solution , either use the mask or the enums . related to # <number> and # <number> . <section> or use one to create the other so they do not get out of sync . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove defines for <allcaps> evs </allcaps> logmode <section> enum is defined here : <url> defines here : <url> <section> remove defines , replace any references with the enums . <section> boolean for overwrite ( although cmd / tlm should be fixed size ) <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
extend cfe service identifier in error codes <section> cfe service identifier is limited to <number> unique values which are fully subscribed : <url> means new modules need to overload existing service identifiers : <url> <section> add one more bit . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
replace character copy with memcpy in <code> <section> character copy performed in a loop instead of a memcpy : <url> <section> memcpy . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"refactor <code> and eliminate typo <section> there ' s a typo in one of the syslogs : <url> also could just write the time structure instead of seconds and then subseconds : <url> <section> write time structure , one syslog with an updated message . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"replace magic number in <code> with <code> <section> magic number : <url> <section> there ' s already a define , use it : <url> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
avoid using <allcaps> ram </allcaps> to hold pointers to static const data <section> using <allcaps> ram </allcaps> to point to static const data : <url> comment also applies to ramdiskmountpoint . ( and to all of target_config . c ) <section> <allcaps> tbd </allcaps> - needs resolution defined . ping <user> <user> to resolve . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"convert defines to constant variables <section> defines are both discouraged by standards and clumsy when type matters . <section> convert to constant variables , performance is maintained and get type checking . use has started but should really convert the existing defines , example : <url> example of improvements , filters as const variables would allow overflow checking : <url> <section> none . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"simplify handling / checking of event type in commands and use a defined mask <section> inconsistent handling / checking of event type when input by command . there is no type mask defined , so some places it ' s constructed and other ' s hardcoded : <url> internal functions <code> and <code> both <section> mask and use a variable with a constructed value where the value should be const , fragile since each individual value is used ( twice ) so easy to get out of sync : <url> <url> all the command handlers that actually use the above helpers already check against a hard coded value and report out of range bit mask : <url> <url> <url> <url> <section> at minimum define a mask ( near bit definitions ) and use it . helpers could check the range and return an error , then handler could just report on failure . <section> could leave the check in the handler and remove the helpers since they ' d just be an | or & ~ , not really worth a helper for this approach . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"incorrect assumption about file name patterns in table build <section> on most cmake platforms the generated object file names are simply the file name ( including the . c ) concatenated with cmake_c_output_extension . so , for example , on table build for sample_app , the file <code> gets compiled into <code> which can then be used to call <code> . apparently this relationship is not guaranteed , there is at least one example of a platform where this gets compiled to <code> instead of <code> . <section> attempt to build on a platform that does not follow the expected pattern . tables will fail to build with a failure to open the object file due to the name mismatch . <section> table should build successfully . <section> i traced this back to a workaround that was put in for older cmake , which assumes the name of the object file : <url> the preferred / correct way to do this is to use the <code> generator expression , but this only works in newer cmake versions . the workaround was to assume a file name based on the expected pattern , which works most of the time , but there are exceptions . <section> originally reported by <user> when building for vxworks <number> . <section> joseph hickey , vantage systems , inc .",0.0
"use consistent type for eventid <section> eventid is defined as <code> and <code> , examples : <url> <url> <section> use a consistent definition . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
replace magic number in <code> defnition <section> magic number used : <url> <section> use a defined size ( this is probably for time ) <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
report error writing header in <allcaps> evs </allcaps> write app data file <section> error from <code> in <code> not reported . <section> add an event to report a failure in writing the file header . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"include element that caused write error in event reporting in <code> <section> element that caused error not included in event , so not obvious how much of the write was completed <url> <section> add the element number <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<code> returns <code> when filter already registered <section> see : <url> really all non - <code> returns from command handlers are handled the same ( increment command error counter ) . <section> really they are all just generic command handler errors , no need to be unique . suggest just simplifying ( there ' s already unique events created ) . <section> could define a unique error code , but it ' s not returned via an <allcaps> api </allcaps> so does not really need to be unique . uniqueness does allow for specific return check when coverage testing , but is it really worth unique codes ? <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor handling of <code> return to eliminate duplication <section> logic for handling <code> repeated all over , example : <url> <section> factor out common logic . consider using a switch . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"put common and local counters in structures to simplify reset all counters command handling <section> individual counter values are reset in reset counter commands , example : <url> and logic is duplicated in every service . <section> common counters ( <code> and <code> ) could be in a structure , and for each service the rest of the counters reset by the generic reset counter command could also be in a structure , and simply memset the structures to <number> on reset . then could easily create a generic reset all counters function as part of # <number> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"pass message id and function code into verify command length functions <section> both message id and function code are already available in typical calling function for the functions that verify command length , so could pass them in instead of extract them from the message ( again ) . note # <number> is open to provide an <allcaps> api </allcaps> to verify command length , so this could be generalized even more by passing in the event id . <section> generalize function , pass in values . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor <code> to use <code> <section> duplicated logic , <code> could get appid and use <code> <url> <url> <section> refactor <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_evs_register - error on truncation and factor out filterlimit <section> <number> . <code> variable is not needed , just use <code> <number> . too many filters are reported in the system log , but should also report an error since this is a significant problem ( will not perform as designed / implemented ) <section> refactor and report <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove deprecated elements ( again ) <section> somehow # <number> got reverted in a few locations ( possible merge strangeness ) : <url> <url> <section> remove . again . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"replace ut_displaypkt with utprintx <section> ut_displaypkt is just a specialized version of utprintx , duplication of logic ( do not need the custom version ) . <section> update internal unit tests to use utprintx , make ut_displaypkt a macro that just calls utprintx <section> deprecate and eventually remove ut_displaypkt ( note there are external users that would need to update ) <section> nasa / osal # <number> - this actually fixes utprintx , once in no need for custom fuction . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"links broken in cfe application developers guide from broken code highlighting <section> the links at the top of the cfe application developers guide on the main branch quit working after heading <number> . this seems to be caused by an extra character added to the closing code highlighting marks , which you can see here : <url> note that the format of the document is also messed up because it highlights normal text as code and vice versa after section <number> . <section> steps to reproduce the behavior : <number> . open up the cfe application developers guide on the main branch on github <number> . click on the heading for <number> in the table of contents . <number> . it does not scroll down to that heading for you . <section> the link for section <number> should take me to that section and the document should not have flipped highlighting in section <number> and beyond . <section> none <section> use github to view the file <section> none <section> jeffrey royer , <allcaps> jsc </allcaps> er6",1.0
"auto increment telemetry sequence count overflow <section> the <allcaps> api </allcaps> ( called by cfe_sb_transmitmsg ) cfe_sbr_incrementsequencecounter has no protection to ensure the sequence counter does not exceed the maximum value dictated by the size of the field in the <allcaps> ccsds </allcaps> primary header ( <number> - bits w / max value <number> . <section> create a for - loop that calls cfe_sb_transmitmsg with the incrementsequencecount flag set to true . have the loop repeat this at least <number> times . view the resultant messages and verify that the sequence count stops incrementing and is stuck at the maximum value . <section> cfe_sbr_incrementsequencecounter ( or the caller cfe_sb_transmitmsg ) should check that the sequence counter does not exceed the maximum value dictated by the size in the header ( <number> ) . the sequence counter should be reset to <number> when it reaches the maximum . <section> in cfe_sb_transmitmsg : <code> in cfe_sbr_incrementsequencecounter : <code> <section> - hardware : n / a - os : n / a - versions : cfe : 2 4 f7b319 <section> n / a <section> pj chapates gateway <allcaps> vsm </allcaps> flight software production <allcaps> jsc </allcaps> , er6",0.0
"generate new set of <allcaps> cfe </allcaps> coverage test stubs <section> to achieve max flexibility the <allcaps> cfe </allcaps> coverage test stubs should have no built - in logic , with all handler logic in a separate function . this is the pattern that was introduced with nasa / osal # <number> , along with the stub generator script . <section> run the stub generator script on <allcaps> cfe </allcaps> core <allcaps> api </allcaps> headers to generate a new set of "" pure "" stub implementation files with no extra logic in them . migrate any existing post - hook logic in the old stub to be a default handler function , as was done for <allcaps> osal </allcaps> stubs . <section> extension of original request in nasa / osal # <number> , but for <allcaps> cfe </allcaps> . depends on nasa / osal # <number> to be accepted / merged before this can be done . <section> joseph hickey , vantage systems , inc .",2.0
"document / implement naming pattern for created elements <section> inconsistent on namespacing of created elements ( see # <number> ) . <section> scrub "" names "" of created elements and how they are defined ( configurable , <code> , locally ) and document / implement a common pattern . really do not need to be configurable , if only used once they do not really need to be a separate define ( only required when id is not available and need to be looked up which is rare sharing case ) , some prefix with <allcaps> cfe </allcaps> , etc . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
const correct parameter inputs in <allcaps> evs </allcaps> <section> <code> should be const : <url> <section> const . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
consider atomic assignments vs locking for a single variable ( possible performance improvement ) <section> in once case <code> is used with a simple assignment : <url> <url> others have a lock for a single assignment : <url> <section> consider using atomic types / assignments <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"report entry index on event log write error , and possibly total for context <section> current entry index and total expected not reported in log write error event : <url> <section> would be helpful to provide context for the error <code> . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use <code> instead of checking <code> in event log logic <section> <code> is already available , do not need to check <code> : <url> <section> use <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"report error when writing event log header <section> the return from <code> is checked when writing the event log header , but there ' s no event sent on error ( it just returns cfe_evs_file_write_error ) : <url> <section> send an event to help narrow down the issue . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
move writing of the event log to the fs background service <section> writing the event log could take a while and is done in the <allcaps> evs </allcaps> context by command : <url> <section> move to the fs background service like the rest of the logs <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"rework cfe / <allcaps> psp cds </allcaps> interface to improve real hardware support / performance <section> currently implementation of critical data store ( <allcaps> cds </allcaps> ) includes a cfe_es_clearcds function that writes uint32 [ <number> ] chucks to <allcaps> cds </allcaps> in a loop to cover the entire area . this could be very inefficient and possibly use up write cycles on the hardware , vs allowing the <allcaps> psp </allcaps> to implement a more hardware specific clear . <url> <section> design / implementation review and update of the <allcaps> cds </allcaps> interface ( especially the cache ) , maybe the <allcaps> psp </allcaps> should report / provide the appropriate cache size for efficient reading / writing . <section> might be less an issue and more just performance wrt modern storage , but <allcaps> eeprom </allcaps> or similar would suffer using current scheme . <section> from code review follow on discussions . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_evs_sendeventwithappid design improvements wrt <allcaps> eid </allcaps> context and calling context <section> cfe_evs_sendeventwithappid is really intended to provide the <allcaps> eid </allcaps> context when an event is created from a library . unfortunately the <allcaps> eid </allcaps> context replaces the app context info ( name ) , which means for short events the ground does not have app context ( can not tell what app generated the event ) . also means filtering by app context is not possible for these types of events , and apps really have no insight into or control over these events . <section> consider options to include both <allcaps> eid </allcaps> context and app context in short messages , filtering , etc . could utilize extra bits , could add a field , etc . may even help to rename cfe_evs_sendeventwithappid to something that indicates overriding the <allcaps> eid </allcaps> context . note if special bits were just reserved , this may collapse down to one <allcaps> api </allcaps> again ( cfe_evs_sendevent ) , but depends on how the rest is addressed . <section> see above . <section> spawned from code review follow - up . related to # <number> and # <number> . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"benchmark memcpy of full event packet vs size of the actual event message and memset the rest to zero <section> may be able to improve event services performance wrt writing the event to the log : <url> by replacing this with a memcpy of the used portion and a memset <number> for the rest . <section> benchmark , if the memcpy / memset is significantly faster consider implementing . <section> it ' s likely all hardware / compiler / optimization dependent and probably in the noise ( may not even notice when flooded w / events ) . if it ' s not worth it we can mark as wontfix and close , but at least it ' s documented . <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"construction of <allcaps> cds </allcaps> name inconsistent with other named elements <section> for the api functions dealing with the <allcaps> cds </allcaps> the variable name has multiple meanings . for registercds ( ) it wants the cdsname . getcdsblockidbyname ( ) and getcdsblockname ( ) both use the full cds name ( of the format "" appname . cdsname "" ) . the header file for these do not explain the difference very well either . also there is no easy way to get a full cdsname from the cdsname because the function that does that cfe_es_formcdsname ( ) is not public . <section> there should be more clarity in the differences as well as a way to get the full cdsname , like having the register function pass back the full name or making the formcdsname function public . <section> they could all use the same thing . <section> alex campbell <allcaps> gsfc </allcaps>",2.0
"improve / clarify log reporting / tracking ( es system log and <allcaps> evs </allcaps> event log ) <section> <allcaps> evs </allcaps> event logging reports <code> , <code> , and <code> . - the log is an array of <code> of size <code> so each entry has a slot - in either discard or overwrite , once the log is filled <code> is set to true , and <code> is incremented for each additional message ( so you can tell how many messages were dropped or added after being full ) . - note <code> is maintained internally but is not in tlm ( counts number of entries in the log , clamps at max ) es syslog reports <code> , <code> , <code> , and <code> . - the log is a more freeform char array <code> of size <code> - in either mode the log is "" full "" when <code> - <code> is less than <code> - <code> is set to the internal <code> which is the highest used element of the char array - <code> increments whenever a message is written , so if in overwrite it ' s not actually the number of entries in the log but the number of entries that have ever been written to the log - there are return codes ( <code> and <code> ) , but they are only returned in discard mode , and not available in tlm - <code> is the full size of the log , <code> <section> numerous misnomers and inconsistencies in log management should be fixed / clarified , within the context of the actual differences in these logs ( char array vs event array ) . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user> <user>",2.0
refactor common code out of <code> and <code> <section> common code in the reset filter related apis is duplicated <section> refactor to reduce duplication . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"consistent use of <code> ( and clarify vs mask ) <section> numerous locations where eventtype is declared as uint16 , but there ' s a defined type <code> <section> use cfe_evs_eventtype_enum_t everywhere <section> use uint16 everywhere <section> code review # <number> - need to sort out enum vs mask use <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"overloaded "" packetid "" use in <code> <section> packetid means other things so it ' s a bit confusing in this context . <section> could be signature , pktidentity , eventsignature , eventcontext , context . <repeated> suggest your own ! <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
scrub error documentation section of command codes <section> error documentation section of command codes is not consistent / complete <section> scrub and update the error documentation for all command codes . needs to detail error cases . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"scrub parameter documentation section of command codes <section> parameter documentation for command codes not complete or always up to date <section> really the structure is the preferred place to document the parameters , the command code documentation is probably better off just referencing the structure . need to confirm all the information in the command code documentation is in the structure documentation and then clean . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"define file subtype value behavior / expectations <section> not clear if the cfe_fs_initheader subtype needs to be one of the fs enums or if it can be user defined by apps . note there is no longer a shell file created by es : <url> <section> need to determine if fs should define all file subtypes , or treat it as an extendable field ( or whatever ) . that will affect if the <allcaps> shell </allcaps> subtype gets removed or renamed ( since there is still an app that would create it ) . note right now apps do not even use <code> , but they do currently set unique values . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"move <code> to internal <allcaps> api </allcaps> <section> <code> is only used internally , should not be exposed as external <allcaps> api </allcaps> <section> move to * _core_internal . h <section> none <section> code review , once moved would also benefit from # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
explicitly sized parameters or data length wrt <code> <section> cfe_fs_extractfilenamefrompath requires data length assumptions <url> <section> explicitly define lengths for parameters or pass in a data length <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"comments / document cleanup relative to <allcaps> evs </allcaps> / fs review ( and # <number> ) <section> <code> parameter descriptions out of order : <url> "" primary header "" not clear in <code> description , really it ' s the size of this header so tools can be agnostic : <url> s / kog / log / : <url> typo , but could also just simplify : get null terminated name for reporting , example below but in <number> copy / paste locations : <url> <section> fix . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"improve <allcaps> evs </allcaps> event filter documentation <section> <code> <allcaps> api </allcaps> documentation not clear , would help to add something like it will treat the next event with that <allcaps> eid </allcaps> like it was the first ( independent of filter method ) along with an example . <url> add description of how they actually work : <url> <section> improve documentation <section> none <section> code review , note conversion to variables is in # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"move internal <allcaps> api </allcaps> ' s and stubs to core_private <section> currently the * core_internal . h files that define cfe internal apis are in core_api along with stubs . <section> move these to core_private since they do not need to be exposed outside of cfe <section> none <section> observations related to code review <allcaps> cfs </allcaps> - <number> , but not directly related to a comment so not marking w / label . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove cfe_evs_unregister <allcaps> api </allcaps> <section> there ' s no use case for apps to unregister themselves from <allcaps> evs </allcaps> using <code> , es cleans them up when an app is being terminated using <code> . <section> remove the <code> public <allcaps> api </allcaps> , confirm requirements also match up . requirement is cevs3101 - delete . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
if an application fails to initialize ; cfe will attempt to restart it indefinitely <section> outside of issuing a processor reset - i am not sure there is a clean way to exit this scenario ( which in theory should never happen in flight ) . this scenario would be further complicated if the app attempting to be started / restarted is included in the startup script . <section> consider implementing a maximum number of restarts . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
"improve robustness of <allcaps> cds </allcaps> checks before re - use / re - build of pool <section> currently the <code> function only confirms that a fixed signature is found at the beginning and end of the memory space , and <code> confirms that the size ( number of entries ) matches . if both of these checks pass , the code will attempt to re - use the contents of <allcaps> cds </allcaps> , rather than re - initializing it . <section> these checks are a little weak . conceivably , the number of registry entries can remain the same , but the size / format of the registry record changes , thereby making the size of the overall registry array larger . the data pool could be reduced by the exact same amount , meaning that the <allcaps> cds </allcaps> trailer will be at the exact some spot , too . in this case the the code might try to re - use the registry but the format has changed and it will be incompatible . should add more values to the size check , not just the number of entries but the sizes / offsets of where the registry and pool start , and it would not hurt to also add a <allcaps> crc </allcaps> - <number> check to this data too , just like is done for data records , before attempting to re - use the data . <section> leave as is , because this is unlikely to occur by random , it would more likely be intentional , and there are other was to force a <allcaps> cds </allcaps> rebuild ( i . e . change sig ) . <section> found during investigation of # <number> <section> joseph hickey , vantage systems , inc .",2.0
"documentation builds should use separate directories <section> the <number> documentation targets ( detaildesign , usersguide , osalguide ) all share the same "" doc "" subdirectory for the doxygen run . this can become a problem when trying to validate documentation builds and building with the <code> option . they work fine when built one at a time , but with <code> at one point my machine got into an endless loop with two doxygen builds running in parallel that kept stepping on the other ' s files . <section> use separate dirs so that builds can be done in parallel without interfering with each other . <section> this should also result in separate "" warnings . log "" files too , that can be more easily checked . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> cds </allcaps> should include some fields of the cfe_es_cds_regrec_t in its <allcaps> crc </allcaps> - <number> validation <section> <allcaps> cds </allcaps> code utilizes a <allcaps> crc </allcaps> - <number> to check the integrity of the <allcaps> cds </allcaps> block . however it only covers the data itself , not any of the metadata of the <allcaps> cds </allcaps> block . when re - using <allcaps> cds </allcaps> memory , the code does not clear old <allcaps> cds </allcaps> blocks for a variety of reasons . the <allcaps> crc </allcaps> - <number> should offer protection against stale data appearing as good data . <section> should include fields from the registry record ( cfe_es_cds_regrec_t ) as well as the data . importantly , this way if the block is re - used and the name is different but the size is the same , the <allcaps> crc </allcaps> check will fail , and the old data from the previous instance is less likely to be interpreted as valid data . <section> offshoot from <allcaps> cfs </allcaps> - <number> review , issues # <number> and # <number> . there are valid reasons _not_ to forcibly clear <allcaps> cds </allcaps> blocks , but the <allcaps> crc </allcaps> check can serve as a reasonable substitute to avoid interpreting old data as valid . this is a suggestion that would make the this protection a little stronger . <section> joseph hickey , vantage systems , inc .",2.0
fix mismatched <code> <code> <section> mismatch : <url> <section> fix <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"document / verify <code> is power of <number> - <number> and sometimes used as <allcaps> mask </allcaps> ( and <allcaps> max </allcaps> ) <section> <code> is used in some places as <allcaps> max </allcaps> and others as a mask , also has to be power of <number> - <number> : <url> <section> document and verify <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
inconsistent error messages in verify header <section> some of the <code> messages do not match the test : <url> <url> <url> <section> fix <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
simpify long if / else if in <code> <section> error cases handled with long if / else if : <url> <section> use table ( or switch ) <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"obsolete logic in <code> file handling ( related to opencreate ) <section> obsolete logic , second <code> will truncate anyways : <url> <section> simplify <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor the cfe_es_*appcmd <censored> handlers to reduce duplicated code <section> similar pattern in <code> , <code> , <code> , <code> <section> refactor to reduce duplicated logic . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"limit send <allcaps> hk mid </allcaps> ' s to <number> in pipe <section> default limit of <number> is excessive , getting behind is an error ( should not spam them either way ) . es example : <url> <section> set to <number> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
default <code> in <code> <section> <code> is set to a default value whenever <code> returns <code> <section> could just set to the default value within this helper <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_es_syslogreaddata requires synchronization , add _unsync to name <section> <code> requires external synchronization : <url> <section> add _unsync to name to match pattern <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"replace duplicated write to sys log , delay , panic pattern <section> same pattern repeats many times : <url> <section> reduce duplicated code . <section> may get removed per # <number> ( would make this <allcaps> obe </allcaps> ) <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"move file system initialization logic out of cfe , should be set up at lower level <section> related to # <number> , file system initialization does not fit well in the cfe layer : <url> <section> remove / move , should be initialized before getting to cfe <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"document gatekeeper pattern in internal / local resource id inline functions <section> ismatch functions check for <allcaps> null </allcaps> pointer , others do not : <url> <url> <section> document justification behind pattern ( ismatch is used first , then all other ' s are "" safe "" ) <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
add compile - time debug capability to confirm functions that require external global locking are locked <section> various functions require global lock : <url> <section> add a debug capability to confirm appropriate locking <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"simplify loop in <code> <section> while loop with dual break could be simplified : <url> <section> refactor to simplify , possibly for loop on apprecptr . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"clarify / document elements in enums including zero dependence <section> set to zero of first element is redundant with standard , not documented : <url> similar case in fs , where <number> is <allcaps> unknown </allcaps> , should document dependence : <url> note it is documented here , really should do similar elsewhere when it matters : <url> <section> document enums , clarify logic dependence on first entry being <number> ( do not move ) . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
cfe_es_perflogadd blocking behavior - redesign or document <section> cfe_es_perflogadd can block : <url> <section> document behavior / impact / context <section> consider design updates to avoid blocking <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
move perflog prototypes from <code> to <code> <section> misplaced prototypes : <url> <section> move to <code> <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"replace multiline <code> macro with inline function <section> use of multiline macros should be avoided ( per coding standard ) : <url> <section> replaced with inline , or one line macro / inline combo <section> wrap with do { . <repeated> } while ( <number> ) , see <url> <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
correct const in generic memory pool apis <section> cfe_es_genpoolrecord_t pointer should be const : <url> <url> <url> <section> make const <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
improve <code> logic for <code> structure <section> magic number ( fixed bit pattern ) used for <code> in <code> is weak : <url> <url> and related checks against the magic number <section> could use actualsize and 2 s complement ( or even 1 s complement ) of actualsize for memory check . higher odds of catching an issue <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_es_genpoolinitialize : error if alignsize is not a power of <number> <section> <code> handles when <code> is not a power of <number> , but may be more appropriate as an error : <url> <section> analyze , make it an error or document why it ' s ok as - is for future reference <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
task not found case not explicitly handled in cfe_es_runexceptionscan <section> not clear if task not found case is handled correctly : <url> <section> analyze and explicitly handle if needed or document why not needed for future reference <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"add doxygen documentation to internal prototypes <section> missing documentation ( example , but scrub all ) : <url> for the block read / write , need to document requirements on the data pointer ( reads / writes size used when initializing handle ) <section> add documentation ( move from implementation if it exists there ) <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"update the cmake / sample_defs / default_osconfig . cmake to be just overrides / changes from osal / default_config . cmake <section> default_osconfig . cmake repeats many of the settings with the same selection as in default_config . cmake , confusing dependency <section> remove duplication , document in default_osconfig . cmake that it ' s for overriding values in default_config . cmake . <section> none <section> came up when trying to figure out why <allcaps> osal </allcaps> coverage test results were different at the bundle level vs osal level , wasn ' t clear that default_config . cmake was being used and hard to sort out what ' s actually being changed in default_osconfig . cmake <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_es_deletecds : zero out block when freed <section> block not cleared when freed : <url> <section> analyze , clear block if needed or document for future reference why it ' s not needed <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
scrub for appropriate / consistent use of sizeof vs os_max_api_name <section> inconsistent use of sizeof vs hard coded size ( example ) : <url> also local sizing ( example where it could just be sizeof ( cmdptr - > appname ) <sad> <url> <section> use sizeof when char arrays sizes are known <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_es_clearcds : check status before while loop to zero <section> status not checked from cfe_es_cds_cachepreload : <url> <section> analyze , check status if needed otherwise document why not for future reference <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_es_registercdsex : clear block if new allocation is needed but not new block size <section> may need to clear block if a new allocation is needed without a changed block size <url> <section> analyze , clear block if needed <section> if not needed , document why for future reference <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"standardize / clean function description comments <section> they need a general scrub , out of date references , etc . example : <url> should clearly indicate implementations that are <allcaps> api </allcaps> ' s vs internal / helper functions <section> automated cleanup . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"eliminate redundant switch in cfe_es_cleanupobjectcallback <section> redundant switch cases , could be eliminated by setting local status variable in first switch : <url> <section> eliminate redundant switch <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add missing prototypes <section> enable - wmissing - prototypes and observe warnings example identified in code review : <url> <section> add prototype <section> none <section> code reivew , specific case related to # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
refactor long switch in cfe_es_processcontrolrequest <section> long switch could be replaced with table and general logic : <url> <section> refactor <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"resolve signed / unsigned comparison warnings <section> enable - wsign - compare and observe warnings . from code reivew : <url> <section> resolve these <section> none <section> code review , specific case of # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
refactor for logic duplication in cfe_es_appcreate and cfe_es_loadlibrary <section> first part of cfe_es_appcreate : <url> and cfe_es_loadlibrary : <url> duplicate logic <section> refactor to reduce duplication <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"handle case of too many tokens in startup file <section> silently consumes <code> if numtokens = = cfe_es_startscript_max_tokens_per_line : <url> looks like it would just concatenate entries after that point , which could lead to strange errors <section> warn / error / report / abort <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
refactor cfe_es_startapplications startup script processing to reduce duplicated logic <section> could loop for volatile / non - volatile startup script processing instead of two if blocks : <url> <section> refactor <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"replace strlen use with memchr logic for checking valid length <section> strlen is an unlimited search , memchr is limited example case : <url> <section> use memchr instead <section> something similar to os_strnlen ( unfortunately not exposed ) <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor similar <allcaps> es id </allcaps> / info related functions to share common logic <section> very similar pattern in the following sets of apis , consider refactor : - cfe_es_getappidbyname , cfe_es_getlibidbyname , cfe_es_gettaskidbyname - cfe_es_getappid , cfe_es_gettaskid , - cfe_es_getappname , cfe_es_getlibname , cfe_es_gettaskname - cfe_es_getappinfo , cfe_es_getlibinfo , cfe_es_gettaskinfo <section> factor out common logic <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use synchronization mechanism instead of delays <section> synchronization mechanism would be better ( more responsive , etc ) vs delays . in cfe_es_waitforsystemstate : <url> in cfe_es_gettaskfunction : <url> <section> replace delay loop w / synchronization method <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use %s , _func_ for all syslog messages <section> function name copy / paste mistakes and various reporting formats used in <code> and <code> : <url> <section> use a common format <code> <section> could use a macro <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user> - may require test update when checking for specific messages",2.0
"refactor cfe_es_restartapp , cfe_es_reloadapp , cfe_es_deleteapp to use common code <section> logic duplicated in cfe_es_restartapp , cfe_es_reloadapp , cfe_es_deleteapp <section> refactor to utilize common logic <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"refactor / split files ( headers and c ) into smaller topics <section> huge files are harder to manage . example : <url> <url> note also split up old "" task "" pattern : <url> <section> split / refactor into more manageable units . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
resolve strange newline formatting <section> strange newline locations : <url> <url> <url> <section> adjust weighting in format definition ( this would be done in cfs ) <section> reformat comments such that they format cleaner relative to cfs format definition <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
<code> incorrect <section> max <allcaps> eid </allcaps> incorrect : <url> <url> <section> fix . <section> none <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove <code> from function prototypes <section> inconsistently applying extern to function prototypes <section> remove , it makes no difference . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> cfe es </allcaps> memory pool parameter order inconsistent <section> some apis have handle first , some do not , example : <url> <url> <section> make consistent <section> could be i / o based ordering , if so justify as such somewhere ( document typical pattern that can be followed ) <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use <code> for <code> memory pointer <section> other routines use <code> , <code> uses <code> : <url> <section> make consistent <section> maybe there was a reason , analyze and if so document <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"scrub return code names for consistency <section> consistent naming pattern not followed for return codes , example : <url> <url> <section> use a consistent pattern cfe_service_severity_description <section> could create via macro , but obscures ( see # <number> ) <section> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove unused error codes <section> unused ( shell capability moved to stand - alone app ) : <url> last sender id logic removed , error code no longer used : <url> <section> remove <section> none <section> <allcaps> cfs </allcaps> - <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"construct return status codes from defined flags <section> error codes are hardcoded : <url> <section> could construct using defined field values , could utilize macros <section> leave as - is , full definition makes them easier to find from a status message . pattern to comment full value to retain this search capability is fragile . questionable benefit of changing at this point since they are all already defined . <section> <allcaps> cfs </allcaps> - <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
cast <code> to <code> <section> <code> does not match pattern for defining other <allcaps> cfe </allcaps> status returns : <url> <section> cast as <code> <section> document why not <section> <allcaps> cfs </allcaps> - <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
update cmake logic to utilize built in capabilities <section> - could get git_executable from cmake module : <url> - could simplify using <code> : <url> <section> use findgit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
convert table search paths if / else checks to lists <section> long if / else : <url> <section> convert to list <section> none <section> <allcaps> cfs </allcaps> - <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"require definition of <code> <section> cpu_id should be explicitly defined , defaulted here : <url> <section> remove default <section> none <section> from <allcaps> cfs </allcaps> - <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cleanup relative to additional compiler warning flags <section> some projects prefer additional flags that trigger warnings in cfe . current set : <url> possible additions for consideration : - wextra - wmissing - prototypes - wimplicit - function - declaration - wnested - externs <section> analyze , fix what makes sense . <section> not required to add to default list , but should compile cleanly if enabled ( for those that make sense ) <section> from <allcaps> cfs </allcaps> - <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"comments / document cleanup relative to es / resourceid review ( and # <number> ) <section> various cleanup : - document <code> in <code> parameter list : <url> <url> - update parameter list in <code> : <url> <url> - add <allcaps> null </allcaps> termination documentation on config lists ( autogenerated and added via build system ) : <url> - fix order of parameter documentation for <code> : <url> - remove <allcaps> obe </allcaps> child priority comment in <code> , related to # <number> : <url> - improve generic counter documentation ( example , purpose ) , really just a thread - safe counter capability ( suggested at one point for <allcaps> cfdp </allcaps> throttling ) : <url> - fix typos : <url> <url> <url> <url> - add comment that <allcaps> null </allcaps> check is done by cfe_es_getappinfo / cfe_es_getlibinfo : <url> - document load library calls library entry function in es context ( must not halt , etc ) - remove obsolete comments : <url> - replace obsolete comments , generically "" for initializing and starting cfe "" <url> - s / read / printed / <url> <section> fix <section> none <section> from <allcaps> cfs </allcaps> - <number> and # <number> code review <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"deprecate cfe_es_childtaskmainfuncptr_t <section> all es task functions can use cfe_es_taskentryfuncptr_t , do not need separate child typedef see : <url> <section> deprecate <section> could add <code> to be able to spawn with context , trade a single definition vs different for main task / child . <section> code review # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , submitted by <user>",2.0
"define and use a version structure for the cfe / <allcaps> osal </allcaps> / <allcaps> psp </allcaps> reporting in tlm <section> repeated individual majorversion , minorversion , revision elements for cfe / <allcaps> osal </allcaps> / <allcaps> psp </allcaps> see <url> <section> use a common structure . <section> none <section> from code review # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , submitted by <user>",2.0
"use macro in cfe_resourceid_isdefined <section> compares directly to <number> see <url> <section> use macro <section> none <section> code review # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , submitted by <user>",2.0
"remove cfe_resource_osal_compatible . h option and force use <section> not really currently an option , could simplify / clarify by forcing it <section> force use <section> none <section> from code review # <number> , various comments . <section> jacob hageman <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , submitted by <user>",2.0
"cfe_fs_readheader & writeheader api headers state wrong returns <section> in the header api ' s for readheader and writeheader they both say that they return the execution status , however the implementation has them return the size of the file they read / wrote if successful and an error code if not . <section> alex campbell <allcaps> gsfc </allcaps>",1.0
add cfe time current time <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add functional tests for cfe time apis – cfe_time_gettime – cfe_time_gettai – cfe_time_getutc – cfe_time_getmet – cfe_time_getmetseconds – cfe_time_getmetsubsecs <section> n / a <section> n / a <section> alex campbell <allcaps> gsfc </allcaps>,2.0
add functional tests for <allcaps> cfe </allcaps> file header management apis <section> need open source functional tests for certifiability <section> add functional tests for cfe file header management apis – cfe_fs_readheader - read a header . – cfe_fs_initheader - initialize a header . – cfe_fs_writeheader - write a header . – cfe_fs_settimestamp - change the timestamp of a header . <section> n / a <section> n / a <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"update codename to caelum and license header for release , version <number> . <number> <section> development version still has development labeling ( as expected ) . <section> upon official release , update relevant version / license info . <section> none <section> wait until official release <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_psp_gettime conversion to <allcaps> met </allcaps> <section> we have a hardware clock in our system that we plan to use as the source clock for <code> . we also have an <allcaps> fpga </allcaps> system that latches the hardware clock into a register on certain events . we ' d like to read the register value after it ' s latched , and then convert it to a cfs <allcaps> met </allcaps> . does <allcaps> cfe </allcaps> time services already have a routine for converting <allcaps> psp </allcaps> times to mets ? <section> a function that i can pass an old latchclock time value into and get back a valid <code> value . something similar to <code> , but with an additional input that replaces <code> . <section> our primary alternative at this point is to add code to the <allcaps> psp </allcaps> that updates our hardware clock via <allcaps> tatt </allcaps> commands . any other ideas would also be welcome . <section> morgan redfield <email> astrobotic",3.0
module list is duplicated / hard coded so can not be modified <section> part of the intent of modules was to be able to replace them . hard - coding of the module list at : <url> defeats this capability . <section> define the module list in a way it can be modified / customized by configuration . <section> none <section> currently breaks message header customization . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping - <user>,2.0
remove <allcaps> builddir </allcaps> from makefile ( breaks if defined ) <section> <code> fails <section> remove the reference <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"make functional tests runnable via cfe_es_start_app_cc command <section> in the functional test proof - of - concept , the test cases are libraries that are loaded in the startup script , and the "" testrunner "" app actually runs them . but because libraries are not loadable / unloadable via command , it requires a custom startup script , and restarting <allcaps> cfe </allcaps> in order to run tests . <section> the functional tests should be integrated with test runner such that they are each their own app , therefore runnable by simply issuing the es command to start the app if they were not part of the initial startup script . <section> this will simplify the process of running tests on targets , since it will alleviate the need to customize the startup script . the <code> library itself will likely need to remain as a library , because it is a common dependency between all test apps . but it should not hurt to simply load this by default in the sample startup script , it will not interfere with <allcaps> fsw </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"duplicate function in readme <section> in the version history of the readme , it states : > removes the now - unnecessary cfe_sb_zerocopyhandle_t type and all apis that refer or require it . replaces cfe_sb_zerocopygetptr ( ) and cfe_sb_zerocopygetptr ( ) with two new simplified functions cfe_sb_allocatemessagebuffer ( ) and cfe_sb_releasemessagebuffer ( ) , respectively . these new functions do not use a separate handle . updates the cfe_sb_transmitbuffer ( ) <allcaps> api </allcaps> to also remove the handle . does affect public apis . the issue is that the version history is stating that the same function , cfe_sb_zerocopygetptr , is being replaced by two different functions . in reality , cfe_sb_zerocopygetptr was replaced by cfe_sb_allocatemessagebuffer . cfe_sb_zerocopyreleaseptr and cfe_sb_zerocopysend , not cfe_sb_zerocopygetptr , was replaced by cfe_sb_releasemessagebuffer . <section> state that cfe_sb_zerocopyreleaseptr and cfe_sb_zerocopysend , not cfe_sb_zerocopygetptr , was replaced by cfe_sb_releasemessagebuffer . <section> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"remove "" pspconfig "" member in config structure <section> the "" pspconfig "" member does not really serve a useful purpose anymore and should be cleaned up . issue nasa / psp # <number> will remove the <allcaps> psp </allcaps> definition of this structure . <section> this structure also needs to be removed from the <allcaps> cfe </allcaps> <code> object . <section> this is co - dependent with nasa / psp # <number> and needs to be done in the same build cycle . the only remaining reference to this <code> member object is via the cfe_psp_version macro , where the version is printed . this should be replaced with a call to <code> instead . <section> joseph hickey , vantage systems , inc .",2.0
"add group name to doxygen "" close section "" command <section> keeping track of large doxygen sections can be hard . <code> <section> add the section name to the closing comment , similar to what we already do for <code> segments . <code> <section> leave as is",1.0
"incorrect limit check in cfe_es_genpoolvalidatestate <section> a check for the "" numbuckets "" member should be <code> but it is using <code> . <section> attempt to validate poolid <number> which uses the max number of buckets . function returns false , but record is valid . <section> cfe_es_genpoolvalidatestate ( ) should return true if using the max number of buckets ( <number> by default ) . <section> one - liner here : <url> <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
refactor cfe_es_err_buffer to cfe_es_bad_argument <section> most functions return bad_argument when they get a null pointer but a few stragglers still use buffer . <section> they should all be consistent and return the same error . <section> this is something that should have been done for # <number> <section> alex campbell <allcaps> gsfc </allcaps>,2.0
cfe_es_getappid missing null pointer check <section> cfe_es_getappid does not have a null pointer check and seg faults if passed one . <section> call it with a null pointer <section> should return cfe_es_bad_argument <section> ubuntu <number> <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"cfe_assert should use sendevent <section> cfe_assert currently has all it ' s outputs done through cfe_es_writetosyslog which makes them hard to read and failures can get lost in all the noise . <section> cfe_assert could instead send events through the test runner , which would give a lot more flexibility to the output . <section> we just leave it as it is . <section> <url> could then be a further enhancement of this done at a later time . <section> alex campbell <allcaps> gsfc </allcaps>",2.0
"convert functional test startup script example to use "" simple "" filenames <section> do not need directory or extension in <url> <section> simplify <section> none <section> discussed at <allcaps> ccb </allcaps> for # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"redundant check in cfe_evs_earlyinit <section> redundant check : <url> only way to get here is if it ' s already cfe_success <section> remove redundant check , false condition can never execute ( would require returning from the <code> ) <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add generation of branch coverage info to genhtml line ( make lcov rule ) <section> genhtml not reporting / generating branch coverage <section> add <code> to genhtml line in makefile <section> none <section> adds the text summary and info in html <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
potentially uninitialized local variable ( false alarm squash ) - codeql <section> another round of potentially uninitialized local variable squashes . all false alarms but easy to initialized . <url> <url> <url> <url> <url> <url> <url> <section> initialize <section> none <section> static analysis warnings <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_es_copymoduleaddressinfo not working <section> when getting the app info , the addressesarevalid is false . that field is set by copymoduleaddressinfo when it ' s return code is not os_success . <section> steps to reproduce the behavior : call cfe_es_getappinfo see that addressesarevalid are set to false . <section> it should not be setting them to false . <section> ubuntu <number> <section> when called on an external app the return code is successful but addressesarevalid is still <number> . when called on a core app the return code it - <number> invalid id <section> alex campbell <allcaps> gsfc </allcaps>",3.0
"misspelled appname string in tbl cfe_tbl_validate function <section> the cfe_tbl_validate ( cfe_tbl_handle_t tblhandle ) has a misspelling in the appname string "" <allcaps> unknwon </allcaps> "" <section> directly visible in cfe \ fsw \ cfe - core \ src \ tbl \ cfe_tbl_api . c - - int32 cfe_tbl_validate ( cfe_tbl_handle_t tblhandle ) <section> the appname array should be initialized to the same , consistent string ' <allcaps> unknown </allcaps> ' as elsewhere in the code . however in the usual case , the appname would almost immediately be replaced with the valid cfe_es_getappname ( ) value upon passing cfe_tbl_validateaccess ( ) and would not have much impact other than test logging . <section> cfe / fsw / cfe - core / src / tbl / cfe_tbl_api . c <code> <section> noticed on code inspection <section> <section> mark o . schlegel , hammers inc",2.0
"consolidate cfe_psp_get_timebase and cfe_psp_gettime <section> this <allcaps> psp </allcaps> function is not particularly well - documented . on some systems ( pc - linux ) it ultimately returns the value of the <allcaps> posix </allcaps> "" clock_monotonic "" clock from the kernel . but on mcp750 it is calculated from a hardware tick counter that wraps every <number> seconds . there is a bunch of logic in <allcaps> cfe time </allcaps> to handle handle this wrap . <section> the bug is that the background task also samples cfe_psp_gettime but does not check for wrap , which works fine on linux but on vxworks this probably introduces a timing anomaly every <number> seconds when it wraps . this probably is not all that noticeable / serious because the background job will just runs an extra cycle and then resume normal operation , but incorrect nonetheless . <section> background job should sample a clock that is known / defined to be monotonic and has consistent / simpler rollover logic . alternatives could be the <allcaps> osal </allcaps> timebase that drives the 1 hz . however this is not guaranteed to exist on platforms that do not use the <allcaps> rtos </allcaps> for the 1 hz . so it might be necessary to define a new <allcaps> psp </allcaps> function , similar to cfe_psp_gettime , but is defined to be monotonic and has a more well - defined rollover characteristic . then this <allcaps> psp </allcaps> function can just read whatever facility is providing 1 hz signal - <allcaps> rtos </allcaps> / <allcaps> osal </allcaps> , hardware register , or whatever . <section> in particular the code here : <url> this works fine on linux but likely causes an anomaly every <number> seconds on mcp750 when the clock rolls over . <section> found during inspection when looking at other issues . <section> joseph hickey , vantage systems , inc .",2.0
"header guard update to match osal pattern <section> current header guards utilized reserved leading <code> , likely also inconsistent helpful if it also catches endif comment ( typically comments the matching define ) <section> apply <allcaps> osal </allcaps> pattern <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"limit dynamically - obtained version info to tags starting with "" v "" <section> tags may be created in the git repo for a number of reasons , not just releases / prereleases , and it is helpful to have the option of also making an annotated tag too so it can have a real description attached to it . but in that case the tag will be picked up by <code> which is what is used by default for dynamically obtained version info shown at runtime . <section> version tags in the <allcaps> cfe </allcaps> framework and <allcaps> cfs </allcaps> apps all follow the general pattern of <code> . so if the dynamic version info is limited to tags that start with <code> ( maybe also a number to be real specific ) this should effectively make it so extra snapshot tags will not be considered - so long as they do not start with <code> . <section> use annotated tags only for those that should be considered baselines , and only use non - annotated tags for any other snapshots . <section> users can still customize this <code> if they happen to use some other tagging pattern / convention . but all the framework stuff already uses the <code> convention . <section> joseph hickey , vantage systems , inc .",3.0
"update cfe_evs_sendevent calls to use macros introduced in # <number> <section> # <number> introduced cfe_evs_senddbg , cfe_evs_sendinfo , cfe_evs_senderr , cfe_evs_sendcrit macros but did not update code to use them <section> update core to use macros <section> none <section> note some coding standards discourage # # in macros . could go back to original implementation in # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the cfe repo . <section> ariel adams , <allcaps> asrc </allcaps> federal <allcaps> edit </allcaps> - also fixes # <number> ( jh )",1.0
"add contributing guide <section> add a contributing guide for the cfe repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"<allcaps> cfe </allcaps> coverage tests not getting built after re - org <section> after directory re - organization , it is missing the new recipes for building the <allcaps> cfe </allcaps> core coverage tests . <section> build + install with unit tests enabled . everything runs and passes but the <allcaps> cfe </allcaps> core tests are not there . <section> <allcaps> cfe </allcaps> core tests should be there <section> some empty placeholders in place of the real thing ( mistake in original pr ) . <url> <section> ubuntu <number> <section> unfortunately everything in tests + ci runs just fine without this being there , so it wasn ' t immediately noticeable that something was missing . <section> joseph hickey , vantage systems , inc .",0.0
"entry point function name too long <section> when trying to run the cfe test runner i got this error <number> - <number> - <time> . <number> es startup : loading file : / cf / cfe_testrunner . so , <allcaps> app </allcaps> : testrun_app os_genericsymbollookup_impl ( <sad> <number> : error : cfe_testrunner_appm : . / cf / cfe_testrunner . so : undefined symbol : cfe_testrunner_appm <number> - <number> - <time> . <number> es startup : could not find symbol : cfe_testrunner_appm . ec = 0 xffffffff it should be trying to use cfe_testrunner_appmain but is getting truncated at <number> characters . when i shortened the function name it worked fine . <section> <number> . add the start test scripts for the startup test . found here <url> <number> . start it . <section> it should run the tests . <section> ubuntu <number> <section> alex campbell <allcaps> gsfc </allcaps>",2.0
"scrub for include < > vs "" "" use ( < > should be system only ) <section> < > used on non - system header includes . example : <url> <section> full scrub / fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"do not rely on <allcaps> osal </allcaps> software_ ( <allcaps> big </allcaps> | <allcaps> little </allcaps> ) _bit_order <section> these endian - indicator macros are problematic for many reasons as documented in nasa / osal # <number> . the continued presence of these macros in <allcaps> osal </allcaps> came up again in a recent code review . <allcaps> osal </allcaps> will likely stop providing these macros in the next version , because nothing in <allcaps> osal </allcaps> is endian - dependent . <allcaps> cfe </allcaps> only uses these to implement cfe_make_big16 / cfe_make_big32 macros . <section> move the nonstandard logic from <allcaps> osal </allcaps> into <allcaps> cfe </allcaps> , because nothing in <allcaps> osal </allcaps> depends on it . for backward compatibility <allcaps> cfe </allcaps> will likely still have to provide this macro for historical reasons , in case some apps use it , and because <allcaps> time </allcaps> uses those cfe_make_big * macros . <section> see nasa / osal # <number> in <allcaps> cfe </allcaps> the logic should be put in a separate header where it can be confined / limited to the scopes where this is actually used / needed , rather than a ubiquitous header like <code> . this way an <code> directive if the check was inconclusive will make more sense since it will not error out on cases where we do not care ( i . e . most ) . <section> joseph hickey , vantage systems , inc .",2.0
"update directory diagrams in application developer guide <section> after pr # <number> the directory structure diagrams in the user guide are in need of an update . only the text was updated in that pr . <section> diagrams should be updated to match the text . <section> see # <number> <section> joseph hickey , vantage systems , inc .",1.0
"clean up es task / app registration <section> in nasa / osal # <number> it is proposed that <code> be finally deprecated / removed . but this function is invoked by two places in <allcaps> cfe es </allcaps> that follow a similar pattern : <code> and <code> . <section> at a minimum , calls to <code> must be removed to allow the function to be deprecated . furthermore there is already a task startup wrapper in es that can be used to call / handle setting up environment ( <code> ) meaning that these two functions themselves can also be deprecated - basically using the same design pattern as <allcaps> osal </allcaps> uses such that we do not need to burden apps with calling this extra function . this design is simpler and less error prone . <section> see nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
"application performance monitoring and deadlines <section> - when developing a cfs application , i want to detect and correct performance problems as early as possible . - when integrating a cfs system , i want to observe application timing so i can confirm whether system performance matches my expectations . <section> - i would like an easy way to track performance statistics for each cfs application , specifically , last , average and max observed run time . - for systems using <allcaps> sch </allcaps> ( scheduler ) , i would also like enough information to trace in detail _when_ each application starts and finishes so i can compare the system ' s actual timing to the timing that i specified . - i would like all this to be possible without adding special performance instrumentation to the cfs application . <section> here are some ways that cfe ( and cfs ) can measure application performance today : | approach | limitation | | - - - | - - - | | es ( executive services ) task execution counter | tracks # of passes through application ' s main loop . does not track detailed timing information . | | es ( executive services ) performance log | tracks detailed timing information , but must be manually maintained ( started and stopped ) by the application . | | hs ( health & safety ) <allcaps> cpu </allcaps> utilization monitoring | tracks overall <allcaps> cpu </allcaps> utilization . not broken down per cfs application . | | hk ( housekeeping ) telemetry messages published by each application | an application ' s hk telemetry message can measure and report any timing information it wants , but this must be implemented by each application , so it ' s not very consistent ! | as a rule , existing methods are limited in that either ( <number> ) they do not track detailed timing information , or ( <number> ) they require application authors to manually instrument their cfs app and thus are not supported for all apps . <section> any solution must take into account the fact that a typical cfs application spends a lot of time idle , waiting for software bus messages . this means that simply instrumenting the cfe_es_runloop ( ) function will not give an accurate sense of how much <allcaps> cpu </allcaps> time is being consumed by even a simple application such as the sample_app . <code> there are many possible solutions . my suggestion is to make cfe_es_runloop ( ) fire either an event or a sb message signaling that each application has reached the top of its main loop ( i . e . , finished executing ) . because application execution is normally _triggered_ by a wakeup message as well , comparing the timing of the two messages allows measurement of application execution time . <code> a "" statistics tracking "" application could subscribe to both messages , compare their timings , and calculate / report any statistics desired , such as last , average , and max observed run time . outsourcing calculations to an app means they can be easily customized or disabled per mission without modifying cfe . <section> i am fond of this particular implementation because it easily enables another feature : application deadlines . a deadline is an execution time bound triggering a configurable action . it can also be thought of as a "" software watchdog "" . deadlines are important because they allow unexpectedly long - running applications to be rapidly detected and can help mitigate the timing impact of such applications on the rest of the system . today , the closest analogous feature is hs ( health & safety ) application monitoring of the es task execution counter . this only detects applications that get "" stuck "" for a long time . also , hs only monitors counters for liveness and does not check that they are incrementing at the expected rate . here is my suggested way to implement deadlines . the scheduler ( <allcaps> sch </allcaps> ) application assigns each scheduled app a deadline of configurable length l . if <allcaps> sch </allcaps> sends the application a wakeup message at time t , it will expect to receive the application ' s runloop ( ) message by time t + l . when the deadline is reached , if the application is not done , <allcaps> sch </allcaps> fires a schedule overrun event . the event can be caught and used by hs ( health & safety ) or some other application . <code> note : i have presented a lot of detail here . i am not tied to any of the details . my goal is to present a starting point for further discussion of whether these features are useful , and for any resulting implementation to be consistent with cfs ' s architecture . <section> peter fidelman - blue origin these ideas were originally presented during a talk at flight software workshop <number> ] ( <url> ( [ slides <url> .",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for cfe or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing cfe or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / cfe is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / cfe while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement single endianness handling pattern <section> multiple ways to handle target endian in various contexts : fsw / cfe - core / src / es / cfe_es_perf . c : cfe_es_setupperfvariables - determines it at runtime fsw / cfe - core / src / tbl / cfe_tbl_internal . c : cfe_tbl_readheaders - determines it at runtime fsw / cfe - core / src / tbl / cfe_tbl_task_cmds . c : cfe_tbl_dumptofile - determines it at runtime fsw / cfe - core / src / fs / cfe_fs_api . c : cfe_fs_readheader ( and many other functions in here ) - determines it at runtime fsw / cfe - core / src / inc / ccsds . h has macros for conversion ( cfe_make_big <wink> who ’ s implementation depends on software_big_bit_order there ’ s an endian flag in the <allcaps> ccsds </allcaps> header osal / src / os / inc / common_types . h defines either software_little_bit_order or software_big_bit_order based on <number> possible defines cfe / cmake / sample_defs / cpu1_platform_cfg . h defines cfe_platform_endian as either ccsds_little_endian or ccsds_big_endian , and also has a separately configurable cfe_platform_time_cfg_bigendian <allcaps> ccsds </allcaps> extended header has an endian bit then there ’ s all the different ways the various defines are used and custom swapping routines , examples : <url> <url> <url> note some cfe_endian . h macros evaluate <code> multiple times . <section> see <url> for a compile time suggestion : <hashtag> define </hashtag> is_little_endian ( ( ( union { unsigned x; char c ;}){ <number> } ) . c ) <section> none <section> triggered from email discussion on setting another endian flag in a toolchain file for an app to use <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping - <user> <user> <user>",2.0
"possible negative char to isspace - static analysis warning <section> in theory a negative value could reach this code through public apis , which would lead to undefined isspace behavior as it gets converted to int . <url> <section> recommended practice is to cast to <code> , such that the conversion to <code> results in defined behavior . <section> could adjust all the parameters involved to <code> , but probably not worth it . <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update / resurrect the add_unit_test_lib / add_unit_test_exe functions <section> currently the <code> functions provide a routine to easily define a <allcaps> cfe </allcaps> app : <code> . this makes it easy for app developers to create an app target that uses all the right compiler definitions , include dirs and link / interfaces libraries . furthermore , having this wrapper in <allcaps> cfe </allcaps> helped future - proof so that apps did not need to change this call when # <number> was implemented . the problem is that we did not employ the same tactic for unit tests . for these , all the special logic for adding flags / includes is basically put into the cmakelists . txt in each app where the ut targets are defined . <section> the <code> does have a <code> and <code> function that was originally intended for this purpose , but these were never really used . we should implement the basic ut logic here and change sample app / lib to use them . <section> currently , the sample_lib / sample_app unit tests break when merging with # <number> because of the different paths and the transition toward interface libraries . rather than just updating these ut builds to work again , using these functions would help avoid this issue in the future . <section> joseph hickey , vantage systems , inc .",2.0
"report <allcaps> psp </allcaps> version info in <allcaps> es hk </allcaps> telemetry <section> currently the <allcaps> es hk tlm </allcaps> message includes the <allcaps> cfe </allcaps> and <allcaps> osal </allcaps> versions , but not <allcaps> psp </allcaps> . also , as noted in nasa / osal # <number> , using preprocessor macros to get <allcaps> osal </allcaps> / <allcaps> psp </allcaps> version info means its evaluated when <allcaps> cfe </allcaps> source code is compiled , and the result actually compiled into <allcaps> cfe </allcaps> . <section> add <allcaps> psp </allcaps> version info to <allcaps> hk tlm </allcaps> . also <allcaps> cfe </allcaps> should use the runtime <allcaps> api </allcaps> to get the version info , such that the info actually comes from the <allcaps> psp </allcaps> / <allcaps> osal </allcaps> library , respectively . <section> see also nasa / cfs # <number> <section> joseph hickey , vantage systems , inc .",2.0
missing requirement for default file name : es task status record to file ( <allcaps> cfe </allcaps> - <number> ) and <allcaps> cds </allcaps> write to file ( <allcaps> cfe </allcaps> - <number> ) requirements needs update to verify dumping executive services task status record and critical data store to a default file name . justifcation : want to provide a default in the event a user does not want to specify one,1.0
"cast vs mask to alter value in cfe_msg_setmsgid v1 - static analysis warning <section> in current implementation of cfe_msg_setmsgid for v1 uses a cast to alter a value : <url> <section> probably more obvious to mask , which would squash static analysis warnings <section> leave as - is <section> static analysis warning , cast alters value <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_time_print possible improvements <section> cfe_time_print does not take a buffer size such that the write to the buffer can be limited , also "" clunky "" implementation to write to the buffer . <section> use snprintf ? consider new <allcaps> api </allcaps> that includes buffer size ? <section> none . <section> could be part of more significant <allcaps> time </allcaps> refactor - # <number> there is a strange static analysis warning on the null character addition that would go away , but somewhat unrelated . <section> full name and company / organization if applicable",2.0
"question : difference between writetosyslog or sendevent hi , i was reading through the application developers guide and i read "" _developers should make use of the event services cfe_evs_sendevent whenever possible . if , however , there is a significant event that cannot be recorded using the cfe_evs_sendevent function , then the developer can use the cfe_es_writetosyslog function . _ "" i was wondering what difference does it make if i use writetosyslog or sendevent if my main goal is to print something to the terminal ? can i just always use writetosyslog ? thanks !",3.0
"coercion alters value caused by incorrect type - static analysis warning <section> cfe_tbl_findtableinregistery returns int16 , regindex is defined as uint32 and only checked for error ( negative ) <url> the last parameter passed to cfe_es_filewritebytecnterr for both uses is status ( int32 ) , yet it expects size_t . <repeated> seems like this is not defined correctly ? <url> <url> <url> not a bug , just an inconsistency warnings <section> correct type <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add documentation build to submodule github actions workflow <section> build cfe documentation at the component level instead of waiting for a bundle - level build this ensures we catch doxygen errors in individual prs as opposed to having to fix them after the pr is merged <section> have users check their prs manually <section> see documentation build example in bundle,2.0
"argument checks in internal functions ( cfe_sb_transmitmsgvalidate , etc ) <section> as discussed in # <number> we need to have some consensus on the proper level of argument checking for internal helper functions . sometimes internal functions have tests to validate their inputs ( range check etc ) on behalf of the caller , in the case where several public apis need to repeat the same tests - - putting these in a helper can reduce repeated code and make all apis consistent in their validation ( a good thing ) . but in other cases the helper is invoked from contexts where the inputs are never out of range or pointers can never be <allcaps> null </allcaps> . testing for such inputs can be redundant . <section> need to confirm / reach consensus on whether functions like cfe_sb_transmitmsgvalidate ( ) in <allcaps> cfe sb </allcaps> need to validate all their arguments . probably should better document _which_ args are tested and _why_ - and if there are limitations on other args ( e . g . certain args are assumed to be non - null ) . <section> this just causes some confusion during review and probably some additional comments / documentation could help . see thread here : <url> <section> joseph hickey , vantage systems , inc .",2.0
"evs_generateeventtelemetry does not handle vsnprintf error cases <section> vsnprintf can return negative error values , but is compared to unsigned int to handle truncation : <url> i would not call this a bug ( will just pass the initialized to zero string ) , but might be worth a unique message ? <section> explicitly handle failure ( and cast for comparison ) <section> place termination character at the start ? any other way to provide clues . <section> static analysis warning for coercion alters value . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_es_checkcounteridslotused does not handle error case ( <allcaps> null </allcaps> dereference ) - static analysis warning <section> cfe_es_checkcounteridslotused - > cfe_es_locatecounterrecordbyid can return <allcaps> null </allcaps> , and cfe_es_counterrecordisused dereferences <url> <url> <url> <section> handle null <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_sb_getuserdatalength possible uninitialized variable ( false alarm ) <section> cfe_sb_getuserdatalength use of totalmsgsize causes static analysis warning . false alarm since msgptr is checked before cfe_msg_getsize , and & totalmsgsize will never be <allcaps> null </allcaps> , so it ' s always set . <section> initialize to <number> to squash the warning . <section> still dislike this function . <repeated> do not use it . <section> # <number> , static analysis warnings <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"possible uninitialized variables - compiler warnings ( release build , centos <number> ) <section> various warnings on centos <number> when <allcaps> buildtype </allcaps> = release : <code> <section> initialize variables where needed <section> none <section> compiler warnings , vs static analysis warnings reported in # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"long switch cases - static analysis warning <section> the following cases trigger a long switch case static analysis warning . <number> . consider moving to a command processing function , or possibly use the command table pattern ( and break up command processing routines into files ) like tbl . <url> <url> <url> <number> . extensive logic in a case , may benefit from being in a function : <url> <section> analyze , possibly refactor . <section> there ' s more logic required to implement the table pattern , so definitely debatable as to the preferred fix . <section> i thought we had an issue to make command processing consistent ( tbl vs everything else ) but can not find it . falls more into the nice to have / refactor bucket so not targeting caelum ( unless someone wants to volunteer ) . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"createpipeerrorcounter only incremented for cfe_sb_cr_pipe_bad_arg_eid or in cfe_sb_deletepipefull <section> createpipeerrorcounter logic does not seem to make all that much sense since it ' s only incremented for one error case , and also incremented as part of deleting a pipe . note the trivial switch below is a static analysis warning , might be more appropriate to count warnings for more cases : <url> <section> trace design to requirements , confirm current implementation makes sense . <section> none <section> uncovered due to static analysis warning , any change will be easier after # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"useless assignments / redundant checks - static analysis warning <section> useless assignments since fileopened is initialized to false ( or already checked for false ) : <url> <url> initialized to zero , then set to zero : <url> already memset to <number> : <url> already checked for numblocksizes . cfe_platform_es_pool_max_buckets <url> already cfe_success : <url> <section> remove . <section> none , useless assignments in the name of future - proofing is a slippery slope . to some ( like me ) these useless assignments make me thing the implementer did not fully understand the implemented logic , was sloppy / careless , or added useless logic "" just in case "" . <section> wait for # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"possible uninitialized variable ( false alarms ) - static analysis <section> all false alarms based on logic , but easy to squash ( just initialize ) . this one could be avoided w / simple refactor ( move success logic into if ) which reduces to one return location ( preferred coding style ) : <url> just initialize : <url> <url> <url> likely resolved if os_opencreate_t initialized the file descriptor on failure : <url> <url> <url> <section> see above <section> none <section> codeql warnings , wait until # <number> is resolved <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"user guide doxygen cutting parts out <section> there are parts of the user guide that when formatted by doxygen are causing parts of the content to get cut out and not included . i happened to find one but imagine there are others . <section> the one example i found was on page <number> for <number> . <number> cfe_tbl_register ( ) the tbloptionflags is missing the last <number> sentences of cfe_tbl_opt_critical . the user guide says • cfe_tbl_opt_critical - when this option is selected , the table service will automatically allocate space in the critical data store ( <allcaps> cds </allcaps> ) for the table and insure that the contents in the <allcaps> cds </allcaps> are the same as the contents of the currently active buffer for the table . this option is mutually exclusive of the cfe_tbl_opt_usr_def_addr and cfe_tbl_opt_dump_only options . it should also be noted that the <section> no information should be lost by doxygen formatting . <section> <url> <section> - adobe acrobat reader <number> <section> alex campbell <allcaps> gsfc </allcaps>",1.0
"es globals need cleanup <section> the es core app is quite disorganized in terms of its internal headers ( what defines what ) and global data structures . in particular there are three global data objects in this module . <url> <url> <url> <section> make a single <code> object as was done for other apps in pr # <number> . further clean up / re - org the internal headers to create a more logical / consistent content would be nice . <section> joseph hickey , vantage systems , inc .",2.0
"alternate condition impossible to exercise - static analysis <section> impossible to hit alternate case ( even considering reconfiguration ) : status is always >= cfe_platform_tbl_max_sngl_table_size ( line <number> ) since it ' s checked at line <number> : <url> numblocksizes > cfe_platform_es_pool_max_buckets is always false on line <number> since it ' s checked on <number> : <url> eventid can never be <number> and regname can never be <allcaps> null </allcaps> , if it was it would be a bug . this sort of thing ( preventing a developer from introducing a bug with logic in production code ) is better prevented via good unit test design . if a case is added it should check the event . <url> <section> remove cases where an alternate condition can not be exercised - a step closer to being able to do mc / dc coverage - remove unnecessary logic <section> occasionally considered "" future proofing "" but developers should never depend on a condition being tested twice when modifying code . <section> triggers codeql warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"mission version cfe_mission_rev description out of date <section> <url> mission version was removed from config file , it ' s intended for identifying mission custom changes to the "" delivered "" fsw , <allcaps> not </allcaps> to cover changes in the configuration file . <section> clarify use of mission version in documentation . <section> none <section> # <number> , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"implement "" cfe_es_getversion ( ) "" function <section> as in nasa / osal # <number> it is preferable to obtain version strings via an <allcaps> api </allcaps> call rather than as a macro , because of how / where it is evaluated . <section> implement <allcaps> api </allcaps> calls that return the version strings currently defined as macros in <code> <section> see nasa / osal # <number> . <section> joseph hickey , vantage systems , inc .",2.0
replace ut_stub_checkforcefail with ut_stub_checkdefaultreturnvalue <section> see nasa / osal # <number> <section> update to use new name <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"refactor "" target_config . c "" logic to avoid <hashtag> include </hashtag> of data fragments <section> the content of the various <allcaps> configdata </allcaps> global data structures is dynamically generated from a combination of build scripts , some which run at prep / generation time and some which run at build time . the pattern currently used here is that the scripts generate "" fragment "" data files that only contain the dynamic content , without any c declarations or any other syntax . this is then paired / combined with the <code> file which is a regular version - controlled file that has the basic structure and declarations ( i . e . all the non - dynamic bits ) and uses <code> to pull in the data fragments where needed ( i . e . a "" fill - in - the - blank "" approach ) . this works well but there are some rules against using the <code> directive with anything other than an normal / conventional fully formed c header file ( i . e . it has <code> extension , fully self contained , syntactically correct , standalone , include - able by any c source file at will ) . so a "" dynamic data fragment "" file which is implemented here does not meet the criteria . <section> have the build system generate fully - formed source files before passing to c compiler in some way . currently evaluating / considering several approaches or combination thereof . <number> . put more of the non - dynamic "" c "" content ( structure ) into cmake <code> templates , generating a separate but fully - resolved . c source for each object that has dynamic content . <number> . pass the file through another explicit macro - processing step ( such as c preprocessor or m4 ) before compiling ( basically introduce another layer of indirection ) to generate a final file . either way the result should be a fully formed . c / . h file without any <code> in its body - as all data items should be "" filled in "" already - which is then built and linked as the current file is . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , remove deployment guide reference <section> fix # <number> - removes deployment guide reference from cmake / <allcaps> readme </allcaps> . md partially addresses # <number> ( removal of deployment guide reference ) <section> n / a - readme update only <section> none <section> n / a <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"question : where is the cfs deployment guide ? <url> says "" for a more in - depth guide and specific examples , see appendix a of the cfs deployment guide . "" i have searched for the cfs deployment guide and cannot find it . has the name changed ? where is it now ?",0.0
cfe_mission_es_max_shell_cmd and cfe_mission_es_max_shell_pkt no longer used <section> cfe_mission_es_max_shell_cmd and cfe_mission_es_max_shell_pkt are no longer used anywhere . <section> since they are no longer used they should be removed . <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"commands using files should utilize new filename parser <section> issue # <number> + pr # <number> introduces a new fs utility <allcaps> api </allcaps> to parse a filename which is aware of the expected path and extension , and will default to these if unspecified in the input . the initial pr only applies it to es startup script . but this creates an inconsistency ; now you can put just a basename e . g . <code> in the startup script , but passing the same string as the filename to <code> command will __not__ work , which does not seem right . <section> for consistency in operation <allcaps> cfs </allcaps> should also employ the same filename parser in all commands that accept a filename . <section> it is ( intentionally , by design ) fairly trivial to update a current call to <code> to use the filename - aware alternative instead . the only minor issue / concern is that the new function has more input validation than <code> does , so it is more important to check the return status . so doing this generally introduces another check + path to generate the error event , so a ut test case needs to be added . but that ' s about it . <section> joseph hickey , vantage systems , inc .",2.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add format check to workflow <section> no indication of software format non - compliance on pull requests <section> add format check to workflow <section> none <section> see # <number> for applying the standard formatting <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"default file name for task info is too long <section> the default filename for the task info file is defined here : <url> the filename portion of the string - "" cfe_es_task_info . log "" - is exactly <number> chars , and <code> is also <number> chars , so it fails the max length test - because it needs to be less than the max for the <allcaps> nul </allcaps> char . <section> build with default config , issue cfe_es_query_all_tasks_cc command with no filename - which causes it to use default . observe error about failure to create file - error code <code> . <section> defaults should work . <section> ubuntu <number> <section> the prefix <code> is <number> chars by itself . a simple fix would be to trim this back to just <code> . would recommend changing all the default filenames for consistency . er log is already just <code> ( no es ) . <section> joseph hickey , vantage systems , inc .",0.0
"auto increment sequence on <allcaps> cmd </allcaps> packets <section> the <code> function has a boolean parameter to indicate if the sequence number should be incremented automatically based on the route . this route - based sequence number overrides whatever was in the buffer . however , this only works on telemetry packets . there is a test that checks specifically if the packet is <allcaps> tlm </allcaps> , and only updates the sequence number if so . this means that all locally - generated messages of the "" <allcaps> cmd </allcaps> "" variety - which includes the various <allcaps> time </allcaps> messages e . g . 1 hz , and all "" send_hk "" packets generated by <allcaps> sch </allcaps> - always have a sequence number of <number> in their header . <section> the sequence number should probably be valid on all these - otherwise there is no way to tell if a message was missed . <section> it is not clear why only locally - generated <allcaps> tlm </allcaps> packets would have a valid sequence , but not locally - generated <allcaps> cmd </allcaps> packets . note sch_lab currently calls <code> with the value set <code> - - so this would have to change too in order to get valid sequence numbers in send_hk packets . <section> joseph hickey , vantage systems , inc .",2.0
"consider simplifying the zero - copy <allcaps> sb api </allcaps> <section> after some refactoring in pr # <number> the whole <code> has become somewhat extraneous - there is no extra handle / descriptor for a zero copy buffer - they are all the same , and this simply refers to the same buffer descriptor now . <section> the <allcaps> api </allcaps> can be simplified and this extra handle removed . the buffer content pointer is good enough to reconstitute the descriptor pointer ( fixed offset ) . <section> leave <allcaps> api </allcaps> as is ( backward compatible , just a little more complex than it needs to be ) . <section> this will affect public apis - cfe_sb_zerocopygetptr , cfe_sb_zerocopyreleaseptr , cfe_sb_transmitbuffer . ( cfe_sb_zerocopysend and cfe_sb_zerocopypass are affected but already deprecated ) . <section> joseph hickey , vantage systems , inc .",2.0
"remove use of hk parameter ( logenabled ) in <allcaps> evs </allcaps> control logic <section> <code> is used in logic , discouraged pattern ( tlm data used for control ) <section> simplify the logic <section> none <section> # <number> , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove cfeesugshellsrv section of users guide <section> es shell command removed , documentation outdated . <section> clean documentation : <url> and all references ( fix next / prev ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , update workflow action badge <section> fix # <number> - remove travis ci badge and add the static analysis badge to <allcaps> readme </allcaps> <section> added and confirmed it worked on branch ( set custom to fork and branch , forced a timeout failure , confirm badge showed failure ) <section> updated badge on <allcaps> readme </allcaps> <section> ci <section> <allcaps> tbd </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <section> full name and company / organization / center of all contributors ( "" personal "" if individual work ) - if <allcaps> nasa </allcaps> civil servant employee or <allcaps> gsfc </allcaps> contractor on <allcaps> ses ii </allcaps> - address / email / phone and contract / task information ( if applicable ) must be on file - else if company - <section> company <allcaps> cla </allcaps> must be on file ( once per release ) : company <allcaps> cla </allcaps> <url> - else if individual - <section> individual <allcaps> cla </allcaps> must be on file ( once per release ) : individual <allcaps> cla </allcaps> <url>",1.0
update <allcaps> readme </allcaps> badges for workflow actions <section> badge in readme still shows travis results <section> update to reflect action status <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
add timeout to actions in workflow <section> default timeout is <number> minutes which is unnecessary and could exhaust allocations . <section> add a timeout in workflows <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
""" pipename "" is unset for debug event <section> mistake in previous pr # <number> where the <code> buffer is used to send a debug event on success but it is only set to a value on failure . <section> enabled debug events , and "" subscription rcvd "" events do not have a valid name . <section> need to get name in all cases , not just failure . <section> ubuntu <number> <section> my preference would be to only print the id in a debug event , as its faster and it saves the work of copying the name since most of the time debug events are turned off anyway . but a "" quick fix "" that does not change the format is to just move the line . <section> joseph hickey , vantage systems , inc .",0.0
cfe_es_writetosyslog stub write to utdebug <section> cfe_es_writetosyslog stub is not informative when debugging <section> add debug output in cfe_es_writetosyslog stub <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update <allcaps> evs </allcaps> optional log requirements ( no longer optional ) <section> the following are listed as <allcaps> optional </allcaps> , # <number> /# <number> removes the option : cevs3013 - <allcaps> evs </allcaps> : clear local event log cevs3014 - <allcaps> evs </allcaps> : set event logging mode cevs3015 - <allcaps> evs </allcaps> : write local event log to file cevs3016 - <allcaps> evs </allcaps> : write local event log order cevs3018 - <allcaps> evs </allcaps> : housekeeping message cevs3108 - <allcaps> evs </allcaps> : store message in event log cevs3108 . <number> - <allcaps> evs </allcaps> : store message in event log - set full flag cevs3108 . <number> - <allcaps> evs </allcaps> : store message in event log - increment overflow counter cevs3108 . <number> - <allcaps> evs </allcaps> : store message in event log - log full behavior cevs3202 - <allcaps> evs </allcaps> : initialize full flag to false on power on reset cevs3203 - <allcaps> evs </allcaps> : initialize logging mode on power on reset cevs3207 - <allcaps> evs </allcaps> : preserve event log reset mode on processor reset cevs3208 - <allcaps> evs </allcaps> : preserve log full state on processor reset cevs3210 - <allcaps> evs </allcaps> : preserve log overflow counter on processor reset <section> update requirements , not optional . <section> none <section> note once services transition to modules (# <number> ) , custom implementations could replicate <allcaps> evs </allcaps> w / o a log if really needed . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"apply style formatting ( release candidate prep ) <section> code has diverged from automated style . <section> apply automated style formatting . <section> none <section> suggest adding as a check in workflow until release . style has been very stable , should be manageable to enforce at least in the short term ( release candidate and release prep ) . could enforce just on rc branch ( es ) if there ' s an issue w / general enforcement . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update ces1007 . <number> and ces1008 . <number> , reload / restart non - param error does not increment command err counter <section> non - command parameter errors ( errors within the object files ) do not increment the command error counter since the command is processed as a request that happens later ( takes time to execute ) ces1007 . <number> : if the cfe application restart fails due to a non - parameter error , then the cfe shall delete the application , <section> , and generate an event message . ces1008 . <number> : if the cfe application reload fails due to a non - parameter error , then the cfe shall delete the application , <section> , and generate an event message . <section> update the requirements . <section> more complex command error handling ( delay the success increment ) . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"cfe_sb_default_qos exposed globally , with internal defaults , passing structure by value <section> cfe_sb_default_qos is extern from cfe_sb . h ( so any code including cfe_sb . h could change it ' s value ! <sad> <url> but the defines are "" internal "" to sb : <url> also structure passed by value : <url> there is no underlying implementation , so currently just a placeholder in the <allcaps> api </allcaps> . <section> possibly convert to bits in a uint32 / <number> or similar ( structure is overkill ) , provide default and the other values publicly as defines , do not expose as a global variable . <section> none <section> found when working # <number> , it ' s out of family since it ' s not at task global scope . <section> jacob hageman",0.0
"custom pipe message limits without requirements or justification <section> expectation is to use defaults unless there ' s a requirement / justification to have custom limits . there is neither for the code snips below , and no clear reason why the default limits are not good enough ( they should be fine ) . <url> <url> <url> <url> note for all but <number> case , the message limit value set is the same as the default ( <number> ) . <section> either justify these differences or just use the default subscribe call . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
calculate crc can not return error code <section> calculate <allcaps> crc </allcaps> returns a uint so any error code you use gets overloaded . <section> be able to handle errors <section> was found while working on # <number> <section> alex campbell <allcaps> gsfc </allcaps>,0.0
"cfe_sb_snd_rtg_eid and cfe_sb_snd_rtg_err1_eid used for all three write file cmds ( route , map , pipe ) <section> event id ' s should be unique , these are not . <section> define event id ' s for all three . also worth a general scrub of event id ' s to ensure they are unique . other considerations : - "" <allcaps> snd </allcaps> "" is a misnomer , these are write commands - there is no event for the file header error <section> none <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es header prototypes for nonexistent functions <section> some old / stale prototypes in <code> are here : <url> these functions are not implemented - there is no definition to go along with these prototypes . <section> remove these - should not prototype functions that are not defined . ( obviously not being called by anything ) <section> noted this when reviewing other nearby changes . <repeated> <section> joseph hickey , vantage systems , inc .",0.0
"split "" resourceid "" type into a separate module <section> the <code> type is currently defined by es , but in issue # <number> and pr # <number> this was extended to be used by sb . there is also a potential to use it for <allcaps> tbl </allcaps> handles as well . there is also some choice here - in that the <code> type can be a simple typedef to <code> for compatibility , or a type - safe wrapper to make sure it does not get mixed . <section> put the type definition and associated access functions / macros / constants into a separate <allcaps> cfe </allcaps> module , like <code> and <code> are currently done . this gets it out from being an "" es "" type , extending it apply to all of <allcaps> cfe </allcaps> core and possibly also apps . <section> this also can incorporate a solution for # <number> - each app may specialize the generic type with its own typedef . <section> joseph hickey , vantage systems , inc .",2.0
"confirm no recursive locking and transition to fast mutex use <section> currently using recursive mutexes due to historical double locks ( see # <number> ) . could use more efficient fast mutexes after confirming all recursive locks have been removed . <section> survey for recursive locks , remove any remaining , and transition to fast mutexes . <section> none <section> # <number> was solved by # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"reduce memory use with <allcaps> mission </allcaps> defines to size tlm vs <allcaps> platform </allcaps> defines for internal table use <section> spawned from # <number> discussions where the point was brought up that <allcaps> platform </allcaps> defines could be used to size internal arrays for tracking ( for example <code> and <code> ) and <allcaps> mission </allcaps> defines could be used for sizing tlm ( so all platforms have the same packet definitions ) . <section> trade the additional requirements / complexity vs memory savings . consider requirements / design / implementation updates . if required , identify prime stakeholder and resources to implement . <section> leave as is where the mission maximums are used for both tlm and internal sizing ( current state meets current requirements ) . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update highest valid msgid documentation and verification <section> <code> description is out of date based on routing module ( with option for hash ) : <url> verification is also based on direct map : <url> <section> update documentation . consider checking that <code> < <code> since the invalid msg_id is set to the maximum value . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <user>",0.0
"suppress format - truncation warnings <section> it ' s only triggered when length limited * printf functions are used , and that ' s why we use them in the cfs context ( to truncate as needed ) . <section> add <code> to default flags , users can customize the flags as needed if they want to see these warnings . <section> up to this point we have been implementing ways to suppress the individual warnings , but that just adds complexity where the point is to truncate when needed . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"possible race conditions in sb pipe operations <section> as part of debugging # <number> recently , it was noted that several historical sb apis are not adequately locking the global data structures that they access . in particular during pipe operations and subscription / unsubscription , some functions are accessing the "" cfe_sb_piped_t "" objects ( pipe descriptors ) in the <code> and routes in the routing table outside any sb shared data lock , or are not maintaining the lock from start to finish . it is therefore possible that another task can modify this data while being accessed by another task . <section> not actually observed "" in the wild "" - this was found by code inspection . to manifest this would require running <allcaps> cfe </allcaps> on a multi - core system where task ( s ) were actively subscribing / unsubscribing or creating / deleting pipes _at the same time_ . <section> all sb global data access should be protected against any possible concurrency issues . <section> some examples of potentially affected routines / operations in older <allcaps> cfe </allcaps> versions ( these are observed in <allcaps> cfe </allcaps> <number> , just a quick skim though - this should <allcaps> not </allcaps> be considered an exhaustive / complete list ) : - cfe_sb_enableroutecmd ( ) / cfe_sb_disableroutecmd ( ) - accesses pipes and routes with no lock - cfe_sb_deletepipefull ( ) - locks initially , but releases lock in the middle of "" destptr "" loop to do unsubscribe , which could possibly also release another task that also accesses the same pipe or change routing ( i . e . changing the same list ) . - cfe_sb_getpipename ( ) - accesses pipetbl without lock - cfe_sb_subscribefull ( ) - when sending the final "" subscription report "" telemetry message , this is actually stored a global , filled while locked , but actually _sent_ after unlock . there is a possibility between the unlock and the send that another higher - priority task will do a subscribe and overwrite the message . <section> n / a <section> during "" steady state "" operations where the routing table is not being changed , there is not much risk , as normal sending / receiving of messages does not actually modify the data in the routing table . <section> joseph hickey , vantage systems , inc .",0.0
"customizable <allcaps> crc </allcaps> algorithms <section> it would be useful to be able to customize which <allcaps> crc </allcaps> algorithms are being implemented in cfe_es_calculatecrc . <section> instead of using a hard - coded lookup table , a user can set a few variables in a configuration file that describes the desired algorithm . on initialization of cfe_es , the lookup tables can be generated based on the configuration variables . i have attached a couple snippets of code to demonstrate a potential implementation . the <allcaps> crc </allcaps> algorithm variables are set in sample_mission_cfg . h . the lookup tables are generated in an initialization function that can be called when cfe_es initializes . <section> the example <allcaps> crc </allcaps> algorithms i used come from here ( <url> the <allcaps> crc </allcaps> - <number> algorithm is currently implemented in cfe_es_calculatecrc . <section> mathew mccaskey hx5 / <allcaps> nasa </allcaps> - <allcaps> grc </allcaps> regenerative fuel cell project snippets . zip <url>",2.0
"update <allcaps> crc </allcaps> algorithm documentation <section> it would be useful to update the documentation in cfe_es_calculatecrc function to include information on the <allcaps> crc </allcaps> algorithms used , specifically <allcaps> crc </allcaps> - <number> as that is currently the only one implemented . <section> include the following information that describes the crc16 algorithm - name : <allcaps> crc </allcaps> - <number> / <allcaps> arc </allcaps> - polynomial : 0x 8 0 0 5 - initialization : 0x0 0 0 0 - reflect input / output : true - xorout : 0x0 0 0 0 <section> while the specific algorithm has several aliases ( some listed here <url> this at least provides enough information for one to recreate the lookup table / perform their own sanity checks on the <allcaps> crc </allcaps> calculations . <section> mathew mccaskey hx5 / <allcaps> nasa </allcaps> - <allcaps> grc </allcaps> regenerative fuel cell project",1.0
"inconsistent pipe id reporting in sb events <section> as a follow on for issue # <number> / pr # <number> - i noticed that the format strings of many sb event texts are not consistent , particularly with respect to pipe ids . some print the pipe name , whereas some just print the id . there is also a debug event that gets generated whenever <code> runs , which means that for events that print the name , they actually generate _two_ events in the event log - which clutters things up . should be a rule of thumb that we should avoid generating more / different events in the process of generating an event - aside from being confusing it can also snowball . <section> only print the pipe ids , not names . , and use a consistent pattern / conversion ( i recommend hexadecimal / <code> conversion for resource ids as it clearly reveals the table index in the lower <number> hex digits ) . getting names at runtime is not totally trivial - there is <allcaps> cpu </allcaps> time to copy the string , and memory to store the name - and it makes all <allcaps> api </allcaps> functions that much more complex . but as long as the ids are in the event text , the names can be looked up later after the fact by dumping the pipe stats to a file . ( assuming that # <number> is fixed too ) . it ' s just faster and easier and keeps the implementation simpler . <section> the previous pr attempted to keep the event text the same as it was whenever possible , but this should be considered as a follow - on to clean up and simplify . <section> joseph hickey , vantage systems , inc .",2.0
"incorrect loop bounds in ut_checkeventhistoryfromfunc <section> incorrect check for events in unit test code in <code> helper routine . the event storage is an array of event ids ( <code> ) but stored in a generic byte buffer . this forgets to divide the <code> ( which is in bytes ) by <code> when reading this , so it ends up checking double the number of entries it is supposed to . after fixing this issue , it also exposes that some tests in <allcaps> tbl </allcaps> unit tests are also broken . <section> found by inspection . <section> should check the correct number of events . <section> loop at issue is here : <url> <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
clean up strncpy use <section> still occasionally using hardcoded defines for the character array length . better to use sizeof to simplify maintenance . also not always setting last character null . example : <url> . <repeated> <url> <section> use sizeof . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"hard lockup if user attempts to start library via cfe_es_start_app_cc <section> a hard lockup occurs if a user attempts to start a library with a stack size of <number> via the cfe_es_start_app_cc command . the only known recovery is to power cycle the unit . worth note , is that this applies only to our sp0 ( vxworks <number> ) and is not repeatable on a linux system . this bug was discovered when testing a <allcaps> ctf </allcaps> script with a copy and paste error in it . libraries are not intended to be started via the start app command , but given the severity of the error . <repeated> i wanted to submit an issue to better understand it . <section> steps to reproduce the behavior : <number> . start sample_lib via cfe_es_start_app_cc command ( note that stack size must be >= cfe_platform_es_default_stack_size in order to produce error ) <section> no lockup <section> - sp0 - os : vxworks <number> - cfe : v6 . <number> + dev295 - osal : v5 . <number> + dev247 - psp : v1 . <number> . <number> <section> add any other context about the problem here . <section> dan knutsen <allcaps> nasa </allcaps> goddard",0.0
"fix # <number> , clarify restart / reload app behavior <section> fix # <number> - clarifies the difference between restart and reload in <allcaps> api </allcaps> / cmd and user ' s guide documentation <section> none , comments only <section> none <section> n / a <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
cfe_sb . h - - <hashtag> if </hashtag> instead of <hashtag> if def </hashtag> cfe_omit_deprecated_6_8 probable typo ? <url>,0.0
"<allcaps> cfe sb </allcaps> pipes not safe across multiple tasks <section> some "" worker "" software design patterns involve multiple threads reading from a common / shared work queue . however due to the way sb buffers are managed , this is not currently possible with <allcaps> cfe </allcaps> child tasks and sb pipes . the "" current "" ( i . e . most recent ) buffer is stored in the pipe descriptor structure , and upon the next entry to <code> this function assumes that the last buffer stored in the pipe descriptor can be freed . but when multiple tasks are reading a single sb pipe , this model breaks , because only one buffer can be remembered . the current buffer is likely still in use by the other task when the next worker thread calls this necessitates some new apis to actually make this work . each worker task will need to individually indicate to sb when it is actually done with the buffer , it can not rely on entry to to <code> to indicate this . <section> _short term fix : _ just document that only one task may operate on a pipe id at a given time . app developers must externally sync their worker tasks to ensure this . recommendation would be to have one designated task ( i . e . the main task ) act as the delegater - it reads the sb pipe , identifies the request , and _copies_ the request data to an available worker thread . after this it can get a new request from the sb pipe while the worker goes on . _longer term fix : _ expose the sb buffer refcount increment / decrement routines separately in the public <allcaps> api </allcaps> , and decouple the previous buffer refcount decrement from <code> . so each worker task can safely get a buffer from sb without inadvertently freeing any previous buffer that may be still in use by other worker tasks . however , this is an <allcaps> api </allcaps> change that would affect all apps , as they now must make a new / additional call into cfe_sb when they are finished with a buffer as <code> cannot not do that automatically . <section> could feasibly have a task - based buffer record so that each <allcaps> cfe </allcaps> task will have its own "" slot "" so to speak , and thereby cfe_sb_receivebuffer could free the previous buffer _from that task_ rather than having the single buffer associated with the pipe id . but this has weakness too - sb has to have a slot for every possible task whether it uses sb pipes or not . it also means the only way to free your previous buffer is to call cfe_sb_receivebuffer ( ) again and get a new buffer . so if the work is a long - running job it will "" own "" the buffer the entire time and prevent its re - use ( and long - running jobs would likely be the reason for using a worker model in the first place ) <section> found when reviewing race conditions in sb as part of # <number> . supporting multiple threads reading the same pipe might be a nice to have but will have inherent race conditions with the current <allcaps> api </allcaps> design . so to keep the <allcaps> api </allcaps> design as is for this cycle we will have to restrict this . <section> joseph hickey , vantage systems , inc .",2.0
"cfe_sb_receivebuffer ( ) - - switch timeout to int32 <section> per discussion at the jan . <number> , <number> <allcaps> ccb </allcaps> , <user> suggested that the timeout parameter should be int32 , not uint32 . this should be changed . see also # <number> <section> <email>",2.0
avoid multiple returns and possible uninitialized variable warning in cfe_time_registersynchcallback <section> multiple returns and an ( invalid ) possible uninitialized variable warning shows up from static analysis : <url> <section> refactor for one return and avoid warning . <section> leave as is ( works ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"<allcaps> cfe </allcaps> intermittently showing invalid message id errors <section> when leaving <allcaps> cfe </allcaps> running for long periods of time , i am seeing occasional errors related to bad message ids / commands appear . for instance : <code> i was actually able to catch one of these in a core dump , and i can confirm that <code> looks like a perfectly well - formed message with msgid of 0x 1 8 1 0 . this particular example was caught at <url> <code> what is particularly mysterious is that 0x 1 8 1 0 is <code> . <repeated> these mids should be delivered only to cfe_time - <allcaps> evs </allcaps> does not subscribe to these - yet for some reason it appears to be delivered to <allcaps> evs </allcaps> . <repeated> <section> build <allcaps> cfe </allcaps> in default debug config ( <allcaps> simulation </allcaps> = native , etc ) . start up <allcaps> cfe </allcaps> core and just let it run . it may take several hours for the first error to appear . <allcaps> cfe </allcaps> appears to continue running normally afterwards though . <section> <allcaps> evs </allcaps> ( or other apps ! ) should not randomly see messages it did not subscribe to . <section> ubuntu <number> ( native ) <section> not sure when this started because everything seems fine when debugging <allcaps> cfe </allcaps> for shorter time periods . but over the last couple weeks i have noticed these messages randomly appearing in terminal windows where i have started <allcaps> cfe </allcaps> and forgotten about it ( overnight or longer ) . although i cite <allcaps> evs </allcaps> here ( because its the one i actually caught in a core file ) this phenomenon occurs in other apps too ( sb , <allcaps> time </allcaps> , etc ) all randomly getting a delivered message id they did not subscribe to . <section> joseph hickey , vantage systems , inc .",0.0
initialize status in cfe_es_waitforsystemstate <section> from <allcaps> lgtm </allcaps> : the variable status may not be initialized here . <url> <section> initialize to success <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"add_psp_module cmake include bug <section> when making <allcaps> psp </allcaps> modules and calling <code> from the respective <allcaps> psp </allcaps> module ' s cmakelists . txt file , the necessary includes are not available and the code will fail to compile due to <code> not being found . <section> steps to reproduce the behavior : <number> . create a <allcaps> psp </allcaps> module in psp / modules / < your module > <number> . create a cmakelists . txt file in psp / modules / < your module > and add line for <code> . <number> . make a . c source file in <code> and <code> in it . <number> . make sure to include this psp module in target . cmake so it will be built w / <code> <number> . build cfs <section> if you have the proper <allcaps> psp </allcaps> module boilerplate set up the compile error you should see is that compiler could not find <code> <section> i went ahead and modified cfe / cmake / arch_build . cmake function <code> include_directories line from <code> to <code> . <repeated> which fixed the problem . <section> - native linux - os : ubuntu <number> - versions [ cfe v6 . <number> - rc2 , <allcaps> osal </allcaps> v5 . <number> - rc2 , <allcaps> psp </allcaps> v1 . <number> - rc1 ] <section> joe mahoney - <allcaps> lta </allcaps> research",0.0
"resolve routeid msgid comparison issue reported by <allcaps> lgtm </allcaps> <section> comparison between routeidx of type cfe_sb_routeid_atom_t and endidx of wider type cfe_sb_msgid_atom_t . this alert was introduced in0c4f5d82 months ago <url> <section> this was implemented when there were two foreach functions , but foreach msgid was removed due to being a resource hog . really do not need a separate helper function anymore and types can be made consistent . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"re - enable static analysis after travis - ci shutdown <section> the travis ci runner ran cppcheck which we do not have anymore <section> submit pull request , notice that travis ci does not run anymore . <section> a success or failure report of a cppcheck run . <section> check from travis . yml <code> <section> n / a <section> part of ongoing travisci to github actions migration",0.0
"cfe_sb_receivebuffer ( ) should use cfe_sb_timeout_t for the timeout parameter in cfe_sb . h . <repeated> <url> but below , the <code> takes uint32 for the timeout . <repeated> <url> should not it be using the <code> type instead of uint32 for the timeout parameter ?",0.0
fix # <number> - corrects documentation for cfe_sb_getpipename ( ) stub <section> closes # <number> this corrects the documentation for the cfe_sb_getpipename ( ) unit test stub function . <section> documentation update only . <section> <email>,1.0
cfe_sb_getpipename stub doc references ut_pipename ? the documentation for the cfe_sb_getpipename stub references setting ut_pipename . <repeated> which <allcaps> afaict </allcaps> is not defined / used . i am assuming that users should use ut_setdatabuffer ( ut_key ( cfe_sb_getpipename ) . <repeated> ) . <url>,1.0
add actions in workflow to replace former ci implementation <section> ci no longer running for pr ' s in nasa repo <section> implement ci as github actions <section> none <section> similar to transition in nasa / cfs <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"return value of cfe_sb_receivebuffer stub does not match documentation for the stock stub function , it returns the default ( cfe_success ) return code but sets the message pointer to <allcaps> null </allcaps> . the documentation states that it defaults to return the <allcaps> timeout </allcaps> error . the logic for the stub may want to reflect this . <url>",1.0
<allcaps> osal </allcaps> guide generation warning <section> generated by user ' s guide action ` ` <code> osapisem ' for \ ref command / home / runner / work / cfs / cfs / cfe / docs / src / osalmain . dox : <number> : warning : unable to resolve reference to <code> osapisem ' for \ ref command / home / runner / work / cfs / cfs / cfe / docs / src / osalmain . dox : <number> : warning : unable to resolve reference to <code> ` ` <section> resolve warnings <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
change ut_clearforcefail to ut_cleardefaultreturnvalue <section> ut_clearforcefail was refactored to ut_cleardefaultreturnvalue for nasa / osal # <number> . it needs to have its name changed here as well . <section> part of nasa / osal # <number> <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"update <allcaps> cfe </allcaps> to use os time conversion / access methods <section> <allcaps> cfe </allcaps> is directly accessing specific fields within <code> which will break when the struct definition changes . <section> instead of directly accessing the <code> and <code> fields within <code> , use the accessor functions to convert / extract the relevant info from the value instead . <section> see nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
"replace calls to os_fsblocksfree <section> this function is scheduled to be deprecated in nasa / osal # <number> . <section> it should be replaced with a call to <code> instead . <section> old function has insufficient range as noted in nasa / osal # <number> . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , create cfe security policy markdown <section> fix # <number> created a draft of a security policy markdown file for cfe . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
cmake - based source selection for <allcaps> rtems </allcaps> toolchain do a cmake - based source selection for <code> note that we should only need to set <code> in the current build scripts . the others are implied . could simplify here . <code> _originally posted by <user> in <url>,2.0
"remove use of <allcaps> osal </allcaps> internal headers <section> functions should use only <code> and <code> . other headers are getting refactored in nasa / osal # <number> . <section> remove direct use of other headers such as <code> <section> this is required in order to implement / merge the fix for nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",0.0
"relation between cfe requirements and unit test implementation hi all ! i have some doubts about how tests are being implemented . in one hand if we look into a ut file , e . g . es_ut . c we can see that all the tests there make reference to ut_report as follows ( i took one at random ) : <code> i tried to have a deeper understanding of what is happening there but if i look for "" cfe_es_setupresetvariables "" o "" setupresetvariables "" or similar i am not able to find extra information neither in cfe_functionalrequirements . csv nor in requirements . docx . i do not know if maybe i am not looking in the correct place or maybe that files are out of date ; anyway i would like to know if there is any file where it is explained why to check "" cfe_es_setupresetvariables - other cause reset "" is performed an ut_printfisinhistory ( . <repeated> ) instruction is performed and not another one . thanks in advance and stay safe out there ,",3.0
"create <code> typedef to maintain app - specific command definitions <section> as part of the message processing pattern , applications currently define a header file ( typically ending in <code> ) that define the structures which serve as i / o message . notable exception to this pattern is in the "" send housekeeping "" commands - this has no app - defined type , it directly uses the type provided by the <allcaps> msg </allcaps> module e . g . <code> . <section> for consistency in operation we should really make an equivalent app defined message type ( e . g . <code> ) for this - it can be a simple typedef to <code> . having a type for this would maintain the pattern of having a dedicated typedef for each command definition that is locally defined / controlled by the app itself . <section> app can still _use_ or depend on types provided by other modules - this is ok - the main thing is that it should not be _assumed_ to do so . the send_hk style commands are unique in that they assume use of a bare <code> for this message . this is fine but the app should say this somewhere , it should not be assumed . having an app fully define its own i / o interface ( with no assumptions ) is also important if / when transitioning to a data dictionary / <allcaps> eds </allcaps> type message system . <section> joseph hickey , vantage systems , inc . _originally posted by <user> in <url>",2.0
"update cfe application developers guide ( <number> comments ) <section> the cfe application developers guide section <number> references the cfe deployment guide . please include the deployment guide or remove the reference . the cfe application developers guide section <number> . <number> states : "" child tasks can only execute at a priority equal to or less than the priority of the application ' s main task . "" which several folks have said is not true . it ' s not true in <allcaps> cfe </allcaps> <number> . x . <section> dan berry / <allcaps> nasa gsfc </allcaps>",0.0
"update sb "" send "" command names that write to a file <section> cfe_sb_sendroutinginfocmd_t , cfe_sb_sendpipeinfocmd_t , cfe_sb_sendmapinfocmd_t and the corresponding command codes actually write to a file . send should indicate a request to send information on the software bus . <section> fix names to be consistent - [x ] cfe_sb_send_routing_info_cc - > cfe_sb_write_routing_info_cc - [x ] cfe_sb_sendroutinginfocmd_t - > cfe_sb_writeroutinginfocmd_t - [x ] cfe_sb_sendroutinginfocmd - > cfe_sb_writeroutinginfocmd - [x ] cfe_sb_sendrtginfo - > cfe_sb_writertginfo - [x ] cfe_sb_send_pipe_info_cc - > cfe_sb_write_pipe_info_cc - [x ] cfe_sb_sendpipeinfocmd_t - > cfe_sb_writepipeinfocmd_t - [x ] cfe_sb_sendpipeinfocmd - > cfe_sb_writepipeinfocmd - [x ] cfe_sb_sendpipeinfo - > cfe_sb_writepipeinfo * - [x ] cfe_sb_send_map_info_cc - > cfe_sb_write_map_info_cc - [x ] cfe_sb_sendmapinfocmd_t - > cfe_sb_writemapinfocmd_t - [x ] cfe_sb_sendmapinfocmd - > cfe_sb_writemapinfocmd - [x ] cfe_sb_sendmapinfo - > cfe_sb_writemapinfo * - [ ] will also need to update comments in # <number> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove test_msg_printmsg in favor of ut_displaypkt <section> test_msg_printmsg was added with <allcaps> msg </allcaps> module , but duplicates what ut_displaypkt already did . no need for both . <section> replace test_msg_printmsg with ut_displaypkt and remove . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"remove system log elements from cfe1521 , es : processor reset preservation list requirement <section> remove system log elements from ces1521 ( <allcaps> cfe </allcaps> - <number> ) requirement . over - specified , out - of - family , and somewhat redundant with ces1511 requirement to preserve the system log . ces1521 : upon a processor reset , the cfe shall preserve the following : - boot source - reset type - reset subtype - reset reason - number of processor resets - maximum processor resets - number of entries in system log - size of system log - number of bytes used in the system log",1.0
"ut stubs for cfe_sb_timestampmsg and cfe_sb_setmsgtime very inconsistent <section> these two functions do almost the same thing in <allcaps> fsw </allcaps> but the ut stubs have entirely different side effects . <code> stores the message pointer in a ut buffer , but the <code> stores the given time in the ut metadata for the message . <section> these should be more consistent . the <code> should update the metadata like <code> does because that ' s what <allcaps> fsw </allcaps> expects . <section> code inspection ( n / a ) <section> noticed this as part of # <number> review / discussion . probably also impacted by # <number> . <repeated> perhaps we can just focus on getting stubs for the cfe_msg module replacements right . we should get away from storing the message pointer in <allcaps> any </allcaps> of these stubs - because it references internal data objects and the life cycle of this object may not be persistent ( i . e . it could be on the stack ) so storing the pointer passed to any of the sb message functions is probably not a good idea . the newer method of creating a ut "" metadata "" object associated with the message pointer is better , because it has a lifespan of the unit test case - so guaranteed to be still valid when the function under test returns . <section> joseph hickey , vantage systems , inc .",2.0
"type mismatch between cleanup stub and implementation <section> the stub of these functions is declared as taking a <code> parameter : - [x ] cfe_evs_cleanupapp - [x ] cfe_sb_cleanupapp - [x ] cfe_tbl_cleanupapp - [x ] cfe_time_cleanupapp <section> these need to be changed to <code> to match <allcaps> fsw </allcaps> <section> ubuntu <number> <section> was not flagged as an error due to <code> not being included . after pr # <number> got merged , the stub mismatch is flagged . <section> joseph hickey , vantage systems , inc .",0.0
"pool buffers should not use <code> as interface type <section> the es memory pool <allcaps> api </allcaps> uses <code> as a buffer pointer - this is the type used in <code> and <code> among others . this presents a few usability problems : - most often the data being stored is _not_ actually <code> - so it generally needs to be type cast by the user . - typecasts are ugly and risky - specifically - typecasts to / from <code> might create a warning about alignment on some platforms ( one direction or the other is likely to be seen as an upgrade in alignment requirement ) - if alignment was the goal , <number> bits is still too low for <code> type , or a <number> - bit pointer , so it fails at that job . <section> the <allcaps> api </allcaps> should use <code> . <section> although this basically turns off type checking , there was no real type checking here to begin with , and pool buffers _intentionally_ should be convertible to any type , so no need for it here anyway . using <code> will clean up the code substantially , allowing a lot of unnecessary type casts to be removed . <section> joseph hickey , vantage systems , inc .",0.0
"questionable address adjustment in sb buffers may break alignment requirements <section> software bus message buffers should handle most restrictive alignment requirements for a message . address arithmetic used in manipulating buffers may break this alignment on some systems . even if not broken , a maintenance issue since an update to <code> could break things unexpectedly . <url> <url> <url> <section> not confirmed , but likely will not meet alignment requirement for a message with long double . <section> safer to use the real buffer type ( instead of <code> ) in the descriptor along with offsetof to size the buffer correctly ( cfe_sb_msg_t for now , or maybe cfe_sb_buffer_t from # <number> ) <section> see above <section> na - inspection <section> # <number> , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"create consistent sb transmit / receive <allcaps> api </allcaps> ' s , refactored to utilize the zero copy pattern <section> duplicated logic in cfe_sb_sendmsg and cfe_sb_zerocopysend ( and related apis ) , refactor could simplify cfe_sb_sendmsgfull . sending / receiving software bus buffers vs the less restrictive alignment message type is not clear , names do not mirror . <section> implement the following : - [x ] cfe_sb_transmitmsg - sends the less restrictive alignment message type by coping it into a sb buffer , then transmitting buffer - [x ] cfe_sb_transmitbuffer - sends a message that is already in a software bus buffer ( like cfe_sb_zerocopysend ) - [x ] cfe_sb_receivebuffer - the old cfe_sb_rcvmsg ( it ' s not a message , it ' s a buffer ) - [ ] cfe_sb_allocatebuffer - the old cfe_sb_zerocopygetptr - [ ] cfe_sb_releasebuffer - the old cfe_sb_zerocopyreleaseptr possibly add flag for incrementing sequence count ( instead of more <allcaps> api </allcaps> ' s like cfe_sb_passmsg ) . <section> none <section> came from # <number> discussions <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
strncpy triggers a build failure in ubuntu focal release builds # # describe the issue <code> fails on *focal* <allcaps> release </allcaps> builds <url> <code> _originally posted by <user> in <url> # # alternative solution use ubuntu bionic for builds instead,0.0
"fix # <number> , apply consistent alignment pattern <section> fix # <number> fix # <number> - since it deprecates <code> and the new stubs are documented correctly partially addresses # <number> ( adds cfe_sb_transmitmsg , cfe_sb_transmitbuffer , cfe_sb_receivebuffer ) - main change is to utilize cfe_sb_buffer_t and cfe_msg_message_t in a consistent manner to facilitate alignment - deprecates cfe_sb_sendmsg , cfe_sb_passmsg , cfe_sb_rcvmsg , cfe_sb_zerocopypass , cfe_sb_zerocopysend - deprecates cfe_sb_tlmhdr_t , cfe_sb_cmdhdr_t - deprecates cfe_sb_cmd_hdr_size and cfe_sb_tlm_hdr_size - redefines cfe_msg_size_t as size_t to minimize duplicated work and facilitate transition to just size_t see also details in the individual commits . why is this necessary ? - the former implementation wasn ' t clear on the use of cfe_sb_msg_t vs cfe_msg_message_t , cfe_sb_tlmhdr_t vs cfe_msg_telemetryheader_t , cfe_sb_cmdhdr_t vs cfe_sb_commandheader_t - worst case alignment was enforce at the message level , making it impossible to use the message types in cmds / tlm without impacting the sizes of some of the cmds / tlm ( they would get rounded up ) - still could not cast to a command type that contained anything that required more than <number> bit alignment now - cfe_sb_buffer_t is aligned for up to a long double , so now for command processing cast alignment warnings are all resolved - clear use of cfe_sb_buffer_t and removal of duplicated / confusing terms - cfe_msg_message_t no longer requires any "" extra "" alignment and is available in the cfe_msg_telemetryheader_t and cfe_msg_commandheader_t structures so no cast is required to use the <allcaps> msg </allcaps> apis ( just pass in the msg ) - cfe_msg_telemetryheader_t and cfe_msg_commandheader_t can now be used in the definition of all cmd / tlm structures and avoid casts ( no more uint8 header of size * _hdr_size ) <section> bundle passed ci , unit tests pass . <section> none , pattern change . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + # <number> , although # <number> is the subject of this pr <section> # <number> , # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <allcaps> edit </allcaps> : also fixed # <number>",2.0
"remove test_sb_cmds_subrptunexpcmdcode ( no longer applicable ) <section> test_sb_cmds_subrptunexpcmdcode seems like it was intended to test the subscription reporting with a command code parameter , but this is a no parameter command . it ' s also just a copy of test_sb_cmds_unexpcmdcode so does not do anything unique . <section> remove . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , include cfe_private . h in stubs <section> fix # <number> - added inclusion of cfe_private . h for stubs that implement related elements <section> built unit test , confirmed expected failure for cfe_es_registercdsex (# <number> ) <section> avoids future divergence . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> depends on # <number> to pass <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
include cfe_private . h in stub implementations so they do not diverge <section> see # <number> <section> include the header <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_es_registercdsex stub mismatch <section> mismatch in cfe_es_registercdsex implementation and stub . <section> inspection <section> matching stub . <section> <url> <url> <section> na <section> looks like it was introduced in daf6c04 , part of fix # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( from stakeholder email )",0.0
"refactor message header alignment and "" raw "" types to fit a clear pattern <section> aligned version of message headers currently in sb , shows different handling of the base type . <url> <section> see discussion below . <section> none . <section> brought up as part of # <number> /# <number> review . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( from <allcaps> ccb </allcaps> discussion )",2.0
refactor ut_setforcefail describe the bug ut_setforcefail was refactored to ut_setdefaultreturnvalue for <url> it needs to have its name changed here as well . expected behavior change ut_setforcefail to ut_setdefaultreturnvalue additional context part of <url> reporter info alex campbell,2.0
"documentation / usage mismatch in <allcaps> cfe es </allcaps> "" start app "" command <section> the <code> is documented as being a default stack size , not a minimum stack size . but the <allcaps> cfe es </allcaps> "" start app "" command enforces it as a minimum value here : <url> but this is not in agreement with how it is documented : <url> <section> n / a <section> should not enforce the default as a minimum . i do not see any <allcaps> cfe </allcaps> platform definition for an enforced minimum stack size . if i remember correctly this was discussed once or twice and the agreement was that this is an operational issue - stack size requirements depend on the app stack usage and the memory constraints of the platform - so <allcaps> cfe </allcaps> cannot ( and should not ) impose some random limitations on it - it should attempt to do what the user requested . so recommendation would be to remove this check . one valid possibility is that if the stack size is specified as <number> ( which is definitely not valid ) , to use the default value instead . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"remove the sb apis deprecated in # <number> and # <number> <section> deprecated code should be removed before major release . <section> remove . note the only remaining dependence on sb metadata is get / set user data size , and preference would be to remove this ( and get / set user data size would then act like all the other default stubs ) . <section> none . <section> # <number> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"user - friendly memory alignment from cfe_sb_rcvmsg <section> ~ command with <number> byte alignment requires a memcpy by the user ( <allcaps> afaik </allcaps> ) . ~ <allcaps> edit </allcaps> - see below , should already provide sufficient alignment . <section> align the buffer for the user ? any other options to make this easier ? <section> none . <section> stakeholder request / question . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( from stakeholder ) <user>",3.0
"pass flags parameter to os_moduleload ( ) <section> change in nasa / osal # <number> adds a "" flags "" parameter to os_moduleload , which needs to be added to <allcaps> cfe </allcaps> where this function is invoked . <repeated> <section> add "" flags "" parameter . initially this can just use the <allcaps> global </allcaps> flag ( <number> ) to maintain the same behavior . <section> dependency of nasa / osal # <number> <section> joseph hickey , vantage systems , inc .",2.0
"ut_setdeferredretcode does not work as explained in ut_support . c <section> <url> description above makes it sound like calls to cfe_sb_rcvmsg will return : <number> , cfe_sb_time_out , - <number> . in practice it returns <number> , cfe_sb_time_out , <number> , <number> , - <number> since each call to ut_setdeferredretcode sets up another entry in the table , and each entry is processed until complete before moving on to the next ( which restarts the counter ) . the osal description is clear , it ' s just not used correctly in cfe : <url> <section> set more than one ut_setdeferredretcode on the same key , observe response . <section> set up so it will do <number> , cfe_sb_time_out , - <number> : <code> <section> see above <section> - hardware : cfs dev server - os : ubuntu <number> - versions bundle main <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"cfe_platform_sb_max_pipe_depth reporting and use misleading in relation to os_max_queue_depth <section> cfe_platform_sb_max_pipe_depth is reported in cfe_sb . stattlmmsg . payload . maxpipedepthallowed , which is not true if it ' s > os_max_queue_depth . <section> maybe remove as a <allcaps> cfe </allcaps> platform config ? it does not size arrays or anything , so it seems arbitrary at the cfe level . <allcaps> osal </allcaps> checks vs os_max_queue_depth . <section> verify < or = os_max_queue_depth ? <section> see nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
pipename refactor removed it from the send pipe info file dump <section> # <number> removed pipename from the structure that is written when the send pipe info command is sent . need to add this information back in . also related to # <number> . likely need to reconsider what is output ( memory addresses likely not helpful ) . <section> observe file output from a cfe_sb_send_pipe_info_cc command before and after # <number> merge . <section> # <number> should not have changed output file . <section> <url> <section> all . <section> observed in build verification test of <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user>,0.0
"consider implementing a common task library <section> there ' s things we code over and over again , and where we do not follow standard patterns we probably should . <section> create a common set of utilities for a task ( aka a task library ) that the core services could also use . candidates : - cfe_task_verifycmdlength ( msgptr , expectedlength , erroreventid , errorcounter ) - could also pass in msgid and fcncode so they do not need to be looked up twice ? see # <number> - cfe_task_resetallcounters - see # <number> - cfe_task_getapptaskname - see # <number> for use in <allcaps> api </allcaps> reporting to provide consistent information - cfe_task_formfullname - see # <number> if a common formation pattern is implemented ( vs just naming pattern ) - generic double - linked list support <section> leave as - is . <section> observed when implementing # <number> , duplicated code is all over for a few of the standard task elements . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"automatically update leap seconds in sample cmake <section> based on # <number> , it would be useful to set up a github bot to check and update this every six months or so . <section> automate updating this file . <section> periodically open an issue when the leap seconds fall out of date . <section> official source of leap seconds <url> <section> gerardo e . cruz - ortiz",2.0
"time not using critical data store <section> the following requirements specify that <allcaps> time </allcaps> should be using <allcaps> cds </allcaps> : ctime2502 upon a processor reset the cfe shall verify the critical data store used to store time values . ctime2501 upon a processor reset the cfe shall acquire the following time elements from the <code> critical data store : - time status data - <allcaps> stcf </allcaps> - leap seconds ctime2700 during normal operation , the cfe shall preserve the following time elements in the <code> critical data store : - time status data - <allcaps> stcf </allcaps> - leap seconds - <allcaps> met </allcaps> ctime2502 . <number> if the critical data store is not valid , all of the time elements shall be initialized in the same fashion as following a power - on reset . there is no <allcaps> cds </allcaps> for time – the respective variables are preserved through the reset area . <section> the requirements or <allcaps> fsw </allcaps> should be updated to reflect intended implementation . <section> dan knutsen <allcaps> nasa </allcaps> / goddard",2.0
"new printf warnings in <allcaps> rtems </allcaps> build <section> a recent change re - introduced some printf type warnings on the <number> - bit <allcaps> rtems </allcaps> build <section> build for <allcaps> rtems </allcaps> i686 target warnings are issued : <code> <section> should build cleanly <section> ubuntu <number> build host for i686 - rtems4 . <number> target . <section> this always happens with fixed width types , needs explicit cast when used with printf . <section> joseph hickey , vantage systems , inc .",0.0
"resolve table services message initialization inconsistencies <section> hk and tbl regpacket are initialized in both cfe_tbl_earlyinit and cfe_tbl_initdata ( called from cfe_tbl_taskinit ) . the notify message packet is only initialized in cfe_tbl_sendnotificationmsg , and gets initialized every call . <url> <url> <url> the cfe_tbl_sendnotificationmsg could just be initialized once , then setmsgid and setfcncode each time . <section> these packets only need to be initialized once . <section> none . <section> observed when working on # <number> additional observation - the notification command gets timestamped , which fails for implementations where there is no time stamp in commands . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"use resource id type for sb pipe id <section> the <allcaps> cfe sb </allcaps> pipe id table is not safe from aliasing or other issues . <section> redefine the cfe_sb_pipeid_t type to be a form of cfe_es_resourceid_t like many other resources have already been converted ( mem pool handles , <allcaps> cds </allcaps> blocks , etc ) . re - use all the same management patterns of this structure . <section> the only potential downside is that resource ids are defined as <number> bit values but pipe ids were only <number> bits . so this will make <code> into <number> instead of <number> . but as long as apps are properly using the typedef and not assuming <code> or otherwise depending on this being a single byte , this should not be noticeable . this is somewhat related to previous issue # <number> - implementing this would be a good step in the right direction for that issue too . <section> joseph hickey , vantage systems , inc .",2.0
sample config leap seconds needs update <section> the sample configuration ' s cfe_mission_time_def_leaps was set to <number> and should currently be <number> <section> steps to reproduce the behavior : visual inspection <section> cfe_mission_time_def_leaps should be <number> <section> <url> <section> n / a <section> # <number> leap second history <url> <section> alex campbell <allcaps> nasa gsfc </allcaps>,0.0
"sb private / internal data structure being written to telemetry dump file <section> the <code> structure is defined within <code> and is internally used to manage the pipe state . but as part of the "" send pipe info "" command this structure is also directly written to a data dump file - making it effectively into telemetry data . <section> code should clearly delineate what is telemetry data intended to be consumed by the ground or other systems , and what is internal data that only resides in local memory . in particular , the <code> also contains pointers , so the dump file resulting from a send pipe info command will contain these internal memory address ( meaningless outside the current <allcaps> cpu </allcaps> ) and it will change size depending on whether it is running on a <number> - bit or <number> - bit <allcaps> cpu </allcaps> . <section> ubuntu <number> <section> whether data is sent directly in a telemetry message in real time or dumped to a file and transferred to the ground system in a deferred fashion , it is all basically telemetry data and the structures used in these data dump files should be defined in consistent ( i . e . non platform dependent ) terms so the tools on the ground can actually parse the file ( or message ) . <section> joseph hickey , vantage systems , inc .",0.0
"update startup processing to optionally use module suffix <section> startup scripts currently need to be modified across systems that have different module suffixes . <section> # <number> makes the module suffix available in software . if there is no suffix specified in the startup script , append it ( backwards compatible ) . this would make startup scripts more portable . <section> none <section> # <number> - table implementation would also benefit from not needing the suffix <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"report task details in query_all_tasks command <section> the current <code> structure , which is written by the query_all_tasks command , only has some very basic task information - the name / id , execution count , and what app the task is associated with . <section> suggest to also include : - stack size - priority - entry point ? ( would depend on # <number> ) <section> stack size is an important statistic for determining memory usage priority is potentially important for real time concerns both of these are tracked by <allcaps> osal </allcaps> and easily available , just have to get it and put it in the structure . <section> joseph hickey , vantage systems , inc .",2.0
"move entry point address info from app table to task table <section> the es global currently tracks task entry point in the app table , not task table . as a result only the "" main "" task entry point of an app is tracked in this regard . as child tasks are created , these all have different entry points , but they are not stored , and therefore cannot be reported in the telemetry as reported via e . g . query_all_tasks . <section> hold the actual runtime entry point address in the task table rather than the app table . <section> this would simplify the current task entry logic as it would only need to look at the task entry , not the app + task entry combination . still would need to hang onto the _configured_ ( string version ) of entry point for when an app is reloaded / restarted . <section> joseph hickey , vantage systems , inc .",2.0
"shorter name for es_backgroundtask <section> with the recent addition of setting the name at the linux os kernel in nasa / psp # <number> , task names are mostly shown in the debugger but not for the es background task . this is because the glibc / linux has a hard limit of <number> characters for this name . so even though os_max_api_name is <number> , names need to be less than <number> chars in order to show up properly . <section> run <allcaps> cfe </allcaps> in debugger and look at task names - "" es_backgroundtask "" does not show up . <section> should show the name . <section> ubuntu <number> <section> recommend keeping <allcaps> cfe </allcaps> task names to be all less than <number> chars even if os_max_api_name is set to a larger limit . <allcaps> osal </allcaps> is fine with longer names , but they just do not show up in the debugger due to the underlying glibc / linux limit . <section> joseph hickey , vantage systems , inc .",2.0
"cfe_fs subsystem has no tracking information <section> all the app core modules are tracked by es , because apps all have an entry in the global app table . so one can get an id and all other expected operations such as name / id lookups work . however <allcaps> cfe fs </allcaps> subsystem is not an app , it is a library . as a result , it cannot be identified / queried in any way . <section> call e . g . <code> and one will get a result of <code> , even though the cfe_fs subsystem definitely exists . <section> the fs subsystem should be registered in the global table as a library , so it can be identified and referred to . <section> ubuntu <number> <section> noticed this with extended testing of # <number> - queries for cfe_es , cfe_sb , etc all work , but an attempt to query cfs_fs does not work , but it probably should . <section> joseph hickey , vantage systems , inc .",2.0
"cfe_msg_initmsg does not always set secondary header bit <section> the behavior of cfe_msg_initmsg seems to be a regression from the old <number> cfe_sb_initmsg , which always set the secondary header flag regardless of the clear / initmsg parameter . there ' s always a <allcaps> ccsds </allcaps> secondary header , so this bit should always be set . <section> call cfe_msg_initmsg with the <code> parameter set to false <section> secondary header flag on message is set to <number> <section> <url> cfe_msg_initdefaulthdr should always be called . <section> - sp0 - os : vxworks - versions : cfe <number> <section> discovered when sbng did not properly set the command code due to missing secondary header flag . this was worked around by calling cfe_sb_initmsg w / the initmsg parameter set to true . <section> john n pham , northrop grumman",2.0
"refactor directory structure so it makes sense again ( fsw contains non - fsw ) <section> fsw is misleading in that it includes unit tests , etc but then there are also fsw implementations within modules . <repeated> <section> implement a flattened / sensible directory structure . needs discussion . <section> - cfe / - cmakelists . txt for the repo - fsw / - cmakelists . txt for the fsw - sbr / - cmakelists . txt for sbr ( and so on for cmake files ) - msg / - core / - es / - . <repeated> - public_inc / - unit - test / - stubs / - coverage / - functional / - eds / - docs / - . <repeated> and so on <section> <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user> <allcaps> edit </allcaps> - updated for gerardo comment",2.0
"compiler warning when using optimized / release build <section> a compiler warning pops up when enabling full optimizations : <code> <section> build with <code> using a recent <allcaps> gcc </allcaps> ( e . g . v9 . <number> + ) such as the one with ubuntu <number> <section> should build cleanly <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"update startup script names to match sample_app and sample_lib <section> pr ' s nasa / sample_app # <number> and nasa / sample_lib # <number> update the function names to use a consistent prefix - <code> and <code> , respectively . the example startup script needs to change accordingly . <section> update entry point names . <section> this is needed at the same time if / when the other two prs are merged . <section> joseph hickey , vantage systems , inc .",2.0
"cfe_es_cdsregdumprec_t has implicit padding <section> related to # <number> - implicit padding should be avoided <section> eventually pack definitions will come from a common definition , with explicit padding <section> none <section> observed in testing bootes <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",2.0
"avoid <allcaps> osal </allcaps> ids in messages / data files <section> <allcaps> osal </allcaps> runtime types are not really defined as part of the external ( i . e . mission - scope ) interface . the <code> is one such example - it is a local runtime type , not really intended to be saved in data files or command / telemetry messages . this might seem pedantic because it is simply a <code> , but when using <allcaps> cfe </allcaps> with a command / data dictionary tool this becomes apparent that the <allcaps> osal </allcaps> types used in telemetry and data files are not part of the data dictionary . ( <allcaps> osal </allcaps> itself does not have a cmd / tlm interface so it naturally would not provide any such entity ) . <section> use the <code> instead . call <code> when writing and <code> when reading , to do the type conversion . the underlying value is compatible ( i . e . both <number> bit <code> , same numbers ) so it should be transparent to external tools . <section> have <allcaps> osal </allcaps> provide a stablized <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> definition of ids ? ( but <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> interface is not really part of <allcaps> osal </allcaps> ' s role - it is a runtime library ) <section> joseph hickey , vantage systems , inc .",0.0
"remove cfe_sb_sendprevsubs in favor of cfe_sbr_foreachrouteid <allcaps> api </allcaps> <section> cfe_sb_sendprevsubs holds locks that are not that useful , sufficient logic required , creates bus traffic , etc . <section> <allcaps> sbn </allcaps> could just use cfe_sbr_foreachrouteid , not really a true "" public "" <allcaps> api </allcaps> . <repeated> but seems like fair use in this case . would be outside of sb lock , but likely ok based on design ( enables subscription reporting first , then check all previous subs ) . <section> at least remove all the locking / unlocking . it does not help . <section> related to # <number> work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user>",2.0
update documentation for message map hash implementation <section> see <url> <code> <section> add this info and general design to documentation <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"potential for missed log messages between dump + clear commands <section> this issue was initially described in # <number> but isolated to a separate ticket for discussion / triage . the es syslog "" dump "" and "" clear "" are separate commands , so there is a window of opportunity between these actions where messages can be lost - as it is not possible to guarantee that no additional messages were written during this time . <section> <number> . log messages are written <number> . dump command issued <number> . more log messages are written <number> . clear command issued . logs written in ( <number> ) above are lost , as they are not in the dump file but they will be cleared by the clear command . <section> should have command structure which can ensure that no messages get lost . <section> joseph hickey , vantage systems , inc . , generalized from comment at <url>",0.0
"syslog support for incremental reads the concept is to use logs for forensic analysis , so yes as debug , but not as an exception more as always there . problem is , by the time you know you want a log it will be gone if you don ’ t get it to a persistent , accessible storage place . algorithm i ’ m trying to support is : on timer : - extract un - read logs - if enough logs have been extracted , package and send the current <allcaps> api </allcaps> supports reading all the logs in the buffer at once and then clearing the logs ( with the race condition that any logs that occur during the reading out will be lost , or need to lock out all loggers during the read which is not acceptable ) . the proposed update to the <allcaps> api </allcaps> is the addition of a single function that instead of setting the buffer size based of endidx , sets the buffer size based on the difference between the buffer - > lastoffset passed in and the writeidx . this is a traditional circular buffer interface and is well supported within the code as it stands , just needs an <allcaps> api </allcaps> to initialize the buffer correctly . advantages are : - traditional circular buffer interface so supports a well established model - allows readings of logs without loss of logs or undesirable locking - no impact to current code , so introduces no risk to current systems",2.0
"ut checking calls to os_printf <section> many unit tests are checking the calls to <code> . but typically all syslog / printf type messages are not fulfilling any sort of requirements , they are just informational in nature . so <allcaps> afaik </allcaps> there is not really a strong justification to specifically check for certain syslog messages , but the fact that the ut does check for these means that any time the syslog messages are changed or refactored in any way , one gets a bunch of nuisance ut failures . as a result we spend a lot of time fixing ut tests for things that are not really relevant to the operation of the code . <section> at least remove checks for number of times <code> was called in a given path . this is really quite irrelevant to pass / fail . the <code> tests might be ok to keep , but an actual return code should be preferred . if there is no return code then this is probably ok - its also less volatile because it just checks format string and confirms that a specific path was taken . <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> evs </allcaps> coverage test fails when cfe_platform_evs_default_type_flag is set to 0 xf <section> when cfe_platform_evs_default_type_flag is set to 0 xf there are two failures : <code> <section> steps to reproduce the behavior : <number> . set cfe_platform_evs_default_type_flag to 0 xf <number> . build unit tests , run cfe - core_evs_ut , observe failure <section> test should pass with debug events enabled ( should not care ) . <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : <number> . <number> - rc1 + dev129 <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
convert software bus destination linked list to circular <section> linear linked list requires more logic at insertion / removal <section> convert to circular <section> none <section> <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( spawned from discussion on # <number> ),2.0
"race condition in control requests <section> due to the order of operations in clean up , the es global lock is given up and then re - acquired : <url> the problem is that this provides a window of opportunity for the underlying state to change externally while the global data is unlocked . <section> this can happen , for instance , if the task that is being cleaned up calls <code> while this state machine is also cleaning up the app . this actually does happen because <code> will return false if there is an exit request pending . it is just masked by the fact that most apps are pending in a message receive queue , so they do not self exit - they are deleted by es instead . i was able to get <allcaps> cfe </allcaps> to segfault / crash by allowing sample_app to exit itself at the very same time that this state machine was also cleaning it up . <section> no crashes , proper clean up . <section> ubuntu <number> <section> due to the ~ <number> second exit / cleanup delay it is unlikely to occur "" in the wild "" but it can easily be forced to happen . in my test i just used a slightly modified <code> that does not pend forever on <code> , and also delays itself such that it self - exits at the exact same time that the es background job is running , which reliably segfaults every time . <section> joseph hickey , vantage systems , inc .",0.0
"use memchr ( ) for string length checks <section> string length verification checks are generally done via the <code> c library <allcaps> api </allcaps> . the potential issue here is that <code> requires / assumes a termination byte to be present . if the user mistakenly passes an unterminated string , the implementation will search sequentially in memory beyond the string ( i . e . forever ) until it either encounters a <allcaps> nul </allcaps> char somewhere in memory , or segfaults , whatever comes first . <section> use <code> for string length check instead , which can specifically check for a <allcaps> nul </allcaps> char within a certain length . for instance , instead of : <code> use : <code> this has the advantage that it will _not_ search beyond the specified <code> , so its a bit safer . it ' s also a more direct check - the code generally does not care what the actual string length is , it just needs to know if its within max_length or not . <section> leave as is . <section> this is a minor thing , but would improve robustness a bit . <section> joseph hickey , vantage systems , inc .",2.0
"eliminating recursive locks in sb could allow for using more efficient resource <section> recursive locks possible in the following code ( may also be in other locations ) : <url> <url> <url> <url> related - the locking in the sendprevsubs command handling does not look like it really helps since it has to unlock to send the message ( same issues as the commands to record route / map info to file ) , typical use case is to enable subscription reporting , then send all previous subscriptions so may make sense to refactor ( and possibly throttle ) . <section> clear filters on the debug messages and trigger ( i stopped sample_app to cause the pipe deletion ) , or just subscribe and unsubscribe twice to trigger cfe_sb_unsub_no_subs_eid . <section> avoiding recursive lock could allow for using a more efficient resource on platforms where it ' s supported . <section> see above . <section> from code analysis , tested on ubuntu <number> . <section> from analysis during # <number> and # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_platform_es_perf_max_ids not fully deprecated <section> cfe_platform_es_perf_max_ids was superseded by cfe_mission_es_perf_max_ids as noted in this comment : <url> however , sample cpu1_platform_cfg . h still contains the definition for cfe_platform_es_perf_max_ids is still referenced in es_ut . c and comments in cfe_es_events . h and sample_perfids . h <section> n / a <section> either cfe_platform_es_perf_max_ids should be totally deprecated and all references should be replaced by cfe_mission_es_perf_max_ids or ( if deemed necessary ) support for platform - specific max values should be re - added in the perf - log implementation . <section> cfe / cmake / sample_defs / cpu1_platform_cfg . h : <number> cfe / fsw / cfe - core / src / inc / cfe_es_events . h : <number> cfe / fsw / cfe - core / unit - test / es_ut . c : <number> <section> n / a <section> n / a <section> pj chapates gateway vehicle system manager <allcaps> fsw </allcaps> production , <allcaps> jsc </allcaps>",0.0
"requirement ces1008 failure <section> requirement ces1008 specifies : upon receipt of a command the cfe shall reload the command specified cfe application from the command specified cfe application file . this is not consistent with how the <allcaps> fsw </allcaps> works . if a reload command is received , the <allcaps> fsw </allcaps> will restart the application with the previously loaded version as long as the command specified cfe application file exists . the same result is seen if an app is started / stopped - then loaded / started with a new version . the system / event log entries will indicate that the loading / starting of the new version of the app is successful . <repeated> however the original version of the app will be the one that will actually be executed . <section> steps to reproduce the behavior : <number> . start an app <number> . send the reload command with a filename that contains a different version of the app ( app name must remain constant ) <number> . verify that the original version of the app was actually the one started . alternatively : <number> . start an app <number> . stop the app <number> . start a different version of the same app ( app name must remain constant ) <number> . verify that the original version of the app was actually the one started . <section> able to restart a task of the the same name . <section> if applicable , add references to the software . <section> os : ubuntu - <number> versions : cfe : v6 . <number> + dev295 ; osal : v5 . <number> + dev247 ; psp : v1 . <number> . <number> <section> dan knutsen",0.0
"provide consistent name lookup <allcaps> api </allcaps> <section> many <allcaps> cfe </allcaps> resources have a name associated with them , but <allcaps> cfe </allcaps> is rather hit or miss on how resource ids ( apps , tasks , libs , etc ) can be looked up by name . for instance , <code> exists , but <code> does not . task ids can be found directly via <allcaps> osal </allcaps> through <code> but there is no <allcaps> cfe </allcaps> version of this despite the fact that es also tracks tasks . <section> for resource types that have names associated , there should be a consistent <allcaps> api </allcaps> to find the id by name , similar to <code> . the following should be implemented , all with the general <allcaps> api </allcaps> pattern ( name in , id out , status return ) : cfe_es_gettaskidbyname ( ) cfe_es_getlibidbyname ( ) cfe_es_getgencounteridbyname ( ) cfe_es_getcdsblockidbyname ( ) <section> keep things inconsistent . <section> this is also a prerequisite to # <number> - to have libs be manageable similarly to apps , part of that is being able to find lib id by name , which is required by several management / query commands . <section> joseph hickey , vantage systems , inc . edit - turns out and <code> does exist already . but the others do not .",2.0
"ctbl6000 . <number> requirement failure - no partial table load field in header current requirement verbiage : if the command specified file ' s header indicates that the file contains only a portion of the table , the cfe shall first load an inactive table image with the contents of the active table image and then load the contents of the command specified file . there is no field in the header that specifies if a table is a partial load . the software detects the partial load and handles it appropriately . <section> we should update the verbiage or consider combining with cfe - <number> ( ctbl6000 . <number> ) . <section> dan knutsen <allcaps> nasa </allcaps> / goddard",1.0
"add system - specific module and library suffixes to configdata struct <section> there are a number of use cases where the <allcaps> fsw </allcaps> could be improved if it knows the proper system - specific extension to use for modules and executable files . see existing issues # <number> and nasa / <allcaps> psp </allcaps> # <number> <section> should add this information to the <code> structure , to make it available for <allcaps> psp </allcaps> / <allcaps> cfe </allcaps> purposes . <section> could also be provided in the <code> structure that resides in the <allcaps> psp </allcaps> library , but this would require explicitly setting in each <allcaps> psp </allcaps> . because cmake already knows this information and its readily available in cmake variables , its simpler and probably more reliable to just put it in the top level config struct based on the cmake value . <section> joseph hickey , vantage systems , inc . , ( based off previous requests in other tickets )",2.0
doxygen description of stub for cfe_sb_sendmsg is not correct <section> description on the stub for cfe_sb_sendmsg is out of date . <section> update description <section> <url> <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>,1.0
"remove "" senderreporting "" from sb private "" global "" the senderreporting field exists in the sb global struct but is only set once and never used . <url>",2.0
"unit tests should use cfe defines instead of os_max_path_len and os_max_api_name <section> scrub unit tests for os size use vs cfe size , related to # <number> , # <number> . anything in io structures should be using cfe sizes ( cfe size is maximum of all platform os maximums ) . <section> os_max_api_name - > cfe_mission_max_api_len os_max_path_length - > cfe_mission_max_path_len in the code use sizeof instead of hard coded sizes . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( spawned from <date> <allcaps> ccb </allcaps> discussion )",0.0
"add search option for relating message id to route <section> core implementation is message id = = message key , leading to a large , sparse message table to get the route index . <section> eliminate message table . order routing table by id and binary search , or other search options ( optimal solution may depend on configured sizes such as number of supported message ids and number of supported routes ) . <section> see also # <number> , hash . <section> allowed by # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add message id to message key hash option <section> core implementation is message id = = message key , leading to a large , sparse message table to get the route index . <section> hash message and deconflict on lookup ( confirm route matches msgid ) . could decrease message table size to a small multiple ( <number> or <number> maybe ) of the routing table size depending on how many conflicts are acceptable . <section> ordering the routing table and implement binary search and completely eliminate message table . <section> see # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"move sb route lookup ( including insert method ) to a module <section> various implementations possible for message and route tables , all with associated advantages and issues . <section> provide the capability to replace the core implementation . <section> none . <section> for implementations that support large msgids , or prefer smaller memory footprint at the cost of performance . hashes , searches , etc . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( per stakeholder request for alternate implementation )",2.0
"stub for cfe_es_runloop default return is false , should it be ? <section> cfe_es_runloop uses ut_default_impl which typically returns cfe_success , which happens to also equal <number> . cfe_es_runloop returns ut_default_impl ! = <number> , which causes the default return to be false ( <number> ! = <number> ) . is that the desired default behavior ? <section> steps to reproduce the behavior : <number> . write a unit test that expects cfe_es_runloop to succeed by default . <number> . run test , see that is not the behavior . <section> i had expected ' true ' to be the default . <section> <url> to run a single loop for a unit test , this is required : <code> <code> the main reason this requirement does not make sense is ut_setforcefail makes one think it should fail , not succeed . <section> <allcaps> rhel </allcaps> <number> <section> if this is the desired behavior , close and disregard this issue . <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",3.0
"add support for "" critical "" subscriptions ( message must be sent or will return error ) <section> software bus currently returns success even if a message is not sent to the subscribers ( queue full or over message limit ) . this causes the message to be dropped with no notification for the sender . this spawned from the cf use case where notification is required to be able to eliminate the semaphore that is currently used for flow control . <section> add support for a subscription to be "" critical "" . on send , check that all critical destinations have room for the message , if not do not send to any destinations and return an error . if every critical destination has room , send to all destinations . all done within the sb lock . for the cf use case , typically the receiver would dedicate a pipe with just that subscription and the individual msg limit check is sufficient ( as long as it ' s smaller than or equal to the queue limit ) . may make sense to transition <allcaps> qos </allcaps> to a bitfield ( currently an enum ) , supporting the subscription critical option . <section> see # <number> , # <number> <section> discussed that cf should cap work per cycle ( avoid free - run if unsubscribed , or no subscribers ) . also generate the message once , and retain to send next cycle if there is no room . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( spawned from splinter on # <number> )",2.0
"improve uniqueness in resource ids <section> in the event that a resource "" a "" such as an app / counter / pool etc is created , then deleted , then another resource "" b "" is created , the code will re - issue the same resource id for "" b "" as was used for "" a "" . this means if a stale reference to "" a "" is stored somewhere , it silently now becomes an alias to "" b"". all validation / checks will pass . <section> should not immediately recycle id values . <section> this is the way <allcaps> osal </allcaps> already works , and is enabled by using abstract ids . with the recently introduced resource id abstractions , it is no longer necessary to limit to the respective table size ( s ) , because ids are not directly used as table indices anymore . this means that a much larger set of potential id values is available , and thus means that ids of old / deleted objects can be different than the new objects while keeping table size the same . <section> joseph hickey , vantage systems , inc .",2.0
"repetitive appid lookups in cfe_sb_sendmsgfull <section> sb has some code to filter an app ' s own messages via <code> . this gets the appid and compares to the appid of the pipe creator , and skips the destination if its a match : <url> the problem is that this is "" inside the loop "" of all destinations in the routing entry . so it will ( potentially ) call <code> multiple times . this also creates a double locking situation , because the sb lock is being held at the time this executes , and the es lock needs to be acquired by <code> <section> code should query the caller appid early , before taking the sb lock . <section> the code works but is inefficient , and double locking is a potential deadlock . <section> joseph hickey , vantage systems , inc .",0.0
update cfe_error . h to use the cfe_status_t type <section> as a followon to # <number> all of the const defines currently cast to <code> and they should be <code> . <section> <email>,2.0
"update cfe source and unit tests to use cfe_status_t <section> as a followon to # <number> , we should update all of the cfe source to use the cfe_status_t return status type instead of int32 . <section> may want to do this in phases , per component ; or incorporate into a clang - format code cleanup change set . <section> <email>",2.0
"cfe req . ces1007 . <number> : restart application - reject on missing file <section> cfe requirement ces1007 . <number> specifies that a user can not restart an application if the original file has been removed . if the user attempts to restart an application following removal of file , the cfe shall reject the command , increment the invalid command counter , and generate an event message . this is not what happens when the restart application command is received . if a user has deleted the cfe application file and then sends the restart application command . the application successfully restarts . <section> steps to reproduce the behavior : delete an applications shared library file from the / cf / location . send the associated restart application command . <section> oracle vm virtualbox os : ubuntu - <number> versions : cfe v6 . <number> - rc1 + dev28 , osal v5 . <number> - rc1 + dev12 , psp v1 . <number> + dev76 <section> dan knutsen <allcaps> nasa </allcaps> / goddard",0.0
"add support for <allcaps> rtems </allcaps> <number> - sample_defs toolchain file updates <section> the cfs bundle currently supports <allcaps> rtems </allcaps> <number> . now that <allcaps> rtems </allcaps> <number> has been released , i would like to update the necessary components to support <allcaps> rtems </allcaps> <number> on the pc - rtems platform . this involves minor modifications to the cfe repository , the <allcaps> psp </allcaps> repository , and the <allcaps> osal </allcaps> repository . these changes can be done in such a way that preserves the current <allcaps> rtems </allcaps> <number> support and adds <allcaps> rtems </allcaps> <number> support . <section> for the cfe repository , the only changes needed are to the sample_defs toolchain files . i need to make a small modification to the <number> <allcaps> rtems </allcaps> toolchain file , and add a new toolchain file for <allcaps> rtems </allcaps> <number> . <section> alternatives include : - not supporting newer versions of <allcaps> rtems </allcaps> , but several projects will depend on <allcaps> rtems </allcaps> <number> support . - dropping <allcaps> rtems </allcaps> <number> support and just making the changes needed for <allcaps> rtems </allcaps> <number> , but there may be projects that depend on <allcaps> rtems </allcaps> <number> . we can consider dropping <allcaps> rtems </allcaps> <number> support on a future release . <section> <section> alan cudmore / <allcaps> nasa gsfc </allcaps> code <number>",2.0
"provide separate type for each resource category <section> pull # <number> provided a generic typedef for resource identifiers . this commit stops using <code> and makes a dedicated type , but the type is the same for all resource categories ( apps , tasks , counters , etc ) . <section> per <user> comment here : <url> it would improve things further to provide a separate / unique typedef for each resource category . <section> this will be implemented as a follow - on to the original change . <section> joseph hickey , vantage systems , inc .",2.0
cast - align warning in sb_ut . c <section> <code> <section> resolve warnings <section> none <section> ubuntu <number> w / cast - align = strict <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"move typedefs used in cmd / tlm to the * _msg . h file <section> cfe_es_appinfo_t and cfe_es_memhandle_t are defined in cfe_es . h , but used in telemetry ( cfe_es_msg . h ) . all the typedefs used in telemetry should be defined in the * _msg . h file . <section> move cfe_es_appinfo_t and cfe_es_memhandle_t into cfe_es_msg . h note cfe_es_taskinfo_t is not used in cmd / tlm . <section> none <section> related to # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> cfe time </allcaps> should initialize the <allcaps> stcf </allcaps> from <allcaps> psp </allcaps> <section> the <allcaps> cfe time </allcaps> subsystem initializes its state using fixed values from <code> and <code> . as a result , all timestamps initially come out as <code> and increment from there . <section> it should get these initial values from the <allcaps> psp </allcaps> instead . this way on platforms that actually have an <allcaps> rtc </allcaps> , it can get the correct value . this would be a big improvement particularly when debugging on a pc / vm because timestamps could be the actual time , not <number> . <section> leave as is . <section> not a high priority , but this is often confusing , particularly to new users and / or test environments that do not have a <allcaps> cfe </allcaps> time server sending time at tone messages . <section> joseph hickey , vantage systems , inc .",2.0
"cmake build not correctly using the "" ${ <allcaps> cpuname </allcaps> } _system "" directive <section> with the current main branch even if the <code> variable is correctly set , it is being ignored . <code> works fine though . <section> run <code> without <code> and a targets . cmake file with <code> set to something non - empty . unexpected error is generated : cmake error at cmake / mission_build . cmake : <number> ( message ) : unable to find toolchain file for default <section> should generate build tree and build successfully . <section> <allcaps> gsfc </allcaps> mcp750 test build <section> joseph hickey , vantage systems , inc .",0.0
"documentation in targets . cmake does not match current implementation <section> <url> <url> cpu number is now assigned differently , name is assigned differently , etc . <repeated> <section> update documentation to be consistent <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"update cfe_sb_getuserdata unit test to catch padding differences between header / payload <section> cfe_sb_getuserdata returns the location right after the header , which is not always the start of the payload if padding gets inserted . <section> add generic packets with all width types , and ensure the correct location is returned . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , replace ut_text with utprintf <section> fix # <number> - replaces ut_text with utprintf and eliminates ut_verbose ifdef ( run time reporting control provided by ut_assert ) <section> built and ran unit tests , passed . spot checked reports and it looked good ( sb_ut , tbl_ut ) <section> minor text changes in report , but now can be controlled by run time test verbosity levels . also reports actual test line number and file ( instead of utility function info ) . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"ut_checkforopensockets prototype duplicated <section> prototype defined in both cfe and <allcaps> osal </allcaps> . <url> <url> implemented here : <url> also violation of magic number use in the implementation , and does not seem to actually do what it says ( i do not see the close ) . <section> maybe remove if not useful ? if not , at least use the correctly scoped prototype and remove the second definition . <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"replace ut_text with utdebug and utprintf , remove ut_verbose ifdefs <section> compile time defines used for controlling reporting levels , also needless redefine ut_assert functions defeats the reporting of function and line number <section> ut_assert provides for run - time reporting levels , use them instead of compile time defines . this will also then cause the line number and file to be useful . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> evs </allcaps> improperly uses the eventcount member for incorrect appid filtering <section> the <code> member of the <allcaps> evs </allcaps> internal app data is intended to track the number of events sent by a particular app . <allcaps> but </allcaps> - it is also overloaded to track if the event came from the wrong app , here : <url> the problem is that this is , by definition , invoked when the calling appid is _wrong_ ( not registered ) , but it is changing a field that is also potentially used for _valid_ ( registered ) appids . <section> this can theoretically occur if an app calls <code> using an old appid value , for instance if an app was restarted it gets unregistered , and then gets a different appid but refs to the old value could still exist . the new appid does not necessarily have the same slot in the table - in fact it should not . the old table entry might refer to a totally different app . so if this happens it will corrupt / change the <code> member on an unrelated app data entry . this can be seen in the <allcaps> evs </allcaps> telemetry , where if the "" unregistered "" event occurs it inadvertently creates a nonzero <code> in the <allcaps> tlm </allcaps> data on an unrelated app that happens to share that slot in the table . also , if the counter was already nonzero because the table entry is in use by another ( registered ) app then this prevents the notification about the unregistered app from appearing at all . <section> should not overload the eventcounter to track a basically unrelated item - which is whether or not an "" unregistered "" event occurred on a different app that happened to map to the same entry . simple fix would be to just introduce a separate field to track this . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"add typedef and nonzero base for resource identifiers <section> app ids , task ids , library ids , and other resources are all represented by a basic <code> identifier , which starts at <number> . <section> there should be a separate <code> for these identifiers , and <number> should be reserved as an "" undefined "" value ( like <allcaps> osal </allcaps> ) such that : - control structures and globals which are <code> to zero will not alias valid entries if they contain ids . - alleviates the need for a separate <code> boolean - <number> can indicate an unused entry , nonzero indicates a used entry this makes everything consistent as well as being simpler and safer . <section> type should initially be a <code> which makes this backward compatible for apps . after this change ids can no longer be directly used as array indices . this has already been removed / fixed in <allcaps> cfe </allcaps> itself in previous prs . <section> joseph hickey , vantage systems , inc .",2.0
"replace calls os_open and os_create with os_opencreate <section> for nasa / osal # <number> the <code> and <code> <allcaps> api </allcaps> calls will be deprecated , because they do not follow the correct pattern of returning an <allcaps> osal id </allcaps> via an output variable , instead returning the id via the <code> return code . <section> use the newly exposed <allcaps> osal api </allcaps> <code> which can replace both <code> and <code> via different flags , and outputs the id as all other <allcaps> osal </allcaps> functions do . <section> prerequisite to being able to deprecate these apis that do not follow the <allcaps> osal </allcaps> pattern . <section> joseph hickey , vantage systems , inc .",2.0
"unable to set return code of cfe_es_calculatecrc using ut_setdeferredretcode <section> the cfe_es_calculatecrc stub always return the value of <number> regardless of what deferred return code i set it to . <section> steps to reproduce the behavior : <number> . create a functionx that calls cfe_es_calculatecrc <number> . write a unit test for the functionx <number> . in ut_functionx , set the return code of cfe_es_calculatecrc as below <code> <number> . run the unit test <section> i expect the return value of cfe_es_calculatecrc to be <number> as i set it to . <section> however , the return value of cfe_es_calculatecrc will be <number> instead of <number> . <section> n / a <section> - hardware - os : centos7 - versions : cfs development build : <number> . <number> - rc1 + dev28 <section> n / a <section> n / a",2.0
"typedef for status return values <section> currently most <allcaps> cfe api </allcaps> ' s return a status code ( the return type defines as int32 . ) the numeric return type is somewhat unclear and could result in confusion with other types of information ( such as inadvertent confusion with return values from <allcaps> osal </allcaps> functions or numeric id ' s ) . <section> <code> in order to facilitate better coding practices , i also propose a utility function : <code> <section> this will require quite a lot of code change but could be migrated incrementally as creating the typedef to the same type will be compatible . eventually it could be changed to a struct wrapper or enum or something that will result in compiler errors when the type is considered a numeric type . <section> <email>",2.0
"fix # <number> , library table id management <section> apply the appid / taskid / counterid pattern to library resources . <section> build and sanity check <allcaps> cfe </allcaps> , ensure library is loaded correctly run all unit tests <section> no impact to behavior . internal change only . <section> ubuntu <number> <section> implement the same pattern on library ids which was previously implemented for apps , tasks , and counters . for unit testing this also moves the library - specific ut calls into a separate function . <section> joseph hickey , vantage systems , inc .",2.0
"update library code to decouple ids from table indices <section> library ids are currently coupled to the library table index . <section> library ids should be opaque values and not interpreted directly as a table index . apply the same pattern as in previous prs # <number> and # <number> to the library code . <section> part of ongoing effort to clean up ids across all of es . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , remove old name and id defines <section> fix # <number> , remove old name and id defines cfe_platform_cpu_id , cfe_platform_cpu_name , and cfe_mission_spacecraft_id use cfe_psp_getprocessorid ( ) , cfe_psp_getprocessorname ( ) , cfe_psp_getspacecraftid ( ) going forward . <section> built with unit tests , passed . also nominal core - cfe run . <section> none <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , install unit test to target directory <section> fix # <number> , install unit test to target directory <section> make unit tests , install , observe they install in correct directory <section> correct install directory <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , returned processor id to default to unbreak toolchain <section> fix # <number> ci port selection depends on processor id , # <number> changed the default which broke toolchain . <section> built , ran , confirmed ci is back to listening on default port . <section> defaults work again in the toolchain <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this change . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"default linux port got changed again . <repeated> <section> processor id was set to <number> , ci uses it to deconflict ports . broke toolchain . <section> normal run , reports ci is listening on <number> ( should be <number> ) <section> use historical port by default . <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main <section> broke in # <number> . really should fix nasa / cfs # <number> ( positive check in ci of proper execution and exit ) , and this would have been caught . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
unit tests no longer installing correctly <section> some unit tests show up in build directory after install <code> <section> make <allcaps> simulation </allcaps> = native enable_unit_tests = true prep make make install <section> they should all show up in build / exe / cpu1 ( for default config ) <section> no idea <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix # <number> , remove dependency on <allcaps> ccsds </allcaps> version define <section> fix # <number> - removes message_format_is_ccsds_ver2 and all references - now replaced by mission_msgid_v2 and mission_include_ccsds_header cmake variables - base mids localized to cpu1_msgids . h and improved documentation indicating example nature of implementation , note issue # <number> may make this obsolete - updated cfe_sb . dox for message module concept - msgid base type now always uint32 ( reduces logic differences ) - removed system log report of version used , in build and obvious from packet sizes - cleaned extra documentation from cfe_sb_msg_id_util . c - removed verification limits on cfe_platform_sb_max_msg_ids - removed ut_getactualpktlenfield and ut_getactualcmdcodefield that depended on the define , should not directly access message in a unit test since it ' s implementation dependent - default <allcaps> ccsds </allcaps> version default now always <number> ( per the standard ) but mission configurable <section> build unit tests , passed except for sample app . build usersguide and confirmed no errors or warnings . <section> none , just no longer requires additional configuration flag <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"document msg module customization method <section> no documentation on how to customize message module <section> add documentation - overview , suggestions , etc include cmake steps to replace : <code> note this is a "" power user "" option and not generally recommended unless absolutely required by the mission . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"document mission_msgid_v2 and mission_include_ccsdsext_header cmake options <section> missing documentation for mission_msgid_v2 and mission_include_ccsdsext_header note not widely used . <repeated> <section> document as example in cmake file ( likely targets . cmake ) mission_include_ccsdsext_header - set to source select to include <allcaps> ccsds </allcaps> extended header ( cfs defined "" standard "" ) mission_msgid_v2 - set to source select version <number> message id implementation , depends on above being set <section> remove support for these in the framework . <repeated> the extended header is not standardized , custom headers can be implemented to support the few cases where the default is not sufficient ( and power users may end up defining their own header anyways ) . the framework does not really work with these settings without additional modification ( apps have v1 mids ) , etc . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"cfe_mission_rev defined in <number> locations <section> cfe_mission_reve defined in <number> locations <section> inspection <section> define in <number> location . <repeated> if it ' s for clone and own , version seems to make sense . <repeated> if it includes configuration versioning then useful in the config file . <section> <url> <url> <section> n / a <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"add function name and line number to cfe_evs_sendevent stub the <code> function , post # <number> will generate debug messages . this ticket proposes wrapping the function in a macro that adds the <code> and <code> to the output . see <url> <section> full name and company / organization if applicable",2.0
"add unsubscribe test case to cover # <number> <section> # <number> looks like it could have resulted in a seg fault , fixed in # <number> unsubscribe after no subscriptions are left . <repeated> <section> add test case . <section> none . should add test to confirm code works . <section> # <number> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",2.0
"fix # <number> , deconflict cfe_es_lib_already_loaded and cfe_es_err_sys_log_truncated <section> fix # <number> - deconflict cfe_es_lib_already_loaded and cfe_es_err_sys_log_truncated eids <section> built and ran unit tests ( checks both those returns ) , passed . <section> eids no longer overloaded . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , generic counter table management <section> apply the appid / taskid pattern to generic counter resources . <section> unit tests build and sanity test <allcaps> cfe </allcaps> . <section> no real logic change - just putting the repeated logic into inline functions . however , this does add a <code> wrapper around counter id allocation , deletion , and lookup to avoid a possible race condition here . this was likely a bug , but never noticed perhaps because these are not a heavily used feature . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"create accessor functions for counter resources <section> the generic counter <allcaps> api </allcaps> uses a zero based id to directly index an array <section> make the "" generic counter "" <allcaps> api </allcaps> follow the same pattern as was done for apps and tasks in # <number> <section> this is for consistency and future development . all resource management should follow this pattern . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add debug message from sendevents <section> fix # <number> - added debug message <section> built and ran test ( used to debug failure in <url> <section> now prints <allcaps> eid </allcaps> and spec when stub apis are called in debug mode . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : main bundle + this commit <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add debug messages from cfe_evs_sendevent stubs <section> requires code changes to debug event messages <section> print a debug message to make event message debugging easier ( just pass in <code> and review messages sent ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"if a message is subscribed , then unsubscribed , additional unsubscribes do not raise error events <section> if a message is subscribed , then unsubscribed , additional unsubscribes do not raise error events <section> have sb subscribe to a message have sb unsubscribe to that message have sb unsubscribe again to that message <section> event message should be raised <section> <url> if a message was previously subscribed to , and all pipes subscribing to it were subsequently unsubscribed , and an additional unsubscribe is issued , a valid routing index would still exist in the msgmap table , and thus an error event would not be raised . <section> n / a , discovered via code inspection <section> n / a <section> john n pham , northrop grumman",0.0
"scrub <allcaps> cfe </allcaps> to use correct type for <allcaps> osal </allcaps> ids <section> nasa / osal # <number> introduces a proper typedef for <allcaps> osal </allcaps> ids : <code> <section> the <allcaps> cfe </allcaps> needs to be scrubbed to use this typedef whenever storing an <allcaps> osal id </allcaps> , rather than <code> <section> keep using <code> as - is , but that defeats the purpose of having a typedef . <section> joseph hickey , vantage systems , inc .",2.0
"have "" make test "" provide full stats on the pass / fail ratio of the asserts <section> when running <code> it only gives information about which testrunner had at least <number> failing assert . this is useful , but very limited . <section> each test file run by <code> provide a "" fail asserts / total asserts "" in the output . <section> running each testrunner individually to get these results . writing my own bash script . <section> could be added as an additional runner <code> ? <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",2.0
"cast align issue in cfe_es_task . c - cfe_es_taskpipe <section> <code> <section> build on gcc <number> + with cast - align = strict <section> clean build <section> <url> <section> - hardware : arm64 - os : ubuntu <number> - versions bundle + mods to cast - align = strict <section> # <number> , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , pass aligned message into cfe_msg_computechecksum <section> fix # <number> - fixes the cast - align error ( use the aligned msg since it ' s available already ) <section> standard build and unit test , passes <section> no more alignment error <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"rpi4 make process throws alignment error following the "" quick start "" section of the <allcaps> readme </allcaps> , generates an error and make failure : <code> at first i thought this was because i was running on the <number> - bit beta raspberry pi os , so i tried it on a different pi4 , this one running the stable <number> - bit distribution ( buster , latest release ( <number> / <number> ) , updated yesterday ( <number> / <number> ) ) . it fails on the <number> - bit version also .",2.0
"cfe_es_err_sys_log_truncated value is not unique <section> <code> and <code> are both defined to be <code> ( in <code> <url> . <section> n / a <section> i think <code> should instead be set to <code> or some other unique value that follows the status code format . <section> n / a <section> n / a <section> n / a <section> keegan moore , <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"consolidate bit manipulation ( and other general ) macros <section> various services define various bit manipulation or other general macros , repeated / inconsistent logic . bit manipulation : <url> <url> <url> os_printf : <url> <url> <section> better scoping , consolidation into general bit manipulation macro header <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove / replace / deprecate questionable macros in sb <section> <url> <section> consider replacing or removing ( deprecating ) . <section> none <section> trying to write specific tickets related to # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , replace cfe_mission_spacecraft_id with cfe_psp_getspacecraftid ( ) <section> fix # <number> - replaced cfe_mission_spacecraft_id use with cfe_psp_getspacecraftid ( ) and updated unit test <section> built version <number> with unit tests , executed and passed <section> no longer uses soon to be deprecated cfe_mission_spacecraft_id <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle integration candidate + this change <section> depends on changes in integration candidate <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"document nested usage of ut_add_test and clarify nomenclature for individual versus groups of tests # # describe the problem the <code> call has some limitations as addressed in nasa / cfe # <number> . some solutions are discussed in that pr . # # proposed solutions <number> . have <code> handle "" nested "" unit tests , or <number> . develop a nomenclature for unit test functions that explicitly indicates whether there are nested unit tests and then rename unit tests accordingly , or <number> . document the anti - pattern , or <number> . split up all unit tests to ensure only one test per function and make this a design pattern . # # additional context _originally posted by <user> in <url> > related to nasa / osal # <number> . individual tests are added w / the ut_add_test call . some tests are grouped at a lower level ( test_msg_ccsdsext is a group of tests ) , and those functions are called directly . same pattern is used in <code> : > > <url>",1.0
"msg module unit tests add tests within tests , which do not get executed with the current osal / ut_assert <section> msg unit tests utilized a pattern where subtests were added within other tests . <section> build and run msg unit test , observe the subtests do not execute . <section> all tests should execute . <section> see pr . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : integration candidate <section> n / a <section> jacob hageman",2.0
"replace msg module use of cfe_mission_spacecraft_id with cfe_psp_getspacecraftid ( ) <section> cfe_mission_spacecraft_id is pending deprecation , see # <number> <section> replace with cfe_psp_getspacecraftid ( ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"tables are not built for static apps <section> tables are not built for static apps , only dynamic apps . ( only for apps in <allcaps> tgt </allcaps> \<x \ > _applist , not for apps in <allcaps> tgt </allcaps> \<x \ > _static_applist ) <section> tables should be built for both types of apps <section> add_cfe_tables ( ) loops over app_install_list : cfs / cmake / arch_build . cmake / line : <number> : <code> but , process_arch ( ) does not populate app_install_list for static apps : cfs / cmake / arch_build . cmake / line : <number> : <code> only for dynamic apps : cfs / cmake / arch_build . cmake / line : <number> : <code> <section> - cfe <number> <section> david degroote flight software engineer <number> n . lincoln avenue pittsburgh , pa <number> <email>",0.0
"fix # <number> , return message address from cfe_sb_sendmsg stub <section> fix # <number> , cfe_sb_sendmsg stub now behaves the same as cfe_sb_timestampmsg ( copies message pointer from local ) fix # <number> , no longer need to emulate cfe_sb_initmsg from test code , set the <allcaps> api </allcaps> / stub data buffers directly . <section> built with tests , tests ran and passed . depends on update to unit test in sample_app , nasa / sample_app # <number> . <section> stub returns message address instead of copy of message . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this commit . <section> nasa / sample_app # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> lgtm </allcaps> issue - integer comparison size mismatch <section> <code> in theory if evtstosend is > max uint16 this could infinite loop . pretty unlikely , but definitely should not be in flight code . <section> i should be sized appropriately <section> none <section> split off from # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es reports version <number> . <number> in telemetry , even when it ' s built off a development branch <section> misidentifies version <section> look at version in es housekeeping packet . <section> system should report a consistent version number at startup , from noops , and in tlm . could go back to the old way where development versions all report a revision of <number> . <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle . <section> got out of sync with new versioning scheme <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , spacecraft id sample set to historical value ( 0x 4 2 ) <section> fix # <number> - set spacecraft id in sample targets . cmake to 0x 4 2 <section> nominal build and test <section> spacecraft id back to historical value ( some toolchains depend on it ) . verified at <allcaps> psp </allcaps> startup , reported as <number> ( 0x 4 2 ) . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( w / cfe / osal main ) + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"spacecraft id sample setting in targets . cmake should be 0x 4 2 <section> historically sample spacecraft id has been 0x 4 2 , when converting to cmake it became <number> ( decimal ) . <repeated> this leads to errors in toolchains expecting the historical value . <section> change to 0x 4 2 <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"deprecate cfe_platform_cpu_id , cfe_platform_cpu_name , and cfe_mission_spacecraft_id <section> got bit by this again ( used cfe_mission_spacecraft_id when cfe_psp_getspacecraftid ( ) should have been used ) . they also currently return different numbers since the define has historically been 0x 4 2 , but the setting in targets . cmake is <number> ( decimal ) . related to # <number> <section> deprecate , actually suggest this error out at compile if defined since it leads to bugs ( mismatch of ids ) in favor of cfe_psp_getspacecraftid ( ) and cfe_psp_getprocessorid ( ) ( and eventually cfe_psp_getprocessorname ( ) , see nasa / <allcaps> psp </allcaps> # <number> ) <section> none . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , remove iterator modification in loop <section> fix # <number> - removed iterator modification from within the loop . <repeated> replaced with break . <section> built and ran unit tests . <section> none <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle ( and cfe / osal main ) + this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
provide a unit test utility to create software bus messages <section> the sample_app example of how to create a software bus message for use by the test is to use the cfe_sb_initmsg stub . as described in <url> tests should not be using stubs directly for utility operations . <section> n / a <section> add a ut_assert utility function that provides this functionality <section> <url> <section> <allcaps> rhel </allcaps> <number> <section> relates to <url> and <url> <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>,2.0
"cfe_es_findcdsinregistry ( ) infinte loop if registry size is zero <section> the loop inside this function has a poorly - constructed condition for ending the loop . it is comparing a <code> type to an <code> type , and in the event that the <code> is zero , it becomes impossible for this condition to be true and the loop runs forever . <section> easy to see in unit test if one clears the <code> data structure between tests . <section> loops should never have ending conditions that are impossible to reach unless they are supposed to be infinite . in the event that <code> is <number> , it should exit immediately . <section> <url> it is generally a bad idea to do any sort of relational comparison ( greater than / less than ) between signed and unsigned types , c + + actually errors about this but c does not . <section> ubuntu <number> <section> this variable is initialized in <allcaps> fsw </allcaps> from the config <code> which does say that the value needs to be at least <number> . but during unit test the value can be zero . interestingly , <code> swaps the weirdly - structured do - while for a normal while loop , so it is ok however it still does a signed / unsigned compare which should be fixed . <section> joseph hickey , vantage systems . inc .",0.0
"loop counters should not be modified in the body of the loop . <section> counter variable , i , is modified inside the for loop , which may lead to an infinite loop . should use while loop instead . <section> root / cfe / fsw / cfe - core / src / tbl / cfe_tbl_task_cmds . c lines <number> - <number> <section> use while loop or add comments explaining the reasoning of using for loop for future developers ( must ensure loop issues will not occur such as the code looping infinitely ) . if using while loop , please provide maximum limit for counter . <section> <url> <section> <url> <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"further break down message module to facilitate customization <section> currently customization of the monolithic message module can either be done by "" cherry - picking "" code from the core and customizing / adding / replacing whatever needs to be customized or "" clone - and - own "" the entire module . "" cherry - pick "" is fragile since it depends on the internal file layout and structure of the message module ( implementation ) , "" clone - and - own "" is a lot of duplicated code and the possibility of divergence from core development . it ' s a similar concept as for a custom <allcaps> osal </allcaps> depending on shared or portable elements in the repo , in that cherry - picking is dependent on implementation , not just apis and the alternative is clone - and - own . <section> break the message module down into the different parts of the header - <allcaps> ccsds </allcaps> primary , <allcaps> ccsds </allcaps> extended , <allcaps> cfs </allcaps> secondary such that they can be included by projects as building blocks , and the "" cherry - pick "" vs "" clone - and - own "" is then in the context of smaller modules . basically if a project wants to customize just the time format , they could either clone - and - own the <allcaps> cfs </allcaps> secondary implementation or cherry pick . the primary and extended headers could be used as is . <section> approach is a project trade , this change makes that decision a smaller impact ( less code either way ) . the code was separated parts of the header by file already as part of # <number> to make cherry - picking easier ( and secondary is separated by field in the header ) , but also makes breaking into separate modules easier . <section> # <number> , # <number> <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"create <allcaps> changelog </allcaps> . md and move development history out of readme . md <section> the development history is clogging up useful information in the readme <section> move history to a new file named <code> <section> move development history to bottom of readme file <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"fix # <number> , add msg stubs and update <allcaps> sb ut </allcaps> <section> fix # <number> - add msg stubs , update <allcaps> sb ut </allcaps> to use them , and remove msg module include from unit tests <section> standard build with unit tests enabled , passed . <section> uts will now use msg stubs . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle + # <number> + this change <section> depends on # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"why does cfe_sb_sendmsg stub not save the passed in msgptr like cfe_sb_timestampmsg stub does ? <section> cfe_sb_sendmsg copies from local the contents of the passed in message pointer , but cfe_sb_timestampmsg copies from local the value of msgptr . <section> steps to reproduce the behavior : <number> . <url> <number> . compare with <url> <section> default cfe_sb_sendmsg stub behavior should be like cfe_sb_timestampmsg . a hook should be required to provide extra behavior . <section> see above . <section> <allcaps> rhel </allcaps> <number> <section> n / a <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",3.0
"remove <allcaps> cfe </allcaps> deprecated code for next release <section> now that the "" <number> . x "" release branch has been created , the next release should remove all code / functions that are currently marked as deprecated . <section> removal of all code currently contained within an <code> conditional compile switch . <section> the removal only applies to "" main "" branch - not the <number> . x release branch , where it will continue to exist for that release series . this assumes the next release ( main ) will become version <number> . there are other changes currently in development which do break some deprecated items - hence why i ' d like to remove this sooner rather than later , as it saves the work of updating / fixing this old code if the intent is to remove it anyway . <section> joseph hickey , vantage systems , inc .",2.0
add functional tests for cfe miscellaneous apis <section> need open source functional tests for certifiability <section> add functional tests for cfe miscellaneous apis – cfe_es_calculatecrc - calculate a <allcaps> crc </allcaps> on a block of memory . – cfe_es_writetosyslog - write a string to the cfe system log . – cfe_es_processasyncevent - notification that an asynchronous event was detected by the underlying os / <allcaps> psp </allcaps> . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add functional tests for cfe generic counter apis <section> need open source functional tests for certifiability <section> add functional tests for cfe generic counter apis – cfe_es_registergencounter - register a generic counter . generated by doxygen <number> <allcaps> contents </allcaps> – cfe_es_deletegencounter - delete a generic counter . – cfe_es_incrementgencounter - increments the specified generic counter . – cfe_es_setgencount - set the specified generic counter . – cfe_es_getgencount - get the specified generic counter count . – cfe_es_getgencounteridbyname - get the id associated with a generic counter name . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add functional tests for cfe performance monitor apis <section> need open source functional tests for certifiability <section> add functional tests for cfe performance monitor apis – cfe_es_perflogentry - entry marker for use with software performance analysis tool . – cfe_es_perflogexit - exit marker for use with software performance analysis tool . – cfe_es_perflogadd - function called by cfe_es_perflogentry and cfe_es_perflogexit macros . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add cfe memory manager <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add cfe memory manager <allcaps> api </allcaps> functional tests – cfe_es_poolcreate - initializes a memory pool created by an application while using a semaphore during processing . – cfe_es_poolcreateex - initializes a memory pool created by an application with application specified block sizes . – cfe_es_poolcreatenosem - initializes a memory pool created by an application without using a semaphore during processing . – cfe_es_getpoolbuf - gets a buffer from the memory pool created by cfe_es_poolcreate or cfe_es - _poolcreatenosem . – cfe_es_putpoolbuf - releases a buffer from the memory pool that was previously allocated via cfe_e - s_getpoolbuf . – cfe_es_getmempoolstats - extracts the statistics maintained by the memory pool software . – cfe_es_getpoolbufinfo - gets info on a buffer previously allocated via cfe_es_getpoolbuf . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add cfe es critical data store <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add cfe critical data store <allcaps> api </allcaps> functional tests – cfe_es_registercds - reserve space ( or re - obtain previously reserved space ) in the critical data store ( <allcaps> cds </allcaps> ) – cfe_es_copytocds - save a block of data in the critical data store ( <allcaps> cds </allcaps> ) – cfe_es_restorefromcds - recover a block of data from the critical data store ( <allcaps> cds </allcaps> ) <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add cfe es child task <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add cfe child task <allcaps> api </allcaps> functional tests – cfe_es_registerchildtask - registers a cfe child task associated with a cfe application . – cfe_es_createchildtask - creates a new task under an existing application . – cfe_es_deletechildtask - deletes a task under an existing application . – cfe_es_exitchildtask - exits a child task . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add cfe es information <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add cfe information <allcaps> api </allcaps> functional tests – cfe_es_getresettype - return the most recent reset type . – cfe_es_getappid - get an application id for the calling application . – cfe_es_getappidbyname - get an application id associated with a specified application name . – cfe_es_getappname - get an application name for a specified application id . – cfe_es_getappinfo - get application information given a specified app id . – cfe_es_gettaskinfo - get task information given a specified task id . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add cfe application behavior <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add cfe application behavior <allcaps> api </allcaps> functional tests – cfe_es_runloop - check for exit , restart , or reload commands . – cfe_es_waitforstartupsync - allow an application to wait for the "" <allcaps> operational </allcaps> "" global system state . – cfe_es_waitforsystemstate - allow an application to wait for a minimum global system state . – cfe_es_incrementtaskcounter - increments the execution counter for the calling task . – cfe_es_exitapp - exit a cfe application . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <allcaps> edit </allcaps> by <user> : removed cfe_es_registerapp since it no longer exists .",2.0
add es application control <allcaps> api </allcaps> functional tests <section> need open source functional tests for certifiability <section> add functional tests for cfe application control apis – cfe_es_restartapp - restart a single cfe application . – cfe_es_reloadapp - reload a single cfe application . – cfe_es_deleteapp - delete a cfe application . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"network_includes . h needs to include siolib . h for vxworks target <section> when using rs - <number> in io_lib under vxworks , siolib . h needs to be included . <section> <number> . use the <number> . x tag to build a cfs system for vxworks . <number> . include io_lib in your apps <number> . ensure io_lib builds trans_rs422 . c <number> . observe build failure : <code> <section> build should succeed . <section> cfe / fsw / cfe - core / src / inc / network_includes . h should look like this ( note the added siolib . h line ) <code> <section> - building under ubuntu <number> host with vxworks <number> - versions - cfe <number> . x - custom <allcaps> psp </allcaps> and <allcaps> osal </allcaps> for <allcaps> ppc </allcaps> target - io_lib master <section> morgan redfield , astrobotic",2.0
"fix # <number> , remove legacy time header format support <section> fix # <number> fix # <number> collapses options down to just <number> bit second , <number> bit subsecond , always big endian . removes old defines , and errors out if the configuration is set to a format that was removed . <section> built and <code> with <code> , passes test . <section> time in header always big endian . <section> - hardware : cfs dev vm - os : ubuntu <number> - versions : main bundle plus # <number> , with this commit on top ( c039fb4 is the commit for this pr , or those marked with fix # <number> ) <section> # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
update cfe application developers guide . md for message module <section> application developer ' s guide covers older concepts ( like using uint8 and cfe_sb_tlm_hdr_size for defining headers ) and references the old apis . <section> update based on msg module implementation <section> none . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fix # <number> , remove os_milli2ticks document reference ( deprecated ) <section> fix # <number> removes reference from documentation . <section> none , documentation . <section> none . <section> n / a <section> nasa / osal # <number> <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
remove os_milli2ticks reference from documentation ( deprecated ) <section> deprecating per nasa / osal # <number> <section> removes references from the developers guide . <section> n / a <section> nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"improve resource management and internal consistency in es <section> executive services ( es ) maintains many internal tables of resources / objects , which track applications , libraries , tasks , counters , and memory pools , etc . there is a lot of inconsistency in how these internal objects are managed / tracked . some have a <code> boolean that is set true / false depending on whether the record is used . app table uses the <code> member . the memory pool passes around direct pointers which are dereferenced ( potentially dangerous ) . furthermore , all "" id "" values issued to external apps are zero based , and therefore can easily alias other object types or even other objects of the same type . for instance , if one app had id "" <number> "" and it was deleted , and after this a new / different app was started , the new app might also be assigned id "" <number> "" . <repeated> this means any old / stale reference to appid <number> will now be referring to the wrong app . <section> define a properly abstract "" resource id "" type and use it consistently across all these various internal tables . the abstraction should be based on / compatible with what <allcaps> osal </allcaps> does for its internal records . - the "" id "" value also serves as a marker to indicate whether the respective table entry is in use or not . - zero is reserved as an invalid value , and marks entries which are <allcaps> not </allcaps> in use . ( e . g . so a <code> to all zero can consistently clear an entry ) . valid entries / ids are never zero . - valid values are split into a "" type "" and sequential "" index "" value - type is unique for apps . libs , counters , etc so these cannot get crossed / misinterpreted ( i . e . can not pass an appid in place of a libid or vice versa ) . - index is sequential and does not immediately repeat ( i . e . do not wrap until 0 xffff , do not recycle / reassign ids after deletion ) . - provide a consistent mechanism to convert id to a zero based index where an array / table is needed . <section> this internal cleanup is a prerequisite to several related tickets : - # <number> - this blurs the difference between libraries and applications and makes the app <allcaps> api </allcaps> also apply to libraries , so they need a consistent means of identification and ( possibly ) make a single unified table . - # <number> - need a better way to identify mem pools in <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> messages , not a direct address / pointer . - # <number> - more examples of ugliness / duplication of logic between apps and libs <section> joseph hickey , vantage systems , inc .",2.0
"header version / implementation selection logic update <section> # <number> separates the header implementation logic and paves the way to use source selection for msgid implementation and <allcaps> ccsds </allcaps> extended header use . it partially uses new cmake flags to implement , but still relies on message_format_is_ccsds_ver_2 being set correctly ( but does not do it by default ) . <section> remove dependencies on message_format_is_ccsds_ver_2 ( see proposal below ) <section> consider changing cfe configs to cmake options ( like the osconfig update ) , and use the cmake options to set the define if still required . or could just set the version <number> define if either cmake option ( from # <number> ) is set . <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"collapse down to <number> time format for packet headers ( missions can customize msg module for alternates ) <section> # <number> made it possible to replace header implementation such that the core no longer needs to carry mission unique logic . it also added the single time format implementation , but did not switch to use it by default to minimize functional changes from that pr . <section> clean / remove all references to cfe_mission_sb_packet_time_format . note the change in # <number> also fixes # <number> when the new implementation is chosen . now just will do big endian , <number> byte sub - second field . <section> n / a <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add msg module stubs , update sb to use them , and no longer include actual msg target in unit test builds <section> follow on to # <number> , since it leaves the msg module as "" internal "" in the context of unit tests ( it includes the target ) . this was done such that it could be shown all the old sb unit tests would pass ( w / minor updates for the bug fixes and reorg ) . <section> add the stubs , rework the sb unit tests , and remove the msg target from ut builds . <section> n / a <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> cfe reload </allcaps> and <allcaps> restart </allcaps> commands handled ( almost ) identically <section> the documentation of the <code> specifically says here that it is _not_ reloaded from the disk file : <url> but in the way the code has evolved , both <allcaps> reload </allcaps> and <allcaps> restart </allcaps> control requests end up going through <code> function : <url> <url> notably , the <code> function will , in fact , unload the module via <code> , and the subsequent <code> function will load it again from disk . also important that the appid might change too as part of this process , which may or may not be expected ? <section> should make the documentation and code match one way or another : - if we want a true "" restart "" without reload , as the documentation for <code> says , we need to update this to <allcaps> not </allcaps> completely unload the module . - or if the current implementation is ok then i ' d say it is not sufficiently different from <code> to warrant the existence of a separate command . <section> i noticed this inconsistency while doing implementation of # <number> . i can put in a fix for this issues as part of the same ( upcoming ) pr , just need <allcaps> ccb </allcaps> concurrence on which way to go - do we make it work as described , or we describe the way it works . <section> joseph hickey , vantage systems , inc .",0.0
"cfe_sb_rcvmsg stub clears buffer , then copies the msg it appears that the cfe_sb_rcvmsg ( ) stub , when it has a buffer defined , clears the buffer , <allcaps> then </allcaps> copies the message pointer . backwards ? see : <url>",3.0
"allow target name subdirectory for install files and handle symlinks <section> just need to add to the paths of locations for the install list from <allcaps> tgt </allcaps> <n> _filelist the possibility of target_defs / <tgt_name> / < <allcaps> filename </allcaps> > also , if the file is a symlink , it needs to be followed to its source but copied as the name in <allcaps> filelist </allcaps> suggests . <section> <code> something like that maybe ? <section> a clear and concise description of any alternative solutions or features you have considered . <section> add any other context about the feature request here . <section> full name and company / organization if applicable",2.0
"fix # <number> , # <number> , update requirements <section> fix # <number> - ces1005 . <number> : remove application load address from start app command - ctbl6003 . <number> : clarify table validation pior to activate - cevs3103 . <number> , cevs3103 . <number> , cevs3001 : remove sb qualifier fix # <number> - csb4344 : added get packet type <allcaps> api </allcaps> requirement - csb4345 : added message id validation <allcaps> api </allcaps> requirement also removed previously deleted requirements from document <section> none , documentation update only <section> none <section> n / a <section> n / a <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"cfe_evs_send { crit | critical | err | error | info | information | debug } wrapper for cfe_evs_sendevent <section> with the expansion of the <code> constants as part of <code> , it got me thinking that we have a lot of extraneous typing when there ' s only four types of events . what about adding wrapper macros / functions that have the "" eventtype "" as part of the function name ? i also recommend both long and short versions , such as <code> and <code> . so , for example : <code> becomes <code> <section> <email>",2.0
"update <number> cfe requirements as part of the cfe certification effort , several requirements have been identified as in need of update : <number> . ces1005 . <number> ( cfe - <number> in <allcaps> jira </allcaps> <sad> need to remove application load address from the list of command parameters in the start application command ( es ) to reflect implementation . <number> . ctbl6003 . <number> ( <allcaps> cfe </allcaps> - <number> in <allcaps> jira </allcaps> <sad> need to update requirement verbiage to reduce ambiguity . a . old verbiage : if a table validation function exists for the specified table , the inactive table image shall be validated . b . new verbiage : the cfe shall reject an activate table command for a table that has a validation function but has not been validated . <number> . cevs3103 . <number> , cevs3103 . <number> , and cevs3001 ( <allcaps> cfe </allcaps> - <number> , <number> , and <number> <sad> requirements imply that the event format mode is sb controlled / commandable when in fact it is controlled by <allcaps> evs </allcaps> . need to swap sb with <allcaps> evs </allcaps> . <section> dan knutsen <allcaps> nasa </allcaps> goddard",2.0
"fix # <number> , update vxworks <number> example toolchain <section> add missing include path to the target / h and wrn / coreip directory . set and clarify difference between wind_home and wind_base variables . remove unrelated comment about <allcaps> cexp </allcaps> ( remnant from <allcaps> rtems </allcaps> ) . fixes # <number> also fixes nasa / psp # <number> <section> build with vxworks <number> . <section> no errors related to missing headers . <section> gs582w - cfelnx test machine ( vxworks <number> ) <section> joseph hickey , vantage systems , inc .",0.0
"update vxworks <number> toolchain <section> the example toolchain file for vxworks <number> does not work "" out of the box "" in combination with the current mcp750 <allcaps> psp </allcaps> . need to add additional include paths and other paths under <code> / <code> environment variables to more easily adapt to other platforms . <section> see nasa / psp # <number> <section> proposing alternative solution this issue via cmake toolchain file modifications . <section> joseph hickey , vantage systems , inc .",2.0
"es - command to load a new application , commands to load / unload / reload libraries <section> currently es can be commanded to unload or reload an existing application . commands should be added to load an application not currently loaded . similarly , there ' s no commands to load / unload / reload libraries - - these commands should be added . <section> addl . commands . <section> <allcaps> sbn </allcaps> currently directly loads libraries , if the library is not already resident . with this change , <allcaps> sbn </allcaps> should command es to load those libraries . <allcaps> sbn </allcaps> also reloads libraries when the <allcaps> sbn </allcaps> configuration table is changed , this should also translate to es commands . <section> <email>",2.0
"use a changelog to keep track of changes instead of having them in the readme <section> the version history in the readme file clutters useful information <section> move the "" version history "" from <code> to <code> and start following this spec : <url> <section> move changelog section in the readme to a section at the very bottom of the file <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"ccsdsv2 msgid construction not <number> bits as described in cfe_sb_msg_id_util . h <section> ccsdsv2 msgid construction not <number> bits as described in cfe_sb_msg_id_util . h . it looks like the 8 th bit of the <allcaps> apid </allcaps> qualifier subsystem id is included , making the msgid <number> bits . <section> n / a , code inspection <section> msgid should mask off bit <number> in subsystem id <section> <url> <url> <url> <section> n / a <section> n / a <section> john n pham , northrop grumman",2.0
"update assert_eq to print both decimal and hex <section> for many cases bits or error codes are being compared , where hex is easier to interpret the difference <section> print both <section> add specific hex assert_eq <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"ut assert library for <allcaps> cfe </allcaps> functional tests <section> there is a need to do functional testing of <allcaps> cfe </allcaps> itself along with apps and libraries . these would benefit from using the same assert macros and test framework as the coverage tests use . <section> this can be done by compiling the same ut assert framework as loadable <allcaps> cfe </allcaps> app . <section> joseph hickey , vantage systems , inc .",2.0
"deprecate sb elements relative to msg module adaption <section> many apis will be updated for consistency relative to the <allcaps> msg </allcaps> module , also element scoping improvements ( sb does not actually care about the header , it just needs to route ) . <section> per <number> - <number> - <number> discussion sb for once # <number> is in . deprecating : - [x ] cfe_sb_pkttype_ * - > cfe_msg_type_t - [x ] cfe_sb_msgptr_t - > cfe_msg_message_t * - [x ] cfe_sb_msg_t - > cfe_msg_message_t - [x ] cfe_sb_msgpayloadptr_t ( use pointer to payload in structure ) - [x ] cfe_sb_initmsg - > cfe_msg_init - [x ] cfe_sb_gettotalmsglength - > cfe_msg_getsize - [x ] cfe_sb_settotalmsglength - > cfe_msg_setsize - [x ] cfe_sb_getmsgtime - > cfe_msg_getmsgtime ( this gets rid of structure return , similar to # <number> issue ) - [x ] cfe_sb_setmsgtime - > cfe_msg_setmsgtime - [x ] cfe_sb_getcmdcode - > cfe_msg_getfcncode - [x ] cfe_sb_setcmdcode - > cfe_msg_setfcncode - [x ] cfe_sb_getchecksum ( no use case defined , what do you need it for ? ) - [x ] cfe_sb_generatechecksum - > cfe_msg_generatechecksum - [x ] cfe_sb_validatechecksum - > cfe_msg_validatechecksum - [x ] cfe_sb_getmsgid - > cfe_msg_getmsgid - [x ] cfe_sb_setmsgid - > cfe_msg_setmsgid - [x ] cfe_sb_getpkttype - > cfe_msg_gettypefrommsgid - [x ] cfe_sb_setmsgseqcnt - > cfe_msg_setsequencecount <allcaps> not </allcaps> deprecating , but will note in <allcaps> api </allcaps> that these are fragile ( guesses based on assumptions ) . future implementation could be replaced via data dictionary sort of access or standards based header definitions ( including secondary header , and flags or extra internal data to mange the real sizes ) : - cfe_sb_msghdrsize : use actual message structure where possible - cfe_sb_getuserdata : use actual message structure where possible - cfe_sb_getuserdatalength : use actual message structure where possible - cfe_sb_setuserdatalength - use cfe_msg_setsize with full message structure where possible - cfe_sb_cmd_hdr_size - > sizeof cfe_msg_commandheader_t ) preferred <elongated> - cfe_sb_tlm_hdr_size - > sizeof ( cfe_msg_telemetryheader_t ) preferred note cfe_sb_qos_t and cfe_sb_default_qos will likely be used for # <number> ( critical subscription ) <allcaps> not </allcaps> deprecating , <allcaps> msg </allcaps> types are unaligned , sb types are now aligned : - cfe_sb_msg_t , cmdhdr_t , tlmhdr_t - > cfe_msg_ * <allcaps> not </allcaps> deprecating cfe_sb_timestampmsg . see # <number> that requests making this part of send . <section> just need to manage these , unique deprecation flag . <repeated> not all actually need to go , but reduced / simplifies unit testing <section> # <number> , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"generate_config_includefile should display an error if no files are found at all <section> while testing other items i noticed that the <code> function will happily create an empty file if neither a user - provided file nor a default / fallback file is available . but because the file is _present_ but does not have any actual content , you end up with a slightly obfuscated compiler error about missing symbols rather than an indication that the expected config file is empty . <section> the function should trigger an error and inform the user that there was no file to use , rather than generating an empty file . it is a misconfiguration , so it should be corrected . <section> joseph hickey , vantage systems , inc .",0.0
"add build name and build number to version . h <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"add struct name for typedef struct in cfe <section> all of the struct used in <code> are declared with <code> , which make the struct anonymous in debug info , and make it harder to access from the debugging tools such as <code> ` <code> ` <code> ` <code> ` <code> ` <code> ` <code> ` <code> ` ` <section> <section> <section> <user>",2.0
"fix # <number> , add to table search path <section> adds to table search path fix # <number> <section> ci <section> just adds to search path <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add to table search path . <repeated> either point solution or general <section> power users have had to clone and own the cmake logic for adding tables to implement preferred directory structure and naming patterns in searching for the table files . currently not a good way ( that i know of ) to customize : <url> <section> some way to customize the search path . <repeated> or we could just do a point solution where we add the desired search path for this stakeholder . if ( <allcaps> exists </allcaps> "" ${ mission_defs } /${ <allcaps> tgt </allcaps> } / tables / ${ <allcaps> tblwe </allcaps> } . c "" ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"scrub all <allcaps> cfe ut </allcaps> stub functions <section> the <allcaps> cfe </allcaps> stub functions remain incomplete and inconsistent . they need a scrub to bring everything up to the level it should be . <section> - all functions prototyped in the <allcaps> cfe </allcaps> public <allcaps> api </allcaps> headers ( the <code> dir ) should also have a stub defined . - all arguments should be registered in the context so the complete context is available within ut hook functions . - the argument names should always match the prototype . <section> joseph hickey , vantage systems , inc .",2.0
"document the cmake build system <section> our documentation does not explain to users how the build system works and how to customize it for their needs <section> a clear description and possibly some graphics showing how the different cmakelists files link with each other and how dependencies flow . from <allcaps> cfs </allcaps> - <number> : document dependencies based on features used ( xxd for "" embedded "" files ) <url> it might make more sense to move this into the github . com / nasa / cfs instead <section> related to conversation started in <url> <section> gerardo e . cruz - ortiz",1.0
"remove getlastsenderid ( ) <allcaps> api </allcaps> and replace with a recvmsg ( ) <allcaps> api </allcaps> that returns the appid of the sender of the message being received <section> the current cfe_sb_getlastsenderid ( ) <allcaps> api </allcaps> is broken , as indicated in # <number> and # <number> , but also as discussed at today ' s <allcaps> ccb </allcaps> , the intent and use - case is really "" who sent *this* message "" not "" who sent the *last* message "" on a pipe . in fact , <allcaps> sbn </allcaps> is currently using this <allcaps> api </allcaps> to prevent <allcaps> sbn </allcaps> message loops , and this <allcaps> api </allcaps> does not work correctly for that purpose . <section> the suggestion is to remove the getlastsenderid ( ) <allcaps> api </allcaps> entirely , and add a new receive method like : <code> that has an additional out parameter which will contain the appid of the app that sent the message returned in the bufptr . <section> <email>",2.0
"rogue license in cmake file <section> <url> <allcaps> nosa </allcaps> is wrong ( it ' s apache <number> ) , and no other cmake files are marked . <section> either mark all the cmake files in the same way with the correct license , or remove . clear guidance for apache <number> cmake files not found , fine with either solution ( trivial fix , already scripted ) <section> n / a <section> found during <allcaps> osal </allcaps> license updates . <repeated> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"secondary header : extracting wrong bits for command on <number> - bit <allcaps> arm </allcaps> platform the tools / . <repeated> / cmdutil has a test to - enable - tlm . sh command to test commands send to a running cfs session #. / core - cpu1 . the command code extracted through the function , cfe_sb_getcmdcode ( ) . <repeated> eventually calls the macro , ccsds_rd_fc ( . <repeated> ) . this macro masks and shifts bits to extract the command code ; however , the cfe / fsw / cfe - core / src / inc / ccsds . h need the following minor modification . original <hashtag> define </hashtag> ccsds_rd_fc ( shdr ) ccsds_rd_bits ( ( shdr ) . command , 0x 7 f00 , <number> ) my change <hashtag> define </hashtag> ccsds_rd_fc ( shdr ) ccsds_rd_bits ( ( shdr ) . command , 0x0 0 7 f , <number> ) once this code change is made , no problems . if this is a bug then the masking and bit shifting for all the secondary header should be changed else please let me know what i might be doing wrong . platform beaglebone : arm <number> <number> - bit linux beaglebone <date> - ti - r42 <hashtag> 1 buster </hashtag> <allcaps> smp preempt </allcaps> tue <date> <time> <allcaps> utc </allcaps> <number> armv7l <allcaps> gnu </allcaps> / linux",3.0
"cf_es_startapplications ( ) uses o_rdonly instead of os_read_only <section> latest os_open ( ) does not support o_rdonly flag <section> just observation trying to find other bug - no solution for that one yet . <repeated> <section> correct <hashtag> define </hashtag> use <section> if applicable , add references to the software . <section> - docker - os : linux fb2def16b3c1 <date> - microsoft - standard # <number> <allcaps> smp </allcaps> wed <date> <time> <allcaps> utc </allcaps> <number> x86_64 x86_64 x86_64 <allcaps> gnu </allcaps> / linux - versions [ versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> ] <section> add any other context about the problem here . <section> maurice smulders / geneva technologies inc",0.0
cfe_sb_timestampmsg in ut_sb_stubs . c does not record msgptr argument value <section> the value passed into cfe_sb_timestampmsg cannot be checked because the context value is not put into the ut_stub_copyfromlocal function . <section> write a unit test that attempts to check this value by setting up ut_setdatabuffer . test fails because the value was never saved so it will not equal the expected value . <section> ut_setdatabuffer when used for cfe_sb_timestampmsg will copy the argument value from local ( ut_stub_copyfromlocal ) . <section> current code : <code> <section> - hardware : pc - os : rhel7 - <number> . <number> - <number> . <number> . el7 . x86_64 - versions cfe <number> <section> add any other context about the problem here . <section> full name and company / organization if applicable,0.0
"consolidate implicit entries in mission_deps to defaults file <section> the build currently sets <code> as a list of dependencies which is basically the <allcaps> cfe </allcaps> core and <allcaps> osal </allcaps> by default . there is a desire to consolidate all "" fixed "" entries into a separate defaults file for increased visibility and manageability . <section> these two dependencies can be consolidated into the <code> default list being proposed in pr # <number> , but this also depends on # <number> so it needs to be implemented separately . <section> this is a dependency of both pr # <number> and # <number> . original discussion here : <url> <section> joseph hickey , vantage systems , inc .",2.0
"failure during cfe_es_exitapp if app calls cfe_tbl_unregister <section> should an app call cfe_tbl_unregister ? on cfe_es_exitapp i get : <code> the documentation ] ( <url> no longer says anything about it so i am starting to think it should not be used . the [ sample_app <url> in the cfs repo also does not call cfe_tbl_unregister either . the code seems to say we should though : <url> <section> <number> . register table <number> . unregister table <number> . call cfe_es_exitapp <section> no errors on exit <section> n / a <section> - hardware : laptop - os : linux - versions : versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> <section> n / a <section> philip cooksey , <allcaps> nasa </allcaps> ames",0.0
"implement generic location for <allcaps> cfe </allcaps> modules <section> there are a number of new modular add - ons for <allcaps> cfe </allcaps> that should be distributed with <allcaps> cfe </allcaps> core but are not really part of the "" core "" proper . such as : - test framework apps - message accessor library these modules should be with the <allcaps> cfe </allcaps> core so that users get a sensible baseline when cloning the <allcaps> cfe </allcaps> core repo as the <allcaps> cfe </allcaps> itself depends on / uses them , but these modules can also be replaced with customized versions at the user discretion . <section> proposal is to introduce a new top level directory <code> to hold these items . this needs to be added to the module path and also to provide a "" defaults "" file that can select the default set ( s ) of modules to include if the user does not override / replace them . <section> joseph hickey , vantage systems , inc .",2.0
"version <number> msgid construction does not match description , overloads bits <section> version <number> code takes the full <allcaps> apid </allcaps> ( 0x 7 ff mask ) , or ' s in a bit for cmd / tlm ( 0x 8 0 mask ) then or ' s in the subsystem id shifted by <number> that means if a user defines an <allcaps> apid </allcaps> of 0x 8 0 for a telemetry message ( which is valid per <allcaps> ccsds </allcaps> ) , the system will report it as type cmd if it gets the type from the msgid . it ' s also a collision between 0x 7 bits from the subsystem id and the 0x 7 0 0 bits of <allcaps> apid </allcaps> . basically logic does not mirror : cfe_sb_setmsgid of 0x 7 ff - > <allcaps> apid </allcaps> = 0x 7 f , type = cmd , subsystemid = <number> cfe_sb_getmsgid from <allcaps> apid </allcaps> =0 x7ff , type = tlm , subsytemid = <number> - > msgid = 0x 7 ff <section> n / a - code inspection <section> get / set should mirror ( setmsgid should not overload bits ) <section> <url> <url> <url> <section> n / a <section> uncovered as part of # <number> work <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"document configs to indicate that <allcaps> max </allcaps> string sizes do not include null - terminator <section> there is a laundry list of string size definitions in sample_mission_cfg . h , cpu1_platform_cfg . h , and default_osconfig . cmake that should be documented as to whether the setting includes a byte for a null - terminator ( so say <code> is defined as <number> , does that mean i must limit my table name to <number> characters plus the null - terminator ? ) this is related to # <number> . <section> <email>",1.0
"further simplify sb unit tests <section> recently the software bus unit tests were updated to employ macros for common code bits , but this only amplifies the fact that the sb unit tests do not follow the typical ut assert model . in particular , they "" collect "" a bunch of conditions together and then assert at the end that all the conditions where true . there is no reason to do this deferred reporting with ut assert , and it only serves to obfuscate the true failure because the ut assert failure message line number can be quite different than what actually failed . <section> now that the macros / wrappers are in place , rather than having them only mimic the old test logic , have them implement the preferred ut assert patterns . - remove <code> global variable . do not keep global state outside ut assert . - remove separate text messages inside "" if "" conditionals and replace with ut assert statements . that ' s what the ut assert <allcaps> api </allcaps> is for , after all . - remove <code> compile - time option . the ut assert has a runtime verbosity flag , just call <code> and the message will only be printed when set to verbose mode . <section> this really just the next step along the path to using ut assert as it was intended , and removing the "" compatibility crutches "" that were put into place because <allcaps> cfe </allcaps> ( and sb in particular ) did not employ the same test patterns as other apps / modules . <section> joseph hickey , vantage systems , inc .",2.0
cfe_sb_validatechecksum implementation does not match description <section> cfe_sb_validatechecksum claims it returns true if not supported : <url> but also claims it returns false : <url> and then implements a false return : <url> <section> read the code . <section> consistency <section> see above <section> n / a <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"msgid abstraction - add <allcaps> api </allcaps> to translate between topic id and msgid <section> currently applications hard - code the <allcaps> mid </allcaps> value they use for both publication of telemetry and subscribing to commands and / or telemetry from other applications . this is typically done via a header file such as <code> . the problem is in a multi - <allcaps> cpu </allcaps> environment this is a barrier ( and often the only barrier ) to having a single binary build be loaded onto multiple processors for core apps within <allcaps> cfe </allcaps> , this is already done by assigning a message "" topic id "" to each core app , which is an offset from a base <allcaps> mid </allcaps> . for instance , in <code> we have : <url> and "" topic "" definitions : <url> and in <code> this organizes it into message ids by topic : <url> offsetting a base <allcaps> mid </allcaps> by a topic value is a completely logical way to solve the issue of running the same code on multiple cpus and assigning different <allcaps> mid </allcaps> values , but <code> values are supposed to be abstract . there should be no assumption that they can be added together like this . additionally , the same translation should be implemented as a runtime <allcaps> api </allcaps> , rather than forcing the value to be computed only at compile time . <section> add a new <allcaps> api </allcaps> to software bus that allows determining a <allcaps> mid </allcaps> value at runtime , given a topic id along with an instance number . for instance : <code> this can be further simplified for "" local "" requests by getting the instance number from the <allcaps> psp </allcaps> , for example , something like : <code> would return the <allcaps> mid </allcaps> of the topic on the current / same <allcaps> cpu </allcaps> . topic ids can be assigned exactly as they are today ( at least for now ) , because they can be assigned at mission scope and are agnostic to <allcaps> cpu </allcaps> / instance number . furthermore , the translation between topic id and and msgid need not be limited to a simple addition / bitmask - the conversion can be a implemented in a user - supplied library and customized based on however a mission chooses to allocate its <allcaps> mid </allcaps> values for routing . subscription requests would then be simplified . for example in es , the hk subscription in : <url> would become : <code> this would in turn make all the <code> header files obsolete and unnecessary . <repeated> because all cpus can use the same topic ids and translate at runtime . <section> message ids can also be assigned in a separate configuration table and loaded via <allcaps> tbl </allcaps> services , which is supported today if the application is written that way , but most are not . for apps that do not already use <allcaps> tbl </allcaps> services for config , it is a fairly substantial change to add it . it is significantly easier to change the <allcaps> api </allcaps> used to translate the <allcaps> mid </allcaps> as proposed here to make the app <allcaps> cpu </allcaps> / instance agnostic , rather than introduce a configuration table for this purpose . <section> obviously not for <allcaps> cfe </allcaps> <number> . <repeated> but recommended to discuss for <number> / <number> or whenever . we might want to consider changing the name from <code> to <code> ( or something ) to make it clearer . but fundamentally its ok , and it still would apply even if the topics are assigned by a tool / database of some type in the future . <section> joseph hickey , vantage systems , inc .",2.0
"low cfe_mission_max_file_len and cfe_tbl_filedef ( . <repeated> , "" sample_app_table . tbl "" ) causes silent non - truncation <section> i was scratching my head why my table file was named "" sample_app_table . tbl \ <number> "" until i realized that cfe_mission_max_file_len is defined as "" <number> "" and "" sample_app_table . tbl "" is exactly <number> characters . if i had one more char , the compiler would err . but it accepts static definition of structs using strings that are the exact length , which loses the null terminator . <section> should allow file names of cfe_mission_max_file_len chars . <section> <email>",0.0
"fix # <number> , remove refs to ccsds data structures <section> replace all direct references to data types defined in <code> with the abstract type defined in <code> . fixes # <number> <section> build and run <allcaps> cfe </allcaps> , sanity check , confirm all unit test pass . <section> no impact to behavior . <section> ubuntu <number> <section> there are similar changes to apps , too , which will be separate prs ( not submitted yet ) . <section> joseph hickey , vantage systems , inc .",2.0
"improve handling of platform config <section> almost every app , including the <allcaps> cfe </allcaps> core apps , have some sort of "" platform scope "" internal config options . and the way we handle this for apps and external entities is currently different than the way we handle this for <allcaps> cfe </allcaps> core . to move forward we need to consolidate this into a single , consistent method that can be applied for both external apps and core apps . <section> cmake already generates the <code> file so with some tweaks we can get it to work for everything . there are several possible approaches to consider : option <number> : do we generate a single "" monolithic "" platform header file and let all apps include it ? - advantage : would look basically like the current "" cfe_platform_cfg . h "" and we can even keep the name , preserving backward compatibility - disadvantage : would contain configs for every app / module on the platform thereby giving access to all sorts of out - of - scope info , no way to enforce apps to use only their own config items , so they could inadvertently break <allcaps> abi </allcaps> consistency by using config items they do not own . option <number> : do we generate a per - app "" focused "" platform header file which is only used by that app ? - advantage : cleaner , better scoping , only give apps / modules a header file containing their own config items , they can not use what they can not see , and thereby can not introduce unexpected <allcaps> abi </allcaps> dependencies . - disadvantage : would probably need to be a different name , as we can not call everything "" cfe_platform_cfg . h "" ( too confusing ) , and would probably ( eventually ) require breaking up the current cfe_platform_cfg . h into a config file per core app ( es_platform_cfg . h , evs_platform_cfg . h , etc ) . in the current <allcaps> cfe </allcaps> core there are examples of cross - pollination too , where <allcaps> evs </allcaps> uses data structures defined by es which are based on platform config . so these become undocumented / uncontrolled <allcaps> abi </allcaps> dependencies . we ' d have to fix those . <section> option <number> is cleaner but arguably more work , might take a little longer to implement , and have a bigger impact on apps . this type of issue is coming more to the forefront when considering things like # <number> , but there have been periodic issues posted in the past regarding the "" weirdness "" around the way <code> is handled , so it would be good to generally fix that too , but need to get some sort of community consensus before implementing anything . <section> joseph hickey , vantage systems , inc .",2.0
"cfe_evs_register should log or send an event when numeventfilters > cfe_platform_evs_max_event_filters <section> when numeventfilters is > cfe_platform_evs_max_event_filters when calling cfe_evs_register , the specified filter table can get silently truncated . in addition , the filters parameter should be marked const as it is copied into the filter table . and not modified . <section> send a message to syslog warning of the truncated filter table <section> send an event message using the <allcaps> evt </allcaps> appid <section> this truncation happens for the ci open source app which has <number> events , but the default cfe_platform_cfg only supports <number> event filters . <section> john n pham , northrop grumman",0.0
"replace "" - - whole - archive "" link switch <section> the <allcaps> cfe </allcaps> core executable link process uses <code> to ensure that all functions provided in libraries are actually linked into the executable . normally during a link procedure , if a compilation unit within a static library does not resolve any unresolved symbol ( i . e . does not implement anything that is actually called by the application ) it is dropped . however because <allcaps> cfe </allcaps> dynamically loads applications / libraries at runtime , this can be a problem if a particular <allcaps> api </allcaps> is only invoked by apps and not by <allcaps> cfe </allcaps> itself . the <code> linker flag does accomplish the goal of making sure all the apis are linked in and available for application use , but it has problems : - the switch is not really supported by cmake , it requires a backdoor approach to add it via <code> . - adding using this method requires the full string of the exact option , which is specific to the <allcaps> gcc </allcaps> / ld toolchain paradigms other toolchains might have a similar option , but would require patching the link line to support them . - even when using <allcaps> gcc </allcaps> , the exact option string also differs depending on whether <code> or <code> tool is used for the final link step . ( in the former case , a <code> prefix is required to pass the option through to the linker stage ) . this has been a frequent issue for <allcaps> fsw </allcaps> target builds in that there is no reliable way to determine if this extra prefix is needed . <section> a possible alternative would be to use the <allcaps> osal </allcaps> "" static symbol "" feature to pull in every <allcaps> api </allcaps> that should be available for application use . <section> leave as - is . <section> downside of this approach is that it requires maintaining a separate list of every public <allcaps> api </allcaps> that <allcaps> cfe </allcaps> core + <allcaps> osal </allcaps> is supposed to contain . however , this is already ( somewhat ) done for unit test stubs . the upside is that it can help catch errors of missing functions . this may become relevant if / when users are allowed to override parts of <allcaps> cfe </allcaps> with their own implementation ( e . g . issue # <number> ) . if a required <allcaps> api </allcaps> is missing , this can detect it early and generate a linker error , whereas the current approach will get a runtime error only if / when an application is loaded that tries to use the missing <allcaps> api </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"remove references to "" <allcaps> ccsds </allcaps> "" structures outside of <allcaps> cfe sb </allcaps> . <section> as a prerequisite to # <number> , all modules other than sb should __not__ refer to the "" <allcaps> ccsds </allcaps> "" data types and macros . <section> remove references to the <code> header file along with any direct references to types defined in this file . use the types or abstractions defined in <code> instead . <section> mostly an issue for the "" send hk "" commands that accept a <code> structure . <section> joseph hickey , vantage systems , inc .",0.0
"add user - specified extra modules to build system <section> as a prerequisite to # <number> , the user needs to have the ability to specify their own set of extra modules to provide for the features they are customizing . <section> a new setting in <code> that allows users to add their own customization layers . this is similar to but slightly different than loadable apps in that : - the same set / config should be applied to all cpus ( i . e . if using for a message abstraction layer , all cpus should share the same one ) . so it belongs as a global setting , rather than a setting associated with a single target . - these would be linked with cfe core , rather than as dynamically - loaded libraries because something like a message abstraction layer is needed by sb itself , so it can not be loaded later . <section> initial function would be very simple - just include the libraries in the build , nothing more . <section> joseph hickey , vantage systems , inc .",2.0
"unit test hooks should refer to context elements by name ( future proof ) <section> old context elements were position based , nasa / osal # <number> allows getting by name so order added in stub no longer matters . <section> get context by name to future - proof against stub changes . <section> none <section> # <number> - example <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"ut_sb_stubs . c decription comment for cfe_sb_rcvmsg does not match code <section> in ut_sb_stubs . c description comment for cfe_sb_rcvmsg incorrectly states that first call returns cfe_success , while additional calls return - <number> . it appears that it will always return cfe_success . <section> steps to reproduce the behavior : <number> . write a test where cfe_sb_rcvmsg is called at least twice . <number> . check result on first call = = cfe_success , will pass <number> . check result on second call = = - <number> , will fail ( result is cfe_success instead ) <number> . additional calls have same result as <number> above . <section> rewrite comment to show that result returned is always cfe_success , unless the commented behavior is what is desired , then fix code to accomplish that . <section> <code> <section> - hardware : pc - os : <allcaps> rhel </allcaps> workstation <number> ( maipo ) , linux <number> . <number> - <number> . <number> . el7 . x86_64 - versions cfe <number> <section> add any other context about the problem here . <section> alan gibson , <allcaps> nasa </allcaps> , <allcaps> gsfc </allcaps> - <number>",0.0
"separate secondary header access <allcaps> api </allcaps> ' s from sb <section> need to support # <number> software bus logic does not care about message format , just use message access apis like all the other services . <section> <allcaps> msg </allcaps> module and header file for all the message getter / setters . deprecation of the <allcaps> sb api </allcaps> ' s . code separation to support source selection / mission configuration . <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"clarify / clean up spacecraft / cpu names / ids <section> defined in platform config : - cfe_platform_cpu_id ( referenced by cfe_platform_tbl_valid_prid_1 and cfe_cpu_id ) - cfe_platform_tbl_valid_prid_1 is used in internal table logic - cfe_cpu_id looks unused - cfe_platform_cpu_name ( referenced by cfe_cpu_name ) - cfe_cpu_name looks unused defined in mission config : - cfe_mission_spacecraft_id ( referenced by cfe_platform_tbl_valid_scid_1 and cfe_spacecraft_id ) - cfe_spacecraft_id looks unused - cfe_platform_tbl_valid_scid_1 used in internal table logic defined by cmake : - cfe_cpu_id_value ( from <allcaps> tgtid </allcaps> ) , sets . default_cpuid in target config - cfe_cpu_name_value ( from <allcaps> tgtname </allcaps> ) sets . default_cpuname in target config - cfe_spacecraft_id_value ( from spacecraft_id ) sets . default_spacecraftid in target config <section> remove / deprecate unused and / or clarify use / intent . looks like spacecraft id may actually be defined differently ( <number> vs 0x 4 2 ) . <section> stay confused . <section> table use looks like it could lead to inconsistencies . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , triggered by <user> comments on nasa / psp # <number>",2.0
"fix # <number> , resolve highest msgid of 0 xffff bug <section> changes message key from uint16 to uint32 to avoid rollover and system hang fix # <number> fix # <number> <section> steps taken to test the contribution : <number> . set cfe_platform_sb_highest_valid_msgid to 0 xffff <number> . built ( <allcaps> simulation </allcaps> = native ) and ran , confirmed startup <number> . ci - <url> <section> full message id range available <section> - hardware : cfs dev <number> - os : ubuntu <number> - versions : bundle w / this change <section> identified / resolved by <allcaps> jsc </allcaps> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
setting highest valid message id ' s to 0 xffff hangs cfe <section> given max number of message keys is <number> + highest valid msgid : <url> and message key is uint16 : <url> setting cfe_platform_sb_highest_valid_msgid to 0 xffff results in forever loop in : <url> <section> set cfe_platform_sb_highest_valid_msgid to 0 xffff and build / run . <section> full <number> bits of message id should be usable . <section> see above <section> - hardware : cfs dev <number> - os : ubuntu <number> - versions : master bundle <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( per <allcaps> jsc </allcaps> identification of the issue ),0.0
"cfe_es_oneapptlm_payload_t telemetry struct contains non mission - scoped - sized array <section> unsure if this is intentional , but <code> is directly used by <code> which is ground visible . <code> uses <code> , whereas all other ground - visible telemetry uses the mission - scoped <code> . <section> <code> should be structured such that the size is dependent solely on mission - scoped constants and consistent amongst all cpus . this is an enhancement as opposed to a bug report since in practice both constants are likely to be same . <section> none <section> none <section> john n pham , northrop grumman",0.0
"ut_sb_stubs . c needs a stub for cfe_sb_deletepipe <section> cfe_sb_deletepipe does not have a stub in ut_sb_stubs . c causing undefined reference error when building unit tests for an app that uses this call . <section> add the stub for cfe_sb_deletepipe with full context tracking . <section> create my own locally in the app ' s unit test , but this does not help everyone . <section> alan gibson , <allcaps> nasa </allcaps>",2.0
"ut_sb_stubs . c needs a stub for cfe_sb_zerocopysend <section> cfe_sb_zerocopysend does not have a stub in ut_sb_stubs . c causing undefined reference error when building unit tests for an app that uses this call . <section> add the stub for cfe_sb_zerocopysend with full context tracking . <section> create my own locally in the app ' s unit test , but this does not help everyone . <section> alan gibson , <allcaps> nasa </allcaps>",2.0
"ut_sb_stubs . c needs a stub for cfe_sb_zerocopygetptr <section> cfe_sb_zerocopygetptr does not have a stub in ut_sb_stubs . c causing undefined reference error when building unit tests for an app that uses this call . <section> add the stub for cfe_sb_zerocopygetptr with full context tracking . <section> create my own locally in the app ' s unit test , but this does not help everyone . <section> alan gibson , <allcaps> nasa </allcaps>",2.0
cfe / <allcaps> sch </allcaps> deadlocks on exit on linux using modules 9 5 f34d25cb2843b8ba9db6338bb0b53cb3e38f92 cfe c2bcebbc4d7e60a41b604e9acfc8af3c60b8536a osal 3 7 ee8eb2d7ce006dc1570b920ae75a7ac5f89d27 psp there seems to be a deadlock upon exit for timers being used by <allcaps> sch </allcaps> . see stacktrace <code>,0.0
"fix # <number> , typo in cfe_es_restartapp writetosyslog <section> fix typo fix # <number> <section> none , typo <section> typo fixed <section> n / a <section> n / a <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , utilize ut macros in sb_ut <section> cleanup of sb_ut . c fix # <number> fix # <number> <section> <email> <allcaps> edit </allcaps> : added fix # <number>",2.0
"utilize new macros and correct some sb_ut . c merge conflicts <section> doing the merge conflicts for the ic merges , i mis - merged a couple of joe ' s changes ( fix # <number> ) . <section> <email>",2.0
"align all software bus message definitions <section> as an extension to the changes in issue # <number> / pull # <number> , the same paradigm should be applied to all other message definitions . this is currently only working "" by chance "" in that the payloads already contain a uint32 ( or larger ) value so it is already aligned . <section> change the header structure which is currently defined as a <code> array into either cfe_sb_cmdhdr_t or cfe_sb_tlmhdr_t so it will be correctly aligned . <section> it is safe to assume all remaining message types were already <number> - bit aligned because there were no remaining compiler warnings about this , which means this change by itself will not have any effect on the existing message sizes or alignment . however , when moving to a <number> - bit build it may become necessary to enforce <number> - bit alignment rather than <number> - bit alignment for <code> and in that case , the sizes and padding may change from what it currently is . <section> joseph hickey , vantage systems , inc .",2.0
"tblhandle used before validation in cfe_tbl_load <section> tblhandle used before validation <section> see code snip , invalid handle could cause fault <section> validate handle before using <section> <url> <section> in code <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , resolve doxygen warnings for tbl <section> fixes doxygen warnings for the tbl subsystem . fix # <number> <section> make doc , grep "" <allcaps> tbl </allcaps> "" build / doc / warnings . log <section> <email>",1.0
"cfe_es_cleanuptaskresources attempts to delete child task twice <section> cfe_es_cleanuptaskresources appears to attempt to delete a child task twice , first via cfe_es_cleanupobjectcallback and subsequently via a direct call to os_taskdelete <section> on linux , call cfe_es_restart_app on an app that has a child task , such as ci , fm , or hs in vxworks , can induce also by inducing an exception causing an application restart <section> app should exit and restart cleanly <section> see cfe_es_cleanuptaskresources <section> - pc , sp0 - s - os : linux , vxworks - versions [ e . g . cfe <date> , <allcaps> osal </allcaps> <date> , <allcaps> psp </allcaps> <number> . <number> , ci , fm , hs ] <section> my colleague alan wang attempted the following : <code> another colleague john hueber reported the following : > ci doesn ’ t restart when commanded because it calls cfe_es_exitapp with the wrong status ( running ) . > if i put a <number> second task delay in ci_appmain before calling cfe_es_exitapp the tasks restarts fine . > it looks like whenever cfe_es_exitapp gets called before the task is deleted then the restart is unsuccessful . > if the task is deleted before it gets to cfe_es_exitapp then the restart is successful . > if the task has child tasks then it takes longer to get to deleting the main task because the child task is in the list of resources that have to be deleted . > there is a bug in this part because deleting the resources of the task also deletes child tasks , and when the resources are deleted cfe_es_cleanupapp tries to delete child tasks ( again ) , which fails and the failure prevents a restart . > > i put ci in apps / hs / fsw / tables / hs_xct . c ( hs_xct_type_app_main ) and apps / hs / fsw / tables / hs_amt . c ( hs_amt_act_app_restart ) > then caused an exception in ci no - op processing by clearing an instruction . with the <number> second delay in ci_appmain the restart was successful . > without the delay the restart is unsuccessful . > <section> john n pham , northrop grumman",0.0
"latex generation issues of mission doc <section> when building the <code> file , multiple warnings are observed from the tex system . additionally , the make process itself ends in error . note that currently the <code> file still gets generated . <section> steps to reproduce the behavior : <number> . make sure that <code> is set to <code> in <code> <number> . do a <code> in <code> <number> . go to <code> <number> . do a <code> <number> . observe all the issues printed to stdout <section> latex warnings should not be generated . make should not end in error <section> leor bleier , <allcaps> nasa gsfc </allcaps> \ code <number>",1.0
"doxygen warnings <section> doxygen warnings due to lack of documentation in the following files : - <code> - <code> specifically for function <code> in both files <section> steps to reproduce the behavior : <number> . build documentation using <code> <number> . observe relevant warnings in <code> <section> functions should be properly documented to avoid warnings <section> leor bleier , <allcaps> nasa gsfc </allcaps> \ code <number>",1.0
remove conditional <allcaps> tbl </allcaps> compilation logic <section> with # <number> <allcaps> tbl </allcaps> is no longer optional ; conditional code / compilation configuration should be removed . <section> <email>,0.0
"remaining alignment warnings in unit test <section> there are a few remaining warnings in the unit test stubs and test cases when compiling on an architecture that has strict alignment requirements . <section> build with enable_unit_tests = true on a platform that requires strict alignment ( e . g . <allcaps> sparc </allcaps> , <allcaps> mips </allcaps> , etc ) . <section> should compile cleanly <section> example error ( first one to appear in my build ) : <code> <section> ubuntu <number> , cross compiling for <allcaps> mips cpu </allcaps> . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , reference to deprecated cfe_spacecraft_id <section> change to <code> , which is the non - deprecated symbol . fixes # <number> <section> build with extended header and <code> and confirm success . <section> build now works with both extended headers and omit_deprecated options set . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"reference to deprecated symbol when extended header enabled <section> if <code> is defined then this references a deprecated symbol and fails to build when <code> is also set . <section> build with both <code> mission config and <code> compile option . <section> should build successfully . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc",0.0
"( <allcaps> wip </allcaps> ) fix # <number> , es comment cleanup <section> draft to consider for comment updates ( remove end , remove function name ) fix # <number> <section> none <section> none <section> n / a <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , deprecate <allcaps> cfs </allcaps> / fs time conversion apis <section> deprecates cfe_time_cfe2fsseconds and cfe_time_fs2cfeseconds - in short the conversion / management of local os time vs mission time is not within the scope of cfe ( it does not manage local os time , so does not maintain an appropriate conversion factor ) . utilize the cfe_fs_header_t time for file creation if needed , synchronize local os time with mission time , or use the return from stat as a relative ( with reset caveats ) fix # <number> <section> build and unit test - <allcaps> simulation </allcaps> = native enable_unit_tests = true with and without omit_deprecated = true all passes <section> none other than no longer supporting <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"memory alignment issues in <allcaps> time </allcaps> ( 3 2 bit , mcp750 , ccsds_ver_2 config ) <section> <code> <section> force alignment where possible without changing bits on the wire <section> remove <code> for this build <section> note there are other alignment issues for other configuration options (# <number> , # <number> ) but they do not show up for mcp750 with <allcaps> ccsds </allcaps> version <number> so are not critical to <number> . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"clarify pipe name scope in documentation <section> from <url> > although the pipe names will not collide with other application pipe names in the cfe this not correct , because pipe names <allcaps> will </allcaps> conflict with other application pipe names within the cfe . it is actually <allcaps> osal </allcaps> that enforces uniqueness of queue names which underpin the sb pipes . <section> update the line in the documentation . <section> none <section> see discussion on # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"cfe cmd / tlm packet clean up <section> cfe telemetry / command packets could be organized such that variables are ordered in descending size to reduce overall length . this would make them easier to maintain and remove some of the alignment issues / reduce required padding . there ' s also configurable length elements before spares , which does not make sense if the configuration changes . also should standardize spare / alignment names , many no longer make sense ( why "" <number> "" in example ) : <url> <section> dan knutsen <allcaps> nasa </allcaps> / goddard",2.0
"mismatched variable types in data structures <section> while auditing cfe tlm packets for <number> bit alignment issues , i noticed that we have instances of mismatched variable types in data structures . this results in data being truncated / corrupted . example : in cfe_es . h : : cfe_es_appinfo_t there are multiple addresses ( startaddress , codeaddress , etc ) declared as uint32 . they should be declared as cpuaddr variables - similar to cfe_es_appstartparams_t : startaddress and os_module_address_t : code_address . another example is the priority , stacksize , and exception action variables . see below for declaration trace : cfe_es_parsefileentry : unsigned int priority unsigned int stacksize unsigned int exceptionaction cfe_es_appcreate : uint32 priority uint32 stacksize uint32 exceptionaction cfe_es_appstartparams_t : uint16 exceptionaction uint16 priority uint32 stacksize cfe_es_appinfo_t : uint16 priority uint16 exceptionaction uint32 stacksize <section> dan knutsen <allcaps> nasa </allcaps> / goddard",0.0
"add documentation for <allcaps> tbl </allcaps> event messages in cfe_tbl_events . h <section> the following events are missing documentation : <number> . cfe_tbl_load_val_err_eid <number> . cfe_tbl_load_src_type_err_eid <number> . cfe_tbl_load_filename_long_err_eid <number> . cfe_tbl_load_short_file_err_eid <number> . cfe_tbl_load_tblname_mismatch_err_eid <number> . cfe_tbl_handle_access_err_eid <section> search <code> for <code> <section> add doxygen documentation like the other eids in the file . delete <allcaps> todo </allcaps> comment <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , es start table <section> fix # <number> this is a re - do of the <allcaps> cfe es </allcaps> "" startup "" table code . this includes unit tests ( coverage ) and requested "" volatile "" boot option . <section> both unit tests and running the core <section> this changes es to use a table to load libraries and load and start applications . this is a significant change to the internals , as libraries are loaded and applications are started in the es task ( spawned by the es main task ) and , of course , a table is used instead of a . scr file . - <allcaps> api </allcaps> change : internal <allcaps> api </allcaps> changes - behavior change : loading from . tbl instead of . scr <section> debian <number> vm <section> <email>",2.0
"cfe_sb_getmsgid use , ut_setforcefail does not set the return code ( returns <number> ) . <section> cfe_sb_getmsgid in cfe / fsw / cfe - core / ut - stubs / ut_sb_stubs . c . cfe_sb_getmsgid is not returning the plss_state_det_wakeup_mid set by ut_setforcefail . the problem i see is the msgid is now calculated by the msgptr which points to a buffer . msg ( defined in cfe_sb_rcvmsg ) but this buffer . msg ( streamid [ <number> ] and streamid [ <number> ] ) is set to all zeros and never set to the plss_state_det_wakeup_mid . in cfe6 . <number> , the msgid was calculated from the stubentry data which is set by ut_setforcefail . <section> steps to reproduce the behavior : here is my unit test sequence <code> <code> the msgid is <number> which should be plss_state_det_wakeup_mid . the reason is because the msgptr points to buffer . msg ( set to all zeros ) defined in cfe_sb_rcvmsg <code> the msgptr is passed to the cfe_sb_getmsgid , where the msgid is calculated using <hashtag> define </hashtag> ccsds_rd_sid ( phdr ) ( ( ( phdr ) . streamid [ <number> ] < < <number> ) + ( ( phdr ) . streamid [ <number> ] ) ) the calucated msgid is <number> since msgptr is pointing to buffer . msg which is set to all zeros . <code> note : for ut_default_impl ( cfe_sb_getmsgid ) ; i . i do see plss_state_det_wakeup_mid being used . <section> return plss_state_det_wakeup_mid <section> - hardware - os : centos <number> - versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> , chksm <number> <section> jose tovias <allcaps> caci </allcaps> / <allcaps> lzt </allcaps> technology",3.0
"missing registering contexts in stub functions i ’ ll work this issue the issue causes seg faults cause by not registering contexts . i resolved this by adding the missing registrations . cfe / fsw / cfe - core / ut - stubs / ut_evs_stubs . c : int32 cfe_evs_sendevent ( uint16 eventid , uint16 eventtype , const char * spec , . <repeated> ) { int32 status ; ut_stub_registercontext ( ut_key ( cfe_evs_sendevent ) , & eventid ) ; ut_stub_registercontext ( ut_key ( cfe_evs_sendevent ) , & eventtype ) ; < - - - - - missing ut_stub_registercontext ( ut_key ( cfe_evs_sendevent ) , spec ) ; < - - - - - missing . <repeated> } cfe / fsw / cfe - core / ut - stubs / ut_es_stubs . c : int32 cfe_es_writetosyslog ( const char * pspecstring , . <repeated> ) { int32 status ; ut_stub_registercontext ( ut_key ( cfe_es_writetosyslog ) , pspecstring ) ; < - - - - - missing . <repeated> } expected behavior return register buffer size = <number> when using cfe_evs_sendevent and buffer size = <number> when using cfe_es_writetosyslog . system observed on : hardware os : centos <number> versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> , chksm <number> reporter info jose tovias <allcaps> caci </allcaps> / <allcaps> lzt </allcaps> technology",0.0
"system log / event string table model unification in <allcaps> fsw </allcaps> and ut update <section> for <allcaps> cfe </allcaps> code that generates syslog messages , the coverage testing checks that a particular message was sent to syslog . the ut code uses a string table , but the <allcaps> cfe </allcaps> code has it hard - coded in the code . <section> unify the string table model in <allcaps> cfe </allcaps> so that all <allcaps> cfe </allcaps> code that uses strings for events , syslog , etc . store those strings in said table . this would simplify ut checks and would also allow for localization of the <allcaps> cfe </allcaps> codebase . <section> removing the ut string table would also make things simpler . <section> <email>",2.0
"<allcaps> cfe </allcaps> needs to provide cmake - based config file for <allcaps> osal </allcaps> <section> currently the <allcaps> cfe </allcaps> cmake script generates an <code> file for <allcaps> osal </allcaps> to compile with . <section> after nasa / osal # <number> is fixed ( pr nasa / osal # <number> ) the <allcaps> cfe </allcaps> will need to pass <allcaps> osal </allcaps> a configuration file in cmake syntax , which then <allcaps> osal </allcaps> uses to generate its own <code> . <section> needed for compatibility <section> joseph hickey , vantage systems , inc .",2.0
"cfe_es_send_mem_pool_stats_cc issues <section> there are multiple issues with the cfe_es_send_mem_pool_stats_cc command : <number> . the command / function ( s ) used are fundamentally flawed in that a user can send a seemingly benign command that can result in a segmentation fault if one of the command parameters is incorrect . for example , if the poolhandle parameter is set to zero a segmentation fault will result ( pretty much any value below xfffffe28 faults on my machine ) . this occurs when handle is validated via the cfe_es_validatehandle function . should consider modifying the cfe_es_validatehandle function + updating the unit test to test command on boundary / extreme conditions . <number> . on a <number> - bit machine if the poolhandle parameter is set to a valid value the function will fail . this is because cfe_psp_memvalidaterange – which is called via the cfe_es_validatehandle function as part of the validation process , limits the max memory range of the handle to xffe <elongated> . <number> . on a <number> - bit machine - compiler added padding will be applied to the command . the order of variable declaration should ideally be descending in size to avoid future conflicts . <section> command works nominally and is vetted via combination of unit / functional tests . <section> oracle vm virtualbox os : ubuntu - <number> versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> <section> dan knutsen <allcaps> nasa </allcaps> / goddard",0.0
"pipe name collision discussion <section> in <url> > although the pipe names will not collide with other application pipe names in the cfe , the developer / operator could become confused if every application named their pipe ( s ) "" my_pipe "" . it should be noted , however , that all pipes for a single application must have unique names . this does not seem to be true since when i add two apps that try to have the same pipe name i get a failure . <section> if i use the same . so file in my startup script but change the app name of the second one : <code> i get the following error : <code> as they are both trying to make the same "" app_pipe "" . <section> i thought given the text that the pipe names would still be unique to that application . <section> n / a <section> laptop distributor id : ubuntu <number> . <number> <allcaps> lts </allcaps> versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> <section> n / a <section> philip cooksey <allcaps> nasa </allcaps> ames ( <allcaps> kbr </allcaps> )",3.0
"fix # <number> , sb subscription report control on separate <allcaps> mid </allcaps> <section> moves inter - app commands to separate <allcaps> mid </allcaps> ( like hk request from <allcaps> sch </allcaps> ) . these requests only come from <allcaps> sbn </allcaps> as of now . no longer using the ground command <allcaps> mid </allcaps> . also updates the unit tests to match the changes ( checks new error , updates <allcaps> mid </allcaps> ' s for command tests ) . fix # <number> <section> build and ran tests local , also ci - <url> <section> <allcaps> sbn </allcaps> will need to init command with new <allcaps> mid </allcaps> <section> - hardware : cfs dev server <number> / ci - os : ubuntu <number> - versions : master bundle + this branch <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , remove es_app_debug functionality <section> deletes now unused cfe_es_countobjectcallback and cfe_es_listresourcesdebug . fix # <number> <section> ci - <url> <section> none , flag was undefined <section> - hardware : ci - os : ubuntu <number> - versions : master bundle + this branch <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
global build options no longer global <section> deprecation flags not showing up in build for cfe / apps / <allcaps> psp </allcaps> <section> prep with <allcaps> simulation </allcaps> = native enable_unit_test = true omit_deprecated = true make <allcaps> verbose </allcaps> = true and see the <allcaps> deprecated </allcaps> flags not applied to cfe / apps / <allcaps> psp </allcaps> <section> global flags should be global <section> none <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle ( was testing fix to # <number> ) <section> critical for ci testing . <repeated> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"add "" special "" es shell commands as real commands <section> es special commands using the <allcaps> shell fc </allcaps> and a special string do not follow command processing model , missing requirements , etc cfe_es_listapplications cfe_es_listtasks cfe_es_listresources <section> implement these as real commands <section> delete these <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , string operations on gcc9 <section> ensure clean build , no warnings on string operations using <allcaps> gcc </allcaps> <number> . <number> . fixes # <number> <section> build code with default config , <allcaps> simulation </allcaps> = native <allcaps> buildtype </allcaps> = release on <allcaps> gcc </allcaps> <number> . <number> . confirm successful build with no warning . confirm unit tests passing sanity check <allcaps> cfe </allcaps> operation <section> no impact to behavior <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> some string ops were genuinely incorrect ( particularly in ut ) but some were perfectly ok and handled correctly per the c spec . in particular the new "" rules "" that gcc9 warns about make the <code> library function ( and some others ) somewhat off - limits even if used correctly . the new string truncation checking feature of <allcaps> gcc </allcaps> generates a boatload of false positives and basically makes certain library functions generate warnings even if used correctly , some other projects have been adding <code> compiler flag to avoid this . however with these workarounds <allcaps> cfe </allcaps> is able to build without adding this , but apps might need it . <section> joseph hickey , vantage systems , inc .",0.0
"many string truncation warnings with newer <allcaps> gcc </allcaps> <section> ubuntu has released <number> <allcaps> lts </allcaps> which includes <allcaps> gcc </allcaps> <number> . <number> . when using this compiler it implements a much stricter ( and often over - zealous ) checking of string ops . for instance : <code> <section> build code with default config using <allcaps> gcc </allcaps> <number> . <number> , with optimization enabled and full warnings . <section> code should build cleanly . <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit . <section> unfortunately <allcaps> gcc </allcaps> warns about <allcaps> any </allcaps> construct which <allcaps> might </allcaps> truncate , even if truncation is anticipated and handled properly in the code . <allcaps> gcc </allcaps> now declares that one is never allowed to truncate anything in a c library string operation , even if you read the manual and coded it correctly per the c spec , it ' s still wrong to gcc9 . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , remove old cfe_arinc653 - related tests <section> fix # <number> removes all conditional preprocessing blocks related to cfe_arinc653 . ( only used in <code> and <code> ) . <section> steps taken to test the contribution : <number> . standard build and test procedure . <code> , <code> , <code> set to <code> then <code> , <code> all unit tests passed . no errors reported by cfs executable . <section> none <section> - imac ( retina 4 k , <number> ) - os : ubuntu <number> ( via vmware fusion <number> . <number> ) - <allcaps> gcc </allcaps> : <number> . <number> - versions : master bundle with this commit <section> also successfully built using custom docker images ( centos <number> , ubuntu <number> , and ubuntu <number> ) implementing the standard build procedure . in this context , different combinations of <code> and <code> were used . no errors reported by cfs executable . <section> none <section> guillaume lethuillier personal , individual <allcaps> cla </allcaps> submitted",2.0
"remove es_app_debug ifdef and related code <section> debug code exists in flight code , uses printf , ifdefed out with es_app_debug . undocumented option . <section> remove . <section> n / a <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , deprecate decompress <section> fix # <number> removes untraced capabilities to decompress libraries or apps on load . for non - startup apps , fs can be used . for startup , recommendation is to compress / decompress as part of boot / startup vs individual applications / libs at load . fix # <number> by deprecating decompress it can be moved to the fs app . fix # <number> static code analysis issues in decompress now n / a <section> steps taken to test the contribution : <number> . standard build with and without code deprecated , <allcaps> simulation </allcaps> = native , enable_unit_tests = true <section> no longer automatically decompresses apps / libraries as part of load <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle + this commit <section> fs app updates will add decompress functionality , and decompress is planned to be implemented as a replaceable library <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove old cfe_arinc653 related tests <section> code breaks if cfe_arinc653 is defined . <section> remove old ifdef ' ed out test code <section> none <section> only used in fsw / cfe - core / unit - test / es_ut . c <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"unit tests fail to build when extended headers enabled <section> as a test of the most recent integration candidate , i attempted to verify operation with extended headers but the unit test code fails to build in this configuration . the following errors exist in <code> : <code> <section> build according to instructions , but set : <code> in mission config . <section> build should succeed . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , infer osal_system_bsptype from cfe_system_psp_name <section> normally the <allcaps> cfe psp </allcaps> uses / links with an <allcaps> osal bsp </allcaps> of the same name . this removes the need to explicitly specify osal_system_bsptype in the toolchain file , as it can be reliably inferred . fixes # <number> this is also another alternative way to fix # <number> <section> build with defaults ( as in <allcaps> readme </allcaps> , e . g . a simple <code> ) , as well as <code> , and for i686 - rtems4 . <number> platform . confirm successful build . also "" forced "" a mismatch by hacking the i686 - rtems4 . <number> toolchain to request bad combinations , and confirm that the build system warns of the mismatch now : if <code> is set to <code> , the following warning happens in <code> <code> likewise if the <code> is set to <code> , the follow is seen ( from <allcaps> osal </allcaps> <sad> <code> finally removed settings of osal_system_ostype and osal_system_bsptype from the toolchain and confirmed that code correctly builds without issue , using the pc - rtems <allcaps> bsp </allcaps> and rtems os layers , as expected for this toolchain . <section> - mismatches between <allcaps> psp </allcaps> / <allcaps> bsp </allcaps> / os are now detected and warned about during make prep - only the cfe_system_pspname is actually required to be specified for a <allcaps> cfe </allcaps> build now . others can be omitted . <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit , with i686 - rtems4 . <number> cross target <section> the related change to infer osal_system_ostype from osal_system_bsptype is in nasa / osal # <number> and pull request nasa / osal # <number> . if it is desired to merge separately this can still be merged but it will have to continue setting osal_system_ostype . <section> joseph hickey , vantage systems , inc .",0.0
"define toolchain via <allcaps> tgt </allcaps> <x> _system in sample configuration <section> see <url> cpu toolchain naming hack . <section> transition to defining the toolchain explicitly , eventually remove the hack support logic . <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update build scripts so only cfe_system_pspname needs to be specified <section> currently when cross compiling the user - supplied scripts / toolchain file need to specify three configurations : - cfe_system_pspname - osal_system_bsptype - osal_system_ostype however , although an os layer can have multiple different <allcaps> bsp </allcaps> / <allcaps> psp </allcaps> layers , each <allcaps> psp </allcaps> only works with a specific os layer . <section> the <allcaps> cfe </allcaps> build should only require that cfe_system_pspname is specified . it should automatically choose the right <allcaps> osal os </allcaps> / <allcaps> bsp </allcaps> layers that correspond to that <allcaps> psp </allcaps> . <section> leaving it as - is has a potential for mismatching incompatible layers . <section> joseph hickey , vantage systems , inc .",2.0
"split unit - test files <section> using the eclipse <allcaps> ide </allcaps> , the large size of the unit test source files triggers the "" scalability mode "" . <section> there ' s little reason the source files need to be monolithic , splitting the unit test code ( further ) into separate files organized by <allcaps> api </allcaps> function or groups of related functions will improve organization , readability and performance . <section> leaving the files as - is . <section> <email>",2.0
"make prep broken out of the box <section> prep fails out of the box when following <allcaps> readme </allcaps> instructions : <code> <section> steps to reproduce the behavior : <number> . follow the <allcaps> readme </allcaps> instructions , make prep fails . <section> expected it to default to pc - linux as in the past . <section> the following does not set osal_system_bsptype since cfe_system_pspname and osal_system_ostype is defined . <repeated> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : master bundle <section> short term work around - pass in <allcaps> simulation </allcaps> = native at prep , or likely can define the target system in targets . cmake ( 2 nd approach not tested yet ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"<allcaps> cfe tlm </allcaps> header needs update to correspond with <allcaps> cmd </allcaps> header previous issue # <number> made it so the <allcaps> cmd </allcaps> secondary header was always in a consistent byte order , such that the content is independent of the endianness of the machine which processes / generates the packet . the submitted fix for this only changed the <allcaps> cmd </allcaps> header , leaving the <allcaps> tlm </allcaps> header alone . for consistency , the network byte order rule should be applied to the <allcaps> tlm </allcaps> header as well . _originally posted by <user> in <url>",2.0
utilize cmake interface libraries <section> see conversation around <url> interface libraries may be a cleaner approach than current implementation <section> consider utilizing interface libraries <section> leave as - is <section> see # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
replace os_fs_ * return codes with common definitions <section> there is mixed use of os_ * and os_fs_ * return codes . <section> suggest deprecation of the os_fs_err_ * defines and switch to common definitions . <section> nasa / osal # <number> nasa / osal # <number> <section> dan knutsen <allcaps> nasa </allcaps> / goddard,2.0
"memory alignment issue in es <section> <code> <section> resolve bug . <section> none . <section> other shell issues , # <number> , # <number> , etc . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"question on table service update procedure and notifications by message <section> i guess some more documentation on this procedure would be beneficial when talking about the table services . this is related to issue # <number> but more on documenting that feature . specifically , there really is not a lot of documentation on notify by message function : > int32 cfe_tbl_notifybymessage ( cfe_tbl_handle_t tblhandle , cfe_sb_msgid_t msgid , uint16 commandcode , uint32 parameter ) ; we want to use this to not have to poll for changes which works but i am slightly confused on the notification process . <section> i have enabled notify by message and i execute the following to test the app : <number> . upload new file to "" spacecraft "" ( just a new table with the table ' s exact name in it ) <number> . send command to load table ( this goes into inactive buffer ) : <number> . . / cmdutil - - endian = le - - host = localhost - - port = <number> - - pktid =0 x1804 - - cmdcode = <number> - - string = "" <number> <annoyed> cf / apps / sampleapplettb2 . tbl "" <number> . send command to validate table in inactive buffer <number> . . / cmdutil - - endian = le - - host = localhost - - port = <number> - - pktid =0 x1804 - - cmdcode = <number> - - half = <number> - - string = "" <number> : sampleapplet_app . satable1 "" <number> . <section> <number> . send command to active table <number> . . / cmdutil - - endian = le - - host = localhost - - port = <number> - - pktid =0 x1804 - - cmdcode = <number> - - string = "" <number> : sampleapplet_app . satable1 "" <number> . <section> questions : first , is this the ideal process for updating tables in flight ? i mostly had to piece together this by looking through the public headers . if i happened to just mistakenly miss some documentation on this then a pointer to that documentation would be awesome ! second , why is there a message after the validation function if the app can not do anything since the new table is still in the inactive buffer . is this a way to potentially ask the app to release the table pointer if it had been holding on to it ? <section> n / a <section> maybe there should be a issue format for questions ? <section> philip cooksey , <allcaps> nasa </allcaps> ames thank you for your time and help !",3.0
"unit tests fail to build when message_format_is_ccsds_ver_2 is enabled <section> unit tests fail to build when message_format_is_ccsds_ver_2 is enabled <section> enable message_format_is_ccsds_ver_2 in <code> run <code> <section> compilation succeeds , however build actually fails due to missing <code> <section> this can be fixed by doing the following <code> however , subsequently a checksum error is encountered when running the tests . this was worked around by doing the following , but unsure if the workaround is correct . <code> <section> - hardware : n / a - os : rhel7 - versions cfe <date> <section> john n pham , northrop grumman",0.0
document length limit of os_max_path_len and os_max_api_name includes null terminator <section> documentation not clear <section> document length limit of os_max_path_len and os_max_api_name includes null terminator <section> none <section> nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"unit tests need to link with ut_coverage_compile_flags / ut_coverage_link_flags <section> nasa / osal # <number> cleans up the compiler flag management , and as part of this it exports two variables , ut_coverage_compile_flags and ut_coverage_link_flags , rather than a single ut_c_flags value . <section> the unit tests need to use these variables , not ut_c_flags . <section> needs to be included with the nasa / osal # <number> merge . <section> joseph hickey , vantage systems , inc .",0.0
"cfe_tbl_loadfromfile ( ) should automagically add extension one issue that is quite an annoyance with the text - based startup file is that it lists the fully - qualified file name , including extension . the issue is that the extension varies from system to system , so when i build with e . g . <code> the extensions need to be <code> , but when building for <allcaps> rtems </allcaps> it needs to be <code> . ideally i ' d like to see a solution that only lists the basename of the app file in the user - maintained source file , and the extra info , in particular the extension , is attached by the build system based on the file type of loadable modules for the particular platform you are building . however the first step to any of this would be to get this table - based change in place , then smarter translation on the build side could be a follow - on . _originally posted by <user> in <url>",2.0
"improve es reset area memory allocation <section> currently the <allcaps> psp </allcaps> provides a single <allcaps> api </allcaps> <code> which is sized according to a user - specified <code> . with a note that says : > this area must be sized large enough to hold all of the data structures . it should be automatically sized based on the cfe_es_resetdata_t type , but circular dependancies in the headers prevent it from being defined this way . this is far from ideal , and in the default configuration 1 7 0 kib is allocated for this area where only 1 2 9 kib is actually used , wasting a fair bit of memory . furthermore , the circular dependency issue was only really a problem in the classic build . in the cmake build the "" target_config "" mechanism can be utilized here to make this a non - issue . <section> the <allcaps> psp </allcaps> generally allocates these memory spaces dynamically at start up anyway . - in the mcp750 this is based on <code> and the addresses are calculated from this base . - in pc - linux these are sysv shared memory segments . - in pc - rtems these are just <code> ' ed to simplify usage in <allcaps> qemu </allcaps> ( data does not survive a reset ) . <allcaps> cfe es </allcaps> should publish the _actual_ size required for its persistent data structures , and this actual size should be used when computing the addresses of these memory areas , rather than a compile - time fixed size which is almost certainly either too big or too small . <section> this issue is related to changes occurring in the exception and reset log implementation ( issues # <number> , # <number> ) . as part of this more of the er log ( or in particular , storing of exception context ) will be moved to the <allcaps> psp </allcaps> rather than being fully managed by es . this in turn changes the size of the cfe_es_resetdata_t structure substantially , and exposes the weakness / issues in how this is being currently allocated . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> evs </allcaps> "" cfe_platform_evs_log_on "" option unit test failure <section> the event services subsystem has a broken compile - time platform option called <code> . the description says : "" the cfe_platform_evs_log_on configuration parameter must be defined to enable <allcaps> evs </allcaps> event logging "" if ut is disabled , then <allcaps> cfe </allcaps> core itself actually seems to build and run ok . however , certain risky things are not clear in the code that : - the <code> will be left uninitialized - the <code> will be left as <allcaps> null </allcaps> the code that accesses these seems to be mostly protected by checking the separate <code> member boolean in the outgoing telemetry packet . this seems like a weak design , in particular because the telemetry packet is supposed to be informational , not an active control structure . <section> disable the <code> option , and build with <code> . <allcaps> cfe evs </allcaps> unit test fails to build with a compiler error . <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit . <section> unless there is a specific requirement for <code> as it stands today , my recommendation would be to deprecate this option and keep it always on , which reduces the testing matrix , and makes the <allcaps> fsw </allcaps> code more consistent . platform config options that actually add / remove <code> code should be avoided , as this has proven to be a testing / support issue time and time again . in this case , only the code that initializes the structures is compiled out . all the code that reads / writes to it is still compiled in , but skipped via a runtime test . so this is not saving much in the way of code / text space . if the goal of this option is to save data space memory , then _mostly_ the same effect can be achieved by keeping the log very small , by setting <code> to a very low number , such as <number> . in this mode the log structure uses only <number> bytes of memory on an x86 - <number> machine , down from <number> bytes with the default size of <number> . and the unit tests still build and pass with the max set to <number> , and it reduces the amount of conditionally - compiled code and variances on the <allcaps> fsw </allcaps> side . <section> joseph hickey , vantage systems , inc .",0.0
"cfe_sb_getlastsenderid returns pointer to internal data , possible race <section> cfe_sb_getlastsenderid returns pointer to data that could be overwritten at any time see <url> for related comments <section> conceptually - app calls cfe_sb_getlastsenderid , gets pointer , data gets overwritten , app takes action based on overwritten data vs original context <section> no race . <section> <url> <section> n / a <section> # <number> <section> jacob hageman",0.0
cfe_tbl should send events instead of using syslog <section> there ' s still a fair bit of code in cfe_tbl that sends syslog messages rather than generating events . <section> these messages should be removed and events generated where appropriate . <section> <email>,2.0
"fix # <number> , better events for cfe_tbl_load ( ) <section> addresses # <number> but this is a draft , still need ut code updates . simplified changes for cfe_tbl_load ( ) to make the code a bit easier to follow ( hey , events generated when results are off - nominal , instead of at the end ? ) partially addresses # <number> <section> initial build / run , ut not updated yet . <section> internal cfe_tbl_loadfromfile ( ) <allcaps> api </allcaps> changed slightly to add appname as a parameter . return value from loadfromfile ( ) no longer relevant for event generation . <section> debian <number> <section> <email>",2.0
add reference to deployed cfe user ' s guide in <allcaps> readme </allcaps> . md <section> user ' s guide is not included in repo <section> add reference to <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"cfe_evs_sendevent stub should provide full context <section> the cfe_evs_sendevent stub for ut - assert does not provide its full context . it only provides the first argument , eventid , providing no way to for unit tests to verify the correct eventtype or event message text was sent . <section> steps to reproduce the behavior : <number> . see the cfe_evs_sendevent stub <url> . only eventid is registered with the context and copied . <section> the cfe_evs_sendevent stub should provide its full context for unit testing purposes , including the eventid , eventtype , and the event message string . <strike> my preference would be that the event message text provided would not include the format specifiers and instead be the resulting string with the format specifiers replaced with the appropriate text . </strike> i have been convinced and also talked myself out of that preference . <section> <code> <section> - cfe <date> <section> n / a <section> eric gilligan <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> - <number>",2.0
table load refactor for cfe_tbl_load ( ) / cfe_tbl_loadcmd ( ) overlap and complexity reduction <section> there ' s code commonalities between cfe_tbl_loadcmd ( ) and cfe_tbl_load ( ) . also varying use of return vs status codes and many if layers within table load should be refactored to reduce complexity . goal ( per sw sys eng handbook guidance ) is cyclomatic complexity of <= <number> . <section> code should be consolidated between cfe_tbl_load ( ) and cfe_tbl_loadcmd ( ) . refactor to simplify / separate into functions . <section> <email>,2.0
add build verification scripts ( <allcaps> ctf </allcaps> based ) <section> no build verification scripts for command requirements <section> add build verification scripts <section> none . <section> need to discuss how we approach this . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cfe_evs_generateeventtelemetry should check return code from cfe_sb_sendmsg ( ) <section> <allcaps> evs </allcaps> , when called to send events , eventually calls down to cfe_evs_generateeventtelemetry ( ) which sends the event to the ports and to the sb via cfe_sb_sendmsg ( ) . however , it currently does not check the return code from sendmsg ( ) . <section> generateeventtelemetry ( ) should report an error to syslog ( and the ports ? ) if it ' s unable to send the event to the sb ( preferably including the original event inside the syslog error report . ) <section> leaving it as it is , it ' s unlikely that cfe_sb_sendmsg ( ) would generate an error . <section> note also that if sendmsg ( ) [ really sendmsgfull ( ) ] generated an error , it would send an event through <allcaps> evs </allcaps> , causing a loop between sb code and <allcaps> evs </allcaps> code ( that will likely go on until the system crashes ) . again , this condition is unlikely , but this logic should be fixed to prevent loops . <section> <email>",2.0
"remove local - endian <allcaps> sid </allcaps> macros , and unnecessary abstraction of mask / shift <section> the following macros are not clearly documented as to use . they only work on a local endian streamid ( like what comes from <code> ) . <url> the ccsds_rd_bits / wr_bits is not <allcaps> ccsds </allcaps> related , and is just a mask / shift . more straight forward to just use mask / shift . see conversation on <url> <section> remove these since they just add to confusion . just use the ccsds_rd_sid / <allcaps> apid </allcaps> / <allcaps> shdr </allcaps> / <allcaps> type </allcaps> / <allcaps> vers </allcaps> macros directly on the header . <section> could deprecate , but no known uses . <section> conversation stemmed from # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> * <allcaps> edit </allcaps> * fixed code blob * <allcaps> edit </allcaps> * fixed my initial issue title and updated description per <user> clarification of intended use",2.0
"unit test - split "" <allcaps> and </allcaps> "" - ed conditionals into separate asserts <section> debugging unit tests can be very difficult , frustrating , and time consuming . one major part of the problem which makes them very debugging - unfriendly is something like the following : <code> the problem with this type of construct is that there are <number> separate tests being combined into one single assert . when it fails , it is not possible to see which of the three conditions are evaluating false . many of them call functions within the test case , too , which further obfuscate what the actual return value was . the only way to test this is run it in a debugger , break at the start of the test , then set a breakpoint inside e . g . ut_eventisinhistory to see what it returned . <section> <number> . at a minimum - split the <code> conditions into separate asserts . this would _at least_ let the developer know which one is actually the fault . <number> . nice to have - employ the macros similar to what <user> added in nasa / osal # <number> , which show the _values_ tested in the log , not simply just a pass / fail . <section> continue struggling to figure out what actually went wrong every time a ut failure comes up . <section> joseph hickey , vantage systems , inc .",2.0
"ability to register a function call for the performance manager ( or call a <allcaps> psp </allcaps> stub ) <section> sounds like historical ( and current ) missions typically end up adding calls to hardware from the performance calls . <section> either add in a <allcaps> psp api </allcaps> and call from es , or support an <allcaps> api </allcaps> to add a function call . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_es_createobjects calls cfe_es_writetosyslog while holding shared data lock <section> during core service task create , <code> calls <code> while already holding the shared data lock in two places , resulting in a recursive lock / deadlock . * location <number> <url> * location <number> <url> <section> it appears it should be calling <code> instead . <section> the second location makes the issue pretty clear : <code> <section> - os : freertos <number> - versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> <section> mike stewart , capella space corporation",0.0
"sb message id documentation is unclear and arguably misleading <section> as a new cfs developer , i have been trying to build my first complete app utilizing the cfe application developer doc ( and as of the last <number> days the md ) . rather than copy / paste the sample_app , it has been my intent to build up my experience by starting from scratch ( i . e . minimize copy / paste ) . thus , when setting up message ids , i utilized the logic explained in section <number> . <number> . it ' s fairly simple and without really knowing what <allcaps> ccsds </allcaps> represented , i read this as follows "" pick any number , let it be unique within the application , but do not set the upper <number> bits "" . so i did . then i finally got around to trying to use the ground system tool by adding my app to the tool . it was at that time , i realized that i had a problem . all my "" commands "" were being interpreted as "" telemetry "" . i figured that i might have associated the wrong info into the tool . no , everything checked out with the tool setup . then i went through my app trying to see if maybe i was improperly initializing or associating something . i could find nothing . then i jumped into the debugger . i found that the first byte of my message id was being checked for <number> characteristics . my message id was failing the two checks and hence my "" command "" had become a "" telemetry "" message and could therefore never be utilized to drive command codes . after researching <allcaps> ccsds </allcaps> and examining the cfe logic , i was able to finally track down the exact spec that outlines what bits should be set within a message id . the lightbulb came on . <repeated> this is why all the default apps use 0x 1 8 <section> values in their msg . h files . unfortunately , it was not explained in the sample code or documentation . this information is massively impactful and should not be left out of the cfe app dev guide . the guide unfortunately makes it sounds like you can pick anything but that is far from the truth . it ' s much more stringent than keeping the <number> most significant bits at zero . <section> the cfe documentation should clearly outline the following : <number> . in the default build of cfs , you are bound to <allcaps> ccsds </allcaps> rules . <number> . explain how those rules influence the cfe api ( aside from message ids , what else do devs need to know about ? ) <number> . and most importantly , clearly explain why / when you need to set bit fields <number> and <number> in your message id . <number> . in the sample_app , it would be nice have some contextual information related to creating proper ids ( for those who might copy / paste the app ) . also , <allcaps> apid </allcaps> is mentioned in the acronyms list but it not utilized in the dev guide document . this needs to be explained or arguably removed from the document . <section> none . devs rely on the documentation to create their apps . <section> i found the info that ties the cfe bit check to an actual spec at <url> ( see section <number> . <number> ) working with dev guide updated as of commit 5 6 0 2 bff3 <section> maurice prather",1.0
"possibly outdated os_initfs / os_mkfs logic for creating / ram <section> cfe <number> . <number> + still retain the original logic for setting up <code> . for poweron resets it works fine , however i think the logic may now be outdated for processor resets . on a processor reset , the flow is : <number> . attempt to initialize the filesystem with <code> . <number> . if that fails , format the filesystem with <code> . this logic may have made sense for older osals , but i do not see how it is helpful with <allcaps> osal </allcaps> <number> + . in the new <allcaps> osal </allcaps> , both <code> and <code> call <code> , with only the final argument <code> differing . both call <code> to initialize the ram disk . for <code> , this is the only impl function called . in the <code> case , <code> is only checked if <code> succeeded , and only if it did , then <code> is called . because the two <allcaps> osal </allcaps> functions follow exactly the same path up until the check for <code> , it seems to me that if <code> fails , then <code> cannot possibly succeed . in other worse , if <code> fails , then the cfe will inevitably panic instead of actually attempting to reformat <code> . <section> n / a <section> i think the intended logic in the cfe start up was to attempt to initialize an existing <code> filesystem on a processor reset , but reformat it if that failed and continue to boot . with the current <allcaps> osal </allcaps> , the only way i can see for that to work would be something like this : <number> . initialize the filesystem with <code> . if that fails , panic . <number> . attempt to mount the filesystem with <code> . <number> . if that fails , use <code> to remove it , and then call <code> . <number> . attempt again to mount with <code> . if that fails , panic . the other possible change for this to work as i think it is intended would be to make <code> fail if given an invalid filesystem . but as written for that to happen , <code> would need to fail , which would also make <code> always fail . <section> cfe <allcaps> ram </allcaps> disk creation on processor reset : <code> os_filesys_initialize ( ) logic : <code> <section> - os : shared <allcaps> osal </allcaps> - versions cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> <section> it ' s very possible that i am misunderstanding something here , in which case i apologize in advance for the noise ! <section> mike stewart , capella space corporation",2.0
"fix # <number> , cfe_es startup table <section> the following replaces the "" startup script "" code with a table file . note this does <allcaps> not </allcaps> include unit test code changes , so ci will fail . this is for <allcaps> ccb </allcaps> consideration before i spend a bunch of time cleaning up ut . fix # <number> <section> builds and runs . <section> replaces the startup script file with a start table that es loads . <section> debian <number> <section> <email>",2.0
add requirements to cover isvalidmsgid and getpkttype <section> exposing cfe_sb_isvalidmsgid and cfe_sb_getpkttype needs to flow from a requirement given the current cfe requirements pattern . <section> add the requirements <section> none <section> # <number> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"es should use a table for the "" startup script "" <section> the es "" startup script "" file ( a <allcaps> csv </allcaps> - like configuration of which applications and libraries to load at runtime ) is not very well designed ( using sscanf ) and not consistent with how cfs generally manages runtime configurations with tables . <section> replace the . scr code with a table . <section> one alternative is to update the . scr parser , and / or use one / more industry - standard file formats ( <allcaps> json </allcaps> , <allcaps> yaml </allcaps> ) and an open - source parser that we would include ( copy into ) in our codebase . general consensus is that the <allcaps> ccb </allcaps> prefers going with the standard table mechanism . <section> might be interesting to see if there ' s a way to change a table without having to re - compile . <repeated> otherwise would be helpful to have a document detailing how , post deploy , an operator can update the es configuration without having to do a full re - deploy . <section> <email>",2.0
"fix # <number> , deprecate cfe_os_ abstracted error codes <section> fix # <number> - deprecates cfe_os_ abstracted os error codes added cfe_omit_deprecated_6_7 just to be consistent also fix # <number> - removes non - existent codes <section> steps taken to test the contribution : <number> . ci - see <url> <section> none <section> - hardware : <allcaps> amd </allcaps> - os : ubuntu <number> - versions : bundle + this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> cfe </allcaps> needs to compile with the interface properties provided by <allcaps> osal </allcaps> <section> after the changes introduced by nasa / osal # <number> , the <allcaps> osal </allcaps> cmake script will no longer force setting of <code> directly in the <allcaps> cfe </allcaps> build by overwriting this value ( which is good ) . instead , any required compile definitions and related information will be conveyed in the more appropriate manner , through the <code> and <code> on the "" osal "" library target . <section> to work with this change , the <allcaps> cfe </allcaps> needs to explicitly check these properties on the osal target and use the values . by setting a directory - scope property at the top level , it will apply to all code . <section> cmake does this automatically so long as the executable directly links with <allcaps> osal </allcaps> . however , this does not apply to the apps which are built as a <code> . this is why it is easier to set the directory property so its all - inclusive . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , remove mission / platform include dirs <section> fixes # <number> removes classic build directories . <section> steps taken to test the contribution : <number> . tested w / ci bundle branch on fork , see : <url> <section> none , reduces user confusion due to duplicate defines <section> - hardware : ci ( <allcaps> amd </allcaps> ) - os : ubuntu <number> - versions : master w / this commit <section> only dependence found in framework was in cfs - groundstation . see <allcaps> x <elongated> </allcaps> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"unify "" table "" and "" . scr "" file loading <section> we currently have two ways of populating configuration data in cfs , the "" table "" <allcaps> api </allcaps> ( loading a binary data structure into memory ) and a "" configuration file "" ( cfe_es_startup . scr ) . these have similar purposes ( load - time configuration ) and could use the same <allcaps> api </allcaps> ? <section> it should be fairly straightforward to automagically determine whether a "" table "" file is an <allcaps> elf </allcaps> or a text file ( first byte = = 0x 7 f => <allcaps> elf </allcaps> ) and if it ' s not <allcaps> elf </allcaps> it should hand off to a text parser ( provided by <allcaps> osal </allcaps> ? ) to parse the table into an in - memory data structure . the current "" csv - like "" structure would not handle complex ( e . g . nested ) data structures but for common tables it should be sufficient . alternatives would be <allcaps> json </allcaps> or <allcaps> yaml </allcaps> or some other text format , but would require a way to disambiguate . table files trade efficiency for easy editing . <section> stick with the separate es code for loading the . scr file and table code . <allcaps> sbn </allcaps> previously used a similar . csv file format for its load configuration but it ' s been moved to a table - based configuration . <section> <email>",2.0
"fix # <number> , updates comments to note that the length limit of os_max_path_len and os_max_api_name includes null terminator <section> fixes # <number> related to nasa / osal # <number> , updates documentation to note that the actual length limit of os_max_path_len and os_max_api_name include the null terminator . <section> ran unit tests . <section> oracle vm virtualbox os : ubuntu - <number> versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> contributor info dan knutsen <allcaps> nasa </allcaps> / goddard",1.0
"fix # <number> , update <allcaps> rtems </allcaps> example toolchain <section> bring the example toolchain for i686 - rtems4 . <number> back into sync with the current <allcaps> psp </allcaps> and platform build module for this system . fixes # <number> <section> build software for i686 - rtems4 . <number> per <allcaps> readme </allcaps> instructions using this example toolchain file . sanity - check <allcaps> cfe </allcaps> build by ensuring it boots and accepts commands . <section> builds without error . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( build host ) building for i686 - rtems4 . <number> <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> rtems </allcaps> example toolchain file incompatible with current <allcaps> psp </allcaps> <section> the example <code> file is no longer compatible with the <allcaps> rtems </allcaps> module within the <allcaps> psp </allcaps> . cmake fails to configure , i get output as follows : <code> <section> build using example toolchain file from sample_defs with unmodified <allcaps> psp </allcaps> , adjusting only for local installation paths ( rtems_bsp_top ) . <section> build should succeed . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( build host ) building for i686 - rtems4 . <number> <section> failures is related to the "" specs "" options on the compiler . the toolchain file and <allcaps> rtems </allcaps> module in the <allcaps> psp </allcaps> got out of sync somewhere along the development path . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , update app dev guide int handler <section> document change only , updates the interrupt handler section to note <allcaps> osal </allcaps> deprecation fixes # <number> <section> none , documentation only <section> none <section> n / a <section> related to <url> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
app dev guide - interrupt handling section update to indicate deprecated <section> related to <url> need to keep guide up - to - date <section> update guide <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fix # <number> , resolve ci warnings and add badge <section> resolves warnings and adds badge to readme fix # <number> <section> steps taken to test the contribution : <number> . ci only <section> no travis - ci configuration warnings <section> - hardware : ci - os : ubuntu <number> - versions : bundle w / this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix travis - ci config warnings and add badge <section> build config validation ( from travis - ci ) - root : deprecated key sudo ( the key <code> has no effect anymore . ) language : unexpected sequence , using the first value ( c ) root : missing os , using the default linux also add badge on <allcaps> readme </allcaps> <section> see <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , <allcaps> ccsds </allcaps> command secondary header endian agnostic <section> implement <allcaps> ccsds </allcaps> command secondary header such that it is endian agnostic in code and unit test support . fix # <number> <section> steps taken to test the contribution : <number> . tested via bundle ci ( including non - zero command send to reset ) <number> . also tested locally with enabling to via cfs - groundsystem this covered both direct cmdutil call and cfs - groundsystem use . <section> cmd code ( and checksum ) are always in the same place ( matches <allcaps> gsfc </allcaps> spec for command secondary header ) <section> - hardware : ci and cfs dev server - os : ubuntu <number> - versions : test bundle with this change and <url> in cfs - groundstation <section> see also <url> these should be merged together <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"cfe_es_runloop increments the main task executioncounter rather than the task that called it <section> inside the <code> function itself , it looks up the maintaskid of the caller and only increments _that_ execution counter , not the execution counter of its own task record . this means no matter what child task actually calls this function , it implements the execution counter of the main task only . note that if the real main task is doing something else and also increments its own task counter , this is a race condition . <section> i suggest one of the following : <number> . just have <code> invoke <code> to increment the counter for the task from which it was called . so if it gets called from a child task , then that child task gets incremented , not the main task . this is at least straightforward / consistent and avoids the race condition . <number> . maintain a separate "" app "" exec counter which is incremented by cfe_es_runloop ( only ) , and use the <code> to account for other regular task activity . <section> noticed this when fixing # <number> and it seemed rather odd / incorrect to be storing the executioncounter where it is . this causes the code to jump to other entries in the table for the sole purpose of reading / updating this value , when it already had the correct app record to start . <section> joseph hickey , vantage systems , inc .",1.0
"add option to enable - - coverage flag on full stack <section> enhancement to be able to report coverage from full stack testing if desired <section> maybe enable_coverage = true , and global_build_options . cmake could add - - coverage if defined ? would duplicate the coverage enabled in unit test executables . <repeated> but does it matter ? <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_evs event filtering does not seem to work correctly <section> <allcaps> evs </allcaps> does not seem to filter out the mask for cfe_evs_first_one_stop . i have not tried other pre - defined filter mask values . <section> steps to reproduce the behavior : <number> . build & run <allcaps> sch </allcaps> as - is with just ci & to as part of the <allcaps> fsw </allcaps> . make sure to subscribes to short / long event messages . increase <allcaps> to tlm </allcaps> pipe depth to max depth . <number> . observe the console output from <allcaps> fsw </allcaps> . <allcaps> to tlm </allcaps> pipe would overflow with <allcaps> sch </allcaps> as sender <section> a clear and concise description of what you expected to happen . <section> if applicable , add references to the software . <section> - hardware - os : centos <number> & <number> . x - versions : cfe <number> . <repeated> x7 , <allcaps> osal </allcaps> <number> . x <section> add any other context about the problem here . <section> full name and company / organization if applicable",3.0
"fix # <number> , add branch coverage reporting <section> fix # <number> , adds branch coverage and removes no - longer - needed report file manipulation to exclude unit test code from coverage report <section> steps taken to test the contribution : <number> . standard build / test / lcov ( same as enhanced ci ) <number> . confirmed branch coverage reported ( ~ <percent> ) <section> no changes to operational behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle w / this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add branch coverage reporting and remove no longer necessary removal of unit test files <section> historically did not report branch coverage and needed to remove the unit test code from coverage reporting . <section> add branch coverage , remove unnecessary processing step <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add build of pdf guides to make documentation rules <section> make documentation rules do not actually make the final pdf <section> add make in the document latex directory . <section> none <section> consider pushing document somewhere useful from ci vs requiring users to generate . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
fix make doc warnings <section> make doc creates multiple warnings ( in build / doc / warnings . log ) some caused by # <number> <section> resolve warnings <section> none <section> intended as project / distribution documentation of entire code base and never really well implemented ( internal elements not well documented ) . major rework required to make this document useful outside just the fix of warnings . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fix # <number> , <allcaps> osal </allcaps> guide scrub <section> fix # <number> , see issue for list of changes . these are the changes required in the cfe repo to scrub the <allcaps> osal </allcaps> guide note <url> is the commit related to this issue . <section> steps taken to test the contribution : <number> . nominal build ( native ) and run , no issues <number> . make usersguide and confirmed no warnings in build / doc / warnings <number> . cd build / doc / users_guide / latex <number> . make <number> . confirm completes and guide looks ok <number> . make osalguide and confirmed no warnings in build / doc / warnings <number> . cd build / doc / osalguide / latex <number> . make <number> . confirm completes and guide looks ok <section> no behavior change other than warnings resolved for doc build <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : bundle w / the commits below <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"clean - up related to <allcaps> osal </allcaps> user ' s guide scrub <section> various fixes / cleanup required related to <url> <section> - removed unused osalguide . dox ( it just copies the main page , unreferenced ) - removed unused cfe_usersguide . dox ( it just copies part of main page , unreferenced ) - fixed directory name reported by make osalguide - updated <allcaps> osal </allcaps> guide name - removed osal_misc_additions ( undefined ) - general consistency / updates of header sections for osalguide - os_taskregister note removed from initialization ( obsolete ) - file descriptor section update ( do not mix os / <allcaps> osal </allcaps> ) - changed include order to maintain document order ( main dox file added first ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
document deprecated elements looks like template broke . <repeated> anyways : add \ deprecated and \ name the group where appropriate relative to the user ' s guide documentation such that it shows up as deprecated . jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fix # <number> , user ' s guide scrub <section> documentation / comments only included in this change . commit <url> - fixes # <number> users guide scrub ( see issue for individual changes ) - fixes # <number> all warnings - fixes # <number> by referencing header documentation ( removes typo ) commit <url> - fixes # <number> commit <url> - fixes # <number> commit <url> - fixes # <number> commit <url> - fixes # <number> <section> steps taken to test the contribution : <number> . standard make / build steps to confirm code wasn ' t broken <number> . make usersguide <number> . confirmed build / doc / warnings . log ( doxygen warnings ) empty <number> . cd build / doc / usersguide / latex <number> . make ( to build the pdf ) <section> user ' s guide generates and and creates pdf without errors <section> - hardware : cfs dev server - os : ubuntu <number> - versions : master bundle w / this commit <section> does not attempt to address # <number> and # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"provide configurable / customizable message abstraction layer <section> sb provides abstraction from <allcaps> ccsds </allcaps> packets , yet the ccsds_commandpacket_t is still referenced directly by the services ( and likely all the apps that accept a command ) and sb functionality itself is tightly coupled to the actual message format . <section> provide a "" <allcaps> msg </allcaps> "" abstraction layer ( like inc / cfe_msg . h and a src / msg ) to implement direct access getters / setters for supported "" header "" fields . allow for selection of the supported message formats , or customization via mission configuration ( and adding of additional getters / setters ) . sb should be abstracted the same as the other services . "" header "" is intentionally vague , since it should include any common fields for which getter / setter abstraction is appropriate related to cfe services and apps . <section> leave as is , which requires clone and own approach for customization and extensive sb impacts . <section> suggest that since this would now support customization , we collapse the open source supported time format options down to <number> ( big endian , with the <number> byte default ) . if missions need something else , they can easily customize . # <number> - separate message access <allcaps> api </allcaps> ' s from sb # <number> - local endian <allcaps> sid </allcaps> macros , unused shift / mask macros ( in ccsds . h ) # <number> - improve <allcaps> api </allcaps> consistency for functions accepting a software bus message # <number> - investigate various verifycmdlength implementations and possible common utility # <number> - unsafe macros , investigate conversion into inline functions # <number> - cfe_sb_getmsgtime ( ) and cfe_sb_setmsgtime ( ) do not handle byte - swapping on _el platforms <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove old <allcaps> asist </allcaps> mnemonics from doxygen comments <section> there ' s alias , extra mnemonic mapping files , and extra comments in code that lead to extra documentation that does not apply to anything other than internal proprietary ground stations . they also are very fragile . <repeated> defining the mnemonic in the middle of a comment block caused warnings like <code> but when defined at the top and immediately followed by another alias there were no warnings . <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
remove undefined error defines in cfe_error . h <section> <url> neither of these exist in <allcaps> osal </allcaps> <section> delete <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
cfe_time_local1hzisr duplicated define <section> defined in both cfe_time . h and cfe_time_utils . h ( standard violation ) <section> single source of truth <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"<allcaps> cfe </allcaps> cmake rules for tables copy the files into / cf , not / cf / tables where expected <section> cfe cmake rules copy the * . tbl files into / cf / and not into / cf / apps where most apps seem to expect them : <section> steps to reproduce the behavior : <number> . build your own cfs tree based on <url> <number> . remove the * _lab apps <number> . add the official repos for cfs_sch . cfs_to , cfs_to , hk , hs and others <number> . configure everything <number> . build ( i was able to build specifically <number> bit on my <number> bit machine using cmake <number> or newer - with the attached config ) cfs_32bit_on_64bit . tar . gz <url> <number> . run <code> <number> . stop it , and do an ls <code> <number> . grep the app tree <code> <section> all . <allcaps> tbl </allcaps> files should be installed into / cf / apps / change to <section> : cmake / arch_build . cmake : install directory in add_cfe_tables needs to include apps <code> <section> - hw : dell laptop <allcaps> xps </allcaps> <number> - os : linux <allcaps> gti </allcaps> - uid0110 <number> . <number> - <number> - generic # <number> ~ <number> . <number> - ubuntu <allcaps> smp </allcaps> wed <date> <time> <allcaps> utc </allcaps> <number> x86_64 x86_64 x86_64 <allcaps> gnu </allcaps> / linux ( distro linux mint <number> ) - versions [ versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> , <allcaps> psp </allcaps> <number> . <number> , chksm <number> on linux , <allcaps> sch </allcaps> <number> . <number> , cfs_to commit 4 5 8 9 edb , cfs_ci , and other apps <section> add any other context about the problem here . <section> maurice smulders geneva technologies inc",3.0
apis do not consistently check return value of functions called <section> apis do not consistently check return values of functions called . i think not checking the return value is likely by design in many of the below cases . <repeated> i just wanted to have the group take a look and determine if any updates are warranted . apis flagged during audit : cfe_sb_api . c : cfe_sb_getpipeopts cfe_sb_api . c : cfe_sb_setpipeopts cfe_sb_api . c : cfe_sb_unsubscribelocal cfe_tbl_api . c : cfe_tbl_register cfe_time_api : cfe_time_externaltime cfe_time_api : cfe_time_externalgps cfe_time_api : cfe_time_externalmet cfe_es_api . c : cfe_es_registercds cfe_esmempool . c : cfe_es_poolcreateex cfe_esmempool . c : cfe_es_getpoolbuf cfe_esmempool . c : cfe_es_putpoolbuf cfe_sb_api . c : cfe_sb_rcvmsg cfe_sb_api . c : cfe_sb_getlastsenderid cfe_sb_api . c : cfe_sb_zerocopygetptr cfe_sb_api . c : cfe_sb_unsubscribe cfe_sb_api . c : cfe_sb_deletepipe cfe_tbl_api . c : cfe_tbl_unregister cfe_tbl_api . c : cfe_tbl_load cfe_tbl_api . c : cfe_tbl_share cfe_tbl_api . c : cfe_tbl_update cfe_es_api . c : cfe_es_processcoreexception cfe_es_api . c : cfe_es_resetcfe cfe_sb_api . c : cfe_sb_createpipe cfe_es_start . c : cfe_es_main cfe_esmempool . c : cfe_es_getpoolbufinfo cfe_es_api . c : cfe_es_waitforsystemstate cfe_es_api . c : cfe_es_runloop cfe_tbl_api . c : cfe_tbl_validate please reference the spreadsheet ( api_audit_v2 . xlsx ) attached to issue # <number> for additional information in regards to why each of the above apis were flagged . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
apis missing check for <allcaps> null </allcaps> pointer ( s ) <section> there are a number of apis that do not currently check to see if a <allcaps> null </allcaps> pointer has been passed in as an input argument . we should consider adding the additional check in the following apis : cfe_es_api . c : cfe_es_calculatecrc cfe_es_api . c : cfe_es_copytocds cfe_es_api . c : cfe_es_createchildtask cfe_es_api . c : cfe_es_getappid cfe_es_api . c : cfe_es_getappname cfe_es_api . c : cfe_es_getgencounteridbyname cfe_es_api . c : cfe_es_gettaskinfo cfe_es_api . c : cfe_es_processcoreexception cfe_es_api . c : cfe_es_registercds cfe_es_api . c : cfe_es_restorefromcds cfe_es_api . c : cfe_es_runloop cfe_es_api . c : cfe_es_writetosyslog cfe_esmempool . c : cfe_es_getmempoolstats cfe_esmempool . c : cfe_es_getpoolbuf cfe_esmempool . c : cfe_es_getpoolbufinfo cfe_esmempool . c : cfe_es_poolcreate cfe_esmempool . c : cfe_es_poolcreateex cfe_esmempool . c : cfe_es_poolcreatenosem cfe_esmempool . c : cfe_es_putpoolbuf cfe_evs . c : cfe_evs_sendevent cfe_evs . c : cfe_evs_sendeventwithappid cfe_evs . c : cfe_evs_sendtimedevent cfe_fs_api . c : cfe_fs_initheader cfe_fs_api . c : cfe_fs_readheader cfe_fs_api . c : cfe_fs_settimestamp cfe_fs_api . c : cfe_fs_writeheader cfe_sb_api . c : cfe_sb_createpipe cfe_sb_api . c : cfe_sb_zerocopygetptr cfe_sb_msg_id_util . c : cfe_sb_getmsgid cfe_sb_msg_id_util . c : cfe_sb_setmsgid cfe_sb_util . c : cfe_sb_generatechecksum cfe_sb_util . c : cfe_sb_getchecksum cfe_sb_util . c : cfe_sb_getcmdcode cfe_sb_util . c : cfe_sb_getmsgtime cfe_sb_util . c : cfe_sb_gettotalmsglength cfe_sb_util . c : cfe_sb_getuserdata cfe_sb_util . c : cfe_sb_getuserdatalength cfe_sb_util . c : cfe_sb_initmsg cfe_sb_util . c : cfe_sb_messagestringget cfe_sb_util . c : cfe_sb_messagestringset cfe_sb_util . c : cfe_sb_msghdrsize cfe_sb_util . c : cfe_sb_setcmdcode cfe_sb_util . c : cfe_sb_setmsgtime cfe_sb_util . c : cfe_sb_settotalmsglength cfe_sb_util . c : cfe_sb_setuserdatalength cfe_sb_util . c : cfe_sb_timestampmsg cfe_sb_util . c : cfe_sb_validatechecksum cfe_tbl_api . c : cfe_tbl_getaddress cfe_tbl_api . c : cfe_tbl_getaddresses cfe_tbl_api . c : cfe_tbl_getinfo cfe_tbl_api . c : cfe_tbl_load cfe_tbl_api . c : cfe_tbl_register cfe_tbl_api . c : cfe_tbl_share cfe_time_api : cfe_time_print cfe_time_api : cfe_time_registersynchcallback <section> na - code review / audit <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
"apis missing argument validation <section> the following apis are missing argument validation : cfe_sb_api . c : cfe_sb_subscribefull - quality is not checked … consider checking that it is <number> or <number> cfe_es_api . c : cfe_es_deleteapp - can get a segmentation fault if user tries to delete an <allcaps> app </allcaps> greater than cfe_platform_es_max_applications cfe_tbl_api . c : cfe_tbl_getaddresses - can result in segmentation fault if numtables grows larger than max number of tables . cfe_tbl_api . c : cfe_tbl_releaseaddresses - should check to make sure numtables is less than cfe_platform_tbl_max_num_tables cfe_es_perf . c : cfe_es_perflogadd - should check if entryexit is either a <number> or <number> cfe_es_api . c : cfe_es_reloadapp - can result in segmentation fault if <allcaps> apid </allcaps> is invalid cfe_es_api . c : cfe_es_createchildtask - input argument ' flags ' is not validated … also it does not appear to be used anywhere , consider removing cfe_es_api . c : cfe_es_getappname - consider comparing bufferlength with os_max_api_name prior to use . cfe_es_api . c : cfe_es_registercds - consider checking if block size is less than cfe_platform_es_max_block_size cfe_fs_api . c : cfe_fs_initheader - subtype not checked cfe_sb_api . c : cfe_sb_zerocopygetptr - is there a maximum message size ? consider verifying msgsize prior to use . cfe_sb_util . c : cfe_sb_setuserdatalength - consider verifying length of user data ( if there exists a limit ) and / or totalmsgsize cfe_sb_api . c : cfe_sb_subscribelocal - msglim is not checked … if a max limit does exist , should add argument validation <section> all input arguments are validated prior to use . <section> na - code review / audit <section> dan knutsen <allcaps> nasa </allcaps> goddard",2.0
"fix # <number> , # <number> , and # <number> , updated cfe app developer ' s guide <section> updated the cfe app developer ' s guide markdown with changes to resolve issues <number> , <number> , and <number> . made a variety of other small content updates and reordered some sections . fixes # <number> , fixes # <number> , fixes # <number> <section> none - documentation only <section> none - documentation only <section> none - documentation only <section> n / a <section> n / a <section> elizabeth timmons - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"expose cfe_sb_getpkttype ( and add stub ) <section> requests to expose packet type as an <allcaps> api </allcaps> ( helps <allcaps> sbn </allcaps> , testing ) <section> add requirement , expose in <allcaps> api </allcaps> header , add stub , etc . <section> n / a <section> slightly related to # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"option to drop oldest message when msg limit on pipe reached ( keep newest ) <section> looks like sb rejects newest message when message limit reached <url> in some cases newest message is of higher priority <section> add option ( maybe part of <allcaps> qos </allcaps> ? ) to remove oldest message from queue when limit reached . easy if the message limit is <number> , likely need trade study if more than one ( reorder queue ? replace oldest w / newest would put them out of order , add new to queue remove oldest and remove gap ? etc ) . performance cost to find / replace / reorder / etc . <section> just subscribe with enough space to hold all , and chew through entire pipe to get the latest then process . <section> requested by <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"user ' s guide scrub <section> user ' s guide out of date and inconsistant <section> general scrub of users guide - replace non - documented formatting mechanisms for return codes ( causes errors ) - custom table aliases for return values causing issues , use built in - make references into links where needed - fix links where needed ( remove private links ) - remove duplicated documentation in * . c files ( <allcaps> api </allcaps> ' s documented in * . h , with prototype ) - remove duplicated brief in <allcaps> api </allcaps> table ( pull from object brief ) - remove xrefitem style formatting ( caused warnings , see # <number> ) - fix glossary table - fix use of <allcaps> bsp </allcaps> where <allcaps> psp </allcaps> applies - performance collection focused on cfe , not tool ( updated reference for java tool ) - update event message format documentation to match order / contents - update applicable documents with modern references - removed no - longer - up - to - date dox templates ( eclipse header templates ) - cleaned up sb sequence counter section - added a couple faqs - single sourced the versioning section - resolved <allcaps> all </allcaps> doxygen warnings ( including those detailed in # <number> ) <section> none <section> related issues : # <number> , # <number> , # <number> , # <number> , # <number> , # <number> , # <number> , # <number> , # <number> , # <number> looks like <allcaps> eds </allcaps> file for sb needs getpipeidbynameerrorcounter <section> - scrub return codes , not all listed in current <allcaps> api </allcaps> documentation - remove autodoc , explicitly document ( futureproof from missing documentation ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"unit test build fails when multiple cpus are defined <section> after updating some projects to the latest baseline , getting a new build failure : <code> <section> the configuration of this project uses multiple cpus that all share the same architecture ( <allcaps> ppc </allcaps> ) but different platform configs ( cfe_platform_cfg . h ) . <section> build should succeed <section> - ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( build host ) - cross compiling for <allcaps> ppc </allcaps> ( embedded linux ) - latest "" master "" baseline ( <number> - <number> - <number> ) <section> this is related to a recent change that separated the ut stubs from the <allcaps> cfe </allcaps> . it works fine with only a single <allcaps> cpu </allcaps> / config , but if multiple cpus are defined then this fails . unfortunately only testing this now - the ci / cd build only uses a single <allcaps> cpu </allcaps> / config . need to remove ut dependencies on a specific "" cfe_platform_cfg . h "" to fix this . ( stubs should not need this file , it is not a real implementation , it is just stubs ) . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> and # <number> , user ' s guide doxygen issues <section> fix # <number> - removed an extra line that caused breakage fix # <number> - removed private paths from user ' s guide processing <section> steps taken to test the contribution : <number> . make prep <number> . make usersguide <number> . cd buid / doc / users_guide / latex <number> . make <section> a clear and concise description of how this contribution will change behavior and level of impact . - <allcaps> pdf </allcaps> file now generated by process above <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : current bundle w / this change <section> n / a <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"remove private files from user ' s guide documentation processing <section> user ' s guide is intended to document external elements ( <allcaps> api </allcaps> ' s , commands , error codes , etc ) , yet includes processing of internal directories . <section> remove internal directories from processing <section> none <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"comment before cfe_sb_rcvmsg mentions cfe_sb_pend , but it should be cfe_sb_pend_forever in the description comment before cfe_sb_rcvmsg in cfe_sb_api . c the timeout value cfe_sb_pend is mentioned ; however , the actual value is cfe_sb_pend_forever . this comment should be changed to reflect the correct value . <url>",1.0
doxygen of users guide fails to create pdf <section> make usersguide cd build / doc / users_guide / latex make observe error : ` ` <code> \ end ' ) * ` ` ` <section> fix so pdf will build . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"add compile time assert that int size is <number> bit <section> per discussion <date> there ' s likely breakage in multiple places on a system where int ! = <number> bit ( standard minimum is <number> bit ) <section> along with # <number> , cfe not really designed to work on a system without char of <number> bit size and int of <number> . enforce / warn on build . <section> improve documentation ? still nice to bail on compile for those who do not read documentation . <section> # <number> , and many other places convert int32 to int or the unsigned equiv . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
clarify cfe_tbl_notifybymessage should not use ground command <allcaps> mid </allcaps> <section> cfe_tbl_notifybymessage should use a separate <allcaps> mid </allcaps> from ground commands to avoid command counter increments ( and any other ground specific processing ) . <section> update documentation to explicitly recommend <allcaps> not </allcaps> using ground command <allcaps> mid </allcaps> . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> * <allcaps> edit </allcaps> * - changed per comments below from a command code issue,1.0
"cfe_sb_gettotalmsglength return type does not support max packet size <section> cfe_sb_gettotalmsglength returns an uint16 , max packet <allcaps> ccsds </allcaps> packet size can be slightly bigger ( <number> vs <number> ) . note the c documentation claims the max return does not include the primary header (# <number> ) , but the <allcaps> api </allcaps> ( h file documentation ) claims it ' s the full packet . the code actually returns the full packet size ( the length field in the <allcaps> ccsds </allcaps> packet + <number> ) . <section> support full <allcaps> ccsds </allcaps> packet size . <section> none <section> initiated by jp / <allcaps> pace </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"<allcaps> api </allcaps> header documentation does not match c file documentation <section> currently the <allcaps> api </allcaps> ' s are documented in both the . h and . c , and they are not always consistent . see : <url> vs <url> <section> document in header only ( remove duplicated info in . c ) , and reference from c files <section> none <section> requested by jp / <allcaps> pace </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"add alternate <allcaps> mid </allcaps> for <allcaps> time </allcaps> diagnostics packet request <section> the current mechanism to collect the diagnostics packet from the <allcaps> time </allcaps> app requires a command to be sent to the app , which increments the <allcaps> time </allcaps> command counter . for anyone that wants this diagnostics packet to be generated regularly , this causes the command counter to also increment regularly , which makes the command counter less useful . <section> add a <allcaps> mid </allcaps> to the <allcaps> time </allcaps> app for diagnostic packet requests , which will not result in the command counter being incremented . this will create two ways to request the <allcaps> time </allcaps> diagnostics packet ( by command or by message ) . <section> - adding a configuration that enables / disables whether the command counter is incremented when this command is received . - check if the command was sent from the scheduler , and do not increment the command count if so . both of these go against the current requirement / philosophy of "" all commands should increment a command counter "" . <section> none . <section> keegan moore - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , message requirements scrub <section> now using the term message ( vs overloading "" command "" ) for a software bus triggered requirement that does not increment the command code ( typically inter - app messages ) fix # <number> <section> none , doc only <section> none <section> none <section> change is on top of the rest of the requirements scrub to simplify review , just view last commit for changes specific to the linked issue . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"disambiguate command vs message requirements <section> "" command "" terminology has been used for both ground commands ( that increment command counters ) and inter - app commands ( that typically do not increment command counters ) . so it ' s unclear in the requirement which sort of use case is intended . <section> "" command "" is ground command with additional associated behavior ( increments command counters ) , "" message "" is typical sb message that does not increment command counter . <section> none <section> discovered during requirements scrub , helps clarify what impacts command counter . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , software bus requirements scrub <section> see issue for detailed list of changes fix # <number> <section> none , doc change only <section> none <section> none <section> commit is on top of previous requirements work to facilitate review , only the last commit is applicable to this issue <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"sb subscription reporting request messages out of family <section> cfe_sb_enablesubreportingcmd , cfe_sb_disablesubreportingcmd , cfe_sb_sendprevsubscmd are processed like commands but do not increment the command counter . typical pattern is for non - ground , inter - app messages to have separate message ids from ground commands . <section> make consistent with standard pattern <section> none <section> see hk message processing , or the message processing in time services that do not increment command counter . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"software bus requirements scrub <section> sb requirements out of date <section> update requirements . <section> n / a <section> summary of changes ( w / links if individual issues exist already ) : - csb4000 - <allcaps> noop </allcaps> command out of family , make consistent with other services - csb4005 - hk message out of family , make consistent with other services - csb4300 - zero copy general requirement reads like level <number> , delete and replace with <allcaps> api </allcaps> requirements - csb4305 . <number> - max message size just clarify wording ( mission config parameter ) - csb4310 - free app resources ( done by es_appexit , delete from sb / <allcaps> api </allcaps> ) - csb4700 : max message id ’ s ( delete ) - csb4701 : sb maximum size ( delete ) - csb4704 : max destinations ( delete ) - csb4705 : maximum pipes ( delete ) - csb4706 : maximum pipe depth ( delete ) - <allcaps> new api </allcaps> requirements : - csb4311 - cfe_sb_getmsgid - csb4312 - cfe_sb_setmsgid - csb4313 - cfe_sb_messagestringget - csb4314 - cfe_sb_messagestringset - csb4315 - cfe_sb_initmsg - csb4315 . <number> - clear message contents and sequence counter - csb4315 . <number> - retain message contents and sequence counter - csb4316 - cfe_sb_getuserdata - csb4317 - cfe_sb_getuserdatalength - csb4318 - cfe_sb_setuserdatalength - csb4319 - cfe_sb_gettotalmsglength - csb4320 - cfe_sb_settotalmsglength - csb4321 - cfe_sb_getmsgtime - csb4322 - cfe_sb_setmsgtime - csb4323 - cfe_sb_timestampmsg - csb4324 - cfe_sb_getcmdcode - csb4325 - cfe_sb_setcmdcode - csb4326 - cfe_sb_getchecksum - csb4327 - cfe_sb_generatechecksum - csb4328 - cfe_sb_validatechecksum - csb4329 - cfe_sb_setpipeopts - csb4330 - cfe_sb_getpipeopts - csb4331 - cfe_sb_subscribelocal - csb4332 - cfe_sb_subscribe - csb4333 - cfe_sb_unsubscribelocal - csb4334 - cfe_sb_passmsg - csb4335 - cfe_sb_msgid_equal - csb4336 - cfe_sb_msgidtovalue - csb4337 - cfe_sb_valuetomsgid - csb4338 - cfe_sb_getpipename ( related to # <number> ) - csb4339 - cfe_sb_getpipeidbyname ( related to # <number> ) - csb4340 - cfe_sb_zerocopygetptr - csb4341 - cfe_sb_zerocopyreleaseptr - csb4342 - cfe_sb_zerocopysend - csb4343 - cfe_sb_zerocopypass - <allcaps> new </allcaps> cmd requirements : - csb4009 - upon receipt of valid command increment command counter - csb4010 - upon receipt of invalid command increment command error counter - csb4011 - cfe_sb_enablesubreportingcmd <number> - csb4012 - cfe_sb_disablesubreportingcmd <number> - csb4013 - cfe_sb_sendprevsubscmd <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , time services requirements scrub <section> updates <allcaps> time </allcaps> services requirements , see issue for details . fix # <number> <section> none , doc update only <section> none , doc update only <section> none , doc update only <section> see related issues , # <number> , # <number> . review just the latest commit for changes directly related to the associated issue . <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"assert ( ) in main - line code <section> in unit tests , we use assert statements . a lot of our code performs a number of safety checks ( pointer is not null , index is less than array size , etc . ) i suggest we develop something similar to the ut assert code , and use as much as possible in the main - line code base in lieu of our current safety checks as it will improve readability and support tooling of code analysis . <section> assert library should generate events , return values , and will need to be able to unwind such things as semaphores . <section> implementing this will introduce risk that we miss a safety check or otherwise mis - translate the check into an assert . need to develop the library and slowly migrate current safety checks to the library . <section> add any other context about the feature request here . <section> <email>",2.0
"time services requirements scrub <section> <allcaps> time </allcaps> requirements out of date <section> update requirements . <allcaps> note </allcaps> <number> - this is not major reworking of the requirements / design (# <number> ) , but focused on just bringing the requirements up to date . future issues will address significant development / rework . <allcaps> note </allcaps> <number> - <allcaps> met </allcaps> functionality still applies here ( not all abstracted to <allcaps> psp </allcaps> ) to support the virtual <allcaps> met </allcaps> capability ( hardware <allcaps> met </allcaps> is not required ) . <section> n / a <section> summary of changes ( w / links if individual issues exist already ) : - ctime2000 - hk requirement not consistent ( update wording ) - ctime2001 - wording scrub , remove "" time server and time client "" inconsistent pattern - ctime2002 - wording scrub , remove "" time server and time client "" inconsistent pattern - ctime2007 - update summary , it ' s really compute <allcaps> sctf </allcaps> given current time - ctime2008 - adjust <allcaps> ctf </allcaps> requirement ( delete , redundant with add / subtract requirements ) - ctime2010 - summary : select tone signal source , of <allcaps> primary </allcaps> vs <allcaps> redundant </allcaps> ( although not explicitly defined ) , setsignalcmd - ctime2012 - force to flywheel ( not just flywheel ) , then will not update time based on tone data / signal . - ctime2012 . <number> - propagates <allcaps> met </allcaps> locally ( update wording ) , uses internal best guess for <allcaps> met </allcaps> . - ctime2013 - remove "" second and subsecond "" , overdetailed and wrong , really <allcaps> sctf </allcaps> - ctime2014 - remove "" second and subsecond "" , overdetailed and wrong , really <allcaps> sctf </allcaps> - ctime23xx - all requests remove extra language ( format specified ) - ctime2701 - time at tone window not handled by ts ( delete , hardware ) , sent by request / cmd - ctime2702 - update <allcaps> met </allcaps> ( delete generic functionality requirement , <allcaps> psp </allcaps> / hardware ) - ctime2703 - <allcaps> met </allcaps> resolution ( delete , <allcaps> psp </allcaps> / hardware ) - <allcaps> new api </allcaps> requirements : - ctime2315 - provide time at tone message functionality given <allcaps> met </allcaps> , provide in message like hk - ctime2316 - tone data given <allcaps> gps </allcaps> - ctime2317 - tone data given time - ctime2318 - register synch callback ( callback at tone signal receipt ) - ctime2319 - unregister synch callback ( unregistersynchcallback ) - ctime2320 - get clock info state flags for <allcaps> time </allcaps> ( getclockinfo ) - ctime2321 - convert a given <allcaps> met </allcaps> to sc time ( met2sctime ) - ctime2322 - local1hzisr , <allcaps> api </allcaps> to trigger <number> hz processing - ctime2323 - externaltone , <allcaps> api </allcaps> to trigger tone processing - <allcaps> new </allcaps> cmd requirements : - ctime2012 . <number> - external time update mode - use updates ( update timekeeping when tone signal and data pair are received ) - ctime2015 - tonesendcmd just sends tone data message ( no time update ) - ctime2016 - tonedata ( cmd ) , triggers receipt of tone data processing - ctime2017 - tonesignal ( cmd ) , triggers tone signal processing - ctime2018 - onehz ( cmd ) , triggers 1 hz cycle processing - ctime2019 - set <allcaps> met </allcaps> , sets abstract <allcaps> met </allcaps> ( not hardware met ) , setmetcmd - ctime2020 - ( adddelaycmd ) - ctime2021 - ( subdelaycmd ) - <allcaps> note </allcaps> : cfe2fsseconds / fs2cfeseconds deleted per # <number> - <allcaps> note </allcaps> : setsourcecmd due refactor / fix per # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , event services requirements scrub <section> event services requirements scrub , see issue for changes fix # <number> <section> none <section> none <section> none <section> stacked commits for requirement scrub , just see latest one for the related ticket <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"event services requirements scrub <section> <allcaps> evs </allcaps> requirements out of date <section> update requirements <section> n / a <section> summary of changes ( w / links if individual issues exist already ) : - cevs3018 - hk requirement not consistent ( update wording ) - cevs3103 . <number> - filter counter configurable max ( change from hard number ) - cevs3110 - free app resources , done by es_appexit ( delete <allcaps> evs </allcaps> req ) - cevs3200 - initialize ports default config per port ( delete , psp / hardware configuration # <number> # <number> ) - cevs3201 - power on event format configurable ( change from long ) - cevs3207 - preserve log mode on processor reset ( clarify requirement , just wording update ) - cevs3209 - processor reset default log mode ( delete , conflicts with <number> ) - cevs3300 - support # of message ports ( delete , psp / hardware dependent # <number> # <number> ) - cevs3301 - event log size ( delete , mission config ) - cevs3302 - # of event filters per app ( delete , mission config ) - <allcaps> new api </allcaps> requirements : - none - <allcaps> new </allcaps> cmd requirements : - none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , table services requirements scrub <section> updates table services requirements per recent scrub , see issue for detailed changes . fix # <number> <section> none , doc change only <section> none <section> none <section> see latest commit for just the <allcaps> tbl </allcaps> changes ( stacked on the rest of the requirement commits to simplify review ) . <section> n / a <section> jacob hageman - <allcaps> gsfc </allcaps> / <allcaps> nasa </allcaps>",2.0
"fix # <number> , executive services requirements scrub ( cmd version ) <section> adds missing es command requirements fixes # <number> <section> none , doc change only <section> none <section> none <section> related to # <number> <section> n / a <section> jacob hageman - <allcaps> gsfc </allcaps> / <allcaps> nasa </allcaps>",2.0
"table services requirements scrub <section> <allcaps> tbl </allcaps> requirements out of date <section> update requirements <section> n / a <section> summary of changes ( w / links if individual issues exist already ) : - ctbl6011 - hk requirement not consistent ( update wording ) - ctbl6301 - free app resources handled by es_appexit , delete <section> <section> - <allcaps> new api </allcaps> requirements : - ctbl6313 : cfe_tbl_validate - ctbl6314 : cfe_tbl_dumptobuffer - ctbl6315 : cfe_tbl_modified cfe - <number> - ctbl6316 : cfe_tbl_manage cfe - <number> - <allcaps> new </allcaps> cmd requirements : - ctbl6013 : cfe_tbl_deletecdscmd - ctbl6013 . <number> : delete <allcaps> cds </allcaps> - table in use - ctbl6013 . <number> : delete <allcaps> cds </allcaps> - not critical table - ctbl6013 . <number> : delete <allcaps> cds </allcaps> - already deleted <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> * <allcaps> edit </allcaps> * - bold items missed in first round",2.0
executive services requirements scrub - missing command requirements <section> es requirements out of date <section> update requirements <section> n / a <section> note # <number> and # <number> missed the following new commands . new command requirements : - ces1029 : cfe_es_startperfdatacmd - ces1030 : cfe_es_setperffiltermaskcmd - ces1031 : cfe_es_setperftriggermaskcmd - ces1032 : cfe_es_queryalltaskscmd - ces1033 : cfe_es_sendmempoolstatscmd <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , executive services requirements scrub <section> updates es requirements , see details in issue . fixes # <number> closed # <number> as a duplicate ( fixed here ) . <section> none , only doc change <section> requirements now match code except where addressed by open issues (# <number> , # <number> , # <number> , # <number> ) <section> n / a <section> note this commit is on top of # <number> commits , just review this commit . <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"es requirements scrub <section> es requirements out of date <section> update requirements <section> n / a <section> summary of changes ( w / links if individual issues exist already ) : - ces1000 - hk requirement not consistent ( not a real command , update wording ) - ces1007 . <number> - restart app claims app will continue running if file missing (# <number> ) , fix req - ces1010 - fix <allcaps> tbd </allcaps> in rational - ces1013 , ces1013 . <number> - shell requirements - remove (# <number> ) - ces1316 . <number> - copy from <allcaps> cds </allcaps> , invalid data case copies data and returns error ( make req match code ) - ces1522 - log mode discard on processor reset ( make configurable , # <number> ) - <allcaps> new </allcaps> ces1523 - log mode on power - on reset ( make configurable , # <number> ) - ces1700 - max apps ( remove , platform specifc ) - ces1702 * , ces1703 * - remove exception handling requirements from cfe ( they are <allcaps> psp </allcaps> ) - ces1704 , ces1705 , ces1706 , ces1707 , ces1708 - remove sizing , platform dependent - ces1302 , ces1303 - processor and spacecraft id are <allcaps> psp </allcaps> apis , remove from cfe req - ces1026 - dumpcds does not dump integrity ( update requriement ) - <allcaps> new api </allcaps> requirements : - ces1329 : cfe_es_poolcreatenosem ( ces1321 also updated to note it ' s the protected version ) - ces1330 : cfe_es_getmempoolstats - ces1331 : cfe_es_getpoolbufinfo - ces1332 : cfe_es_reloadapp - ces1333 : cfe_es_runloop - ces1334 : cfe_es_waitforsystemstate - ces1335 : cfe_es_waitforstartupsync - ces1336 : cfe_es_getappinfo - ces1337 : cfe_es_incrementtaskcounter - ces1338 : cfe_es_registergencounter - ces1339 : cfe_es_deletegencounter - ces1340 : cfe_es_incrementgencounter - ces1341 : cfe_es_setgencount - ces1342 : cfe_es_getgencount - ces1343 : cfe_es_getgencounteridbyname - ces1600 : cfe_fs_readheader - ces1601 : cfe_fs_initheader - ces1602 : cfe_fs_writeheader - ces1603 : cfe_fs_settimestamp - ces1604 : cfe_fs_extractfilenamefrompath , <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> * <allcaps> edit </allcaps> - * remove shell requirements added , ces3121 update noted , added new requirement numbers",2.0
"doxygen event documentation needs scrub <section> doxygen event output does not match code in at least <number> case , see cfe_es_initstats_inf_eid <section> scrub event doxygen and confirm it matches actual output ( and type ) <section> maybe <hashtag> define </hashtag> the string as a single definition and link in documentation <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> - update <allcaps> api </allcaps> documentation <section> updates <allcaps> api </allcaps> documentatin fix # <number> <section> steps taken to test the contribution : <number> . make usersguide <number> . verified modifications <section> none <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle <section> does not fix everything , just <allcaps> api </allcaps> ' s see also # <number> for device driver <allcaps> api </allcaps> removal <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update doxygen cfe <allcaps> api </allcaps> documentation <section> at minimum , cfe_tbl_notifybymessage is missing <section> scrub and include references to all <allcaps> api </allcaps> ' s in documentation <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add native permissive mode configuration <section> this adds the native_osconfig . h which is included after the default_osconfig . h if <allcaps> simulation </allcaps> = native is set . fix # <number> <section> steps taken to test the contribution : <number> . copy cfe / cmake / sample_defs to top dir ( per standard setup instructions ) <number> . make <allcaps> simulation </allcaps> = native prep <number> . make ; make install ; <number> . execute core - cpu1 in build / exe / cpu1 and confirmed permissive mode <number> . also did steps above with just make prep , and confirmed permissive mode wasn ' t set <section> no longer requires sed "" hack "" to change the setting in default_config . h <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle with this branch <section> update related <allcaps> readme </allcaps> ' s and ci to no longer perform sed "" hack "" <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_tbl_load should produce clearer message when it has a file header mismatch <section> cfe_tbl_loadfromfile compares the application ' s name + table name with the string in the header of the file . if you configure the cfe_es_startup . scr with a different application name than what is expected in the header , you get an obtuse "" fail to load tbl ' <app> . <tbl> ' from ' / cf / <file> . tbl ' "" not making it clear that it ' s purely a mismatch of the header . <section> at minimum it should indicate that the matter is a mis - match of the header and the expected header ( which means that the file is there , for example ) . better would be to report the actual contents of the header and the expected value . the <allcaps> eid </allcaps> for the error is unique so cfe_tbl_load can produce an event with more specific text . <section> could have cfe_tbl_loadfromfile generate the event , but that ' s an "" internal "" fn so probably not . <section> add any other context about the feature request here . <section> <email>",2.0
"<allcaps> cfe es </allcaps> unnecessarily keeping multiple copies of task / app names <section> when reviewing the changes for other tickets , noted that the <allcaps> cfe es </allcaps> is storing the app name in the <code> twice . it is stored in the <code> subfield , as well as the <code> sub field . these appear to be always set together , to the same value , such as in cfe_es_appcreate for example : <url> <url> it then goes on to store the same string a third time in the tasktable [ x] . taskname field for the task itself : <url> the name is a string value and therefore takes a fair bit of memory to store . in the "" stock "" example config this bloats the size of the es data structures by about <number> bytes , but could easily be much more in a real deployment if os_max_api_name is set longer and / or the max number of apps / tasks is larger . <section> should store _at most_ one copy of the name in the <code> , but even that might not be needed if it is always the same as the main task name ( which it appears to be ) . for tasks , <allcaps> osal </allcaps> already stores the task name . for the <allcaps> es api </allcaps> calls that need to get the name , it should just lookup the name from <allcaps> osal </allcaps> , just like we are doing for sb in # <number> <section> joseph hickey , vantage systems , inc .",2.0
"maximum number of cfe instances ? this is not a bug , but a question related to cfe usage : we are currently trying to perform multi - agent simulations using applications developed on the cfe middle - ware . a single agent is launched by running the core executive . however , we are not able to launch more than <number> instances of cfe on a single linux machine . the 8 th instance of cfe throws errors : "" createpipeerr : os_queuecreateerr returned - <number> "" please see attached image . are there any parameters that could be changed to enable more instances of cfe to run on a single machine ? changing the default values of os_max_queues , cfe_platform_sb_max_pipes did not seem to help . createpipeerr <img> <section> <allcaps> nia </allcaps> / <allcaps> nasa </allcaps> langley",3.0
"documentation on cfe_sb_getmsgtime ( ) / setmsgtime ( ) needs updated . they do not set / get timestamps for commands ( cfe_sb_cmd_hdr_size ) . <section> documentation does not clearly state that <code> and <code> are only useful if the message header is big enough . basically , the <code> does not have this field and so it would return <number> . <section> amend the documentation to let others know that those functions are not used when the <code> <section> actually it would probably be better if there was some kind of assert or check to inform the programmer that the function probably should not be used since returning <number> is really returning nothing . maybe ? <url> from <url> <section> documentation in <code> pg . <number> : > before sending an sb message to the sb , the application can update the sb message header . the most common update is to put the current time in the sb message . this is accomplished with one of two <allcaps> sb api </allcaps> functions . the most commonly used function would be cfe_sb_timestampmsg ( ) . this <allcaps> api </allcaps> would insert the current time , in the mission defined format with the mission defined epoch , into the sb message header . the other <allcaps> sb api </allcaps> that can modify the sb message header time is cfe_sb_setmsgtime ( ) . this <allcaps> api </allcaps> call sets the time in the sb message header to the time specified during the call . this is useful when the application wishes to time tag a series of sb messages with the same time . > > other fields of the sb message header can be modified by an application prior to sending the sb message . these fields , and the associated apis , are listed in the following table : i did not see anywhere that it said if the message is a command msg , i . e . , <code> then it will not have a timestamp and therefore these functions return <number> . code : <url> just went down a rabbit hole trying to figure out why the message header sizes did not match in my test cases . <section> philip cooksey at <allcaps> nasa </allcaps> ames",2.0
"remove obsolete * . mak files <section> find . / - name "" * . mak "" shows obsolete make files <section> remove them <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , remove device driver requirements <section> fixes # <number> - deleted ces1321 . <number> which was just a copy of ces1321 ( from old documents ) - fixed summary on ces1515 . <number> - in a separate commit , now ordering by id ( the correct flow ) <section> none - requirements change only <section> n / a <section> n / a <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove device driver references from app development guide and cleanup <section> device driver apis never implemented , guide has references to a design model that does not work <section> device driver scrub : - scrub the guide , remove non - existent references other minor cleanup : - fix table of contents - remove old doc file <section> n / a <section> see # <number> and # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add usersguide / osalguide to local targets <section> added userguide and osalguide to the local target list to avoid makefile warning fix # <number> <section> steps taken to test the contribution : <number> . ran make userguide and osalguide and confirmed no longer outputs warnings <section> passes enhanced ci <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle with this change <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_sb_getlastsenderid will crash if if called before message sent on pipe cfe_sb_getlastsenderid assumes that cfe_sb . pipetbl [ pipeid ] . currentbuff is not <allcaps> null </allcaps> . upon cfe_sb_createpipe , this will be null . currentbuff is only set upon receiving a message in cfe_sb_rcvmsg ( ) . so , if cfe_sb_getlastsenderid is called before receiving a message the program will crash . this is steven seeger from <allcaps> gsfc </allcaps> . guess i have a personal account on github . <happy>",0.0
unit test macros and example use with sb <section> sample macro - ification of ut code for <allcaps> ccb </allcaps> consideration . partial implementation of # <number> fix # <number> <section> made sb unit tests and confirmed all passed . <section> simplified ut code <section> debian linux <section> <email> <allcaps> edit </allcaps> : added this fixes # <number>,2.0
macros for simpler unit test code <section> existing cfe unit test code is voluminous and contains a lot of redundant conditional code . <section> the checking of conditions in cfe unit tests can be simplified with macros and / or functions . <section> would still like to consider a test generator of some sort . <repeated> <section> add any other context about the feature request here . <section> <email>,2.0
"doxygen warning for \ "" usersguide \ "" <section> doxygen errors for "" usersguide "" must be fixed before submitting a pull request defined by ci <url> <url> <section> ` <code> ` <section> amd64 compiler : gcc c <allcaps> buildtype </allcaps> = debug omit_deprecated = false <section> warning : overriding recipe for target ' usersguide ' warning : ignoring old recipe for target ' usersguide ' <section> anhelina yurkova <allcaps> nasa goddard </allcaps> / <allcaps> asrc ses ii </allcaps>",2.0
cfe tlm packet <number> - bit alignment issue <section> compiler add padding is applied to cfe telemetry packets if the data region does not start on a <number> bit boundary and the packet contains a <number> bit variable . <section> steps to reproduce the behavior : <number> . nominal build process . <number> . enable tlm . <number> . bit bust a telemetry packet containing a <number> bit variable . <section> no compiler added padding should be applied . <section> ubuntu <number> - bit - <number> <section> dan knutsen <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"build failure of ut_time_stubs with <allcaps> buildtype </allcaps> = release <section> matrix build fails with : <allcaps> buildtype </allcaps> = release omit_deprecated = false see also <url> ( enhanced ci ) <section> steps to reproduce the behavior : <number> . see ci process / results <section> successful build <section> <code> <section> - ci system , integration candidate bundle <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"separate execute in shell functionality from core cfe service <section> command to execute in shell a concern in some security scenarios . <section> remove from the core , better suited to an app ( optional , can be included or loaded based on mission requirements / needs ) <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"deprecate multiple "" success "" code responses <section> <allcaps> api </allcaps> ' s with multiple "" success "" codes are frequently mishandled <section> single success response , unique information should be passed back in parameters <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
""" error , can not open es app startup file : / cf / cfe_es_startup . scr "" when running a sample cpu1 application <section> i apologize in advance if the following issue that i am reporting is caused by my misunderstanding of the cfs / cfe cmake build system . the issue is that i am getting the following issue when <number> ) i run the <code> command from the <allcaps> cfs </allcaps> repository and also <number> ) if i run it from clion with the changes described in # <number> . <section> <code> the log : <code> <section> <code> the log : <code> ` ` <code> . / cf / cfe_es_startup . scr <code> ` <code> ` <code> cfe_es_startup . scr <code> . scr ` file available to <allcaps> cfs </allcaps> . <section> none . <section> stanislav pankevich ( <allcaps> pts </allcaps> , private german space company )",3.0
add functional test for sb unsubscribe / resubscribe with incrementing count <section> # <number> updated sequence counter behavior . need to add a functional test to cover it . <section> add a functional test . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"potential for app exit failure when not passing back runstatus <section> cfe_es_exitapp reports error when passed in exitstatus is cfe_es_runstatus_app_run . typical app pattern ( see <url> is : ` <code> ` but cfe_es_runloop does not update runstatus on internal request to stop : <url> <section> steps to reproduce the behavior : <number> . send restartapp , will error and fail to restart . <section> set passed in runstatus to the control request for the case above : runstatus = cfe_es_global . apptable [ appid ] . controlreq . appcontrolrequest allows the app to take appropriate action . <section> - cfs dev server - os : ubuntu <number> - versions : current dev ( <number> . <number> ) <section> fails build verification testing <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"update section <number> . <number> “ hardware servicing ” application in developer ' s guide <section> section <number> . <number> hardware service in developer ' s guide needs to be updated . <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for src / time <section> current coverage : <number> % cfe_time_api . c cfe_time_cfe2fsseconds <code> cfe_time_print <code> cfe_time_task . c cfe_time_taskinit <code> cfe_time_utils . c cfe_time_getreference <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for src / tbl <section> current coverage : <number> % cfe_tbl_api . c cfe_tbl_register <code> cfe_tbl_update <code> cfe_tbl_manage <code> cfe_tbl_task_cmds . c cfe_tbl_loadcmd <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for src / sb <section> current coverage : <number> % missing code coverage for the following : cfe_sb_api . c cfe_sb_setpipeopts <code> cfe_sb_sendmsgfull <code> cfe_sb_task . c cfe_sb_taskmain <code> cfe_sb_appinit <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for src / fs <section> current coverage <percent> missing coverage for the following : cfe_fs_decompress . c fs_gz_eat_header_reentrant <code> <code> fs_gz_huft_build_reentrant <code> <code> <code> <code> <code> <code> <code> fs_gz_inflate_dynamic_reentrant <code> fs_gz_inflate_stored_reentrant <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for cfe_es_apps . c <section> current coverage for cfe_es_apps . c = <number> % missing coverage test for the following : cfe_es_appcreate <code> cfe_es_cleanupobjectcallback <code> cfe_es_cleanuptaskresources <code> cfe_es_countobjectcallback <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for cfe_es_task . c <section> missing code coverage for the following : cfe_es_taskinit <code> <code> <code> cfe_es_housekeepingcmd <code> <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for cfe_es_start . c and cfe_es_syslog . c <section> coverage test : <percent> missing coverage for the following : cfe_es_start . c : cfe_es_createobjects <code> cfe_es_syslog . c : cfe_es_syslogreaddata <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for cfe_es_shell . c <section> no coverage test for cfe_es_shellcountobjectcallback <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"incomplete coverage test for cfe_es_api . c <section> current coverage : <number> % missing coverage for the following : cfe_es_setappstate <code> cfe_es_reloadapp <code> cfe_es_exitapp <code> cfe_es_deletechildtask <code> cfe_es_getappidinternal <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"add global scope option to omit deprecated items <section> fix # <number> adds a "" global_build_options . cmake "" file akin to the existing arch_build / mission_build option files . include an example of this file that optionally does add_definitions ( ) to omit the deprected elements for build testing . <section> build with and without the omit_deprecated flag on the prep command , and confirm that it is correctly translated to the <code> globally for all tools and <allcaps> fsw </allcaps> code . <section> affects build system only . no change to runtime behavior . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"add compiler option examples <section> fix # <number> - add extra compile options for mission scope and arch scope . these are separated such that the same basic structure will also apply to cross compile environments that do not / cannot use the same flags on both ( host and cross ) builds . for "" mission "" build the targets are never cross compiled , only built for the native host machine . it should be safe to assume a compiler in the <allcaps> gcc </allcaps> family and the strict warnings should _always_ be applicable here . for "" arch "" build the options are compiler vendor dependent . the file as - supplied can only be used if all the target cross compilers are in the same family and support the same warning options . however , this file can be modified without affecting the options used for the host side tools . <section> build for <allcaps> simulation </allcaps> = native and confirm full suite of warnings is used for both host - side tools and <allcaps> fsw </allcaps> code . also build for other platforms ( <allcaps> mips </allcaps> , <allcaps> rtems </allcaps> ) where the code is not ( yet ) fully warning - free . confirmed that the warnings can be modified at the arch_build without affecting the host - side tools which are still built with full warnings . <section> no impact to runtime behavior <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( build host ) <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"doxygen obsolete warning <section> obsolete warning when creating osalguide / usersguide / doc : ` ` <code> details_at_top ' at line <number> of file <code> show_directories ' at line <number> of file <code> html_align_members ' at line <number> of file <code> xml_schema ' at line <number> of file <code> xml_dtd ' at line <number> of file <code> ` ` <section> anh van , <allcaps> nasa </allcaps> goddard",1.0
use src_local_path as single source of truth this avoids the two path diverging and possibly causing problems in the future <section> the call to <code> is building its own path even though its contents are identical to <code> . this change avoids possible divergence of these values in the future . <section> ran a local build . <section> no change in behavior .,1.0
"cfe_es_perflogadd needs better mutual exclusion <section> the <code> routine uses <code> in an attempt to get exclusive access to a common global data structure to record performance metrics / state . this is insufficient . the <code> function is generally not implemented on <allcaps> smp </allcaps> , and even if it is , it probably only affects the current core . either way , it will <section> provide exclusivity , because the other cores can still access the data even when interrupts are disabled . this function is also a no - op in the <allcaps> posix osal </allcaps> . <section> enable performance monitoring on a <allcaps> posix </allcaps> system and observe that occasionally samples occur in the log out of order or otherwise appear corrupted . this is likely due to concurrent writes to the same entry related to insufficient locking . <section> the function should use some form of primitive that actually does provide exclusivity between threads ( such as a mutex / spinlock ) and not an interrupt lock . <section> <url> <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , update tone leap variable <section> fixes # <number> <section> <number> . modified cpu1_platform_cfg . h such that i could reproduce the error : <hashtag> un def </hashtag> cfe_platform_time_cfg_bigendian - - > <hashtag> define </hashtag> cfe_platform_time_cfg_bigendian <number> . corrected cfe_time_tone . c via replacing all instances of attoneleaps variable with attoneleapseconds . <number> . recompiled software : make prep make make install <number> . ran software and verified that the issue was fixed : . / core - cpu1 <section> the software will compile and run successfully . <section> oracle vm virtualbox os : ubuntu - <number> version : cfe <number> . <number> ; <allcaps> osal </allcaps> <number> . <number> ; <allcaps> psp </allcaps> <number> . <number> <section> none <section> dan knutsen <allcaps> gsfc </allcaps> / <allcaps> nasa </allcaps>",0.0
"avoid alignment warnings on some cpus <section> - fix # <number> partially address # <number> ( overlapping issue ) on cpus with strict alignment requirements , some <allcaps> cfe </allcaps> code that uses a char - type pointer ( e . g . uint8 <wink> to compute memory addresses triggers an alignment warning when it gets cast back to the actual data type . in the mempool implementation , the pointer should be sufficiently aligned already , because the address computation already takes <allcaps> cpu </allcaps> alignment requirements into account when calculating the addresses / offsets . - for the cfe_sb pool buffers , using the <code> type , which is integer in nature , avoids the warning . - for the cfe_tbl internal table pointer , use a <code> internally to store the buffer pointer , rather than a <code> . this changes the casting needs elsewhere . <section> build <allcaps> cfe </allcaps> with enable_unit_tests = <allcaps> true </allcaps> confirm all unit tests passing perform sanity test on <allcaps> cfe </allcaps> ( normal startup , send commands from console ) build for mips64 and ensure that ( some ) alignment warnings are fixed <section> no change to behavior . fixes build warnings only . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> there are still some remaining alignment cast warnings regarding the message types , where a local message buffer is cast to a <code> which has a higher alignment requirement . this is a little harder to fix as it requires changing the local buffer definition . <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"consistent results from cfe_es_syslog_append and cfe_es_writetosyslog <section> from # <number> , cfe_es_writetosyslog : > upon additional review - the only "" extra "" thing that cfe_es_writetosyslog does is a final call to os_printf to duplicate the syslog message onto the console , which would not be done when calling the functions individually . > in particular , this means that any syslog messages generated in the <allcaps> cds </allcaps> use case would not appear on the console . this could be a valid concern / issue that might warrant a fix . <section> consistent behavior <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , create osal api guide with doxygen <section> create osal api guide <section> steps taken to test the contribution : <number> . make prep <number> . make osalguide <section> - hardware - ubuntu <number> - <allcaps> cfe </allcaps> <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"create osal api guide with doxygen <section> auto - generate osal api guide with doxygen <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"issue # <number> , update toolchain - ppc - vxworks6 . <number> <section> - fix # <number> update toolchain - ppc - vxworks6 . <number> . cmake to include new bsp name reference <url> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"update toolchain - ppc - vxworks6 . <number> . cmake <section> update toolchain - ppc - vxworks6 . <number> . cmake to use mcp750 - vxworks name <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"improve <allcaps> api </allcaps> consistency for functions accepting a software bus message <section> the data types accepted by the <allcaps> sb api </allcaps> are not entirely consistent . most <allcaps> api </allcaps> functions that operate on software bus message buffers accept a <code> . there are some exceptions , most notably the <code> function accepts a <code> . <section> all <allcaps> sb api </allcaps> functions that operate on message buffers should use the <code> type ( or <code> ) <section> making the interface type - correct helps the compiler ' s type checking do its intended job , helping to catch / avoid the possibility of passing a data buffer which is not actually an sb message buffer . using <code> permits anything to be passed in , effectively disabling all checking . <section> joseph hickey , vantage systems , inc .",2.0
"set osal_system_bsptype for native builds <section> fix # <number> this explicitly specifies the <allcaps> bsp </allcaps> to use when using <code> flags to the build . all other example toolchain files already included this setting . <section> rebuild code with and without <code> flag . confirmed no build issues / changes . <section> no impact - build script change only . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> this makes it compatible after a related <allcaps> osal </allcaps> build script cleanup is also merged ( see nasa / osal # <number> , nasa / osal # <number> ) . <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"<allcaps> cfe </allcaps> cmake toolchain script ( s ) should set osal_system_bsptype <section> the <allcaps> osal </allcaps> scripts contain some convoluted logic to deal with the fact that the <allcaps> cfe psp </allcaps> and <allcaps> osal bsp </allcaps> are overlapping in function . in particular the <allcaps> osal </allcaps> script checks <code> as a fallback if osal_system_bsptype is unset , in order to decide which <allcaps> bsp </allcaps> to use for unit tests . it is desired to clean this up and simplify this logic . <section> all example toolchains should set osal_system_bsptype so that <allcaps> osal </allcaps> builds a specific <allcaps> bsp </allcaps> for the platform , to be used for unit testing as well as ( eventually ) the <allcaps> psp </allcaps> startup as well . <section> having this variable set simplifies the <allcaps> osal </allcaps> build considerably and makes it better isolated from the <allcaps> cfe </allcaps> build . a proposed change to <allcaps> osal </allcaps> ( as part of issue nasa / osal # <number> ) will make the <code> a required option , failing the build if it is unset this change to the <allcaps> cfe </allcaps> toolchains should be backward - compatible . <section> joseph hickey , vantage systems , inc .",2.0
"alignment warnings when casting char * pointers <section> when compiling on architectures with strict alignment requirements , casts between <code> ( as used in some pointer arithmetic to calculate addresses ) to other types triggers a warning about alignment . <section> build for an architecture with strict alignment requirements ( <allcaps> sparc </allcaps> , <allcaps> mips </allcaps> , etc ) . example compiler warning : <code> <section> should build cleanly with no warnings <section> - ubuntu <number> <allcaps> lts </allcaps> build host - <allcaps> mips </allcaps> cross compiler ( mips - poky - linux - gcc version <number> . <number> ) <section> many of these are actually safe because <allcaps> cfe </allcaps> ensures that the <code> as well as the base / pool addresses are aligned for the largest data types . however , because the pointer arithmetic is done as a <code> the compiler sees the cast from an <code> to a larger type as an issue . <section> joseph hickey , vantage systems , inc .",2.0
"update ut entry point to correspond with <allcaps> osal </allcaps> / ut assert change <section> - fix # <number> use <code> instead of <code> as the entry point function for test applications . this needs to be merged in coordination with a related change in <allcaps> osal </allcaps> / ut assert . this also updates the ut application final link to use "" ut_assert "" rather than "" ut_bsp "" , as the separate bsp for unit test is also getting phased out . <section> build <allcaps> cfe </allcaps> for all supported platforms ( native linux , <allcaps> rtems </allcaps> , vxworks ) in conjunction with related <allcaps> osal </allcaps> pull request and confirm unit test build and run successfully <section> no change to behavior <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> needs to be merged in coordination with nasa / osal # <number> <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"use "" uttest_setup "" as name of entry point for unit tests <section> in nasa / osal # <number> , the ut assert library is being modified to use a different entry point function name for unit test code , not <code> as is used for a normal application . <section> the <allcaps> cfe </allcaps> unit tests need to use <code> instead . <section> any name could work for test setup , but the issue is that it has to be different than that of a normal application . this is so the normal entry point can be provided by ut assert here , allowing better layering . <section> changing the name of the test entry point makes more sense because these only use the <allcaps> osal bsp </allcaps> but run with the stub library for <allcaps> osal </allcaps> itself . it is therefore not really accurate to name the entry point as <code> because this is not an <allcaps> osal </allcaps> application at all , it is a unit test . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"issue # <number> , resolve cpp check <section> - fix # <number> resolve cpp check <section> steps taken to test the contribution : <number> . cppcheck - - force - - inline - suppr - - std =c 9 9 - - language =c - - error - exitcode = <number> - - enable = warning , performance , portability , style - - suppress = variablescope - - inconclusive fsw / cfe - core / src <number> > cppcheck_flight_cfe . txt <section> - hardware - ubuntu <number> - <allcaps> cfe </allcaps> <number> <section> add any other context about the contribution here . <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"fix # <number> , const string initialization <section> fixes # <number> <section> steps taken to test the contribution : <number> . make enable_unit_tests = <allcaps> true simulation </allcaps> = native prep <number> . make <number> . make install <number> . make test <section> no change <section> - cfs dev server - os : ubuntu <number> - versions : master bundle with this commit <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
fix missing const warning with - wdiscarded - qualifiers enabled <section> initialization discards const qualifier . <repeated> warning in sb_ut . c with the following flags enabled : <code> <section> add const ( the internal variables are not modified ) . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"issue # <number> , adding travis . yml for cppcheck on flight <section> - fix # <number> adding travis . yml for cppcheck on cfe - core / src <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"adding cppcheck for cfe - core / src <section> adding travis . yml for cppcheck on cfe - core / src <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"cppcheck for cfe - core / src <section> resolve cpp check warning . <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"fix # <number> , always increment sequence counter <section> - fix # <number> note that this means route entries will never be removed and unsubscribe messages will never be sent . <section> built and ran the sb unit tests . all passed , with changes included in this pull req . <section> sequence id ' s of messages should increment even when there ' s ( currently ) no subscribers to that message id . <section> debian vm <section> <email>",2.0
"many unit tests report event count errors as hex <section> unit tests check the number of events sent during the test , many of these in sb_ut . c are reported as hex . <repeated> such as in test_sb_cmds_sendprevsubs ( line <number> . ) <section> uncovered when i was changing getpipename to produce events ( as part of making it a public <allcaps> api </allcaps> ) and the unit test event counts had to be updated . a simple test is to change the "" exprtn "" for a test . <section> event counts should reported in decimal . <section> see above . <section> linux vm <section> n / a <section> <email>",2.0
"separate the <allcaps> cfe </allcaps> stubs from ut test cases <section> fix issue # <number> build the <allcaps> cfe ut </allcaps> stub library separately from the test cases . this moves the stub files into a separate ut - stubs directory , and the library is now called "" ut_cfe_core_stubs "" note : minor cleanup also done as part of moving . two stub files were in the source tree but not being built or used by any framework test config . these were : ut_arinc653_stubs . c ut_configdata_stubs . c these are now removed . also cleaned up some old macros / ifdefs that were never enabled or used in the current tests . <section> build <allcaps> cfe </allcaps> using default configuration with enable_unit_test = <allcaps> true </allcaps> . confirm <allcaps> cfe </allcaps> core executes normally . confirm all <allcaps> cfe </allcaps> unit tests build and run as normal . <section> no impact to behavior . <allcaps> cfe fsw </allcaps> code is unchanged , this only affects ut build / link procedure . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"investigate various verifycmdlength implementations and possible common utility <section> cfe_*_verifycmdlength <censored> is defined for each service except <allcaps> tbl </allcaps> , and <allcaps> tbl </allcaps> does it slightly differently within cfe_tb_taskpipe . <section> suggest a common implementation . <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"build system needs to better separate the ut stub function from the ut test cases <section> currently the "" unit - test "" subdirectory generates libraries that provide stubs for all public <allcaps> api </allcaps> calls defined in the <allcaps> cfe </allcaps> core apps , as well as test cases and executables for unit testing the <allcaps> cfe </allcaps> itself . having these combined like this causes a few problems : - the two products have different scopes . the ut stubs apply globally across the entire mission and can / should be used for all ut ( platform - independent ) , but the test cases do need to be tuned to the platform , so a separate set of test cases needs to be built per - platform . - as a result , the ut stubs themselves are also built per - platform . this is wasteful but more importantly this makes linking to the <allcaps> cfe </allcaps> stubs from application ut code difficult . - it is also undesirable just from a general code organization standpoint . the directory structure would be cleaner if these were in separate subdirectories . <section> build code with enable_unit_tests = <allcaps> true </allcaps> and observe that the <allcaps> cfe </allcaps> "" stub "" library is named "" libut_cfe_core_default_cpu1_stubs . a "" ( i . e . build specifically for the default / cpu1 platform config ) and it resides in the same directory as the ut executables / test cases . <section> the stub library should be named only "" libut_cfe_core_stubs . a "" and it should be in a separate subdirectory from the unit test cases themselves . <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> joseph hickey , vantage systems , inc .",2.0
"suggested upper limit value creates infinite loop when the user sets <code> , the documentation specifies a range of <number> to 0 xffff . this value is later used in a <code> in cfe_sb_priv . h as follows : <hashtag> define </hashtag> cfe_sb_max_number_of_msg_keys ( <number> + cfe_platform_sb_highest_valid_msgid ) this value is then used as the upper limit of a for loop here <url> . the problem is that if the user sets the upper limit of 0 xffff as specified , the <code> becomes <code> . this value is used as the upper range of the for loop linked above . since the iterator used in that loop is a unsigned <number> bit integer , it can never reach <code> and creates an infinite loop . suggested fix would be to : <number> . stop using <code> s which add to other <code> s <number> . never use <code> s as iterator range variables <number> . check types of all iterators <number> . change the documentation of <code> to say max value of <code>",2.0
clean up table services comments <section> inconsistent comments found on line <number> in cfe_tbl_internal . c ' . <section> ' cfe_tbl_internal . h ' should be replaced with ' cfe_private . h ' <section> <section> general scrub recommended . <section> dan knutsen <allcaps> nasa gsfc </allcaps>,1.0
"exception and reset log possible race conditions <section> cfe_es_clearerlogcmd and cfe_es_writetoerlog both modify shared cfe_es_resetdataptr values . cfe_es_processcoreexception and cfe_es_resetcfe both use cfe_es_writetoerlog ( both are <allcaps> api </allcaps> ' s , so could be out of es context ) . <section> looks to me like if cfe_es_clearerlogcmd gets interrupted by the processing of an app core exception , the log could get corrupted . <section> no race . <section> see functions above . <section> - latest cfs bundle dev branch <section> not observed , via code review . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"initialize system log mode implementation does not match requirement ces1522 <section> requirement ces1522 "" upon a processor reset , the cfe shall set the system log mode to discard . "" implementation : <url> the build verification test just happens to pass because the sample configuration defaults the mode to discard . <section> update requirement or implementation . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"clarify cfe_es_syslog_append use vs cfe_es_writetosyslog <section> cfe_es_syslog_append is used is just a few places ( cds , esmempool ) , everywhere else is cfe_es_writetosyslog . <section> consistency is preferred for maintenance and usability , if there is not sufficient justification for a separate macro , remove it and use cfe_es_writetosyslog . <section> if there is clear justification , consider adding to the macro documentation / comments <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> *edit* - typo",3.0
"remove device driver references from code <section> # <number> is to remove device driver requirements , there are also references in the software . <section> remove references to device drivers , "" cfe_drv "" , etc from software , configuration files , documentation , etc . for example : <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add <allcaps> contributing </allcaps> . md is your feature request related to a problem ? please describe . github repositories are suggested to have a <allcaps> contributing </allcaps> . md document which describes best practices for developers wishing to contribute to the main release . describe the solution you ' d like develop a <allcaps> contributing </allcaps> . md document with simple stuff like "" follow the coding style guidelines "" , run unit tests prior to a pull request , etc . describe alternatives you have considered likely will need to incorporate or reference existing documentation . could also use the wiki capabilities of dropbox . additional context add any other context about the feature request here . requester info chris knight , <allcaps> nasa </allcaps> ames research center .",1.0
"fix # <number> , add <allcaps> sb api </allcaps> to get pipe by name <section> fixes issue # <number> <section> make mission - all ; run cpu1 / cfe_core_default_cpu1 / unit - test / cfe_core_default_cpu1_sb_ut <section> adds a new function , cfe_sb_getpipeidbyname , which retrieves the pipe id given a name of a pipe . as this would conflict with the removal of the pipename from the pipetbl , this code uses the os_queuegetidbyname and iterates across the pipetbl to find the matching entry . <section> ubuntu <number> - bit linux <number> . <section> chris knight , <allcaps> nasa </allcaps> ames research center .",2.0
"doxygen warning expected <tr> tag and illegal command <section> / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / inc / cfe_es . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / inc / cfe_es . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / sb / cfe_sb_priv . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! / media / sf_share / cfs_11_5_2019 / cfs / cfe / fsw / cfe - core / src / inc / cfe_sb_msg . h : <number> : warning : illegal command \ sb_pipeoptsec as the argument of a \ c command <section> steps to reproduce the behavior : <number> . make usersguide <section> - hardware - ubuntu <number> - doxygen <date> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"untraced feature to decompress apps / lib on load <section> the feature to decompress apps / libraries on load that end in . gz does not have requirements or associated build verification . note it is covered in coverage / functional testing in fs_ut . c . <section> <number> . remove this feature from the core ( allows # <number> to externalize decompress to be implemented cleanly ) <number> . add requirements , design , and build verification and resolve how to implement vs # <number> desire to externalize <section> - implemented in cfe_es_apps . c - utilizes cfe_fs_api . c : cfe_fs_isgzfile , cfe_fs_getuncompressedfile , cfe_fs_decompress . c and cfe_fs_decompress . h <section> cfe_fs_decompress prototype is defined in both inc / cfe_fs . h and cfe_fs_decompress . h <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfs style guide <section> code and file naming in cfs and apps is inconsistent and does not follow a particular set of guidance , and no guidance were developed previously for cfs . <section> develop a "" style guide "" in markdown format for inclusion in cfe / docs , describing code formatting conventions , symbol naming conventions , documentation conventions , directory structure and file naming conventions , etc . this should be referenced by the app developer ' s guide and any other relevant docs and may incorporate or replace parts of existing documents . perhaps also link / refer from the github wiki . <section> other options include adding style information to the app developer ' s guide or identifier naming conventions documents . <section> jake provided the <allcaps> gsfc </allcaps> "" indent "" flags that are standard at <allcaps> gsfc </allcaps> , this is a good starting point for formatting and should be documented . <section> chris knight , <allcaps> nasa </allcaps> ames research center",1.0
"cpp check error <section> cpp check has warning . cfe / fsw / cfe - core / unit - test / ut_time_stubs . c : <number> <url> uninitialized variable : result cfe / fsw / cfe - core / unit - test / ut_time_stubs . c : <number> <url> uninitialized variable : result <section> steps to reproduce the behavior : <number> . cppcheck - - force . <number> . see warning <section> - hardware - <number> - cppcheck <number> , cfe <number> . <number> , osal <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",0.0
"set <code> to no for doxygen document builds and resolve all <code> and <code> warnings <section> the extract_all flag set to <allcaps> yes </allcaps> defeats the warn_if_undocumented and warn_no_paramdoc enabled errors <section> set extract_all to no and explicitly document all elements for at minimum the usersguide documentation . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <allcaps> edit </allcaps> - separated original issue , warning file name now in # <number>",1.0
"fix # <number> , unable to resolve link <section> fixed doxygen warning : unable to resolve linke <section> steps taken to test the contribution : <number> . make usersguide <number> . cfe_es_msg . h : <number> : check cfe__es__msg_8h . html <number> . cfe_evs_msg . h : <number> : - cfe__evs__msg_8h . html <number> . cfe_evs_msg . h : <number> : - cfe__evs__msg_8h . html <number> . cfe_es . dox : <number> : - cfeesugswreset . html <number> . cfe_es . dox : <number> : cfeesugcdssrv . html <number> . cfe_es . dox : <number> : - cfeesugmempoolsrv . html <number> . cfe_es . dox : <number> : - cfeesugmempoolsrv . html <number> . cfe_evs . dox : <number> : - cfeevsugcounters . html <number> . cfe_evs . dox : <number> : - cfeevsugfaq . html <number> . verify warning . log that warning is longer there . <section> - hardware - ubuntu <number> - cfe <number> . <number> , rc - <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"doxygen misc warning <section> cfe / fsw / cfe - core / src / inc / cfe_es . h : <number> : warning : expected <tr> tag but found tk_lnkword token instead ! cfe / fsw / cfe - core / src / inc / cfe_es . h : <number> : warning : the following parameters of cfe_es_waitforsystemstate ( uint32 minsystemstate , uint32 timeoutmilliseconds ) are not documented : parameter ' minsystemstate ' cfe / fsw / cfe - core / src / inc / cfe_es_msg . h : <number> : warning : found unknown command <code> \ c ' cfe / fsw / cfe - core / src / inc / cfe_fs . h : <number> : warning : the following parameters of cfe_fs_initheader ( cfe_fs_header_t * hdr , const char * description , uint32 subtype ) are not documented : parameter ' description ' parameter ' subtype ' cfe / fsw / cfe - core / src / inc / cfe_sb . h : <number> : warning : argument ' optsptr ' of command <user> is not found in the argument list of cfe_sb_getpipeopts ( cfe_sb_pipeid_t pipeid , uint8 * optptr ) cfe / fsw / cfe - core / src / inc / cfe_sb . h : <number> : warning : the following parameters of cfe_sb_getpipeopts ( cfe_sb_pipeid_t pipeid , uint8 * optptr ) are not documented : parameter ' optptr ' cfe / fsw / cfe - core / src / inc / cfe_sb_msg . h : <number> : warning : illegal command \ sb_pipeoptsec as the argument of a \ c command <section> steps to reproduce the behavior : <number> . make usersguide <section> - hardware - ubuntu <number> - doxygen <date> , rc - <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"doxygen warning , unable to solve link <section> doxygen gives warning , unable to resolve link . <repeated> etc doxygen_warning_cfe_unable_to_resolve . txt <url> <section> steps to reproduce the behavior : <number> . make usersguide <section> - hardware - ubuntu <number> - doxygen <date> , rc - <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"doxygen warning : explicit link <section> doxygen gives warning : explicit link request to ' cfe_sb_cmdhdr_t ' could not be resolved . <repeated> etc userguide_warning_explicit_link . txt <url> <section> steps to reproduce the behavior : <number> . make usersguide <section> - hardware - ubuntu <number> - doxygen <date> , rc - <number> - <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
add sample vxworks toolchain file <section> no example toolchain file to build for mcp750 included . <section> add the toolchain file used for testing . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
exclude unit - tests from lcov report ( skews results ) <section> unit test coverage results skewed by unit - test directory inclusion ( shows uncovered stub lines ) <section> lcov - - remove unit - test ( or whatever ) from the coverage . info line in makefile . sample <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
remove test results from fsw path <section> test results should be supplied as artifacts with the release . these results are outdated and not used for any new comparison checks . <section> remove from <allcaps> fsw </allcaps> . <section> none <section> specifically : - cfe / fsw / cfe - core / unit - test / esresults - cfe / fsw / cfe - core / unit - test / evsresults - cfe / fsw / cfe - core / unit - test / fsresults - cfe / fsw / cfe - core / unit - test / sbresults - cfe / fsw / cfe - core / unit - test / tblresults - cfe / fsw / cfe - core / unit - test / timeresults <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"remove device driver requirements <section> device driver requirements are unimplemented . hardware libraries or apps already cover the required functionality . unloading a library is risky / complex , better to remove from startup script and restart . <section> remove device driver requirements . <section> requirements were debated , no solid use case to justify the additional complexity . <section> na <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"task id not valid in cfe_es_deleteapp <section> when deleting an app the task id not valid message was observed : <code> the app was still deleted . <section> steps to reproduce the behavior : <number> . should be able to recreate by just deleting an app ( say sample_app ) on vxworks6 . <number> <allcaps> osal </allcaps> ( i have not had a chance to verify myself ) <section> appid = <number> , taskid seem to start in the 6 5 5 xx range . i ' d expect the code to use the right values in the right calls . <section> needs investigation <section> - mcp750 - os : vxworks6 . <number> - versions : rc - <number> bundle <section> seen during build verification testing . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> found by walt m .",0.0
"cfe_evs_writelogfilecmd requires recursive locking <section> the function <code> in cfe_evs_log . c locks <code> for the entire duration of the function . if an error is encountered , it will call <code> , which also tries to lock the mutex . if the os / <allcaps> osal </allcaps> do not support recursive locking on mutexes , this will lead to a deadlock . <section> steps to reproduce the behavior : <number> . cause an error during the execution of <code> ( by e . g . giving it an invalid filename ) . <section> this may be expected behavior , if cfe requires its mutexes to be recursively lockable . if so , this is not a bug and i will have to modify our <allcaps> osal </allcaps> . but if that is not the expectation , then i would this function should relinquish its lock before calling <code> . more specifically , it looks like the this can be accomplished by moving the line <code> to just before each instance of <code> in the function . by each of these points , this function is done accessing sensitive <allcaps> evs </allcaps> data . <section> * cfe_evs_writelogfilecmd ' s release of the lock <url> <section> - capella flight computer - os : freertos <number> . <number> - versions : cfe <number> . <number> , <allcaps> osal </allcaps> <number> . <number> ( plus in - house freertos port ) <section> i found this while testing our fix for # <number> . <section> mike stewart , capella space .",0.0
"<allcaps> es cds </allcaps> defines two nearly identically - named constants with different values <section> the <allcaps> cds </allcaps> code uses two mission - scope configuration values : <code> <code> the values are actually different ; the "" <allcaps> length </allcaps> "" version is just the <allcaps> cds </allcaps> base name , where as the "" <allcaps> len </allcaps> "" is the size of the qualified name ( <allcaps> app </allcaps> . cdsname form ) . <section> no runtime issue , this is a style / maintenance issue . <section> the names should be more different and distinctive . suggest that <code> should be renamed to indicate that it reflects the size of the base name only . this value appears to primarily be used internally to <allcaps> cds </allcaps> , and does not get directly used in telemetry packets , so it would be easier to rename , with less impact on existing code . <section> joseph hickey , vantage systems , inc .",2.0
running core - linux . bin startup errors the startup says the queue depth may be too large for the os to handle . the msg_max defaults to <number> but when trying to change it the os does not allow msg_max file be saved in the editor . there is another problem with createpipeerr . image <img>,3.0
"fix # <number> , update developer ' s guide to use sample app , create markdown <section> fix # <number> , update to use sample app for template , update images , create markdown <section> anh van , <allcaps> nasa </allcaps> goddard <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"update developer ' s guide to use sample app , create markdown version <section> update developer ' s guide to use sample app instead of qq , create markdown version . <section> anh van , <allcaps> nasa </allcaps> goddard",1.0
"user / beginner friendly permissive mode implementation failure when running as a normal user due to not setting the permissive mode should be user friendly . both for message queues and priorities failures . also requesting a command line option , or default to permissive mode for the bundle ( should just work out of the box on a linux system for a new user , the bundle is not a flight distribution ) . maybe relate it to <allcaps> simulation </allcaps> = native setting ? note current way it ' s set up ( as an <hashtag> un def </hashtag> in default_osconfig . h precludes passing it in as an option ) . worth discussing since currently the bundle defaults to debug mode with no optimization anyways . perhaps permissive mode is also appropriate ? distribution guide ( or whatever documentation is available ) could cover transition to more flight - like configuration .",2.0
"switch default linux toolchains back to posix ( was posix - ng ) removing last gen and next gen in to it ' s place in cfs_osal [ cfs_osal : <number> ] , requires going back to posix for default toolchain .",2.0
"quoting issue in doxygen build the arch_build . cmake file converts the cmake_c_flags variable and translates the defined macros into the doxygen command line . however , if the cmake_c_flags string is empty , then this fails . need to add quotes to make it work with an empty string .",0.0
add flag at prep stage to omit_deprecated need an easy way for users ( and the ci system ) to omit all deprecated elements . something like make omit_deprecated = true prep which would then internally add all the - dcfe_omit_deprecated - dosal_omit_deprecated and so on flags when building everything .,2.0
"need to dynamically determine whether extra flag prefix is required when linking <allcaps> cfe </allcaps> on platforms that link executables via gcc , these need to have an extra "" - wl , "" prefix on linker options . however , on platforms that call "" ld "" directly , these do not need the prefix , and using the prefix causes an error .",0.0
"remove calls to deprecated <allcaps> psp </allcaps> functions as part of the changes for <allcaps> psp </allcaps> trac [ cfs_psp : <number> ] and [ cfs_psp : <number> ] the following functions are proposed to be deprecated : { { { int32 cfe_psp_portread8 ( cpuaddr portaddress , uint8 * bytevalue ) ; int32 cfe_psp_portwrite8 ( cpuaddr portaddress , uint8 bytevalue ) ; int32 cfe_psp_portread16 ( cpuaddr portaddress , uint16 * uint16value ) ; int32 cfe_psp_portwrite16 ( cpuaddr portaddress , uint16 uint16value ) ; int32 cfe_psp_portread32 ( cpuaddr portaddress , uint32 * uint32value ) ; int32 cfe_psp_portwrite32 ( cpuaddr portaddress , uint32 uint32value ) ; int32 cfe_psp_memread8 ( cpuaddr memoryaddress , uint8 * bytevalue ) ; int32 cfe_psp_memwrite8 ( cpuaddr memoryaddress , uint8 bytevalue ) ; int32 cfe_psp_memread16 ( cpuaddr memoryaddress , uint16 * uint16value ) ; int32 cfe_psp_memwrite16 ( cpuaddr memoryaddress , uint16 uint16value ) ; int32 cfe_psp_memread32 ( cpuaddr memoryaddress , uint32 * uint32value ) ; int32 cfe_psp_memwrite32 ( cpuaddr memoryaddress , uint32 uint32value ) ; int32 cfe_psp_eepromwrite8 ( cpuaddr memoryaddress , uint8 bytevalue ) ; int32 cfe_psp_eepromwrite16 ( cpuaddr memoryaddress , uint16 uint16value ) ; int32 cfe_psp_eepromwrite32 ( cpuaddr memoryaddress , uint32 uint32value ) ; int32 cfe_psp_memcpy ( void * dest , const void * src , uint32 n ) ; int32 cfe_psp_memset ( void * dest , uint8 value , uint32 n ) ; } } } for cfe_psp_memcpy / cfe_psp_memset it is preferred to use the c library memcpy / memset call instead . for the access functions , just dereference the pointer locally ( as this is all they ever did ) .",2.0
"add psp_version creation as part of version . cmake <allcaps> psp </allcaps> build is unique in that it does not follow the pattern of apps , cfe , and osal for producing version information ( as part of version . cmake ) . consistent build framework is preferred .",2.0
"remove dependencies on bit_order macros osal / src / os / inc / common_types . h defines software_big_bit_order and software_little_bit_order that are targeted for future deprecation . need to remove dependencies in cfe / fsw / cfe - core / src / inc / ccsds . h , which defines cfe_make_big * macros , which are used in time services . eventually solved by <allcaps> eds </allcaps> , but need to solve it before actually deprecating these elements . slight relation to # <number> <allcaps> edit </allcaps> - the macros have been moved to cfe : <url> - deprecate these see also # <number>",2.0
"replace "" osalbool "" and "" boolean "" types with c99 bool <allcaps> ccb </allcaps> intends to deprecate the <allcaps> osal </allcaps> - provided "" boolean "" and "" osalbool "" types in version <number> . <number> , in favor of the c99 - specified "" bool "" type . <allcaps> cfe </allcaps> needs to be updated to stop using these types along with the related macro definitions : <code> and <code> should be <code> <code> should be <code> <code> should be <code>",0.0
"remove backwards compatibility provided by _enhanced_build_ no longer supporting classic build ( does not work with next - gen osal either ) , remove old backwards compatibility support and the associated _enhanced_build_ flag .",0.0
"enhanced versioning reporting updates github repos do not include the name in the tag ( since each repo is separate ) , so the git describe with - - match "" ${ <allcaps> name </allcaps> }* "" comes up blank . the most recent tag in every branch ( babelfish and github ) is legit , so no need to filter . recommend removing this match , and including the names in the print string : as in : <allcaps> cfe </allcaps> : %s , <allcaps> osal </allcaps> : %s looks like mission_pspmodules is not coming through as expected , suggest adding <allcaps> psp </allcaps> : %s ?",0.0
"remove old <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",0.0
"remove - m32 flag from sample toolchain files sample posix toolchain files still include - m32 , are we ready to default to <number> ?",0.0
"remove cfe logic to support backwards compatibility to last gen <allcaps> osal </allcaps> opening for discussion making osal_opaque_object_ids the only option ( removes support for last - gen <allcaps> osal </allcaps> ) in <number> , and need to agree to plan for end of summer release . notes - users not updating cfe and <allcaps> osal </allcaps> together , as well as updating to cmake may have challenges with end - of - summer release . should not be a surprise .",2.0
"convert cfe_omit_deprecated_6_6 to deprecate by default switch ifndef cfe_omit_deprecated_6_6 to ifdef cfe_deprecated_6_6 , user action is to define if needed but leave out by default .",0.0
"remove reference to _have_stdint_ in doxygen input file relates to [ cfs_osal : <number> ] in cfe_osal , where the _have_stdint_ define is removed . now always using stdint . h ( burden is on projects if they use a platform that is not compliant with c99 ) .",0.0
"time state flags near duplicate functions , one skips istonegood cfe_time_getstateflags in cfe_time_utils . c is nearly identical to cfe_time_getclockinfo in cfe_time_api . c except getstateflags does not include istonegood flag ( both convert state data to flags ) . recommend removing getstateflags ( internal , only used in hk generation ) and replace with call to getclockinfo ( from <allcaps> api </allcaps> ) . from keegan moore email thread ( <date> )",0.0
"support separate app and table install subdirectories from christopher westerman ( <date> email paraphrased ) - requested support in arch_build . cmake to install tables and apps to different subdirectories . supporting "" separation of concerns "" design principle .",2.0
"add naming convention document from # <number> , but wasn ' t merged to <number> . <number>",0.0
cfe / es has hard coded values for command pipe depth and buffer limits the es init function has : cfe_es_taskdata . pipedepth = <number> ; cfe_es_taskdata . limithk = <number> ; cfe_es_taskdata . limitcmd = <number> ; these values should be user configurable . in addition the <number> cfe apps do not initialize their command pipe depths and buffer limits consistently ( but all are <allcaps> not </allcaps> user configurable ) .,2.0
"cfe_mission_es_max_shell_pkt causes es error when unsigned when cfe_mission_es_max_shell_pkt is defined as an unsigned value ( 2 0 0 0 u , for example ) and a shell command is executed that results in a shell output file of less than cfe_mission_es_max_shell_pkt , es gets stuck in a loop of sending millions of es shell telemetry packets . this error / loop is in the int32 cfe_es_shelloutputcommand ( const char * cmdstring , const char * filename ) function . i think it is caused by the filesize variable ( int32 ) getting converted to an uint32 and under - flowing . a workaround to this is to keep cfe_mission_es_max_shell_pkt defined as a signed integer , but i think that the fix should be for es to fix this under - flow . the cfe_mission_es_max_shell_pkt should be able to be thought of / defined as an unsigned value .",0.0
provide standard byte swap functionality via <allcaps> eds </allcaps> utilities as discussed on [ cfs_psp : <number> ],2.0
"cfe_platform_es_app_kill_timeout defined in multiple places the cfe_platform_es_app_kill_timeout macro is defined in multiple places , which can cause confusion and errors . it is defined in both of these files : fsw / platform_inc / cpu1 / cfe_platform_cfg . h fsw / cfe - core / src / inc / cfe_es . h",0.0
"clean up remaining use of deprecated config macro names in the <number> release all configuration macros were revised to contain a "" <allcaps> mission </allcaps> "" or "" <allcaps> platform </allcaps> "" designator in their name to indicate scope . the previous , non - designated names were deprecated , and a compatibility mapping was added . however , there is still some code that continues to directly use the old name . this should be fixed to use the correct name .",0.0
"add path to additional cmake modules for <allcaps> psp </allcaps> when building and linking <allcaps> cfe </allcaps> executables and shared libraries , the flags and procedures may not always be exactly the same as the standard defaults . furthermore , the upstream cmake does not have a platform file for all <allcaps> cfe </allcaps> / <allcaps> osal </allcaps> targets ( e . g . <allcaps> rtems </allcaps> ) so the <allcaps> rtems psp </allcaps> must supply an appropriate file to use here . the cmake_module_path should be extended with an additional path that is under the <allcaps> psp </allcaps> , so module file ( s ) can be found here .",2.0
update comments / documentation in the example targets . cmake file the <code> file that is included as a sample has some documentation that is incomplete / outdated . new features have been added since this file was originally written .,0.0
"add feature to support binary data blobs linked with <allcaps> cfe </allcaps> executable in a recent <allcaps> grc </allcaps> project , <allcaps> cfe </allcaps> was deployed on a virtualized host that had no runtime - accessible persistent storage at all . although there was a place to store the <allcaps> cfe </allcaps> executable image itself , the executing runtime image could not read or write to this area as a filesystem . the apps were statically linked with the executable , but there is no place to put the startup script ( cfe_es_startup . scr ) . a generic solution to this problem was to add a method for the cmake build to include arbitrary "" binary blobs "" and link these directly into the executable image , so the <allcaps> psp </allcaps> / <allcaps> cfe </allcaps> can access them at runtime . the content of these blobs can be entirely implementation - specific . the <allcaps> cfe </allcaps> framework just needs an "" out of the box "" way to link these images into the executable to make deployment on this type of platform easier . for the <allcaps> grc </allcaps> use - case , we used this approach to store an "" initial ramdisk "" tar file which the <allcaps> psp </allcaps> then untar ' ed into the ramdisk before starting <allcaps> cfe </allcaps> . however the approach could be used for storing any arbitrary data file , such as an <allcaps> fpga </allcaps> bitfile or <allcaps> dsp </allcaps> / microcontroller firmware .",2.0
"es perflog dumper thread should be persistent <code> spawns a child task to run <code> . there should be a persistent thread to handle dumping the data , created during initialization . this will require some changes to <code> which is currently written to run only once . - - - - background : i sent the following to the <allcaps> cfs </allcaps> community mailing list : > cfe_es_perflogstop spawns a new thread via cfe_es_createchildtask to > dump the performance data to disk . this occurs whenever es receives a > command to stop recording performance data . > > it ' s my understanding that spawning threads at runtime , as opposed to > during initialization , is discouraged in real - time code due to > overhead like allocating memory . see , e . g . > <url> > which states "" all rt threads need to be created at startup time , > before the rt show time . "" > > should a persistent "" dumper "" thread be spawned during es > initialization rather than when the stop command is received ? i then received an off - list reply from dave mccomas : > i noticed the same thing when i looked at the code after your other email and i agree . do you mind writing a ticket .",0.0
"size and alignment of cfe_es_memhandle_t vary depending on platform ; ground - visible structures affected <code> is [ <url> defined ] as <code> and the size and alignment of <code> vary by platform . this type is used as a member in ( at least ) the following telemetry structures : * [ <url> cfe_sb_housekeepingtlm_payload_t ] * [ <url> cfe_tbl_housekeepingtlm_payload_t ] * [ <url> cfe_es_poolstatstlm_payload_t ] it is also used in ( at least ) the following command structure : * [ <url> cfe_es_sendmempoolstatscmd_payload_t ] on <number> - bit platforms which require self - alignment ( e . g . x86_64 , aarch64 ) , the presence of a <code> member causes the structure to require <number> byte alignment . this results in a <number> byte hole between the <number> byte telemetry header and payload when the payload is defined as a separate structure , such as the cases noted above . note that unlike the various address values in <code> , the actual value of these handles is needed on the ground for use in the es "" send mempool stats "" command , which takes a handle as its argument . in addition , these telemetry structures do not have a field indicating the validity of the handle . both of these factors suggest the fix accepted by the <allcaps> ccb </allcaps> for <code> , populating the fields with the low bytes of the value and marking them invalid when the fields are too small to hold the actual value , may not be viable for these structures .",2.0
add top level readme for open source release top level readme that shows up on github likely want to also merge this to dev and maintain ( vs the wiki which does not ship with the release ) .,0.0
"remove gcov files , <allcaps> itos </allcaps> and <allcaps> asist </allcaps> directories cleaning of release for github",0.0
update copyright and license for open source cfs framework ( dev branch ) update / add copyright and license to apache <number>,0.0
"missing migration path for <allcaps> cfe </allcaps> <number> es enum values in <allcaps> cfe </allcaps> <number> , es introduced scoped names for several enumerated constants and deprecated their old names . for example , <code> was introduced to replace <code> . while developers were encouraged to migrate to the new names and an example <code> command was given , the old names remained usable unless <code> was defined . <allcaps> cfe </allcaps> <number> introduced a different style of scoped names , e . g . <code> , and provided aliases to the pre - <number> names , but did not provide compatibility aliases for the <number> versions . the result is that developers who attempted to follow the new naming scheme in <number> found their apps failing to build in <number> , whereas using the deprecated name would have continued to work . <allcaps> cfe </allcaps> <number> should provide aliases for the names from <number> as well as the pre - <number> names . for example , in addition to {{{# ! c <hashtag> define </hashtag> cfe_es_app_run cfe_es_runstatus_app_run } } } there should be {{{# ! c <hashtag> define </hashtag> cfe_es_runstatus_app_run cfe_es_runstatus_app_run } } }",0.0
"update <allcaps> eds </allcaps> files to match release plan to advertise the <allcaps> eds </allcaps> techdev branch as part of the release , so the <allcaps> eds </allcaps> files should be updated to match .",0.0
update copyright and license for open source cfs framework release <number> . 0 a need to update / add copyright and license to apache <number> for open source release of <number> . 0 a .,0.0
"es performance debug messages have incorrect parameter the second parameter in the following two debug event messages are incorrect : cfe_evs_sendevent ( cfe_es_perf_filtmskcmd_eid , cfe_evs_debug , "" set performance filter mask cmd rcvd , num % d , val 0x %x "" , ( int ) cmd - > filtermasknum , ( unsigned int ) cmd - > filtermasknum ) ; cfe_evs_sendevent ( cfe_es_perf_trigmskcmd_eid , cfe_evs_debug , "" set performance trigger mask cmd rcvd , num % d , val 0x %x "" , ( int ) cmd - > triggermasknum , ( int ) cmd - > triggermasknum ) ; in both cases "" num "" should be removed from the second parameter variable . the casting should also be examined .",0.0
"memory alignment issues in table services the <allcaps> cfe </allcaps> code has some problem areas for cpus that have strict memory alignment requirements ( e . g . <allcaps> sparc </allcaps> ) . casting from a type with smaller requirements to a type with larger requirements generates a compile time warning and may induce a runtime exception if the memory actually is not aligned . the following errors exist in the <allcaps> tbl </allcaps> subsystem : { { { / cfe / fsw / cfe - core / src / tbl / cfe_tbl_internal . c : in function ' cfe_tbl_removeaccesslink ' : / cfe / fsw / cfe - core / src / tbl / cfe_tbl_internal . c : <number> : <number> : warning : cast increases required alignment of target type [ - wcast - align ] status = cfe_es_putpoolbuf ( cfe_tbl_taskdata . buf . poolhdl , ( uint32 <wink> regrecptr - > buffers [ <number> ] . bufferptr ) ; ^ / cfe / fsw / cfe - core / src / tbl / cfe_tbl_internal . c : <number> : <number> : warning : cast increases required alignment of target type [ - wcast - align ] status = cfe_es_putpoolbuf ( cfe_tbl_taskdata . buf . poolhdl , ( uint32 <wink> regrecptr - > buffers [ <number> ] . bufferptr ) ; ^ } } } <allcaps> note </allcaps> : this is related to <allcaps> psp </allcaps> ticket [ cfs_psp : <number> ]",0.0
memory alignment issues in software bus the <allcaps> cfe </allcaps> code has some problem areas for cpus that have strict memory alignment requirements ( e . g . <allcaps> sparc </allcaps> ) . casting from a type with smaller requirements to a type with larger requirements generates a compile time warning and may induce a runtime exception if the memory actually is not aligned . the following errors exist in the sb subsystem : { { { / cfe / fsw / cfe - core / src / sb / cfe_sb_api . c : in function ' cfe_sb_zerocopygetptr ' : / cfe / fsw / cfe - core / src / sb / cfe_sb_api . c : <number> <time> : warning : cast increases required alignment of target type [ - wcast - align ] return ( cfe_sb_msg_t <wink> address ; ^ / cfe / fsw / cfe - core / src / sb / cfe_sb_api . c : in function ' cfe_sb_zerocopyreleaseptr ' : / cfe / fsw / cfe - core / src / sb / cfe_sb_api . c : <number> <time> : warning : cast increases required alignment of target type [ - wcast - align ] ( uint32 <wink> ( ( ( uint8 <wink> ptr2release ) - sizeof ( cfe_sb_bufferd_t ) )); ^ / cfe / fsw / cfe - core / src / sb / cfe_sb_buf . c : in function ' cfe_sb_getbufferfromcaller ' : / cfe / fsw / cfe - core / src / sb / cfe_sb_buf . c : <number> <time> : warning : cast increases required alignment of target type [ - wcast - align ] cfe_sb_bufferd_t * bd = ( cfe_sb_bufferd_t *)((( uint8 <wink> address ) - sizeof ( cfe_sb_bufferd_t ) ); ^ / cfe / fsw / cfe - core / src / sb / cfe_sb_util . c : in function ' cfe_sb_getmsgtime ' : / cfe / fsw / cfe - core / src / sb / cfe_sb_util . c : <number> <time> : warning : cast increases required alignment of target type [ - wcast - align ] tlmhdrptr = ( cfe_sb_tlmhdr_t <wink> msgptr ; ^ / cfe / fsw / cfe - core / src / sb / cfe_sb_util . c : in function ' cfe_sb_setmsgtime ' : / cfe / fsw / cfe - core / src / sb / cfe_sb_util . c : <number> <time> : warning : cast increases required alignment of target type [ - wcast - align ] tlmhdrptr = ( cfe_sb_tlmhdr_t <wink> msgptr ; ^ } } } <allcaps> note </allcaps> : this is related to <allcaps> psp </allcaps> ticket [ cfs_psp : <number> ],0.0
"cfe_time state saved in <allcaps> cds </allcaps> does not include "" delaydirection "" cfe_time has some features to save the current state of the reference to <allcaps> cds </allcaps> , which is then restored after reset . this includes the "" delay "" value that is used by time clients to adjust / compensate for distribution delays in the time signal . while the delay amount is saved in <allcaps> cds </allcaps> , the accompanying delay direction value is not saved . it is always reset to "" <allcaps> add </allcaps> "" after booting . so , for instance , if a time client had been running with a delay compensation value of e . g . - 1 0 ms before reboot , it would become + 1 0 ms after reboot and restore from <allcaps> cds </allcaps> . this seems incorrect .",0.0
"calling cfe_time_getreference in interrupt context can lock up system ocean color instrument <allcaps> fsw </allcaps> has been debugging watchdog resets since early february . we are running cfe <number> and <allcaps> sch </allcaps> <number> . last weekend , we disabled the watchdog , let the <allcaps> fsw </allcaps> freeze , and attached a debug monitor that let us see processor registers and memory . the backtrace indicates that <allcaps> fsw </allcaps> is calling cfe_time_getreference in interrupt context : grmon2 > bt % pc % sp # <number> 0x 4 0 2 d3260 ( = cfe_psp_gettime =0 x402d323c + <number> ) 0x 4 0 1 4 6 8 f0 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 4 1 0 x402ef1c0 </hashtag> <happy> ' ' ' cfe_time_getreference ' ' ' =0 x402ef1a8 + <number> ) 0x 4 0 1 4 6 9 5 8 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 5 1 0 x402ee5ec </hashtag> ( = cfe_time_getmetsubsecs =0 x402ee5a8 + <number> ) 0x 4 0 1 4 6 9 e0 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 6 1 0 x404d5f14 </hashtag> ( = sch_getmetslotnumber =0 x404d5f10 + <number> ) 0x 4 0 1 4 6 a80 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 7 1 0 x404d60ec </hashtag> <happy> ' ' ' sch_majorframecallback ' ' ' =0 x404d5fb4 + <number> ) 0x 4 0 1 4 6 ae0 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 8 1 0 x402ef9d8 </hashtag> ( = cfe_time_notifytimesynchapps $ part <money> =0 x402ef9ac + <number> ) 0x 4 0 1 4 6 b40 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 9 1 0 x402f00e4 </hashtag> ( = cfe_time_tone1hzisr =0 x402effcc + <number> ) 0x 4 0 1 4 6 ba0 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 1 0 1 0 x402d49c0 </hashtag> ( = cfe_psp_interruptcallback_dleonint11 =0 x402d4658 + <number> ) 0x 4 0 1 4 6 c28 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 1 1 1 0 x40012570 </hashtag> ( = handler_irq =0 x40012528 + <number> ) 0x 4 0 1 4 6 c88 ( = tidletask0_stack_base =0 x401442d0 + <number> ) <hashtag> 1 2 1 0 x40011dcc </hashtag> ( = intent =0 x40011ca8 + <number> ) 0x 4 0 1 4 6 cf0 cfe_time_getreference appears to be stuck in this <allcaps> do while </allcaps> loop : void cfe_time_getreference ( cfe_time_reference_t * reference ) { < other irrelevant code > do { versioncounter = cfe_time_taskdata . completeversioncounter ; < other irrelevant code > } while ( versioncounter ! = cfe_time_taskdata . pendingversioncounter ) ; these two counters are changed in task context , so i believe that anytime sch_majorframecallback is called when these counters are different , <allcaps> fsw </allcaps> will get stuck in this do while loop .",0.0
"cfe_es_restartapp ( ) writetosyslog typo the first writetosyslog ( ) occurrence indicates the message is from cfe_es_deleteapp instead of cfe_es_restartapp : cfe_es_writetosyslog ( "" cfe_es_deleteapp : cannot restart a <allcaps> core </allcaps> application : %s . \ n "" ,",0.0
"cfe_sb_createpipe : improve message when os_queuecreate fails currently if <code> fails in <code> , the message is just <code> . it would be valuable to show the name of the error rather than ( or in addition to ) the numeric error code . the <code> function may help here if it ' s available in all of the <allcaps> osal </allcaps> implementations . it may be valuable to provide other details depending on the error . for example , the message in the case of <code> could indicate the name of the pipe that was requested ( and is already in use ) .",2.0
"sb memory limit on individual pipes discussion spawning from # <number> and # <number> , <allcaps> apl </allcaps> has a use case for limiting the memory used on a pipe . different implementations were discussed ( see attached email chain ) . for steering committee discussion .",2.0
trade <allcaps> evs </allcaps> generalize filter requirement update <allcaps> ccb </allcaps> <date> discussed # <number> and # <number> which would complicate the filter design . consider if this functionality is worth a requirements change and trade additional complexity at the architecture level . kicked up to steering committee .,2.0
"restrict pipes to the app they were created in discussed in <allcaps> ccb </allcaps> <date> that sb could be updated to restrict pipes to use within an app , as part of ticket # <number> discussion . this would restrict the current capabilities of the system and valid points were raised on both sides . see attached email thread for further details . submitted as a requirements enhancement to trigger discussion at the architecture / steering committee level .",2.0
"time services need cleanup relative to requirements per <allcaps> ccb </allcaps> on <date> , time services goes way beyond it ' s requirements . need to re - evaluate configuration options and reduce mission specific code . as part of the cleanup , factor out duplicate code . specifically referenced at code review in command handling . - <code> , <code> , <code> , and <code> are all basically the same logic , etc . - break of files # <number> , specific note from <allcaps> cfs </allcaps> - <number> was the lack of a cfe_time_tone . h - <code> and <code> are basically the same logic , refactor - # <number> - # <number> - mutually exclusive defines could just be a boolean ( but will likely go away w / refactor ) , note cfe_time_verify . h is excessively complex at this point <url>",2.0
"executive services generic counter facilities not thread safe the executive services provides a "" generic counter "" <allcaps> api </allcaps> ( register , delete , increment , decrement , get , set ) . the implementation of these functions do not take any sort of mutex when accessing the table or performing these operations . as a bare minimum , the registration should ensure that two tasks simultaneously creating counters should be protected against collision .",0.0
"scrub all public <allcaps> api </allcaps> calls to ensure that all input parameters are properly sanitized before use as a matter of policy , all <allcaps> cfe </allcaps> function calls that are available for use by external apps or libraries ( i . e . all headers in the <code> subdirectory ) should sanity - check their input values before using them . during recent code reviews it was noted that at least two of these functions were missing a required range check , as noted in bug # <number> . this task is to perform an additional review on the public <allcaps> api </allcaps> calls and ensure that proper input value sanitization is being performed .",2.0
"cfe_fs_decompress infinite loop on truncated gzip file if cfs_fs_decompress is given a truncated gzip file , it will enter an infinite loop in which it attempts to read more data from the file , gets nothing , and tries again . discovered by accidentally attempting to have es load a new compressed application ( which we did not know had been truncated ) , which led to es getting stuck and an eventual watchdog reset . the problem seems to be that running out of bytes in a gzipped file before decompression is finished is not considered an error . i can see how this might be intentional if it is expected that the file handle might be a stream that could present data after being emptied , but for the normal file use case i think it is a bug . suggested fix by combining the two checks at line <number> of cfe_fs_decompress . c : if ( state - > insize = = <number> ) return <allcaps> eof </allcaps> ; if ( len = = os_fs_error ) { state - > error = cfe_fs_gzip_read_error ; return <allcaps> eof </allcaps> ; } into one : if ( ( state - > insize = = <number> ) ! || ( len = = os_fs_error ) ) { state - > error = cfe_fs_gzip_read_error ; return <allcaps> eof </allcaps> ; } recommend investigation if insize might temporarily hit <number> during a normal decompression . reported via email from mike stewart , <email>",0.0
"<allcaps> ccsds </allcaps> secondary header consistency update update data structure definition of <allcaps> ccsds </allcaps> command secondary header to be consistent with the rest of the message header definition . from /* - - - - - <allcaps> ccsds </allcaps> command secondary header . - - - - - */ typedef struct { uint16 command ; /* command secondary header */ /* bits shift - - - - - - - - - - - - description - - - - - - - - - - - - - - - - */ /* 0x0 0 ff <number> : checksum , calculated by ground system */ /* 0x 7 f00 <number> : command function code */ /* 0x 8 0 0 0 <number> : reserved , set to <number> */ } ccsds_cmdsechdr_t ; to /* - - - - - <allcaps> ccsds </allcaps> command secondary header . - - - - - */ typedef struct { uint8 command [ <number> ]; /* command secondary header */ /* bits shift - - - - - - - - - - - - description - - - - - - - - - - - - - - - - */ /* 0x0 0 ff <number> : checksum , calculated by ground system */ /* 0x 7 f00 <number> : command function code */ /* 0x 8 0 0 0 <number> : reserved , set to <number> */ } ccsds_cmdsechdr_t ; requested by tam via email .",0.0
resolve all compiler warnings all compiler warnings need to be resolved prior to the next release . requested by tam via email .,0.0
"cfe_es_scanapptable ( ) possible race conditions the <code> is called from the es message processing thread , but it does not lock the global es data structure when reading / writing from the global data . es software bus command messages are safe because this function is called by the same thread that is processing those messages , therefore concurrency is not possible here . but other functions , like <code> and <code> are part of the public <allcaps> api </allcaps> and these also update the same fields within the app state data structure that <code> is reading . <code> can also modify fields within this structure and this is called by pretty much every app in the system . this issue was noted while reviewing the fix for a similar issue in # <number> .",0.0
fs - externalize cfe_fs_decompress the decompression code should be removed and compile - time hooks to connect in an external decompression library should be provided .,2.0
<allcaps> cpu </allcaps> utilization calculation and idle task <allcaps> cpu </allcaps> utilization is currently calculated using an idle task . this can waste power and prevents the processor ( s ) from entering sleep or other power management states . as part of the <allcaps> smp </allcaps> implementation this issue should also be addressed .,2.0
"sb : remove appname ( and pipename ? ) from cfe_sb_piped_t in looking at sb code , i noticed that cfe_sb_piped_t has two character arrays , appname and pipename . appname , particularly , is a waste of memory to have in each pipe structure ( it should be maintained in one location ) and there is an appid field in the piped_t so it ' s not needed for finding pipes . same may go with pipename , as the <allcaps> osal </allcaps> queue takes the name as a parameter ( need to ensure the pipe name does not already exist in <allcaps> osal </allcaps> . )",2.0
"fix es unit test writetosyslog warning in es_ut . c , the <code> function is invoked with a generated ( non - const ) string used in place of the format string . some compilers generate a warning about this . the fix is simple .",0.0
"build system support for linking symbol table when using the dynamic loader on some <allcaps> rtos </allcaps> ' s ( <allcaps> rtems </allcaps> notably , but probably others too ) there is an extra build step required to build an executable capable of runtime linking . for <allcaps> rtems </allcaps> , this is : <number> . build all objects and link the executable as normal <number> . invoke the <code> tool to build a symbol table object <number> . re - link the executable using the objects from ( <number> ) and ( <number> ) this is possible in cmake by defining some custom commands , but requires a few hooks in the build system to do this , since it is os - specific .",2.0
"critical tables do not preserve filename of last loaded table file table services issue reported by <allcaps> oci </allcaps> : cfe table services provides a feature for having critical tables . these tables preserve their information across processor and application resets . the to application assumed that this included the filename of the last loaded table file . however , it does not . this should be fixed in the cfe_tbl application . also , there was an <allcaps> mks dcr </allcaps> that addressed this issue but it was never implemented .",0.0
"compiler warnings regarding some cfe_sb <allcaps> api </allcaps> calls the <code> , <code> , and <code> <allcaps> api </allcaps> calls trigger compiler warnings if they are called with a buffer that is qualified as <code> . as these <number> functions are read - only ( they do not modify the buffer ) the input should be qualified as <code> , which fixes the warning .",0.0
"improve <allcaps> cfe </allcaps> support for statically linked apps for some <allcaps> cfe </allcaps> deployments there are good reasons to _not_ use a dynamic loader for applications , and instead link <allcaps> cfe </allcaps> plus all applications into a single executable . this would typically be a "" minimalist "" target using an <allcaps> rtos </allcaps> that does not include dynamic loading , or a safety - critical subsystem where dynamic loading in general introduces operational variables . this had been possible in previous versions of <allcaps> cfe </allcaps> but it was ugly - - an application needed to be modified for static loading and needed use some preprocessor macros to make the necessary connections . it also used a special initialization path in <allcaps> cfe es </allcaps> . with the latest <allcaps> osal </allcaps> changes we can now support a much cleaner approach , where applications do / / not / / need any special treatment to support static linkage . the <allcaps> osal </allcaps> symbol lookup can be configured such that it can return the correct entry point even without os dynamic loader support .",2.0
"race condition in cfe_appcreate ( ) function this has been split to a separate ticket from # <number> . per email from preston faiks on <number> - <number> - <number> , there is an actual observed race condition issue with <code> out in the field : when es is loading and starting apps , one app might fail initialization and call cfe_es_exitapp ( ) if that occurs , its app state will be set to cfe_es_app_state_stopped . when apps are scanned , it will be removed from the app table and that table entry set to not in use . as es continues to load apps , it will make use on the now unused app table entry . it will not change the app state in the entry until it has successfully loaded the app into memory . the process of loading an app into memory can cause the task to pend on file system ( or network file system ) and allow other tasks to run . as that app continues to be loaded , another app scan can occur and detect the app entry as both in use and stopped , and will unload it . when es finishes loading the app , it will spawn a task at an entry point which was just unloaded by the scanning task , causing it to execute from unloaded memory and crash . i have reviewed this code again and the race condition risk described is definitely still present in the current development branch , but this is not the only example . there are other similar race conditions that are possible regarding the use if the <code> boolean field . having an observed failure should escalate this in priority now .",0.0
"possible buffer overrun in cfe_es the function <code> had hardcoded the size of the various output buffers to be os_max_api_name or os_max_path_len . this should use the <code> operator rather than using a specific macro , since that will accurately use the correct size , however it is defined . we previously updated most of these but this one was missed in the previous pass .",0.0
"es comments need checked for consistency lots of copy / paste type errors in es . for example , after cfe_es_incrementtaskcounter ( ) the comment says /* end of cfe_es_exitchildtask ( ) */",1.0
es apptable . taskinfo . numofchildtasks incremented but never decremented,0.0
"buffer size warnings with <allcaps> gcc </allcaps> <number> when compiling <allcaps> cfe </allcaps> with <allcaps> gcc </allcaps> version <number> , some new warnings about possible buffer overflow appear in the <allcaps> cfe es </allcaps> shell code . for example : { { { cfe / fsw / cfe - core / src / es / cfe_es_shell . c : <number> : <number> : error : ‘ , prnt app name : ’ directive writing <number> bytes into a region of size between <number> and <number> [ - werror = format - overflow <happy> sprintf ( line , "" task id : % 0 8 d , task name : % 2 0 s , prnt app id : % 0 8 d , prnt app name : % 2 0 s \ n "" } } }",0.0
<allcaps> evs </allcaps> delete event filter doxygen incorrect in file cfe_evs_msg . h the delete application event filter doxygen is incorrect . it states the command structure is cfe_evs_appnameeventidmaskcmd_t when it should be cfe_evs_appnameeventidcmd_t this was caught because a tool used the doyxgen to auto generate cmd & tlm definitions for <allcaps> cosmos </allcaps> so it is important to fix .,2.0
"document cfe_es_writetosyslog ( ) can be used when cfe_es_registerapp ( ) fails on thu , <date> at <time> , fleming , thadeus < <email> > wrote : it ' s clear that cfe_es_registerapp is supposed to be the first <allcaps> cfe </allcaps> function an app calls , and that the app should not continue if the call fails . however , it ' s not clear whether it ' s kosher to call cfe_es_writetosyslog to log failure of cfe_es_registerapp . it appears to be both safe ( the function source does not look at the app ' s entry in the apptable ) and common practice ( e . g . the gen_app_code app template does it ) . i ' d suggest that apps be allowed to call writetosyslog when registerapp fails , and that the practice is documented so that future versions of cfe do not modify writetosyslog in such a way that it would become a problem .",2.0
<allcaps> cfe es crc </allcaps> does not document polynomial <date> : mark pallone ( <allcaps> gsfc pace </allcaps> / <allcaps> oci </allcaps> ) reported the generator polynomial used in a <allcaps> crc </allcaps> implementation is fundamental information . the cfe_es_calculatecrc function does not state what generator polynomial it ' s using : <url> dave mccomas addition : this is a subset of a larger documentation issue . the cfe should have a flight - ground <allcaps> icd </allcaps> <allcaps> edit </allcaps> - updated link,1.0
"add cmake function to add cpus by function rather than assume consecutive cpu ids . currently , the cmake rules require that cpus are built in order and will stop looking for cpu targets when a cpu idx is not found . propose that a cmake function can be executed from the targets . cmake file which explicitly adds the cpus to be built for the mission .",2.0
"expose cfe_sb_isvalidmsgid ( ) <allcaps> cfe </allcaps> apps would benefit from a publicly - available isvalidmsgid ( ) function ( or perhaps an expanded "" is valid message "" function , that would check all header fields ? ) for example , <allcaps> sch </allcaps> has a function to validate its message table entries and has its own logic for determining whether a message id is valid or not . this would particularly facilitate ccsds_ver_2 transitions .",2.0
"add support for <number> - bit builds cfe should build and run on <number> - bit platforms such as x86_64 and <allcaps> arm </allcaps> cortex - a53 . this should be implemented by making pointer types more generic than "" int32 "" .",2.0
"incorrect documentation for cfe_tbl_releaseaddress reported by mark pallone <allcaps> gsfc pace </allcaps> / <allcaps> oci </allcaps> project on <date> : the documentation for cfe_tbl_releaseaddress says that if you get the return code cfe_tbl_err_never_loaded , "" this pointer must be released with the cfe_tbl_releaseaddress <allcaps> api </allcaps> before the table can be loaded with data . "" i think this is a copy / paste error , likely from cfe_tbl_getaddress .",1.0
"deprecate / remove network_includes . h ? <code> seems to be a strange file to have in the executive . nothing else in cfe uses it , and it is the only file in the core ( non stub ) code to test the various <code> macros ( <code> , <code> , etc . ) . should this file continue to exist as part of cfe ? or can it be deprecated and eventually removed ? apps that use it could keep their own copy as needed .",2.0
"cfe time var name changed in . h but not in code cfe master <number> release osal <number> . 1 a psp <number> . <number> building for vxworks <number> <allcaps> sparc </allcaps> ut700 kspace / plss_cws / . <repeated> / <allcaps> cfs </allcaps> / cfe / fsw / cfe - core / src / time / cfe_time_tone . c / home / sduran / aemu_workspace / plss_cws / . <repeated> / <allcaps> cfs </allcaps> / cfe / fsw / cfe - core / src / time / cfe_time_tone . c : in function ' cfe_time_tonesend ' : / home / sduran / aemu_workspace / plss_cws / . <repeated> / <allcaps> cfs </allcaps> / cfe / fsw / cfe - core / src / time / cfe_time_tone . c : <number> <time> : error : ' cfe_time_tonedatacmd_payload_t ' has no member named ' attoneleaps ' cfe_time_taskdata . tonedatacmd . payload . attoneleaps = <allcaps> from </allcaps> cfe 8 6 ce044 , <number> release plus a couple of hot fixes , master before <number> release , cfe_time_utils . h typedef struct { cfe_time_systime_t attonemet ; /* <allcaps> met </allcaps> at time of tone */ cfe_time_systime_t attonestcf ; /* <allcaps> stcf </allcaps> at time of tone */ - - - > int16 attoneleaps ; /* leap seconds at time of tone */ int16 clocksetstate ; /* time has been "" set "" */ int16 clockflystate ; /* current fly - wheel state */ cfe_time_systime_t attonedelay ; /* adjustment for slow tone detection */ cfe_time_systime_t attonelatch ; /* local clock latched at time of tone */ cfe_time_systime_t currentlatch ; /* local clock latched just "" now "" */ cfe_time_systime_t timesincetone ; /* time elapsed since the tone */ cfe_time_systime_t currentmet ; /* <allcaps> met </allcaps> at this instant */ } cfe_time_reference_t ; <allcaps> from </allcaps> cfe master 9 0 fdf9f <number> release , cfe_time_utils . h - - - var name changed in header , but not in cfe / fsw / cfe - core / src / time / cfe_time_tone . c : <number> <time> typedef struct { cfe_time_systime_t attonemet ; /* <allcaps> met </allcaps> at time of tone */ cfe_time_systime_t attonestcf ; /* <allcaps> stcf </allcaps> at time of tone */ - - - > int16 attoneleapseconds ; /* leap seconds at time of tone */ int16 clocksetstate ; /* time has been "" set "" */ int16 clockflystate ; /* current fly - wheel state */ cfe_time_systime_t attonedelay ; /* adjustment for slow tone detection */ cfe_time_systime_t attonelatch ; /* local clock latched at time of tone */ cfe_time_systime_t currentlatch ; /* local clock latched just "" now "" */ cfe_time_systime_t timesincetone ; /* time elapsed since the tone */ cfe_time_systime_t currentmet ; /* <allcaps> met </allcaps> at this instant */ } cfe_time_reference_t ; i do not see the issue with a linux build . i think it might be associated with <hashtag> define </hashtag> cfe_platform_time_cfg_bigendian the default is to <hashtag> un def </hashtag> cfe_platform_time_cfg_bigendian - makes sense on linux / x86 but for vxworks / <allcaps> sparc </allcaps> , i would think it should be defined . "" * * if this configuration parameter is defined , the <allcaps> cfe </allcaps> time server will * * publish time tones with payloads in big - endian order , and time clients * * will expect the tones to be in big - endian order . "" vxworks / sparc will build if <hashtag> un def </hashtag> cfe_platform_time_cfg_bigendian",0.0
"enforce strict <allcaps> ascii </allcaps> in document files this is an extension of the previous ticket . with the creation of this ticket , # <number> will have its scope reduced to cover only the already integrated changes to source code , allowing us to confirm that those changes are included in the <allcaps> cfe </allcaps> <number> release . this ticket will continue to carry the task of enforcing strict <allcaps> ascii </allcaps> for the remaining cases , which are all document files ; this work will take place after the <allcaps> cfe </allcaps> <number> release .",0.0
improve doxygen for <allcaps> cfe sb </allcaps> msgid wrappers it was noted when reviewing # <number> that the msgid wrapper functions could use some expanded doxygen documentation .,0.0
"remove doxygen - generated <allcaps> html </allcaps> files currently , we keep a snapshot of the <allcaps> html </allcaps> files produced by doxygen in the git repository . this is a potential source of problems as it might be out of date . it is the sense of the <allcaps> ccb </allcaps> that we should remove these from the git repository ; instead , when we make a release , we will run the command to generate them , and include the <allcaps> html </allcaps> tree in the published image .",1.0
"sb remove printmsghdr function the sb printmsghdr function does not protect against accessing invalid memory . in addition , this function is specific to debugging during development . this code should not be used during flight and could be a risk to the system . it is recommended to remove this code and create a library for hosing debug functions and utilities . this ticket will be used to remove the printmsghdr function . an alternate ticket will be created for developing a debug library .",0.0
"unit tests doing assignent instead of equality check when experimenting with # <number> , two test cases were also discovered where an assignment was being done rather than an equality check . this is not a "" failure "" , but rather these tests could never fail - it is defeating the purpose of the test case entirely .",0.0
"sb unit test failure on powerpc target when reviewing the unit test results for the <number> test systems for the <allcaps> cfe </allcaps> <number> release , there was one unit test failure case . on the <number> - bit powerpc test target , this unit test failure was observed : { { { [ <allcaps> fail </allcaps> ] <number> sb_ut . c : <number> - cfe_sb_messagestringget - destination size = <number> } } }",0.0
"cfe <number> documentation updates this ticket will be used for all cfe <number> documentation updates including the <allcaps> vdd </allcaps> . a listing of the needed documentation updates will be added to this ticket as tickets , requiring code updates , are reviewed and determined there is an associated documentation change .",2.0
"es - memory pool size no longer requires <number> - bit alignment the <allcaps> ccb </allcaps> approved commit under trac # <number> redesigned the es memory pool to perform alignment in accordance with the base address vs . the size of the data pool . this change affects es requirement ces1321 . <number> which is no longer needed . instead a new error check is performed to ensure the size of the pool is not less than the minimum block size . the affected requirement , along with its parent , is pasted below for reference . ces1321 : "" ces1321 upon receipt of a request the cfe shall allocate a block of memory of the specified size from the specified memory pool . "" ces1321 . <number> : "" ces1321 . <number> if the specified size is not an integral multiple of <number> bit words , the size shall be rounded up to an integral of <number> bit words . """,0.0
"please provide va_list variants of variadic functions i have recently encountered a need to conditionally call <code> or <code> depending on the app ' s status . unfortunately , both of these functions are variadic functions , and they can not easily be wrapped in another variadic function . the c standard library provides variants of its variadic functions that take a <code> . for example , <code> has the <code> variant . please provide similar variants for cfe ' s variadic functions . the implementation would be simple : the majority of the function ' s logic can reside in the <code> version , and the variadic function can become thin a wrapper around the <code> version .",2.0
"fix <allcaps> eds </allcaps> discrepancies after # <number> merge after merging # <number> , this changed some things in the <allcaps> ccsds </allcaps> header and there needs to be a corresponding update to the <allcaps> eds xml </allcaps> files and related items to ensure that the <allcaps> eds </allcaps> actually matches the running code . this change circles back to the <allcaps> eds </allcaps> side and updates the <allcaps> xml </allcaps> files so they correspond to the code .",0.0
"table services task pipe function incorrectly handling commands when calling the appropriate command message handler , the table services taskpipe function is failing to pass the entire message to the command processing function , resulting in a truncated message .",0.0
"table services sometimes copies buffers to itself running the <allcaps> tbl </allcaps> unit test in valgrind / memcheck reveals that under certain circumstances , the <code> and <code> functions attempt to copy a buffer onto itself . this is technically undefined behavior , as <code> requires that the source and destination not overlap .",0.0
"type safety and improved handling of cfe_sb_msgid_t values in <number> , as we move to supporting msgid ' s , msgkey ' s , routeidx , and other types , we should move away from using native c types and wrapping the types in a struct to prevent accidentally using the wrong type in assignments and function calls . this will , of course , require re - tooling any existing code that expects the type to be a simple type . <repeated> for example , instead of : <code> use : <code>",2.0
"continuation of <allcaps> eds </allcaps> integration for <allcaps> cfe </allcaps> integrate the remaining <allcaps> eds </allcaps> features which are not yet included as part of the <allcaps> cfe </allcaps> <number> release . this is a continuation of # <number> for the next <allcaps> cfe </allcaps> release . defects to resolve : # <number> , <allcaps> tbd </allcaps> enhancements to resolve : <allcaps> tbd </allcaps>",2.0
"cfe <allcaps> tbl </allcaps> - table name arrays incorrectly sized cfe <allcaps> tbl </allcaps> provides internal macros for appropriately sizing table names . table names are a concatenation of the appname , delimiter , and tblname i . e . "" appname . tblname "" . the size of the character array holding the table name needs to fall on a <number> - byte boundary in support of the <allcaps> tbl </allcaps> registry . the table names sent down in telemetry need to be sized accordingly using the cfe_tbl_max_full_name_len macro vs . the cfe_mission_tbl_max_name_length macro which is used to compute cfe_tbl_max_full_name_len . for reference , the internal table name length macro computations ( defined in cfe_tbl . h ) include : /* computation for maximum length allowed for a table name . <allcaps> note </allcaps> : "" + <number> "" is for <allcaps> null </allcaps> character and "" . "" ( i . e . - "" appname . tblname "" ) */ <hashtag> define </hashtag> cfe_tbl_max_full_name_len_comp ( cfe_mission_tbl_max_name_length + os_max_api_name + <number> ) /* ensure the table name falls on a <number> - byte boundary */ <hashtag> define </hashtag> cfe_tbl_max_full_name_len ( ( ( cfe_tbl_max_full_name_len_comp + <number> ) / <number> )* <number> )",0.0
"remove message_format_is_ccsds ifdefs from <allcaps> cfs </allcaps> code currently , most of the functions in cfe_sb_util . c and a few others are like : { { { void cfe_sb_initmsg ( void * msgptr , cfe_sb_msgid_t msgid , uint16 length , boolean clear ) { <hashtag> if def </hashtag> message_format_is_ccsds ccsds_initpkt ( ( ccsds_prihdr_t <wink> msgptr , ( uint16 ) msgid , length , clear ) ; <hashtag> end if </hashtag> } /* end cfe_sb_initmsg */ } } } it ' s confusing what else would be done in these functions ( and nothing else is done . ) as joe said , if someone implemented a wholly different sb message format , they are likely to write their own set of functions and having a bunch of <hashtag> if </hashtag> / elseif / elseif / elseif / endif blocks would be confusing and difficult to maintain . the suggestion from the <allcaps> ccb </allcaps> today was to remove these <hashtag> if defs </hashtag> . it might be worthwhile to put in a check at the top of the file that generates a compiler warning / error if it ' s not defined . <repeated>",2.0
cfe <number> verification testing required for release this ticket will be used to document the cfe <number> . <number> verification testing that will be performed at each center and capture the results of each test .,0.0
"event messages generated during library init get dropped i have a <allcaps> cfe </allcaps> based project that uses multiple libraries , which are loaded in the startup script as a cfe_lib rather than a cfe_app . today i found that one of the library initialization routines was failing . despite generating an event using cfe_sendevent on the condition , no event was reported on the console . the issue is that library init routines are called from the main thread context , and therefore not in the context of an executive services task . this causes cfe_es_getappid to fail - which is probably correct . however this causes cfe_evs to effectively drop the message on the floor , and it is entirely silent in this case . this might be intended behavior but it caught me off guard since i got no output whatsoever . one possible fix is to just stick to cfe_es_writetosyslog during library init functions but perhaps we should consider having event services actually do this , so the message at least goes somewhere visible .",0.0
"<allcaps> cfe sb </allcaps> and <allcaps> time </allcaps> components missing length verification on incoming messages as discussed during the <number> - <number> - <number> <allcaps> ccb </allcaps> meeting , the software bus and time subsystems within <allcaps> cfe </allcaps> are not checking the length of incoming messages . executive services and event services are both verifying that the length of the supplied message is sufficient before calling the handler . table services also verifies the length using a different approach . however sb and <allcaps> time </allcaps> have no validation , thereby theoretically allow a message that is too short to be passed to the handler , which could result in a crash . this has always been the case , this is not a new issue . note that full <allcaps> eds </allcaps> integration ( a potential target for <allcaps> cfe </allcaps> <number> + ) provides length checking on all packets automatically . so this already fixes the issue . but there needs to be a decision made whether to implement an interim change here for <allcaps> cfe </allcaps> <number> .",2.0
cmake script cleanup the cmake build scripts could benefit from some general cleanup prior to release of <allcaps> cfe </allcaps> <number> . in particular : - some comments are obsolete or incorrect - there is some dead code or broken options present - some refactoring would improve readability and maintenance the <allcaps> ghaps </allcaps> project did some cleanup here and i will push a commit under this ticket containing the modifications,2.0
clean up build warnings for <allcaps> cfe </allcaps> <number> there are several warnings that appear in a build of the current development branch that should be cleaned up prior to the <number> release . for instance : { { { fsw / cfe - core / src / es / cfe_es_api . c : in function ‘ cfe_es_getappid ’ : fsw / cfe - core / src / es / cfe_es_api . c : <number> <time> : warning : unused variable ‘ taskid ’ [ - wunused - variable ] uint32 taskid ; } } } there is also a cmake warning in new versions of the tool ( v3 . <number> + which is in ubuntu <number> ) and another const - ness warning regarding <code> that shows up with - wwrite - strings enabled .,0.0
"sb - add "" promiscuous "" pipe option particularly when debugging and diagnosing issues , it ' s useful to have an app that can capture all messages , no matter what is subscribed to by that pipe .",2.0
"cfe time service should be endian - neutral currently the cfe time service assumes time messages are in platform - endian format , which will cause headaches in mixed - endian environments . cfe time messages should standardize on one byte ordering ( i suggest network - order , aka big - endian ) .",0.0
"cfe_es mempool returns buffers that are not aligned per email from ryan prentice to the cfs - community mailing list on <number> / <number> : issues with tables containing doubles i tracked this down to be a mempool issue . i ’ ve posted part of the stack trace below that is responsible for assigning memory from the mempool for the table data . cfe_es_getpoolbuf ( ) - cfe_esmempool . c : <number> cfe_tbl_register ( ) - cfe_tbl_api . c : <number> line <number> of cfe_esmempool . c sets the address of the pointer where the table data will be loaded . { { { * bufptr = ( uint32 *)( bdptr + <number> ); } } } below are some values i pulled out of the debugger . { { { bdptr bd _t * 0x 4 2 a6d100 sizeof ( * bdptr ) unsigned long int 0x0 0 0 0 0 0 0 c ( uint32 *)( bdptr + <number> ) uint32 * 0x 4 2 a6d10c * bufptr uint32 * 0x 4 2 a6d10c } } } in my table , the first piece of data is a double and the above code would have that double start at an address that is not double word aligned . to test that this is in fact that location that the problem originates , i added four bytes to * bufptr and set it to 0x 4 2 a6d110 in the debugger , forcing it to be double word aligned . i then hit play and crossed my fingers , and what do ya know , it worked . adding an int32 as the first member of the table allowed me to proceed past the issue , but i feel like that is a very fragile solution . issues with sb messages containing doubles i ’ m getting unaligned memory exceptions when receiving a message that contained doubles from the sb . it appears the payload isn ’ t guaranteed to begin at a double word boundary . there is no way to pad for this since the payload is aligned sometimes and unaligned others . i ’ ve pasted the stack trace below .",0.0
"build failure when using std =c 9 9 a recent code change pushed to development may break the build for in certain configurations . on my projects we generally build using the <code> flags , which used to work . however the introduction of a binary constant broke it : { { { cfe / fsw / cfe - core / src / sb / cfe_sb_api . c : in function ‘ cfe_sb_sendmsgfull ’ : cfe / fsw / cfe - core / src / inc / cfe_sb . h : <number> <time> : error : binary constants are a <allcaps> gcc </allcaps> extension [ - werror ] <hashtag> define </hashtag> cfe_sb_pipeopts_ignoremine 0 b00000001 /* *< \ brief messages sent by the app that owns this pipe will not be sent to this pipe . */ ^ cfe / fsw / cfe - core / src / sb / cfe_sb_api . c : <number> <time> : note : in expansion of macro ‘ cfe_sb_pipeopts_ignoremine ’ if ( pipedscptr - > opts & cfe_sb_pipeopts_ignoremine ) ^ cc1 : all warnings being treated as errors cfe_core_default / cmakefiles / cfe_core_default . dir / build . make : <number> : recipe for target ' cfe_core_default / cmakefiles / cfe_core_default . dir / src / sb / cfe_sb_api . c . o ' failed } } }",0.0
"es - incorrect use of cfe_sb_messagestringget function in cfe_es_shelloutputcommand the calls to cfe_sb_messagestringget on lines <number> and <number> in cfe_es_shell . c are passing in an incorrect "" sourcemaxsize "" parameter causing the command to be truncated to <number> characters . possible solutions are documented in the attached email thread . the <allcaps> ccb </allcaps> will determine final solution .",0.0
"add option for medium_format mode in <allcaps> evs </allcaps> event services currently support configurations for long vs . short format event messages . a medium format that includes the dynamic data out of the event text string , along with the time stamp , event type , processor id , application name , and <allcaps> eid </allcaps> would be a useful addition to the set of <allcaps> evs </allcaps> configurations .",2.0
"checking return codes in <allcaps> cfe </allcaps> for example , in cfe_sb_createpipe , it calls cfe_es_getappid but does not confirm that it returned cfe_success . should it check that return value ? ( the appid is zeroed by getappid . ) this could create a situation where an app creates a lock ( and somehow an error is generated ) and the app could not later delete the pipe as it does not "" own "" it . it would be good to scrub all <allcaps> cfe </allcaps> code , looking for calls to internal functions that do not verify the return . also , what should be the behavior when these calls do not return cfe_success ? should they generate events ( when <allcaps> evs </allcaps> may not be functional ) or syslog messages or os_printf ?",2.0
"add "" maximum <allcaps> eid </allcaps> "" comment to the top of all cfe events . h files if a new event identifier ( <allcaps> eid </allcaps> ) needs to be added , and the best place for the event identifier is not at the end of the identifier list , developers may be inclined to renumber the preexisting eids to be in numerical ascending order with the new <allcaps> eid </allcaps> . renumbering existing eids could break tools , tests scripts , etc . it is recommended to comment all the cfe event . h files ( as was done with sb_events . h under ticket # <number> ) to alert developers on the max <allcaps> eid </allcaps> value in the file and how to number new eids using the max .",0.0
"cfe_sb_createpipe should avoid nesting locks cfe_sb_createpipe calls getappid and getappname in a block of code that uses a lock to protect against concurrent modification . ( per recommendation from joe ) we should avoid nesting locks , so these calls should go outside the protected block .",0.0
"cfe_es_getappid should call cfe_es_getappidinternal simplifies the code , ensures the same logic .",0.0
sb - stats telemetry packet is not time - stamped a line was deleted at some point in the cfe_sb_task . c file that used to timestamp the sb - stats message before going out on the s / w bus . the cfe_sb_sendstats ( ) routine merely needs a line added back in : cfe_sb_timestampmsg ( ( cfe_sb_msg_t <wink> & cfe_sb_taskdata . stattlmmsg ) ;,0.0
"option to not receive messages i send ? i would like to have an app ( detailed description below ) that can publish messages with id ' s that the same app is subscribed to . this would create loops and the app would have to mark messages to identify which it sent versus which were sent by other apps . given that the pipe has an app id , it would be easy to ( in sendmsgfull ) skip any pipes that have the same app id as the caller . can sb have a pipe option to not receive messages from the owning app ? detailed description : i am writing a voting application for redundant processor / sensor environments . as a test framework , i would like to read packets on the sb and to make duplicate copies so that the voter would have redundant messages to vote on . i ' d like the duplicate packets may have the same id as the original message .",2.0
add timestamps to <allcaps> evs </allcaps> logging to stdout often it ' s useful to know the time a message is generated in the stdout log . adding a timestamp to evs_sendviaports ( ) as an option would be helpful .,2.0
"have an option to set the timestamp in cfe_sb_sendmsg whether it be a compile - time option , a different function , or a parameter , it would be useful for specific timing testing to have telemetry messages timestamped by the sb code at the time the message is sent , rather than when the app calls setmsgtime or timestampmsg ( ) .",2.0
"sb - expose an <allcaps> api </allcaps> to increment / decrement the usecount of the buffer applications may want to retain the buffer provided by rcvmsg for longer than when the app makes the next call to the function . this should only require incrementing / decrementing the usecount of the cfe_sb_bufferd_t structure that precedes the buffer , and there is currently a private function "" cfe_sb_decrbufusecnt ( ) "" for decrementing this counter . can cfe_sb_decrbufusecnt ( ) be made public , and a companion function of incrbufusecnt be added as well ?",2.0
"cfe performance ids are private definitions performance identifier definitions should not be "" hidden "" in private header files . they should be made public in a configuration file . attached email thread contains additional information on mission use case for need to change a cfe performance identifier value .",0.0
"es shell command telemetry timing is hardcoded the cfe_es_shelloutputcommand hard codes a delay of <number> milliseconds to prevent flooding on large shell output messages over the software bus . this delay should be configurable to allow greater flexibility and support on a wide range of platforms . the email thread that brings this issue to attention and starts the discussion on the solution is pasted below for reference : from : <email> [ mailto : <email> ] on behalf of strege , susanne l . ( <allcaps> gsfc </allcaps> - <number> ) sent : tuesday , <date> <time> to : <allcaps> nasa </allcaps> core flight software community configuration control board mailing list < <email> > subject : re : [ cfs - community - ccb ] fw : cfe es shell command telemetry timing i ’ m in favor of removing the hardcoded hack and replacing with a platform configuration . unless anyone objects , i ’ ll write up a ticket and assign to the next release . from : <email> [ mailto : <email> ] on behalf of hickey , joseph p . ( <allcaps> grc </allcaps> - lss0 ) [ <allcaps> zin technologies inc </allcaps> ] sent : tuesday , <date> <time> to : <email> subject : re : [ cfs - community - ccb ] fw : cfe es shell command telemetry timing seems pretty clear to me - - the <allcaps> api </allcaps> / prototype directly out of osapi - os - core . h is : int32 os_taskdelay ( uint32 millisecond ) ; inside the call , the milliseconds are then converted into whatever units the underlying os uses to measure time passing . for vxworks this is converted to ticks , but for other oss like <allcaps> posix </allcaps> this is converted to nanoseconds for use with e . g . nanosleep ( ) . all in all i think this is a perfectly fine example of an abstraction layer doing what it is supposed to do . the only question is whether cfe_es_shell . c should hardcode it to 2 0 0 ms - - this is very hackish to me . on many systems it may not need a delay at all and could be <number> . but i agree , if there is any documentation out there which is describing the parameter of os_taskdelay as anything else , we need to fix that . would not hurt to ask . on <date> <time> , limes , gregory l . ( <allcaps> arc </allcaps> - ti ) [ <allcaps> sgt </allcaps> , <allcaps> inc </allcaps> ] wrote : oops - - i forgot to confirm the units of the parameter <wink> so , what document do we need to fix , given that saul was under the impression that the parameter was in ticks ? - - greg limes work : <email> home : <email> cell : <phone> land : <phone> ________________________________________ from : <email> [ <email> ] on behalf of hickey , joseph p . ( <allcaps> grc </allcaps> - lss0 ) [ <allcaps> zin technologies inc </allcaps> ] [ <email> ] sent : tuesday , <date> <time> to : <email> subject : re : [ cfs - community - ccb ] fw : cfe es shell command telemetry timing the argument to os_taskdelay is in milliseconds , so i am not sure where the concern arises ? i would support replacing the hardcoded "" <number> "" in cfe_es_shell . c with something more configurable , but i am not sure that cfe_psp_get_timer_tick is the right answer either . for instance on some psps that do not necessarily have direct access to this information , it returns <number> . besides that , it is defined as returning the number of ticks per second ( a rate ) , not a tick period , so it makes no sense to me to pass this value directly into os_taskdelay . if anything , i would suggest making another platform configuration define , and just using it here i . e . : os_taskdelay ( cfe_platform_os_shell_delay ) ; then the users can set it to whatever they ' d like . on <date> <time> , strege , susanne l . ( <allcaps> gsfc </allcaps> - <number> ) wrote : this looks like a valid suggestion to me . if others agree , i ’ ll put in a ticket and assign to the cfe <number> . <number> release . from : weiss , saul h [ mailto : <email> ] sent : tuesday , <date> <time> to : strege , susanne l . ( <allcaps> gsfc </allcaps> - <number> ) < <email> > cc : hinz , david b . ( <allcaps> jsc </allcaps> - ga111 ) [ <allcaps> lockheed martin corp </allcaps> ] < <email> >; clark , ronald h < <email> > subject : cfe es shell command telemetry timing susie , reviewing the cfe_es_shell . c , i noticed the following call in cfe_es_shelloutputcommand : os_taskdelay ( <number> ); my concern is that <number> is the default system tick hardcoded into the <allcaps> osal </allcaps> . so , this equates to a <number> second delay . we are using a different frame rate and so planned to use a different tick rate . i think the cfe_es_shell . c code should be updated to : os_taskdelay ( cfe_psp_get_timer_tick ( )); thoughts ? saul h weiss lockheed martin space systems company orion <allcaps> vpud csci cpe </allcaps> <phone> - - joe hickey software engineer - <allcaps> zin </allcaps> technologies , inc . phone : <phone> / <phone>",2.0
"' printf ' : mismatch between the type expected by the conversion specifier %x and the type of the argument . cfe_evs_disableportscmd calls evs_sendevent with a format string for printf that contains the %x specifier ( cfe_evs_task . c : <number> : <number> ) . evs_sendevent is also a varargs function and is called in this case with a variadic argument of type unsigned char . this gets promoted via the default argument promotions to a value of type int ( which is a signed type ) . however , evs_sendevent calls vsnprintf with the variadic argument list and the format specifier , which triggers undefined behavior because the %x specifier is expecting a value of type unsigned int . the fix is to add a cast to "" unsigned int "" in the call to evs_sendevent",0.0
no way to find an existing pipe id by name there is no way to find a pipe id given a pipe name for an existing pipe .,2.0
"remove all <allcaps> mks </allcaps> $ log comments in file header prologs the git version control system eliminates the need to have "" change logs "" included in each source code file . the original cfs <allcaps> mks </allcaps> change logs have been accumulating since <number> making the source code files very lengthy . the logs are outdated and of little practical use . now that the code is being maintained via git , the old <allcaps> mks </allcaps> $ log tags are no longer used . the old <allcaps> mks </allcaps> $ log tags and old <allcaps> mks </allcaps> log information / comments should be removed from all source code files . note : this needs to be performed after ticket # <number> changes have been merged to prevent any merge conflicts .",0.0
"<allcaps> ccsds </allcaps> electronic data sheet ( <allcaps> eds </allcaps> ) integration integrate consultative committee for spacecraft data systems ( <allcaps> ccsds </allcaps> ) electronic data sheets ( <allcaps> eds </allcaps> ) into the cfs tool chain and code base . an <allcaps> eds </allcaps> is a formal machine readable ( <allcaps> xml </allcaps> ) specification of interfaces for both hardware and software components . the primary use cases are to support : a ) exchange of unambiguous interface definitions in a standard format between organizations ( as <allcaps> ccsds </allcaps> is an international standards body , organizations includes other international agencies , and industry partners ) b ) automatic generation of interface code , system models , system tests , and mission operational databases c ) run - time support for plug - and - play systems there are two <allcaps> ccsds </allcaps> standards documents that specify the schema and terms to be used in the data sheets for cfs <number> ) <allcaps> xml </allcaps> specification for electronic data sheets for onboard devices and software components ( <allcaps> ccsds </allcaps> blue book <number> ) <number> ) specification for dictionary of terms for electronic data sheets for onboard components ( <allcaps> ccsds </allcaps> magenta book <number> ) this ticket is intended to address <allcaps> eds </allcaps> use at the cfs message layer ( software bus ) . another major use is at the device layer ( hardware component ) which is the target of major studies at the european space agency , and the china academy of space technology . the device layer use case will be a future cfs ticket .",2.0
"<allcaps> ccsds apid </allcaps> name space expansion expand the cfs software bus topic name space using extensions to the <allcaps> ccsds </allcaps> space packet secondary header . within the cfs architecture the <allcaps> ccsds </allcaps> primary header <allcaps> apid </allcaps> is used as a unique system - wide topic identifier . this ticket is intended to address several issue with the current <allcaps> ccsds </allcaps> space packet <allcaps> apid </allcaps> topic name space <number> ) difficulties allocating and managing the limited number of apids during development <number> ) insufficient number of apids for large systems <number> ) <allcaps> apid </allcaps> allocations for formation flying , distributed systems , multi - core , and partitioned systems <number> ) loss of spacecraft and subsystem identifying information as packets traverse the network stacks implementation of the extended header will include a compile time directive to include or disable extended header support . see attached file for header format .",2.0
"scrub all verify . h files from ticket # <number> : a scrub of the cfe_xx_verify . h files is needed for all the services to ensure that the checks make sense and remove the checks that do not make sense , ensure the proper rationale is provided for all the checks that do make sense and possibly adjust their values .",2.0
"add compile - time assert to ensure <number> - bit char type ticket # <number> - <allcaps> jsc </allcaps> : change uint8 to char for strings in interface structures . this change however , assumes use of the "" char "" data type as an <number> - bit type . this assumption is stated in the cfe doxygen and readme release notes however , this information could be missed by users . assumptions should always be explicit . adding a compile - time assert would be useful . it was recommended by the community <allcaps> ccb </allcaps> to place this assert in the cfe vs . the <allcaps> osal </allcaps> since the <allcaps> osal </allcaps> is not dependent on the char type being <number> - bits . the cfe_es_erlog . c file also contains a compile - time assert . it is not a good practice to scatter / hide compile - time asserts across multiple source files . it is highly recommended to move all cfe compile - time asserts to a separate / shared c file i . e cfe_compiletime_assert . c",2.0
"update sample cmake configuration <allcaps> cfe </allcaps> includes a "" sample_defs "" directory containing a sample configuration for cmake , which fell out of date over time . this needs to be updated . this is an ex - post - facto report ; we fixed this on the fly while creating the <number> . <number> tarball ; this ticket will be used when cycling this hotfix back into development .",0.0
"process cfe application developers guide with doxygen to allow linkage to code / files as discussed at the <date> <allcaps> ccb </allcaps> meeting ( reference cfs systems engineering handbook discussion in the minutes ) , the cfe application developers guide contains a significant amount of <allcaps> api </allcaps> references . indirectly referencing the cfs <allcaps> api </allcaps> ' s in an external document is prone to error . the <allcaps> api </allcaps> information should be referenced directly from the code . it is highly recommended to move the application developers guide to the cfe doxygen user ’ s guide .",1.0
"doxygen generator code had gotten stale the cmake build system included some logic to support building the doxygen - based <allcaps> cfe </allcaps> documentation . however these rules had gotten out of date with respect to other changes that had gone into the build since they were written , and a couple variable name and path names need to be fixed .",0.0
cfe cmake does not build out - of - the - box the list of options included in the cmake / sample_defs directory are out of date . these options have not been kept up with the cmake options that are defined in the test area used for the bamboo builds .,0.0
"cfe ces1515 . <number> requirement failure requirements ces1515 and ces1515 . <number> state : "" ces1515 upon a processor reset , the cfe shall create all operating system objects required by the cfe . "" "" ces1515 . <number> if the creation of the operating system object fails , the cfe shall perform a power on reset . "" to satisify this requirement , the cfe_es_createobjects function makes a call to the cfe_psp_panic function in the case where the return from os_taskcreate ! = os_success . the cfe_psp_panic function however , does not perform a power on reset . it performs an exit ( - <number> ) . to correctly satisfy this requirement , es needs to make a call to cfe_psp_restart with an input argument of cfe_psp_rst_type_poweron to specify a power on reset . this may not be the best solution . it is recommended to reconsider this requirement . it may be the best / required course of action to perform a power on reset following a processor reset if the creation of one of the cfe core application objects fails . this may not be the best / required course of action if the creation of one of the applications listed in the es startup script fails . it should be noted that this requirement has not been properly handled in past releases of the cfe . the call to the cfe_psp_panic function to satisfy this requirement has been in place since the initial release of the cfe . it was recently found that the test to verify this requirement was faulty producing a false positive .",0.0
"additional <allcaps> cfe </allcaps> start up state for application sync although the cfe <number> . <number> release improved synchronization during start up , it only implements a single state ( <code> ) which is supposed to indicate when everything is ready . however , this may not be sufficient for all applications . specifically , some applications have an "" early "" init in which its local data structures are all set to an initial state , followed by a "" late "" init that may require some communications with other applications or libraries . an application would need to also complete this "" late "" initialization in order to be considered completely up and running . currently the start up sync only handles the early init ; late init , if required , is generally done while in the "" operational "" state but this also a race condition in that requests can be made to an application that has not been fully initialized . this race condition was observed in the <allcaps> eva cws </allcaps> project where one app needed to wait for other apps to be fully loaded before completing its initialization , so it was using <code> before doing its late - phase init . but other applications ( also using the same sync call ) were calling other functions before the late - phase init had completed . the solution is to add another <allcaps> cfe </allcaps> startup state for this late - phase init .",2.0
"cfe_evs_register filters argument should be of type cfe_evs_binfilter_t * if the filters argument of cfe_evs_register is not null , it is always cast to "" cfe_evs_binfilter_t *"", the parameter should be of that type and not "" void *"". ( if users want to pass another type that is compatible , they can cast on their call to make it explicit . ) void * invites passing the wrong type of pointer .",0.0
"misleading cfe doxygen : cfe_sb_deletepipe during app development , a developer commented on the following : ' ' after testing , it appears that the comments in the cfe_sb_deletepipe are not correct . all created pipes are automatically deleted on <allcaps> cfs </allcaps> shutdown and no app specific calls to cfe_sb_deletepipe is required . calling deletepipe in cleanupcallback function gives the following error : ' ' { { { <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : pipe delete error : caller ( cfe_evs ) is not the owner of pipe <number> } } } the cfe doxygen has : ' ' ' int32 cfe_sb_deletepipe ( cfe_sb_pipeid_t pipeid ) ' ' ' description this routine deletes an input pipe and cleans up all data structures associated with the pipe . all subscriptions made for this pipe by calls to cfe_sb_subscribe will be automatically removed from the sb routing tables . any messages in the pipe will be discarded . ' ' ' applications must call this routine for all of their sb pipes as part of their orderly shutdown process . ' ' ' ' ' ' however , ' ' ' cfe_es_cleanupapp ( uint32 appid ) calls cfe_sb_cleanupapp ( appid ) ( in cfe_sb_priv . c ) which deletes all of an app ' s pipes . so when the app developer tries to do that same cleanup themselves they get an error . it ' s a question of resource management . how should the documentation be updated to tell the developer what to do ?",0.0
cfe ces1702 . <number> and ces1703 . <number> requirement failures the original implementation to satisfy es requirements ces1702 . <number> and ces1703 . <number> involved making a call to the cfe platform configuration variable cfe_es_exception_function within the <allcaps> psp </allcaps> . changes to the <allcaps> psp </allcaps> have now resulted in the failure of these two requirements ( requirement text is provided below for reference ) . cfe requirements should be satisfied within the cfe code base . failed requirements include : ces1702 . <number> if the <allcaps> cpu </allcaps> exception was caused by the operating system or cfe core then the cfe shall initiate a <platform_defined> response . ces1703 . <number> if the floating point exception was caused by the os or cfe core then the cfe shall initiate a <platform_defined> response .,0.0
"add cfe <allcaps> itos </allcaps> record files provide an initial release of cfe record files that define the cfe command and telemetry database for the <allcaps> itos </allcaps> ground system . it is believed these record files are substantially correct and complete however , they have been tested only lightly . it is important to get these files delivered with the next cfe so that they may be readily available for use and aid in fining errors or needed updates , documentation , etc .",2.0
"cfe_es_shelloutputcommand is truncating output filename in the cfe_es_shelloutputcommand , when a filename is passed into the function , the call to cfe_sb_messagestringget is truncating the input filename into the output filename variable . the truncation is occurring due to the sizeof the pointer to the input filename being used as the sourcemaxsize input in the call to the cfe_sb_messagestringget function on lines <number> - <number> : int32 cfe_es_shelloutputcommand ( const char * cmdstring , const char * filename ) { . <repeated> else { ( void ) cfe_sb_messagestringget ( outputfilename , filename , <allcaps> null </allcaps> , sizeof ( outputfilename ) , sizeof ( filename ) ); }",0.0
"cfe_es_reloadappcmd references incorrect data in call to cfe_es_reloadapp in the cfe_es_reloadappcmd function , the wrong data is being passed into the call to the cfe_es_reloadapp function . the cfe_es_reloadapp function takes in the appid and the name of the application file to load . instead of the filename being passed in , the name of the application is being passed in . see code snippet below from cfe_es_task . c lines <number> - <number> : cfe_sb_messagestringget ( localapp , ( char <wink> cmd - > application , <allcaps> null </allcaps> , os_max_api_name , sizeof ( cmd - > application ) ); result = cfe_es_getappidbyname ( & appid , localapp ) ; if ( result = = cfe_success ) { result = cfe_es_reloadapp ( appid , localapp ) ;",0.0
"<allcaps> evs </allcaps> unit test code coverage incomplete in task . c ( <allcaps> gsfc dcr </allcaps> <number> ) cfe_evs_task . c - <percent> % coverage ( <number> lines of code <allcaps> not </allcaps> executed ) the lines not covered are in cfe_evs_taskinit : - : <number> : /* register <allcaps> evs </allcaps> task for event services */ <number> : <number> : status = cfe_evs_register ( <allcaps> null </allcaps> , <number> , cfe_evs_binary_filter ) ; <number> : <number> : if ( status ! = cfe_success ) - : <number> : { # # # # # : <number> : cfe_es_writetosyslog ( "" <allcaps> evs </allcaps> : call to cfe_evs_register failed : rc =0 x % 0 8 x\ n "" , ( unsigned int ) status ) ; # # # # # : <number> : return status ; - : <number> : } <allcaps> reason </allcaps> : none",2.0
"<allcaps> evs </allcaps> - cfe_evs_writeappdatacmd references incorrect variable in call to os_creat in the cfe_evs_writeappdatacmd function , the wrong variable ( uninitialized ) is being passed into the os_create function . localname ( initialized via the call to cfe_sb_messagestringget ) should be passed in to os_creat rather than appdatafilename . see code snippet below from cfe_evs_task . c lines <number> - <number> : /* copy the commanded filename into local buffer to ensure size limitation and to allow for modification */ cfe_sb_messagestringget ( localname , ( char <wink> cmdptr - > appdatafilename , cfe_evs_default_app_data_file , os_max_path_len , sizeof ( cmdptr - > appdatafilename ) ); /* create application data file */ filehandle = os_creat ( appdatafilename , os_write_only ) ;",0.0
"incorrect leap seconds in docs under the cfe user ' s guide ( doxygen ) : core flight executive documentation » cfe time services overview file : cfe / docs / cfe usersguide / doxygen / cfetimeugcomponents . html . <repeated> this sentence is now quite out of date : "" the initial count of leap seconds ( <number> ) was established in january of <number> , the first leap second was added to the initial count in june of <number> , and the current count of leap seconds is <number> . "" we are up to <number> ( <url> - <date> ) . consider revising the verbiage so we do not have to keep updating it .",0.0
"enhanced build version . h collisions the <allcaps> cmake </allcaps> build system <allcaps> cfe </allcaps> / cmake / version . cmake code generates a version . h file that overrides the version . h required to build for vxworks . suggested fix is to change the generated filename to cmake_version . h , and make the change to <allcaps> cfe </allcaps> / cmake / target / src / target_config . c to include the new filename",0.0
"sb timeout receive unit test failure when running the sb unit tests via the "" classic build "" , the sb is failing due to an unexpected return : unexpected return in timeout receive test , exp = - <number> , act = - <number> the failure appears to be due to the unit test not setting the proper return value before the call to cfe_sb_rcvmsg . in the sb_ut . c source code file in the test_rcvmsg_timeout function there is an <hashtag> if n def </hashtag> statement around the ut_setrtncode function that is blocking the return code from being set properly .",0.0
fix git version strings built into executable the cmake build system includes version information acquired by running <code> in various source trees being used by the build . these version strings are then linked directly into the output executable . in testing the <allcaps> cfe </allcaps> <number> release i noticed that it wasn ' t quite working correctly . the git revs were ok but it in some cases was referencing the wrong base tag or no base tag at all .,0.0
cppcheck - strncpy - fills may not be null terminated this ticket will is addressing the following cppcheck warnings : e - ja / cfe / fsw / cfe - core / src / es / cfe_es_apps . c : <number> : warning : the buffer ' ramdiskpath ' may not be null - terminated after the call to strncpy ( ) . / home / bamboo - remote - agent / bamboo - agent - home / xml - data / build - dir / <allcaps> cfs </allcaps> - <allcaps> cfscfe </allcaps> - ja / cfe / fsw / cfe - core / src / es / cfe_es_apps . c : <number> : warning : the buffer ' ramdiskpath ' may not be null - terminated after the call to strncpy ( ) . / home / bamboo - remote - agent / bamboo - agent - home / xml - data / build - dir / <allcaps> cfs </allcaps> - <allcaps> cfscfe </allcaps> - ja / cfe / fsw / cfe - core / src / es / cfe_es_shell . c : <number> : warning : the buffer ' cmd ' may not be null - terminated after the call to strncpy ( ) . / home / bamboo - remote - agent / bamboo - agent - home / xml - data / build - dir / <allcaps> cfs </allcaps> - <allcaps> cfscfe </allcaps> - ja / cfe / fsw / cfe - core / src / es / cfe_es_shell . c : <number> : warning : the buffer ' outputfilename ' may not be null - terminated after the call to strncpy ( ) . <date> - <allcaps> ccb </allcaps> meeting discussed solution to replace strncpy call with cfe_sb_messagestringget,0.0
"redundant initializations if a variable is declared and initialized , then a value is immediately stored in it , we get a warning . the redundant initializer did not need to be added and we are removing them .",0.0
"shush cppcheck there are some specific places in the code where we want cppcheck to not produce warnings , without generalizing in any way to other code . this involves inserting comments like { { { /* cppcheck - suppress unsignedpositive */ } } }",0.0
"es - createchildtask <allcaps> api </allcaps> function does not use "" flags "" input parameter the <allcaps> api </allcaps> definition of the cfe_es_createchildtask <allcaps> api </allcaps> function is : int32 cfe_es_createchildtask ( uint32 * taskidptr , const char * taskname , cfe_es_childtaskmainfuncptr_t functionptr , uint32 * stackptr , uint32 stacksize , uint32 priority , uint32 flags ) the "" flags "" input parameter which is intended to be used to pass into the <allcaps> osal </allcaps> os_taskcreate call , is not being used . instead the call to os_taskcreate hardcodes the os_fp_enabled macro for the "" flags "" input . this implementation of the <allcaps> api </allcaps> is very misleading and limiting . in addition , es defines a "" flags "" macro in the cfe_es_perf . h called cfe_es_perf_child_flags that is passed into the cfe_es_createchildtask <allcaps> api </allcaps> function call when es spawns a child task to write its performance log data to a file . the flags used when creating child tasks need to be defined across all implementations vs . "" hidden "" in private cfe service header files . this macro should be removed and replaced with an appropriate <allcaps> osal </allcaps> macro . an accompanying <allcaps> osal </allcaps> ticket may need to be written to add all "" flags "" options .",2.0
"update cfe version number for <number> . <number> release this ticket will be used to update the version header file to update the version number to <number> . <number> for test and release . once cfe version <number> . <number> has been populated to the master branch , this ticket will be used to set the version number to <number> . <number> to indicate the code is development code retrieved from the "" development "" branch .",2.0
"<allcaps> smp </allcaps> : thread safety issues in cfe_time around the sync callbacks the <code> and <code> functions are not thread safe , as they do not utilize any sort of global mutex when searching the table . these are called by applications during startup , which is exactly the situation where multiple threads __might__ be calling these functions at the same time . furthermore , <code> does not protect against a callback being unregistered at the same time a tone message comes in .",0.0
"es does not check target file existence before attempting to reload an application ( <allcaps> gsfc dcr </allcaps> <number> ) if the following command is sent : / fsw_es_reloadapp <allcaps> application </allcaps> ={ application } , <allcaps> appfilename </allcaps> ={ file } and if the file does not exist , the application will be deleted but cannot be reloaded . this is because es does not check to see if the file exists first . this and any other es command that requires file existence should check for the file existence before attempting to do operations on the application .",0.0
refactor cfe_es_appcreate and cfe_es_loadlibrary these functions actually perform <number> major operations : * calling <code> to load the module * calling <code> to find the entry point / init function and calling that entry point / init function . ( for apps this also involves <code> here whereas a library init function is called directly ) * manipulate the internal <allcaps> cfe es </allcaps> global tables to store the data related to the application / library these major functional items should be broken into separate functions . this will make <code> and <code> much cleaner looking and remove the overloads needed to support static loading as in ticket # <number> .,2.0
"unsafe macros , investigate conversion into inline functions some places in <allcaps> cfe </allcaps> - - notably , in ccsds . h - - there are macros that do things like this : { { { <hashtag> define </hashtag> ccsds_wr_apid ( phdr , value ) \ ( ( phdr ) . foo [ <number> ] = ( value > > <number> ) , \ ( phdr ) . foo [ <number> ] = ( value & 0 xff ) ) } } } this means that if "" value "" is an expression , odd things happen when the macro is expanded . this appears in many places in ccsds . h and we need to do a scan of other headers as well . it needs to be : { { { <hashtag> define </hashtag> ccsds_wr_apid ( phdr , value ) \ ( ( phdr ) . foo [ <number> ] = ( ( value ) > > <number> ) , \ ( phdr ) . foo [ <number> ] = ( ( value ) & 0 xff ) ) } } } this change needs to happen for all the places where a macro parameter is an operand in an experession , and does not yet have parens around it . <allcaps> update </allcaps> <number> - <number> - <number> : <allcaps> ccb </allcaps> recommends that in many cases we would benefit from changing these macros into c99 "" inline "" functions , so this ticket is being hijacked !",0.0
"<allcaps> eds </allcaps> : the es "" loadlibrary ( ) "" call - avoid duplicates and pass id the <code> call currently does not check if a library with the same name is already loaded . it should probably do this , and if a duplicate is found it should return an error code indicating that the library is already loaded . in the same area , the library id should be passed to the init function so any data structures / api calls associated with the library can be properly tracked in case the library is unloaded in the future .",2.0
"clean up es startup object table in reviewing # <number> it was determined that a better approach to changing the type of the "" stackptr "" field would be to do some more general cleanup here and remove the unused field .",2.0
"fs - extractfilenamefrompath function needs revision the "" stringlength "" variable defined in the fs extractfilenamefrompath function does not meet <allcaps> misra </allcaps> standards ( <number> typedefs that indicate size and signedness should be used in place of the basic numerical types ) . the simple solution ( shown in ticket # <number> ) , "" replaced casting from int to size_t as must store return of strlen . "" , resulted in an additional "" correction "" variable which in turn may result in an infinite loop . it is recommended to rewrite this function .",2.0
possible buffer overrun in format strings used for scanf particularly in <code> this uses the %s to read strings into fixed length buffers . there is a possibility of overrun if the actual string exceeds the allocated size .,0.0
"cfe <number> documentation updates this ticket will be used for all cfe <number> documentation updates including the <allcaps> vdd </allcaps> . a listing of the needed documentation updates will be added to this ticket as tickets , requiring code updates , are reviewed and determined there is an associated documentation change .",2.0
"sb : "" cfe_sb . h "" should not depend on cfe_platform_cfg . h the public include file <code> currently includes <code> within it . however , nothing within cfe_sb . h actually depends on the macros in this file . usage of <code> macros should be limited to <allcaps> cfe </allcaps> itself ; however , <allcaps> cfs </allcaps> apps may include <code> . having the platform config included like this can cause problems for apps as it prevents them from building in a platform - config - agnostic way .",0.0
allow c99 code in <allcaps> cfe </allcaps> . update compiler flags to allow c99 code to be used everywhere in <allcaps> cfe </allcaps>,0.0
"cfe_es_appcreate does not unload an object file if the entry point is not found the function cfe_es_appcreate is used for the <allcaps> es api </allcaps> and the es command interface to load and start a new application . if the entry point for the new application does not exist in the object file for the application , the function returns an error , but does not try to unload the object module . this leaves the system with a loaded object module that is not tracked by the cfe . in addition the <allcaps> osal </allcaps> still has an entry for the object module , and will reject another attempt to load the same file , with the same module name . action : fix the code in cfe_es_appcreate to unload the object file in the event the entry point symbol is not found .",0.0
"add explicit "" return "" after functions that are not supposed to return function calls such as <code> do not normally return , except when running with a "" stub "" implementation during unit test . to keep the testing accurate , these functions should be immediately followed by an explicit "" return "" statement so that any instructions later in the function will <section> be executed .",0.0
<allcaps> jsc </allcaps> : update <allcaps> cfe </allcaps> unit tests roll - up of all <allcaps> jsc </allcaps> changes to the <allcaps> cfe </allcaps> unit tests,0.0
"<allcaps> jsc </allcaps> : add l / u / ul suffixes to literal values add an "" l "" , "" u "" , or "" ul "" suffix to all literal values and macro constants in <allcaps> cfe </allcaps>",0.0
"<allcaps> jsc </allcaps> : add "" void * "" casts add explicit <code> casts where ever a local object is being passed into a function that accepts a void pointer .",0.0
"<allcaps> jsc </allcaps> : type correctness fixes use the correct types for interacting with the system library . * use <code> to store results from functions such as <code> . * use correct type when calling <code> elsewhere , where / / <allcaps> not </allcaps> / / interacting with the system library , use fixed - width types instead of native types .",0.0
"fix size check in cfe_es_initializecds ( ) in the <code> function , the pool size is computed by the following code : { { { cfe_es_global . cdsvars . mempoolsize = cdssize - cds_pool_offset - sizeof ( cfe_es_global . cdsvars . validityfield ) ; } } } however , if the passed - in "" cdssize "" is actually smaller than the sum of these two constants , then the size will wrap and become very large . this code must first check that the passed - in size is not smaller than this constant , if it is , the subtraction should not be done .",0.0
"fix potential issues in es_cleanupapp ( ) in <code> there are two issues : * the <code> may be deleted twice . it may first be deleted when deleting the child tasks , then it is deleted again later in the function . * it calls <code> unconditionally . it is possible that this is / / not / / an external application , for instance if it is a core application then it was not loaded from a module and the contents of the <code> field are not valid .",0.0
"<allcaps> jsc </allcaps> : change uint8 to char for strings in interface structures use the <code> type when storing strings , rather than <code>",0.0
"<allcaps> jsc </allcaps> : update code constructs to <allcaps> misra </allcaps> recommendations * modify loops to / / not / / use <code> * do not modify loop control variables within the loop , use break instead * make sure all <code> constructs have final <code>",0.0
<allcaps> jsc </allcaps> : remove unnecessary cast on os_write cleanup - remove unnecessary cast on os_write ( ) call,0.0
"add missing "" . payload "" structure member designations the <code> structure access was missing in certain conditionally - compiled code paths within <code> . this caused compilation failure when these options were enabled and the compiler attempted to build this code .",0.0
"replace os_converttoarrayindex ( ) with a macro <allcaps> jsc </allcaps> has noted that the compiler for their vxworks target does not understand the c99 "" inline "" keyword . an inline function had been used as a compatibility bridge for the "" - ng "" versions of <allcaps> osal </allcaps> that require additional work to convert an <allcaps> osal id </allcaps> to an array index . compilation was failing on this declaration . rather than making this an out - of - line function ( the easiest approach ) it would be cleaner and less of a performance hit to replace this direct call with a macro . the macro can either call the conversion function or be a pass through .",0.0
"resolve "" - m32 "" <allcaps> cfe </allcaps> classic build issues the classic <allcaps> cfe </allcaps> build historically built for <number> - bit x86 linux , on <number> - bit x86 linux build machines . building on a <number> - bit x86 linux server requires the use of the "" - m32 "" flag , but <allcaps> only </allcaps> when the target is the classic <number> - bit x86 linux . this also requires that the server has <number> - bit goodies , often "" multilib "" is the thing you need to google if this is busted . currently , inserting this flag where it is missing or removing it where it is present requires editing files , which is a speedbump for developers and a blocker for automatic systems when building both <number> - bit x86 and any other target . need to set up the classic makefiles so that we default to - m32 not being present , and allow it to be inserted on demand from the command line or via an environment variable ( at the developer ' s option , both need support ) .",0.0
"improve cppcheck configuration for <allcaps> cfe </allcaps> the initial level of support for "" cppcheck "" within the <allcaps> cfe </allcaps> build plan is a simple implementation using default checking , widened to maximize coverage but not otherwise tuned . while any individual mission or project using <allcaps> cfs </allcaps> may decide to do this work , this is only mildly in their direct interest , but it is very much in the interest of the <allcaps> cfs </allcaps> community as a whole that it gets done . we can make cppcheck more useful , both for checking the <allcaps> cfe </allcaps> core applications themselves and for checking code that uses them , by setting up a configuration file that tells cppcheck as many details as possible about the intended interfaces . for example : - indicating functions that acquire and release resources so that cppcheck can attempt to report failures to release a resource ; this is not just memory allocation but includes lock aquisition and anything else managed using one function to acquire ( or open or connect . <repeated> ) and another to release ( or close or disconnect ) . - indicating where a function requires that a pointer , passed as a function parameter , must point to initialized memory , so that cppcheck can report things like "" trying to strcopy where the source array has not been initialized . "" there are other details we can also express in the cppcheck library configuration file , generally of flavor similar to the above .",2.0
"cfe_es_getappname ( ) undefined output when failure occurs the <code> function is reasonably well defined - it sets the appname output buffer and returns <code> when everything went well , and it also nicely ensures that the output buffer is null terminated with the specified output buffer size ( all good things ) . = = <allcaps> problem </allcaps> : = = most callers of this function do not check the return code . <code> does not touch the output buffer in case of failure ( any return code other than <code> ) and this would mean that the output may not be null terminated at all , or may be left with garbage from a previous value . some callers explicitly add a null char to the buffer at the last position in the buffer , but this still leaves the possibility of treating a buffer full of garbage ( or the previous value ) as the correct value . = = <allcaps> proposal </allcaps> = = as a near term fix <code> should return an empty string in addition to the error code .",0.0
"printf format specs need to be cleaned up there are many cases like this , where the variable to print is a different type than the format . many of these have simply been casts to get rid of the compiler warning , but the format spec is what probably really should be fixed to match the type . for example , cfe_sb_getcmdcode ( ) returns a uint16 , the format spec would more appropriately be % u , rather than % d . in this case , a large , valid , command code will get printed out as a negative value , which will be confusing , because command codes are not negative values . cfe_evs_sendevent ( cfe_sb_bad_cmd_code_eid , cfe_evs_error , "" invalid cmd , unexpected command code % d "" , ( int ) cfe_sb_getcmdcode ( cfe_sb . cmdpipepktptr ) ); there are many cases like this through out cfe that need to be reviewed and cleaned up .",2.0
standardize version numbering ( in <allcaps> cfe </allcaps> ) bring version number management within <allcaps> cfe </allcaps> into line with the cfs standards documented at <url>,0.0
"es unit test failing on x86_64 due to uint32 memory handle another case of a <code> being used to store a memory pool handle , which fails when running the unit tests on a <number> - bit build . using the <code> typedef instead solves the problem .",0.0
"copies to / from message payloads should use the sizeof ( ) operator where possible when reading / writing software bus message payloads , strings must be always char [ ] arrays ( not pointers ) by definition . many times these these are defined as something like : <code> and later they are filled using something like : <code> however , instead of using the <code> in the runtime code , it is more future - proof to use the <code> operator to get the array size . this is particularly true when the payload structures are generated from an <allcaps> eds </allcaps> ( electronic data sheet ) since there may not even be a simple macro to use in that case . the <code> operator will always work even if the size is a hardcoded value or the macro name changes in a future version .",2.0
"simplify function pointer manipulations there are a number of places within the <allcaps> cfs </allcaps> projects where the usage of function pointers is somewhat obfuscated by the inclusion of redundant operators . removing those operators can improve the clarity of the code . the redundancies are based on code that , when written , did not properly base itself on the following aspects of function pointers in the c programming language . <number> . function names decay into function pointers in the same way that array names decay into pointers to their first elements , which means that an <code> operator is redundant when setting a pointer to point at a function . for the classical example of this , see most <code> examples , where no <code> is applied to the comparison function when passing it as the last argument , which has type ' ' pointer to function . <repeated> ' ' <number> . the function call operator <code> ' ' args ' ' <code> operates on a function pointer - - so every function call you see actually is invoking the above decay semantics . this means that the <code> operator is ' ' not ' ' needed when calling a function via a function pointer . happily , this also often means that you also do not need an extra level ( or two ? ! <repeated> ) of parentheses to asure that the <code> is applied to the function pointer and not to the return value . <number> . calling a function pointed to by a structure member is a very common operation , and with the above in mind , note that there is no parsing or evaluation order ambiguity ; no extra parentheses are required to assure that <code> and <code> and the function call operator are evaluated in the proper order . my task - - embodied in this ticket - - is to seek out cases in the <allcaps> cfe </allcaps> source code where redundant operations are applied to function pointers ( at assignment sites ' ' and ' ' at call sites ) , and provide recommended changes to improve clarity . specific examples will accumulate in the comments below . ticket to be closed when my scan of the project is complete , and all call sites have been resolved ( whether the resolution is to improve them now , file a ticket for later improvement , or where we will be leaving the code unchanged ) . ' ' ( this also makes the code robust against the rare but troublesome case where an external function changed from a function to a function pointer . <repeated> we may never do this , but it is always good to foster good code hygene . ) ' '",2.0
naming convention for macros in cfe_mission_cfg and cfe_platform_cfg the <code> and <code> files contain numerous macros for tuning <allcaps> cfe </allcaps> to the jobs that need to be performed . the two files have different scope : * <code> is shared by all cpus within the spacecraft / mission * <code> is specific to a single <allcaps> cpu </allcaps> within the spacecraft / mission . it is important that the scope of these definitions is well defined and used consistently throughout the code . a naming convention should be introduced so that it is clear when reading the code whether the macro has mission - level or platform - level scope .,2.0
es performance child task priority is not configurable task priorities should not be hidden read - only cfe files . it is recommended to place all cfe application and task priority settings in the platform configuration file .,0.0
"<allcaps> tbl </allcaps> - dump table registry data command can hog <allcaps> cpu </allcaps> ( <allcaps> gsfc dcr </allcaps> <number> ) the <allcaps> gsfc nicer fsw </allcaps> team discovered that it takes approximately <number> second to process the dump table registry command when there are <number> <allcaps> rts </allcaps> tables and that lower priority tasks generate various error events related to not getting an opportunity to run . adding a platform configuration definition to insert task delays into the process loop will increase the time necessary for cfe_tbl to finish the command but will allow lower priority tasks to run while the command is being processed . also , creating some test code that puts performance markers around the file i / o calls within the command processor may identify where the bulk of the command process time is spent . it may be possible to reduce the command execution time by optimizing the command handler code if the bulk of the execution time is not being spent inside the file system .",0.0
"sb - duplicate pipe creation causes failure to delete pipe ( <allcaps> gsfc dcr </allcaps> <number> ) when a software bus pipe is created , the sb service will assign a new pipe id to the system . if the same pipe is created again , sb will change its pipe id and prevent the original pipe from being deleted . see attachments for more detail .",0.0
"<allcaps> ccsds </allcaps> header file macro ccsds_inc_seq generates a compiler warning when referenced ( <allcaps> gsfc dcr </allcaps> <number> ) the macro ccsds_inc_seq defined in ccsds . h generates a compile time warning because it calls the macro ccsds_wr_seq with <number> arguments . the first argument is "" phdr "" which is ok , but the second argument is "" ccsds_rd_seq ( phdr ) + <number> "" which is not ok . the problem is that the second argument results in code that looks like (x + <number> > > <number> ) , which is unclear . putting "" ccsds_rd_seq ( phdr ) + <number> "" inside parens results in code that looks like ((x + <number> ) > > <number> ) which is ok . change macro ccsds_inc_seq from : { { { <hashtag> define </hashtag> ccsds_inc_seq ( phdr ) ccsds_wr_seq ( phdr , ccsds_rd_seq ( phdr ) + <number> ) } } } to : { { { <hashtag> define </hashtag> ccsds_inc_seq ( phdr ) ccsds_wr_seq ( phdr , ( ccsds_rd_seq ( phdr ) + <number> ) ) } } }",0.0
"possible buffer underrun in cfe_fs_decompress . c [ <allcaps> mms </allcaps> - <allcaps> ivv </allcaps> - <number> ] [ <allcaps> obs </allcaps> - <number> ] [ <allcaps> gsfc dcr </allcaps> <number> ] source code file : cfe \ fsw \ cfe - core \ src \ fs \ cfe_fs_decompress . c line <number> output from code analysis tool : "" buffer overflow , array index of ' x ' may be outside the bounds . array ' x ' of size <number> declared at line <number> may use inde "" { { { <number> while ( ( i & ( ( <number> < < w ) - <number> ) ) ! = x[ h ] ) { <number> h - - ; /* do not need to update q */ <number> w - = l ; } } } the array x could be under run if h attains a value of - <number> . this will occur if the condition does not evaluate to true before h is decremented below <number> . this could also lead to an infinitely executing loop .",0.0
"remove "" cpu "" directories from fsw / platform_inc keeping separate cpu directories in fsw / platform_inc is redundant , unnecessary , and prone to error when the platform configuration files need to be updated . it is recommended to remove the cpu directories and maintain only one copy of the cfe_platform_cfg . h and cfe_msgids . h files .",0.0
"es creates redundant sys log entries when creating er log entries ( <allcaps> gsfc dcr </allcaps> <number> ) for most of the reset cases , es will create an entry in the exception and reset log ( er log ) and it will also create a syslog entry . both the er log and syslog are stored in the preserved <allcaps> ram </allcaps> on a platform , so it is probably not necessary to create the redundant syslog entries . determine the impact to unit and build tests , and remove the duplicate syslog entires for resets .",2.0
update cfe_es_system_log_size verify to allow larger sys log files ( <allcaps> gsfc dcr </allcaps> <number> ) the es verify . h file will only allow a max sys log file of <number> bytes . there is no documented rational for this limit .,0.0
sb - add last pipe id and msg id to routine telemetry for diagnosing message limit error and buffer overrun errors ( <allcaps> gsfc dcr </allcaps> <number> ) often the sb message limit error and buffer overrun error event messages are filtered . in order to help diagnose these sb issues it would be helpful to include the last pipe id and message id associated with these errors in routine telemetry .,2.0
"es - add ability to recreate the <allcaps> ram </allcaps> disk via command ( <allcaps> gsfc dcr </allcaps> <number> ) the es startup creates and initializes the <allcaps> ram </allcaps> disk . if the <allcaps> ram </allcaps> disk becomes corrupted there is no ground interface provided to recreate the <allcaps> ram </allcaps> disk . during <allcaps> gsfc gpm tv </allcaps> testing , a <allcaps> ram </allcaps> disk corruption was experienced . a processor reset was needed in order to restore the <allcaps> ram </allcaps> disk to an operational state . see the attached <allcaps> pfr </allcaps> description for more details .",2.0
"cfe time subsystem has calls to os functions that do not exist for non - default configurations in the cfe time subsystem , there are a couple of calls to functions that do not exist : os_getlocalmet and os_setlocalmet . these calls are conditionally compiled by a configuration parameter , and probably not used often . note : <allcaps> gsfc </allcaps> ' s <allcaps> mms fsw </allcaps> uses these functions and had to provide them .",0.0
"es - invalid memory handle when restarting / deleting an application with tables ( <allcaps> gsfc dcr </allcaps> <number> ) when you delete an application that uses tables ( e . g . hk ) and then restart another task ( e . g . sc ) for a second time , the es task writes to the system log that there are invalid memory handles . seems like when tables get unregistered is where the errors are happening . message says it got a bad pointer for this table , not sure if the app in messed up . this problem is not isolated to restartapp . it occurs in deleteapp as well . what it looks like is that the linked list is not getting cleaned up properly when an app is deleted or restarted . further investigation in the <allcaps> cfs </allcaps> lab narrows the problem down to the removeaccesslink function in cfe_tbl_internal . c . the errors are being generated on table handles from the deleted app . the buffer that is trying to be placed back into the pool is set to <allcaps> null </allcaps> because it has already been put back into the pool . the tables that were "" cleaned up "" still contain the appid of the deleted app . when the subsequent app is restarted , its appid becomes that of the deleted app and inherits the table handles from the previous app . for example , the hk app has <number> tables and the sc app has <number> tables . when hk is deleted , the <number> tables are removed and the entries still contain the appid of hk . when sc is restarted , it becomes the appid that hk was . the reason the errors occur on the 2 nd restart is because on the first restart sc had a unique appid . on the second restart , it has inherited hks original appid . in this case , you will see <number> sets of errors when sc is restarted . the sc application did not show any adverse functionality because of these errors . all that is happening is that the putpoolbuf function is reporting an error when trying to return a <allcaps> null </allcaps> buffer to the pool .",0.0
"update "" cfe - <allcaps> oss </allcaps> - readme . txt "" the <allcaps> oss </allcaps> readme file was updated when the <allcaps> cfe </allcaps> <number> . <number> hotfix release tarball was prepared for and distributed to sourceforge , but the updated text was not then also stored in the cfe / docs directory . this commit captures the updated readme text from the <allcaps> oss </allcaps> tarball and places it in the cfe / docs tree .",0.0
"cfe_es_system_log_size update makes cfe_evs test fail the change made to cfe_es_system_log_size in the <allcaps> cfe </allcaps> <number> . <number> hotfix release causes the cfe_evs test to fail . the test case that fails is case <number> where the size of the es reset area is jammed to zero using a stub and cfe_evs_earlyinit is called . the tested behavior is that a specific string is printed via the system log output which has been mocked . the mock does an exact string compare of the data against a fixed set of patterns . because the size of the structure has changed , the exact content of the error message has been modified and the message is no longer being recognized by the syslog printing mock , and the test then does not know that the correct condition was trapped .",0.0
"correction of an infinite loop in cfe_sb_task . c in cfe_sb_sendrtginfo ( ) the case where ( pd = = <allcaps> null </allcaps> ) followed by continue will result in an infinite loop . the proper correction is to replace the continue with a break , so that the loop is exited on an error . the correction was made in the following changeset , as part of static code analysis changes : commit : [ changeset : 5 9 6 4 0 e0 ]",0.0
"add ut assert stubs to <allcaps> cfe </allcaps> = = = history = = = as part of <allcaps> osal </allcaps> tracs [ cfs_osal : <number> ] and [ cfs_osal : <number> ] , the basic ut assert framework was integrated into <allcaps> osal </allcaps> so that it will be available for all unit testing . the <allcaps> osapi </allcaps> stub functions were also added as a side library distributed wit",2.0
"support for statically linked <allcaps> cfs </allcaps> applications some platforms ( <allcaps> rtems </allcaps> , for example ) do not natively support the concept of dynamic module loading . even on platforms that do offer this feature , it is sometimes beneficial to statically link anyway , at least in certain circumstances , since there is some extra runtime overhead when using a dynamically linked library vs . a statically linked library . this will add the build infrastructure to do this , along with the necessary hooks to include statically linked modules into the <allcaps> psp </allcaps> as well as <allcaps> cfs </allcaps> applications and libraries . see also [ cfs_psp : <number> ] for the <allcaps> psp </allcaps> enhancement to work with this .",2.0
"default configuration setting for cfe_es_startup_script_timeout_msec is too big the cfe_es_startup_script_timeout_msec default configuration setting is currently set to <number> seconds . a full cfs system typically takes ~ <number> second to launch and initialize the cfe and all applications . the cfe "" out - of - the - box "" open source release package initializes in less than a second . having the system wait <number> seconds causes the software to appear as though it is hung . it is recommended to set the default for this configuration to <number> second . projects with a larger application base can configure accordingly .",2.0
cfe_es_system_log_size default value is too small the default value for the cfe_es_system_log_size is set to 2 k ( <number> ) . this is not large enough to hold all the cfe startup system log entries . it is recommended to increase this 1 k larger ( default <number> ),0.0
"integrate cfe_time with <allcaps> osal </allcaps> timebase <allcaps> api </allcaps> the enhancement that adds "" timebase "" functions to <allcaps> osal </allcaps> was approved and merged in [ cfs_osal : <number> ] . with this feature , cfe_time can now set up its own 1 hz callback function . this is the final / complete solution to the race condition issue described in [ cfs_psp : <number> ] , because <allcaps> cfe time </allcaps> can request the 1 hz callbacks after the rest of initialization is fully complete ( and not before that time ) .",2.0
"fix build failures on <allcaps> rtems </allcaps> there are two issues that cause a build failure when using a recent <allcaps> rtems </allcaps> toolchain / library : * { { { msg_dontwait } } } now / / is / / defined by the library headers . this is re - defined in { { { fsw / cfe - core / src / inc / network_includes . h } } } - possibly an older library did not define this ? * { { { putchar ( ) } } } is a defined as a macro , but the { { { fsw / cfe - core / unit - test / osprintf_priv . h } } } file has a function prototype for this which conflicts . this function prototype really should not be here .",0.0
"cfe <allcaps> time </allcaps> unit tests break when different configuration options are used when using the unmodified sample version of the { { { cfe_platform_cfg . h } } } file , the test cases defined in { { { time_ut . c } } } all pass . but if the user makes any time - related modifications to the platform config file , many of the unit test cases break . in particular , configuring a time server vs . time client or setting src_met = = <allcaps> true </allcaps> , etc . the test cases in "" time_ut . c "" need to include / accommodate other valid configuration options .",0.0
"remove depenedencies on software_big / little_bit_order any usage of software_big / little_bit_order is an indicator of a problem area as code is ported to additional platforms . code should be written endian - neutral wherever possible . the { { { software_big_bit_order } } } and { { { software_little_bit_order } } } are not reliable , as they assume this value based on the <allcaps> bsp </allcaps> type but that is not always correct . for instance , the pc - linux <allcaps> bsp </allcaps> assumes software_little_bit_order but in fact that <allcaps> bsp </allcaps> is also fully applicable to big - endian platforms running linux as well . some architectures ( <allcaps> mips </allcaps> , <allcaps> arm </allcaps> , etc ) have both big - and little - endian modes of operation which further invalidates this macro . in fact the c standard does not specify any portable way to determine endianness at / / compile time / / , however runtime checks using a union are fairly easy and reasonably portable where it is absolutely necessary to do something different .",2.0
"<allcaps> cfe </allcaps> is closing filehandles that were not opened the new unit tests are catching errors where <allcaps> cfe </allcaps> is closing filehandles that were never successfully opened . it is actually passing an os error code ( not a filehandle ) into { { { os_close ( ) } } } . the "" real "" <allcaps> osal </allcaps> should notice this and do nothing , but the unit test is strict about this and this does cause ut to fail .",0.0
"submit cfe <number> . <number> test artifacts , user ' s guide , and documentation submitting : <number> . cfe <number> . <number> test report , log , and data files to the / test - and - ground / test - review - packages / results directory <number> . update test procedures to the / test - and - ground / asist / local / prc directory <number> . updated doxygen user ' s guide files to the / docs / <allcaps> cfe </allcaps> usersguide / doxygen directory <number> . unit test results to the / fsw / cfe - core / unit - test / xxresults directories ( where xx is the name of the cfe service ) <number> . version description document to the / docs directory",2.0
"<allcaps> cfe es </allcaps> unit test failures caused by startup sync fix the startup sync fix (# <number> ) caused some unit test failures . this is due to the fact that the counters never get incremented as expected , since this is done by the child thread . therefore the verification that the child thread actually started cannot be unit tested . as an interim fix this check will be removed from the main code . this will make unit tests pass in <number> . <number> . ironically , this is making the main code slightly less robust in order to appease unit tests . in the future a unit test "" hook "" function can be implemented for { { { os_taskcreate ( ) } } } that imitates the counter increment so the startup verification can be but back in at that time .",0.0
"<allcaps> cfe es </allcaps> mempool code uses "" uint32 "" where it should be "" cpuaddr "" fix a leftover case of using uint32 where the intent is to store a memory address . this is the start address in the "" pool_t "" structure .",0.0
"update <allcaps> cfe </allcaps> unit tests after rebase of <allcaps> osal </allcaps> ticket <number> previously , <allcaps> cfe </allcaps> ticket # <number> was implemented which was based on the proposed unit test framework implemented within <allcaps> osal </allcaps> [ cfs_osal : <number> ] . the unit test framework has since been revisited and the related <allcaps> osal </allcaps> ticket has been rebased accordingly . unfortunately , this broke some items that had been done originally within trac # <number> . trac <number> can no longer be rebased since it is merged in "" development "" already , so this ticket will fix the unit test breakage .",0.0
"failure to test should be <allcaps> fail </allcaps> the bamboo test plan does not currently complain if it is unable to stage and run unit tests on a target , for the simple reason that our test list is currently entirely driven by parsing results returned by the target . if the target vm is offline ( as it was last weekend ) , there are no indications that the test programs did not run , and the presence of a few test results ( the ones from static analysis ) keeps bamboo happy . the plan itself , or its top level scripts ( same thing ) , needs to keep track of the list of test programs , and generate test failure reports for any such program for which it does not obtain results .",0.0
"sb only increments message sequence count where there are subscribers in the current implementation of the software bus , sequence counter management is handled in the routing table . the routing table only includes entries that have subscribed messages . this results in the sequence counter being incremented only if there are subscribers to a message . if a message is unsubscribed to and then resubscribed , the sequence counter will be reset to zero . a message sequence count should reflect the production of the message vs . the receipt of a message . one use case for this implementation is to support the filtering of a message via the sequence count . <allcaps> apl </allcaps> / <allcaps> spp </allcaps> project implemented a solution to increment the sequence count upon production of the message regardless of whether or not there are any subscribers . the solution involved removing the sequence count table from the routing table . this exact solution may not support the new / expanded <allcaps> apid </allcaps> / message id name space . expanding the message id name space will need to be considered when implementing the overall solution to increment the sequence count to reflect message production .",0.0
"sb pipes are not protected . it is possible for a task to fetch messages from an sb pipe that was created by some other task , and this can happen easily if someone fetches using <allcaps> zero </allcaps> as the pipe id . this prevents the consumed message from arriving at its intended destination . note that applications fetching from the wrong message id might notice this issue if they are reporting the receipt of messages with unexpected message id numbers . solving this may require some attention to use cases where a pipe is created by one task , to be used by another . we may also want to think about the use case where multiple tasks fetch messages from a single pipe , with the *intention* that messages go to one of the several tasks . is this use case sufficiently interesting to offset the complexity of the code required to support it ?",2.0
"minor fixes for cmake unit test build the <allcaps> cfe </allcaps> unit test build was assuming the use of "" - pg - - coverage "" options for gcc . most targets do support this for coverage analysis however some do not ( <allcaps> rtems </allcaps> , for example ) as the runtime component of this feature may not be present in the target ' s c library . therefore the ut build currently fails for these targets . also , the <allcaps> osal </allcaps> build scripts have a feature to allow installation of the unit test executables to the target binary directory . this is based on the value of a cmake variable called "" install_target_list "" , but the current build scripts are not setting this variable . this ticket will * generate an appropriate value for install_target_list * use the ut_c_flags as computed by the <allcaps> osal </allcaps> build * add an "" install "" line for the <allcaps> cfe </allcaps> unit tests as well these are all fairly minor changes and only affect unit test .",0.0
"some symbols not making it into final core executable file in the current "" cmake "" - based build scripts , the final cfe core executable file is missing symbols that are not directly referenced in other parts of <allcaps> cfe </allcaps> . a notable example of this is { { { cfe_tbl_register } } } . because these are defined in a shared library , the linker is simply not including them as they do not serve to define any unresolved symbols from the linker ' s point of view . the { { { - rdynamic } } } option is already being used , but it does not apply since the <allcaps> cfe </allcaps> core code is in a static library . there are several approaches to this problem : <number> . use the { { { <allcaps> module </allcaps> } } } library type instead of making a static library for the <allcaps> cfe </allcaps> core . this way the { { { - rdynamic } } } export option will be applied to all the cfe code as it should be and therefore all functions included in the final link . <section> but it requires cmake v2 . <number> + ( released <number> ) . however <allcaps> rhel </allcaps> still includes a very old version of cmake from <number> with their distribution so going this route forces users of <allcaps> rhel </allcaps> to go to other sources for a newer cmake . <number> . use the { { { - - whole - archive } } } linker option to force the linker to include all objects from the <allcaps> cfe </allcaps> core , <allcaps> psp </allcaps> , and <allcaps> osal </allcaps> libraries during the link . this works , but the { { { - - whole - archive } } } is specific to the <allcaps> gnu </allcaps> ld linker and is unlikely to be supported on any other linkers . however , it appears that all targets supported by <allcaps> cfe </allcaps> use the <allcaps> gnu </allcaps> ld linker so this may not be a problem . <number> . create a "" fake "" function that calls all external functions , which causes them to be undefined and therefore included in the link . this does not change linker options or build scripts so should work with <allcaps> any </allcaps> linker and the old version of cmake , but it wastes some memory as this function is still loaded into memory , and it will require maintenance to keep it up to date .",0.0
"suspicious implementation of short_format mode in evs_sendpacket ( ) this code sequence occurs within the { { { evs_sendpacket ( ) } } } function : { { { /* ( <allcaps> lsw </allcaps> ) is the intent to write the event text to the log but not the sb msg ? <repeated> */ if ( cfe_evs_globaldata . evs_tlmpkt . payload . messageformatmode = = cfe_evs_short_format ) { /* send an empty message if short format is enabled */ evs_pktptr - > payload . message [ <number> ] = ' \ <number> ' ; /* ( <allcaps> lsw </allcaps> ) this is pointless - - why bother to send a buffer with an empty string ? <repeated> */ } } } } it appears that someone ( <allcaps> lsw </allcaps> ? ) already noticed the strangeness here some time prior to the <number> . <number> release . the intent here may have been to send only the event id and omit the actual string , since most event id ' s have fixed strings with them . however , the length of the actual packet ( in the <allcaps> ccsds </allcaps> header ) is never adjusted , so although the first character of the message payload is overwritten with a <allcaps> nul </allcaps> , <section> so there is absolutely no benefit to doing this in the current form .",0.0
"<allcaps> evs </allcaps> "" output ports "" should be a function of the <allcaps> psp </allcaps> currently the <allcaps> evs </allcaps> has <number> "" output ports "" implemented as functions within <allcaps> evs </allcaps> : { { { evs_outputport1 ( ) , evs_outputport2 ( ) , evs_outputport3 ( ) , evs_outputport4 ( ) } } } these are all <section> to { { { os_printf ( ) } } } the premise here seems logical - - to have several different destinations that the message may be sent . but the current implementation does not allow for that to really happen . the proposal is to change this to a <allcaps> psp </allcaps> implementation : { { { cfe_psp_sendeventtoport ( uint32 portnum , const char * message ) ;}}} this single <allcaps> api </allcaps> could be used for all ports , and the <allcaps> psp </allcaps> could switch based on the "" portnum "" value if needed , or simply call { { { os_printf } } } for all messages as it does in the current code .",2.0
"clean up <allcaps> evs </allcaps> ports implementation fix a few minor issues with <allcaps> evs </allcaps> ports implementation : <number> . although a macro is used when checking bits of the "" outputport "" mask , the value is still effectively hard coded with the shift , so the macro cannot change without also breaking these checks ( violates the spirit of using the macro to begin with ) . a simplification of the conditional will allow them to change independently ( just mask and non - zero ) : <url> <url> <url> <number> . when sending to multiple ports , the ( essentially ) same snprintf ( ) is done for each one and only one digit in the string changes . would be way more efficient to construct the later half of the string once , and change the port number . the first issue should be resolved prior to integration with <allcaps> eds </allcaps> as those macros become part of the <allcaps> eds </allcaps> . therefore they should be changeable without breaking the implementation that uses them . the second issue is just a performance / size enhancement .",2.0
"cfe_sb_getmsgtime ( ) and cfe_sb_setmsgtime ( ) do not handle byte - swapping on _el platforms assuming <allcaps> ccsds </allcaps> telemetry packet secondary header timestamps should be big - endian format , on little endian platforms ( when _el is defined ) , cfe_sb_setmsgtime and cfe_sb_getmsgtime should swap bytes for proper time interpretation .",0.0
"fix startup file pathnames in cmake version of the sample configurations the cmake install currently does not create an extra / apps / subdirectory to install the files . this makes it incompatible with the current platform config file that specifies the startup file to be : { { { / cf / apps / cfe_es_startup . scr } } } with the current installation script it should simply be : { { { / cf / cfe_es_startup . scr } } } this change only affects the sample configurations , nothing in the runtime code .",0.0
"unit test stub function ut_getactualcmdcodefield not restored with <allcaps> ccsds </allcaps> secondary header ( <allcaps> gsfc dcr </allcaps> <number> ) a change was made to the format of the cfe <allcaps> ccsds </allcaps> command secondary header to enforce the header to be in big endian in cfe <number> . <number> . the cfe unit test stub function ut_getactualcmdcodefield was updated accordingly . the change to the cfe <allcaps> ccsds </allcaps> command secondary header was restored to the original definition of the header in cfe <number> . <number> . the cfe unit test stub function ut_getactualcmdcodefield however , was not restored . the original code for this function is attached .",0.0
"exiting an application creates an application with an unknown state ( <allcaps> gsfc dcr </allcaps> <number> ) es will continually send out event message # <number> - "" es_proccontrolreq : unknown state ( % d ) application %s "" , with the unknown state set to <number> , when an application exits via the cfe_es_exitapp <allcaps> api </allcaps> function call . see attached email thread for more details .",0.0
fix es unit test failures the current es unit test has a number of failures that need to be addressed . file attached showing current unit test report file with <number> failures .,0.0
"clean up massive number of warnings in sb_ut . c the { { { sb_ut . c } } } file generates hundreds of warnings in the build , mostly about incompatible types within printf - style calls . this prevents building with - werror , and also makes it really difficult to work with the file in general since eclipse marks nearly every line as a warning .",0.0
"many command processors in <allcaps> cfe </allcaps> do not confirm null - termination of strings within the message across all <allcaps> cfe </allcaps> / <allcaps> cfs </allcaps> applications , many message definitions contain strings as "" char [ ] "" arrays . however , very few <allcaps> cfe </allcaps> command processors confirm that these strings are actually null terminated within the allotted length before passing them to other <allcaps> cfe </allcaps> functions and / or c library functions such as "" strcmp "" , "" strlen "" , etc . the <allcaps> cfe </allcaps> architecture needs to clearly define the rules here and also be consistent when following them .",0.0
"pre - cmake fallback build script needs updating . provision was made in the build system for building with either the classical build tree ( tools / gsfc_build ) or the modern cmake based system . mainly this was put in place back when cmake was coming on line , and has not been used or maintained since the cmake support became part of the baseline "" development "" tree . this facility was recently activated by the <allcaps> hotfix </allcaps> <number> . <number> integration candidate , and could use some attention . we should also consider activating the bamboo job that applies the pre - cmake build script to post - cmake branches , if we want to make sure that the classical build keeps working in parallel with the cmake build . or not , if we want to be more aggressive about pushing people forward into the brave new world of better build systems . <repeated> yeah , a <allcaps> ccb </allcaps> decision .",0.0
"file operations in cfe_es_shelloutputcommand ( ) need cleanup this function can be simplified and also made more robust . * does unnecessary copying of the input parameters . * does <allcaps> not </allcaps> always ensure proper null termination of the inputs . ( copying strings could be justified if it was to ensure null termination of the inputs ) . the "" cfe_es_shellcmd "" function that is calling this should ensure null termination but it does not . * matching of the "" es "" special commands needs improvement - it will not run any os command that happens to start with "" es_ "" , and it will also not handle it correctly if one happens to be a substring of another but not a complete match . * it does not check the return codes from either "" os_read "" or "" os_write "" calls and assumes they all work perfectly - the correct operation of this function , in fact , does depend on them all working perfectly . in the worst - case scenario , a benign failure of an os_write ( ) call could have a cascade effect causing a later os_read ( ) call to block indefinitely . * the return value of os_lseek ( ) is not properly checked . it also relies on having an os implementation of lseek that can accurately "" measure "" the size of the file . not all filesystems / file types are seekable in this nature . * it will not work with any "" special "" file or file system that does not support seeking or read / write file handles ( such as a pipe ) . * it unnecessarily extends the file on disk to add up to <number> extra spaces , which is only to coax the message generator loop into producing an extra message . * overall , the loop that is generating the telemetry messages can be simplified quite a bit . * the fixed 2 0 0 ms delay between messages should at least be configurable , but there is still no way to tell if buffer overflow is occurring * there is no sequence number , and way to tell at the receiving side of one intermediate component message was lost . ( possibly outside the scope of this , and no way to really fix this without changing the binary format of the messages ) .",0.0
"cfe_time fails to build with cfe_time_cfg_src_met set to <allcaps> true </allcaps> this issue was introduced by # <number> - some structure accesses hiding behind this conditional compile needs to have "" . payload "" added to them . as a separate enhancement , the bamboo tests should be updated to build using this configuration , along with the many other <allcaps> time </allcaps> options available .",0.0
"buffer overrun in stub implementation of cfe_time_print for unit testing an alternate "" stub "" implementation of cfe_time_print exists in unit - tests / ut_time_stubs . c the cfe_time_print ( ) function outputs the passed - in time value to a small fixed - size buffer . the ut stub version of this function uses the wrong size for its call to snprintf and is way too wordy in its output , easily overrunning the real size of the buffer . this is one thing causing unit tests to crash in <number> . <number>",0.0
"extend cmake app search path when apps are listed in the targets . cmake file , the cmake scripts already implements a dynamic search path to find matching entities in the source tree . right now the users typically add their own apps to the "" apps "" directory which become intermixed with the official <allcaps> cfs </allcaps> applications . while this is ok , this does present a challenge to a git novice - - if they cloned the babelfish repositories directly , then a simple ( default ) { { { git push } } } command may inadventently send all their private apps up to babelfish . ideally , the mission should at least create their own branch , or better yet , create their own vc repository and not / / directly / / use babelfish git clones ( such as the "" subtree "" method documented in the wiki ) , but this is unfortunately not the path of least resistance . by adding some extra names into the default app search path , the project - specific apps can be placed outside the official "" apps "" tree . this way , the apps repository remains "" pristine "" and unmodified , and an errant { { { git push } } } will do no harm .",2.0
"cmake support for elf2cfetbl usage the current cmake support structure does not include support for the old style <allcaps> cfe </allcaps> tables - - that is , where the table is embodied in a source file within the application , which is compiled with the application headers ( as well as headers from <allcaps> cfe </allcaps> , <allcaps> osal </allcaps> , and so on ) , and which is then converted from the <allcaps> elf </allcaps> object file format into a <allcaps> tbl </allcaps> file . asking each project that wants to convert to cmake to independently work out how to get the files compiled then converted is asking for a significant duplication of effort - - as this turns out to be something more than a couple easy lines of make scripting . it is more reasonable for us to work it out once , and provide a solution that projects can use ( or adapt ) as desired .",2.0
"<allcaps> cfe time </allcaps> fails to build when cfe_time_cfg_signal set to <allcaps> true </allcaps> the cfe_time_cfg_signal configuration macro will add calls to a function { { { os_selecttone ( ) } } } if it is set to <allcaps> true </allcaps> . however , os_selecttone is neither prototyped nor implemented in any released version of <allcaps> cfe </allcaps> or <allcaps> osal </allcaps> , as far as i can tell . it does not seem to be documented anywhere what this is supposed to do . it is currently not possible to build <allcaps> cfe </allcaps> with this configuration set to <allcaps> true </allcaps> due to this problem . calling this a minor defect for now , as it only appears when using this configuration option .",0.0
application startup race conditions ( <allcaps> gsfc dcr </allcaps> <number> ) applications will fail to start when they are started via the es start application command ( cfe_es_start_app_cc ) and the es application has a lower priority than the application being started by the command . this issue will also occur if the os startup code is a lower priority than the applications that are being started in the startup script .,0.0
"cfe_es_processcoreexception ( ) is not interrupt - safe the cfe_es_processcoreexception ( ) architecture needs to be re - examined . this is the equivalent of an interrupt handler and likely triggered as the result of a hardware interrupt . however the implementation calls other cfe_es functions , some of which take the global data mutex ( cfe_es_lockshareddata ) , do console output ( cfe_es_writetosyslog and other functions which ultimately do printf ) , or call os_taskdelay . all of these operations are unsafe to do in an interrupt context on most platforms . this may not be an issue if the end - result of the exception is a processor reset , which is probably the only safe thing to do . although the option to restart the task does exist , the system may be too far gone after this .",0.0
"<allcaps> smp </allcaps> : cfe_es_writetosyslog ( ) is not multi - thread safe the cfe_es_writetosyslog ( ) function is called from many places across <allcaps> cfe </allcaps> and many different threads ( upwards of ~ <number> references to this function throughout <allcaps> cfe </allcaps> and <allcaps> cfs </allcaps> ) . internally this uses the shared "" reset area "" pointed to by cfe_es_resetdataptr and makes multiple references to the "" systemlogindex "" and "" systemlogentrynum "" in the reset area . however , the read / modify / update sequence of these members is not protected by any sort of mutex .",0.0
"<allcaps> smp </allcaps> : <allcaps> cfe time </allcaps> uses <allcaps> osal </allcaps> intlock / intunlock for mutual exclusion interrupt locking simply prevents incoming interrupts ; is not a mutual exclusion mechanism and will __not__ achieve "" exclusive access "" on all types of processors . mutual exclusion is more of a side - effect that occurs on a single - core processor that uses a timer interrupt to perform task switching duties . on a multi - core processor , this will not work . furthermore , in the <allcaps> posix osal </allcaps> , intlock / unlock are no - ops , and interrupt control is a kernel - level function and not something that user space tasks can do ( even as root ) . this should be replaced with a mutex , as this is what the code is really trying to do .",0.0
"race conditions / dependencies between <allcaps> cfe </allcaps> core apps the "" core "" applications have significant dependencies between them that need to be more pro - actively satisfied . there are some race conditions during the startup phase that can pose some serious problems if things are not executed in the right order . the summary of what happened is below , but here is a list of the basic problems : * start up code should synchronize at least the "" core "" applications and ensure that each one has reached it ' s respective "" runloop "" before starting the next one , regardless of what the platform config sets the priority to ( likely depends on # <number> ) . * evs_isfiltered should range check before doing the table lookups based on passed - in values * <allcaps> cfe sb </allcaps> and <allcaps> evs </allcaps> ( at least ) populate different values into their own "" appid "" global variable before initialization . sb does nothing ( <number> by default , which is in fact a valid appid for a different app ) but <allcaps> evs </allcaps> initializes this to 0 xfffffffff , which has very ill - effects if actually used for something , and nothing really checks for this . for those interested , here are the details of the specific sequence of events discovered when debugging application startup on the microblaze processor used by the <allcaps> eva </allcaps> team at <allcaps> grc </allcaps> : <number> . as dictated by the table within "" cfe_es_objtab . c "" , the <allcaps> cfe </allcaps> core applications are started ( tasks created ) in the order of <allcaps> evs </allcaps> , sb , es , <allcaps> time </allcaps> , bl . <number> . in the default / example platform configuration , these have respective priorities of <number> ( <allcaps> evs </allcaps> ) , <number> ( sb ) , <number> ( es ) , <number> ( <allcaps> time </allcaps> ) , and <number> ( <allcaps> tbl </allcaps> ) . <number> . <allcaps> time </allcaps> task will run it ' s taskmain first even though it is 4 th in the start sequence . <number> . as part of this init sequence , it calls cfe_sb_createpipe ( ) which in turn calls cfe_evs_sendeventwithappid ( ) in several places ( for errors as well as an unconditional "" debug event "" at the end ) . the appid supplied is "" cfe_sb . appid "" which is uninitialized since sb has not executed yet . in this case the value used is actually <number> . <number> . in turn this eventually calls evs_notregistered ( ) ( since cfe_evs_taskinit has not run ) and then evs_sendevent ( ) as part of that . <number> . evs_sendevent ( ) calls evs_isfiltered ( ) with the contents of cfe_evs_globaldata . evs_appid , which is also uninitialized but set to "" 0 xffffffff "" , not zero like cfe_sb . appid . <number> . this appid value is not range - checked by evs_isfiltered and ultimately segfaults and crashes <allcaps> cfe </allcaps> core .",0.0
"race condition within cfe_es_appcreate when starting an application , <allcaps> cfe es </allcaps> calls "" cfe_es_unlockshareddata ( ) "" before os_taskcreate ( ) , then calls cfe_es_lockshareddata ( ) again to perform several more updates to the global table after the task id is obtained . this unlock - relock opens up an opportunity for the child thread to read the shared table data before it is fully populated . this can cause many problems . one specific one is that cfe_es_getappid ( ) ( which many tasks call very early in their init procedures ) will fail , which can have a serious snowball effect . note that the initial core app creation ( cfe_es_createobjects ) and child tasks ( cfe_es_createchildtask ) keeps the global lock for the entire procedure , so these are safe .",0.0
"<allcaps> cfe es </allcaps> "" startupsyncsemaphore "" subject to multiple race conditions the "" startup sync "" mechanisms are based on a binary semaphore , a boolean flag , and a counter . the handling of these various separate entities leaves several opportunities for race conditions to occur . at a minimum , this could cause "" waitforstarupsync "" to pend incorrectly , but could have other more serious side effects ( unknown ) depending on how the apps are using this . this is one problem that the <allcaps> eva </allcaps> team at <allcaps> grc </allcaps> are experiencing while deploying <allcaps> cfs </allcaps> on the xilinx microblaze platform .",0.0
enforce strict <allcaps> ascii </allcaps> replace all non - <allcaps> ascii </allcaps> characters ( i . e . copyright symbol ) with <allcaps> ascii </allcaps> equivalent .,0.0
update cfe_fs_initheader to to handle error / invalid length conditions the cfe_fs_initheader <allcaps> api </allcaps> function should perform checks on the header information being passed into the function and return an appropriate error code . see ticket # <number> for additional details . cfe services that make calls to this <allcaps> api </allcaps> should be updated to handle the error code .,2.0
"ut_sb_stubs broken by packet layout change the structure defining the message layout changed , placing the message content in a separate structure , requiring current code that was "" pointer - > field "" to be adjustd to read "" pointer - > packet . field "" this change must be applied to code in <code> that is only compiled when <code> is defined . the automatic test system used to check out <allcaps> cfe </allcaps> builds defines <code> in order to collect supporting evidence useful for debugging any failures or errors encountered during testing .",0.0
"update cfe unit tests the version of the unit tests currently included with cfe <number> . <number> were developed and tested against cfe <number> . <number> . due to cfe changes , all of the tests no longer pass . also , the tests have only been tested with the linux <allcaps> osal </allcaps> / pc - linux <allcaps> psp </allcaps> and arinc653 <allcaps> osal </allcaps> / orionscp <allcaps> psp </allcaps> . <allcaps> jsc </allcaps> has updated the tests to work fully with cfe <number> . <number> . <allcaps> jsc </allcaps> is also updating the tests to build and run on vxworks <number> ( on the <allcaps> sparc </allcaps> leon3 processor ) . these updates are being tracked in the <allcaps> jsc </allcaps> subversion repo and need to be pushed into a proper git branch and further work continued from there .",0.0
"fix "" no return "" warning on cfe_sb_readqueue ( ) function this is not a "" real "" warning , but it is flagged by static code analysis in eclipse that the cfe_sb_readqueue ( ) function has no return statement . although there is no real code path that will / / not / / get to a return statement , static code analysis does not see that . a trivial fix to consolidate the scattered return ' s into a single return at the end will get rid of this warning and make the code more readable .",0.0
"unit test stubs need to be kept in sync with their respective real implementations the "" unit - test "" code implements stub functions for all function calls which are / / not / / under test . in addition to stubs for the <number> core <allcaps> cfe </allcaps> functions , there are two other stub files : * ut_bsp_stubs . c * ut_osapi_stubs . c the difficulty here is that both the <allcaps> api </allcaps> / prototype of all the functions as well as the real implementation of those functions come from an external source , specifically the <allcaps> psp </allcaps> library and the <allcaps> osal </allcaps> library . if either the <allcaps> osal </allcaps> or <allcaps> psp </allcaps> changes , the corresponding change must be made to the <allcaps> cfe </allcaps> stub files to keep them in sync . futhermore , if another project tries to use the updated stub files with an older version of <allcaps> osal </allcaps> , the build will now break due to the mismatched definitions . it would be nice to simply make a rule that a defined <allcaps> api </allcaps> is never going to change , but that is not practical . __solution 1 __ utilize a preprocessor macro to "" tune "" the function definitions in the stub files to match what the <allcaps> osal </allcaps> / <allcaps> psp </allcaps> should be for that particular version advantages : can be implemented right away without any synchronized change to <allcaps> osal </allcaps> / <allcaps> psp </allcaps> libs . disadvantages : does not scale . code can get pretty messy with lots of <hashtag> if def </hashtag> ' s if it changes more than once . still requires <allcaps> cfe </allcaps> to "" know "" the <allcaps> osal </allcaps> / <allcaps> psp </allcaps> prototypes so breaks the independence of the two libraries . __solution 2 __ move the stub implementation to the same component that provides the real implementation . for this , the ut_bsp_stubs . c file would be relocated to the <allcaps> psp </allcaps> library and the ut_osapi_stubs . c file would be relocated to the <allcaps> osal </allcaps> library . the <allcaps> psp </allcaps> and <allcaps> osal </allcaps> builds would provide a separate ut stub product ( a library ) that the <allcaps> cfe </allcaps> unit test could link with . advantages : arguably a more logical place for the stub code . reduces need for synchronized changes in the future , better forward / backward compatibility between versions . also , other ( non - <allcaps> cfe </allcaps> ) users of <allcaps> osal </allcaps> library could also use stub functions . disadvantages : requires a synchronized change to get started ( solution <number> could help here ) . also would only work using cmake makefiles , although the <allcaps> gnu </allcaps> makefiles could probably be updated accordingly as well .",0.0
fix duplicate structure definitions in table unit test similar to trac # <number> for the mempool structures - - the dispatch table structure definitions are duplicated in the cfe_tbl_task . c and tbl_ut . h . the tests will break if these diverge . a more suitable place for these would be in cfe_tbl_task_cmds . h so the same definitions can be included in both places without duplication .,0.0
"ensure that return codes from <allcaps> psp </allcaps> functions are checked in some circumstances the return code from <allcaps> psp </allcaps> functions ( e . g . cfe_psp_getresetarea ) is either not checked or incorrectly checked . wherever the return code is checked , instead of specifically checking for an error code like so : { { { if ( status = = cfe_psp_error ) { < handle error > } } } } the code should check for non - success instead : { { { if ( status ! = cfe_psp_success ) { < handle error > } } } } this will make it more future - proof to <allcaps> psp </allcaps> implementations that might return more specific errors .",2.0
"pointer arguments to functions that are input only should be declared "" const "" marking the pointer parameter as "" const "" , particularly for string arguments , allows them to be called using string literals or other data that is already constant . this may make a substantial difference on some targets where the executable can actually be linked to put the read - only data section in <allcaps> rom </allcaps> rather than <allcaps> ram </allcaps> . however , in order to do this properly / safely the code must treat this as read - only data . by declaring it "" const "" the compiler will flag any writes to it . changing the prototypes should not affect current usage .",2.0
clean up unused local variables compiling with - wall complains about unused local variables in some functions . this will cause the build to fail if - werror is also used . this change is a prerequisite to turning on strict compiler settings in the default build .,0.0
"fix type mismatches and remove unnecessary typecasting this ticket is to fix up areas of the code that have type mismatches or other unnecessary typecasting . * in some areas , the standard "" int "" type is used when it should be the <allcaps> osal </allcaps> int32 / uint32 type . * in other areas , values are cast to certain types when it is not necessary to do so because the compiler will automatically do the right thing . in the latter case , the type cast should be removed , because in certain situations it can actually interfere with the compiler doing the right thing and make it do the / / wrong / / thing instead . an example of this is casting to "" int "" with operands that are actually unsigned types and / or different widths . in the case that the forced "" int "" is a negative value , a sign extension might be performed and this might produce an unexpected result . in general , a cast should only be used when there is a good reason why the compiler ' s default conversion rules are not sufficient .",0.0
"consolidate <allcaps> cds </allcaps> and generic / ram mempool code into single implementation currently there are two memory pool implementations in es : * cfe_es_cds_mempool . c * cfe_esmempool . c these two are very similar except that the <allcaps> cds </allcaps> uses offsets rather than direct pointers , and it calls into the <allcaps> psp </allcaps> to perform actual read / write functions . it would not be very hard to consolidate these into a single implementation . each implementation consumes about <number> - 5 kb of code / data space so this consolidation would make es a little smaller in addition to making it cleaner .",2.0
"fix duplicate mempool structure definitions in unit test code the unit test code uses its own ( re - ) definitions of the memory pool management structures . specifically , these structure definitions are duplicated : * cfe_es_cdsblockdesc_t * cfe_es_cdsblocksizedesc_t * cfe_es_cdspool_t * bd _t * blocksizedesc_t * pool_t these should not be redefined here . if these ever diverge from the definitions that <allcaps> cfe es </allcaps> uses , the tests will break . the definitions should be moved to a header file and <hashtag> include </hashtag> ' ed in both places to ensure that the same definitions are always used .",0.0
"code in <allcaps> cfe time </allcaps> fails to compile with strict compiler settings when strict compiler flags are used , there are several instances of unused variables in <allcaps> cfe time </allcaps> . these are related to the configuration options ( e . g . cfe_time_cfg_default_tai ) where under some configurations a variable is declared and / or set but not actually used . the preprocessor macros need to be adjusted such that the variable is not declared unless it is used .",0.0
"error constants defined in "" cfe_error . h "" incorrectly use the "" l "" suffix the "" l "" suffix on an integer literal tells the compiler that it is supposed to be interpreted as a "" long "" type . however , <allcaps> cfe </allcaps> error constants are supposed to be <number> - bit signed integers , which may or may not be the same thing as the system native "" long "" type . to be correct , the constants should be defined to be the same as the "" int32 "" <allcaps> osal </allcaps> type and the "" l "" suffix should be removed . this causes problems on a <number> - bit machine where the "" long "" type is <number> bits .",0.0
"data pointer argument to cfe_es_calculatecrc ( ) should be const since cfe_es_calculatecrc ( ) does not modify the data passed into it , the pointer should be declared "" const "" in the prototype . this will not affect any existing usage of the function , but it will allow usage in areas where the data is already "" const "" .",0.0
"stack pointer parameter to cfe_es_createchildtask should not be marked "" const "" by definition , a task ' s stack memory must be writeable . the stack pointer parameter to cfe_es_createchildtask ( ) is qualified as "" const "" . although this matches <allcaps> osal </allcaps> ' s task <allcaps> api </allcaps> , <allcaps> osal </allcaps> is wrong too and should be fixed . see : [ <url> this ticket should be merged into <allcaps> cfe </allcaps> <section> the <allcaps> osal </allcaps> ticket is fixed . this change will not affect compatibility with prior versions of <allcaps> osal </allcaps> because it is ok to pass a non - const pointer for a const parameter ( but vice - versa is an error ) .",0.0
"fix inclusion of <allcaps> psp </allcaps> private header files in <allcaps> cfe </allcaps> layer certain files are directly <hashtag> include </hashtag> ' ed from the <allcaps> psp </allcaps> library in the <allcaps> cfe </allcaps> code . only the "" public "" <allcaps> psp api </allcaps> defined in "" psp / fsw / inc "" should be directly used by application code . other files such as those under an architecture - specific <allcaps> psp </allcaps> ( e . g . psp / fsw / pc - linux / inc ) should be treated as private data to that particular <allcaps> psp </allcaps> and <allcaps> not </allcaps> be used or called directly from the application . if some value is necessary then a public <allcaps> api </allcaps> should be defined to retrieve it , rather than <hashtag> including </hashtag> it directly . fixing this up will make the build cleaner and more efficient . it will also ensure that application code is portable to __all__ <allcaps> psp </allcaps> ' s because it does not depend on some value that only one particular <allcaps> psp </allcaps> provides . note there is a corresponding ticket in the <allcaps> psp </allcaps> to stop using <allcaps> cfe </allcaps> headers as well : [ <url> when both of these tickets are merged in the incremental build process becomes much cleaner and faster .",0.0
"modify code that reads or writes memory addresses in external messages to use wapper in the current version , some external interface ( command / telemetry ) messages contain direct <allcaps> cpu </allcaps> memory addresses . this can be very bad for several reasons : * memory addresses can be a different size on different cpus * since memory addresses are likely to change from run to run ( even in the same build ) it makes it difficult to script tests * the receiver has no way to validate it ( other than <allcaps> null </allcaps> ) . * if the address value ever gets corrupted or an invalid value is used , the consequence is usually dire ( a crash ) . ultimately the use of direct memory addresses in messages should be avoided . as a first step to this , this ticket will modify those locations that a memory address is read or written from an external message to use a wrapper function . this ticket will not change any functionality in itself , but it will provide a path going forward such that the wrapper function can be modified to convert the address to / from a safe , verifiable , architecture independent value rather than using the address directly .",2.0
"remove cfe_es_devsrvr code cfe_es_devsrvr . c and . h appear to be stale / obsolete and not being called or referenced by anything else in cfe . furthermore , it should be deprecated anyway since device - support code logically fits better within the <allcaps> psp </allcaps> . at the cfe layer it should be all hardware - independent code . if this is correct , these two files should be removed from the build .",0.0
"<allcaps> smp </allcaps> : cfe_time_getreference ( ) has insufficient protection against update while reading in the current implementation , cfe_time_getreference ( ) uses a lockless version counter that is checked before and after reading the reference time to determine if the time got updated while it is being read . however , this protection is insufficient for some systems : * the global needs to be marked "" volatile "" for this to have any effect . if compiled with optimizations , the optimizer is likely to remove the "" redundant "" read of the global value therefore defeating the purpose of the loop altogether . * it does not protect against the reader interrupting the writer and receiving a "" half - updated "" value . running the updater at higher priority does not work on multi - core cpus since the two threads can be concurrently running .",0.0
"cfe_time_gettime ( ) should not return a structure in general it is not a good idea to return a structure from a function because compilers do not all perform this the same way . some compilers / abis are reasonably efficient at this ( as gcc seems to be ) , but others are not so efficient and will do extra copies of the structure .",2.0
"display extended version information from the build the <allcaps> cfe </allcaps> build currently contains a <number> - part version number , i . e . "" <number> . <number> "" . this version number is is <hashtag> define </hashtag> ' d in a header file and is manually updated with each official release . however , git and cmake ( see ticket # <number> ) offer additional build information where the current git commitid and most recent tag name are built into a global object that is accessible at runtime . when it is available , this extended build information should be displayed along with the manually updated official version number . the major benefit here is that it updates automatically with __every__ commit , not just official releases . it also indicates the whether the source code tree has been modified from the pristine version in the commit ( "" dirty "" ) or not . it is extremely useful to have this information built into the executable in order to verify the correct binary is loaded as well as being able to reproduce running binaries when needed .",2.0
"external <allcaps> cfe </allcaps> message definitions should not depend on values from cfe_platform_cfg . h or osconfig . h some structure definitions that define specific ground commands and telemetry messages use array sizes for strings that are either defined in osconfig . h ( e . g . os_max_path_len ) or cfe_platform_cfg . h ( e . g . cfe_es_max_applications ) . however , by definition , these header files contain parameters that are tunable to the specific <allcaps> cpu </allcaps> . for instance , a resource - constrained <allcaps> cpu </allcaps> may need to reduce cfe_es_max_applications to a small number to save memory . it is therefore problematic to use these values to define messages that serve as a data definition across processors , particularly in a multi - board setup . external message definitions must be limited to <section> configuration parameters only , such as cfe_mission_cfg . h , where all cpus as well as the ground system will have the same values .",0.0
"<allcaps> cfe </allcaps> enumeration names in order to reduce the chance of name space conflicts , enumerated names should follow the general form , with the value prefixed by the group name and the app name : < <allcaps> appname </allcaps> >_< <allcaps> groupname </allcaps> > _ <valueid_1> < <allcaps> appname </allcaps> >_< <allcaps> groupname </allcaps> > _ <valueid_2> . <repeated> < <allcaps> appname </allcaps> >_< <allcaps> groupname </allcaps> > _ <valueid_n> this ensures that even if two enums use the same value name ( s ) they will not conflict with each other . most <hashtag> define </hashtag> ' d values already follow this general form , but there are some exceptions . these should be fixed to be consistent .",0.0
<allcaps> cfe es </allcaps> makes assumptions about <allcaps> osal </allcaps> opaque objects <allcaps> osal </allcaps> returns object identifiers which are defined as uint32 values . in the current implementation of <allcaps> osal </allcaps> they happen to be zero - based but this should not be a requirement ; in fact there are several advantages to making these identifiers non - zero - based . the primary offender is the es core application using the task id from <allcaps> osal </allcaps> directly as an array index . to ensure compatibility the <allcaps> osal </allcaps> object ids should be treated as opaque integers of undefined range .,0.0
"add "" const "" to function prototypes where appropriate in particular , this should be done at least for functions that accept char * strings but do not modify them . if a string literal ( by definition a const char <wink> is passed into function argument that is declared a non - const char * , a compiler warning may be generated and the build will fail if compiled with strict settings . this ticket will add "" const "" to function parameters where appropriate .",0.0
"clean up "" extern "" declarations at the top of c files in the <allcaps> cfe </allcaps> core apps , many files reference functions and data structures defined in other files . however , the function prototypes or "" extern "" declarations are not in common header files , but simply put at the top of the c file that uses it . while this does build , it defeats the type checking done by the compiler . it is far from ideal because if the real variable type or function prototype ever changes , the linker will still happily link it together even though they might be completely incompatible ( or worse , incompatible in a really subtle way ) . the only reason to <allcaps> not </allcaps> put a declaration in a header file is if it should not be called or referenced by <allcaps> cfs </allcaps> apps , but this can be solved by creating a private <allcaps> cfe </allcaps> core shared header file .",0.0
"fix use of uint32 to store a memory address in many places a uint32 is used to store a memory address which breaks horribly on <number> - bit architectures . the new version of <allcaps> osal </allcaps> "" common_types . h "" introduced a "" cpuaddr "" type to address this - - it is defined as an integer type large enough to store a memory address on the local processor . this ticket is to replace all uses of a uint32 to store a memory address with the cpuaddr type for better portability . this is a requirement for a native <number> - bit build to work .",0.0
implement initheader call in <allcaps> cfe fs </allcaps> all <allcaps> cfe </allcaps> apps that write a file should prefix that file with a header object defined in fs . currently they do so on - the - fly by simply memset ( ) ' ing the structure to zero and setting a key field . this should be cleaned up and moved to an initheader ( ) call in <allcaps> cfe fs </allcaps> such that if fields need to be added to the header in the future this can be done without having to touch many different places where the header is initialized / written .,2.0
reentrant version of decompress routine in <allcaps> cfe fs </allcaps> the fs application has a feature where it can decompress file content on the fly . however the decompression routine keeps its internal state in global variables which makes it non - reentrant . to protect against concurrent usage a mutex is used but this has a major performance impact . the global variables should be replaced with a state structure so that it can be multithreaded like all other parts of <allcaps> cfs </allcaps> . for the time being a global state object can be implemented in order to preserve <allcaps> api </allcaps> compatibility .,2.0
"split message definitions from headers all of the cfs messages are currently defined in c structures . as a first step toward moving to "" electronic data sheets "" to describe the external data format , these need to be slightly modified to better separate the header portion of the structure from the payload portion of the structure . currently , message structures are typically defined by reserving a block of space for the header as a uint8 array of size cfe_sb_cmd_hdr_size or cfe_sb_tlm_hdr_size . this approach has several issues : * using a fixed - size block assumes only a single type of encapsulation ( <allcaps> ccsds </allcaps> ) will ever occur . this may not be the case , as other non - <allcaps> ccsds </allcaps> encapsulations may be a requirement for some missions . * the fixed size block is not guaranteed to be properly aligned for a <allcaps> ccsds </allcaps> header . since it is declared as a uint8 array , the compiler will not ensure any alignment this structure . it is technically not valid to cast this as a <allcaps> ccsds </allcaps> header since that contains uint16 ' s . * this is unlikely to be compatible with electronic data sheets ( <allcaps> eds </allcaps> ) no matter what specific implementation is used . since the definition of the message content ( payload ) and the message header ( <allcaps> ccsds </allcaps> or other format ) will come from different data sheets , it becomes very problematic to have them mixed together like this . to solve this problem requires a bit of restructuring : instead of declaring the format of the payload directly within the message structure , declare a separate "" payload "" structure and define it in there . this adds one extra layer to the structure tree but will improve flexibility going forward , and it will <section> change the external data format , so compatibility with ground systems is unaffected . it only affects the syntax of code accessing members of the payload structure .",2.0
document applications in trac wiki it would be helpful to construct a small wiki page corresponding to each application in cfe giving a quick overview of each . i suggest including hotlinks on each such page back into the doc subtree of the specific app for extended documentation - - as clones will obtain the content of the project sources but do not clone the trac wiki .,0.0
"compiler errors / warnings on evs_sendevent ( ) calls on some architectures one roadblock to turning on strict compiler settings ( such as - werror ) with full error checking is that <allcaps> many </allcaps> compiler warnings are generated by printf error checking done by gcc . the full error checking is <section> because it verifies that the argument corresponding to each escape code is the right type , e . g . %s has a string , % d has an integer , etc . the problem is that we are using the <allcaps> osal </allcaps> abstractions such as int32 or uint32 . for example , on some systems , printf ' ing an int32 needs a "" % d "" and on other systems it needs a "" % ld "" depending on whether it was typedef ' ed as an int or a long . so fixing an error on one platform by changing the escape code in the format string only generates an error on a different platform . in order to fix this so that it builds without warnings on all platforms , any argument that ultimately gets passed to any c library printf ( ) call needs to be cast to the right fundamental c type , not the abstracted type , at the call to the variadic function . note this is really only an issue for variable argument functions since for normal functions the correct type is known and the compiler automatically casts it when possible . but for variadic c library functions this is not possible so we must explicitly ensure that the argument gets converted to the correct type / / for the c library / / . <allcaps> gcc </allcaps> is nice enough to implement warnings for this when it is mismatched , we should leverage that .",0.0
"enhanced build system for cfs the alternate build system uses cmake and offers several enhancements : * completely isolated build tree - no mixing of source files and generated files * dynamic application search path , supports "" app - store "" concept by keeping app repos separate from cfs repos . * supports multiple different build configurations from the same source tree * includes mechanisms for electronic data sheets ( data dictionary ) support and lua functional testing support in the future",2.0
"use appropriate atomic type for inter - thread sync the rv tool analysis reported several cases of reading / writing shared memory variables without a lock . the intention behind the code was that the data type being read / written simultaneously here was atomic in nature , thus the parallel access would be safe , as it is not possible to catch an atomic value mid - update . to be more portable the code should use the c99 type <code> to ensure that the data type is in fact atomic on the given platform . currently it is using <code> which is not guaranteed to be atomic on all platforms . calling this "" minor "" because the <code> type will be atomic on all the platforms that the code in question is actually used on . there is no bug currently here , this is just to prevent a future bug if this code is expanded to smaller cpus ( microcontrollers ) where <code> is not atomic .",0.0
"clear <allcaps> bss </allcaps> on app restart under normal conditions , when a task is started , the process of loading the task will clear the <allcaps> bss </allcaps> segment ( used to store global - scope variables that are not explicitly initialized ) . however , if a task is "" restarted "" without "" reloading "" it may find that its <allcaps> bss </allcaps> segment still retains the content from the prior run . we discussed this at the <allcaps> ccb </allcaps> meeting on <number> - jan - <number> , and the moderate concensus was that it might be most useful for the <allcaps> bsp </allcaps> to explicitly clear the <allcaps> bss </allcaps> of tasks before they are started . according to my notes , joe was going to take a look at this .",0.0
"<allcaps> api </allcaps> for querying libraries ( like <allcaps> cfe es </allcaps> queryapp ) <section> unable to verify library image integrity ( cs cannot scrub library code space ) <section> implement <allcaps> api </allcaps> for querying library information , such that an app could scrub <section> none <section> none <section> jacob hageman / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps> external request from cfs - community email list on <date>",2.0
timstamp all cfe generated sb messages <section> sb subscription report message is not timestampted : <url> <section> timestamp should be added here and anywhere else it ' s missing for all cfs generated sb messages : <code> <section> none <section> none <section> jacob hageman / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps> originated from <allcaps> pace </allcaps> / <allcaps> oci </allcaps>,2.0
"sample makefile should use strict compiler flags and treat warnings as errors <section> the default makefiles / cmake scripts do not enforce any strict compiler warning flags and do not treat warnings as errors . this means issues like # <number> can more easily slip past . <section> building the <code> branch as a "" release "" ( - o3 ) using the default settings / sample config / makefile wrapper by preparing as : <code> then run make and you do get some warnings , at least when using gcc <number> . x and above : <code> however , the build continues and completes the process with no error results . <section> the build should stop , because warnings are problems that need to be resolved . if the build does not stop then it is very easy to not notice these issues . <section> ubuntu <number> ( <number> - bit ) , kernel <number> . <number> - <number> - generic , gcc <number> . <number> <section> joseph hickey , vantage systems , inc .",2.0
"about the <allcaps> psp </allcaps> mak file hi i am very new for write . mak file . i checked gcc ( <number> . <number> ) manual , found some symbols such as - wall , - m32 , but did not find __ix86__ . could you tell me how can i find this ? which manual should i reference to ? i want to make psp and osal for raspberry or freertos ! thanks sincerely",3.0
"did you close the forum hi , did you close the forum or did we need an authorization to access ? thanks",3.0
"could not copy app . so to / cpu1 / exe / cf / apps hi when i delete all app . so in this fold , then i make clean , make config and make again , there are not any app . so in this fold ? is this right ? thanks ! sincerely",3.0
"could not find the directory . <repeated> / cfe / inc in each app directory , such as sample_app / fsw / for_build / makefile , there is "" - i . <repeated> / cfe / inc "" , but i could find this sub directory in cfe / build / cpu1 / cfe , where i can get sample_app int the directory / cfe / build / cpu1 . thanks ! sincerely",3.0
<allcaps> posix </allcaps> : your queue depth may be too large update documentation to show posix fix : edit / etc / sysctl . conf and add the lines : <code> # # or edit as root <code> is set to <number> or some value appropriate . <code>,2.0
"compiling for raspberry pi would like to run on my <allcaps> arm </allcaps> based raspberry pi , the instructions do not seem to detail a means of building for different arch . thanks",3.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"remove explicit file name references in doxygen file comments to avoid warnings <section> file comment without a filename implies the comments apply to the current file . adding the file name makes doxygen try to match that file . the issue is there ' s multiple files with the same name , so doxygen gets confused unless you add full path . really it ' s just overhead since the point is to comment the current file . sample warning if you <code> from the bundle : ` ` <code> os - impl - binsem . c ' supplied as the second argument in the \ file statement matches the following input files : / home / jhageman / cfs / cfs - github / osal / src / os / posix / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / rtems / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / vxworks / src / os - impl - binsem . c please use a more specific name by including a ( larger ) part of the path ! ` ` ` <section> easiest to just remove the name since for every case the comment applies to the current file <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the tblcrctool repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the tblcrctool repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for elf2cfetbl under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing elf2cfetbl undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / tblcrctool is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / tblcrctool while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"report error and use exit ( <number> ) for errors and exit ( <number> ) for success <section> reporting same exit code for error and success , does not include error information ( strerror ) general pattern supports scripting / failure reporting . <section> exit ( <number> ) for success , exit ( <number> ) for errors , use strerror when reporting for all error cases <section> none <section> # <number> discussion <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"check for and report lseek failures <section> lseek errors not checked : <url> <section> should explicitly report if lseek fails , could indicate a file shorter than the fs header length ( very useful to know ! ) <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
read failures are not handled <section> there ' s a coercion alters value static analysis warning on for readsize : <url> <section> handle an error from read <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for tblcrctool . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"report version and add include build name and build number <section> need a better way to describe versions during development . currently the tool does not report its version when compiled . <section> create a version file ( see # <number> ) and use the template in sample_app and other "" version . h "" files throughout the framework . <section> none <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"remove references to <allcaps> lro </allcaps> <section> need to clean up multiple references to <allcaps> lro </allcaps> heritage in source code <section> see source code ; ctrl - f lro shouls find multile occurences . <section> no references to specific missions . <section> <code> <section> source code <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",0.0
"fix input options handling dashes <section> the "" help "" option is triggered by <code> which only uses one dash . full - word options should use double dashes . <section> see code <code> <section> use <code> instead <section> if applicable , add references to the software . <section> source code <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , apply standard code style <section> whitespace changes only . fix # <number> <section> ci - <allcaps> tbd </allcaps> <section> none <section> - hardware : ci - os : ubuntu <number> - versions : bundle w / all whitespace change commits <section> note - not enforcing , just a single cleanup since there ' s no pending activity in this repo . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
apply standard code style <section> inconstant style <section> see <url> and <url> <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"recommended lgtm issues <section> recommended issue from lgtm : cfe_ts_crc . c : <code> <section> anh van , <allcaps> nasa </allcaps> goddard",0.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"create version header file , update to x . x . <number> , report on execution",2.0
tblcrctool hardcodes table file header size maintenance issue with hardcoded header size in tblcrctool,2.0
"tblcrctool build warnings the tblcrctool had build warnings ( using centos <number> ) . easy fix . adding <hashtag> include </hashtag> < stdlib . h > fixed it . also the makefile has the wrong include directory ( should be "" - i . "" ) and it breaks if make clean is already run ( need "" rm - f "" ) .",0.0
"table <allcaps> crc </allcaps> tool fails to close file descriptor analysis of the 2 7 b <allcaps> vpu fsw </allcaps> code revealed that there is a potential leak of an allocated resource in the file cfe_ts_crc . c . the resource "" fd "" is opened but never closed before the function returns . vputopproject / cfs / <allcaps> cfe </allcaps> / tools / tblcrctool / cfe_ts_crc . c <number> /* open the input file if possible */ - - > <number> fd = open ( argv [ <number> ] , o_rdonly ); <number> if ( fd < <number> ) <number> { <number> printf ( "" \ ncfe_ts_crc error : can not open input file ! \ n "" ); <number> exit ( <number> ); <number> } <number> /* seek past the number of bytes requested */ <number> lseek ( fd , skipsize , seek_set ); <number> <number> /* read the input file <number> bytes at a time */ <number> while ( done = = <number> ) <number> { <number> readsize = read ( fd , buffer , <number> ); <number> filecrc = cfe_es_calculatecrc ( buffer , readsize , filecrc , cfe_es_crc_16 ) ; <number> filesize + = readsize ; <number> if ( readsize ! = <number> ) done = <number> ; <number> } <number> /* print the size / <allcaps> crc </allcaps> results */ <number> printf ( "" \ ntable file name : %s \ ntable size : % d bytes \ nexpected ts validation <allcaps> crc </allcaps> : 0x % 0 8 x\ n \ n "" , argv [ <number> ] , filesize , filecrc ) ; <number> <number> return ( filecrc ) ; <number> }",0.0
sch_lab does not support sending commands with arguments <section> sch_lab does not support sending commands with arguments . this is needed when scheduling messages such as lc ' s sample action point command & hk ' s send combined packet command . <section> sch_lab supports sending commands with arguments . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
resolve static analysis uninitialized variable warnings <section> warning from static analysis ( license restricts publishing results ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"allow sch_lab to schedule faster than 1 hz <section> some <allcaps> fsw </allcaps> apps require a wakeup event faster than 1 hz . when debugging these apps it is not ideal to be forced to deploy the full <allcaps> sch </allcaps> , since its configuration is much more involved . <section> keep using <allcaps> sch lab </allcaps> which is intended for debugging apps , but be able to send wakeups faster than 1 hz . <section> deploy full <allcaps> sch </allcaps> ( complicated , and a distraction from the real objective of debugging some other app ) . <section> if cf is run at only 1 hz wakeup it would take a long time to transfer files . <section> joseph hickey , vantage systems , inc .",2.0
"update cfe_msg_message_t conversions to use cfe_msg_ptr macro <section> in nasa / cfe # <number> introduces a <code> macro which converts a cmd / tlm header object to a <code> pointer , which is intended to be used rather than assuming a specific member name ( e . g . <code> ) . <section> use the macro instead of assuming <code> member name . <section> required when using generated headers , as the member name may not be "" msg "" or may be further encapsulated . <section> joseph hickey , vantage systems , inc .",2.0
"improve consistency in application of cfe_sb_msgidtovalue / valuetomsgid conversions <section> a <code> value , like other ids , is supposed to be a unique type / opaque value that identifies a message within the sb application context . although it is currently implemented using an integer ( <code> specifically ) application should not assume this . instead , a set of macros and inline conversion functions ( cfe_sb_msgidtovalue and cfe_sb_valuetomsgid ) are provided for when the application needs to interpret the value as an integer for a valid purpose . <section> add conversions where they are currently missing <section> see nasa / cfe # <number> for full info . a separate issue + pr will be submitted for each framework app . <section> joseph hickey , vantage systems , inc .",2.0
"infinite loop if initialization fails for any reason <section> sch_lab does not exit / abort if its initialization fails - it will continue into its main loop anyway . in turn , it is possible that the "" cmdpipe "" was not initialized when this task calls <code> . this will return an error , but it just repeats the loop , forever . <section> delete or do not install the <allcaps> sch lab </allcaps> table file , so the loading of the table will fail . sch_lab then enters an infinite loop , because the cmdpipe is not valid , continually generating this error event : <code> <section> if it did not successfully initialize itself , <allcaps> sch lab </allcaps> should skip the remainder of its main function , since behavior is non - deterministic if not fully and successfully initialized . <section> the "" while "" loop here should probably be moved to an "" else "" block , so it will only be entered if initialized successfully . <url> <section> ubuntu <section> joseph hickey , vantage systems , inc .",0.0
"using void * * reference <url> according to this reference <url> , we should use the cfe_tbl_getaddress like : <code> the c reference recommends this instead of ( void * <wink> casting .",2.0
"remove references to cfe_es_registerapp <section> as part of nasa / osal # <number> and nasa / cfe # <number> the registration apis are getting fully deprecated and removed . applications no longer need to call os_taskregister , cfe_es_registerapp , or cfe_es_registerchildtask . <section> remove references to these functions . <section> will be required with nasa / osal # <number> and nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the sch_lab repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the sch_lab repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for sch_lab or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing sch_lab or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / sch_lab is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / sch_lab while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"transmit messages with sequence number updates <section> currently the <code> function invokes <code> to send the messages but the <code> parameter is set to <code> . this means that all commands generated from sch_lab have the same sequence number - whatever was in the table , probably <number> . <section> should increment sequence counter so the recipient sees a properly incrementing count on each message . this can be used to detect a missed message among other things . <section> suggesting just changing this line ( 2 nd parameter ) from false to true : <url> <section> joseph hickey , vantage systems , inc .",2.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for sch_lab . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"update for suggested alignment enforcement pattern ( nasa / cfe # <number> ) <section> see nasa / cfe # <number> , inconsistent pattern <section> match suggestion in nasa / cfe # <number> , use the "" raw "" message cmd / tlm types in definition . <section> none <section> nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove dependencies on deprecated sb apis <section> sb apis deprecated in nasa / cfe # <number> <section> update to use <allcaps> msg </allcaps> module . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , add header guard to sch_lab_sched_tab . h <section> fix # <number> - add header guard ( the other warning on the ticket was already resolved ) <section> built cleanly <section> none , good coding practice <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
""" standard "" table organization <section> sch_lab should use cfs standard table organization , to better facilitate per - target tables , etc . right now , the table source is in fsw / src and the table header definition includes ci and to header files which are only needed by the table . <section> <number> . move the table source to fsw / tables <number> . remove the <hashtag> includes </hashtag> in sch_lab_sch_tab . h <number> . rename sch_lab_sch_tab . h to sch_lab_table . h <section> none <section> see <url> for another example of how this would be structured . <section> <email>",0.0
"add build number and baseline to version file <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , update table comments / instructions <section> fix # <number> <section> none ( ci ) , comment update only . <section> none <section> ci <section> none <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"clarify schedule table guidance <code> has some guidance for creating the scheduling table , including "" make sure the table is terminated by the sch_lab_end_of_table entry "" <url> . but in looking at the file history , it does not look like the default schedule table has included a <code> entry ever in the past year , which is as far back as that file history goes . should that guidance be removed ?",0.0
"fix # <number> , apply standard style <section> whitespace changes only . fix # <number> <section> ci - <url> <section> none <section> - hardware : ci - os : ubuntu <number> - versions : bundle w / all whitespace change commits <section> note - not enforcing , just a single cleanup since there ' s no pending activity in this repo . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"app should treat cfe_sb_msgid_t values as opaque <section> for compatibility going forward , code should not assume that <code> is an integer . <section> when dealing with an integer , such as when printing in events / messages or for backward compatibility with <allcaps> mid </allcaps> <code> ' s , the code may use <code> and <code> conversion routines . <section> architecturally , the <code> is supposed to be an opaque / abstract value that identifies an endpoint on the software bus routing domain . the specific meaning of integer values is already different in an "" extended header "" ( <allcaps> ccsds </allcaps> v2 ) build vs . the standard header build . therefore apps should never make assumptions regarding the specific integer values , and all introspection of <code> values should be through the <allcaps> cfe sb api </allcaps> only . <section> joseph hickey , vantage systems , inc .",2.0
build fails with deprecated cfe / <allcaps> osal </allcaps> elements removed # <number> describe the bug build fails on <number> undeclared errors : errors . txt to reproduce make omit_deprecated = true prep ( requires nasa / cfe # <number> ) expected behavior clean build system observed on : cfs dev server <number> os : ubuntu <number> versions : mostly <number> ( + commit above ) reporter info jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"sch_lab should consolidate its globals into a single structure <section> other <allcaps> cfe </allcaps> core apps all use a single global structure to keep its runtime state . this is preferable because the structure acts as a "" namespace "" and keeps the globals separate from those of other apps . <section> replace individual globals with a single <code> structure which contains all the global variables as members . <section> this is particularly important on systems where globals go into a "" common "" section and strange behavior can happen if a name collision occurs . <section> joseph hickey , vantage systems , inc",2.0
"fails to build on raspbian <section> building sch_lab under raspbian ( a debian variant for raspberry pi <allcaps> sbc </allcaps> ' s ) fails due to alignment issues . <code> <section> build on raspbian . <section> error - free compile . <section> if applicable , add references to the software . <section> raspberry pi zero w . <section> add any other context about the problem here . <section> <email>",0.0
apply standard code style <section> inconstant style <section> see <url> and <url> <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"improve table handling <section> does not actually allow table management within the task loop <section> actually follow the table management pattern , allowing updates ( should be a decent example ) <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cfe_tbl_getaddress ( ) may return cfe_success <section> the code is testing the return code for only <code> . however the <code> function may return <code> as well , per the documentation and implementation . <section> either <code> or <code> should be accepted as valid returns . <section> <url> <section> joseph hickey , vantage systems , inc .",0.0
"improper calls to cfe_es_writesyslog <section> at some point some extra writes to the syslog were added , for example : <code> there are two issues : <number> . use of the "" line - continuation "" backslash to split across lines - - note this does _not_ remove the leading whitespace on the next line , so the actual literal result will have a large space in it . <number> . lack of a cast on the parameter . this causes build failure on platforms where <code> is actually a <code> , not <code> . <section> build for a <number> - bit platform . triggers a warning about the incorrect argument type . <section> should build cleanly on a <number> - bit platform . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit build host , building for i686 - rtems4 . <number> target . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"sch_lab table definition uses cfe_sb_msgid_t type without including header for it <section> all code compilation units should explicitly <code> the headers for all types / macros / functions which are directly used by that unit . the "" sch_lab_sched_tab . h "" defines a structure that depends on <code> , but it does not include the header that provides this type . <section> compilation fails when building with the <code> branch , which includes a change that causes the definition of <code> to no longer be implicitly included . <code> <section> the build should complete successfully . <section> ubuntu <number> . <number> <allcaps> lts </allcaps> <number> bit ( build host ) <section> joseph hickey , vantage systems inc .",0.0
"schedule app not using <allcaps> cfe </allcaps> table <section> no <section> schedule lab app is not using cfe table service . recommend implementing cfe table service . <section> none <section> none <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"replace deprecated cfe refs , # <number> fixes # <number> submitted by <user> , <allcaps> cla </allcaps> on file testing : - make enable_unit_tests = <allcaps> true simulation </allcaps> = native prep - built on linux with - dcfe_omit_deprecated_6_6 with no build errors - make test passed ( except osal_timer_ut which occasionally fails on linux ) - cfs executes and loads apps with no issues",2.0
remove dependencies on deprecated cfe elements with : <code> build errors : <code>,2.0
"enhanced version reporting use sch_lab_version from cfecfs_version_info . h if available and report on <allcaps> noop </allcaps> and startup ( along with classic version numbering ) classic version numbering can then just be updated on release , vs for every commit .",2.0
remove classic build support only supporting cmake build going forward .,2.0
"remove <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",2.0
confirm valid perf_id use originated by abrown4 ( <number> on babelfish ) : cfe reserves <number> - <number> perf - ids . need to confirm ci_lab does not use these .,0.0
"fix # <number> , convert <code> return codes and variables to <code> testing performed * * github ci actions all passing successfully . <section> no change to behavior . <code> is more expressive and improves consistency with cfe / cfs . <section> avi weiss <user>",2.0
ds <code> return codes and variables should be converted to <code> expected behavior * * use the more expressive <code> and improve consistency with cfs . <section> avi weiss <user>,2.0
"use generated stubs ds unit testing currently uses a set of stubs for its internal units that are not generated by the tool <section> use the generated stubs directly whenever possible , as this makes future maintenance easier - when an <allcaps> api </allcaps> changes , just re - run the generator tool to update the stubs . <section> this requires some additional separation of items - global variable stubs should be in a separate compilation unit , as the tool does not generate these . <section> joseph hickey , vantage systems , inc .",2.0
"remove conditionally compiled code conditionally - compiled code is a maintenance problem because code then needs to be validated both ways , with the condition on and off , and it is easy for the lesser - used / non - default option to become stale or broken , particularly with respect to the coverage testing . <section> remove conditional compilation , replace with runtime conditional checks , which can be constant - value in <allcaps> fsw </allcaps> context , but can be coverage test both ways via a single binary build . <section> in general conditional compilation of large chunks of code should be avoided , per <number> coding standards . example here of a block that is <number> lines long : <url> <section> joseph hickey , vantage systems , inc .",2.0
"strncpy source sizeof while building with <section> flag the compiler complains about "" error : argument to ‘ sizeof ’ in ‘ strncpy ’ call is the same expression as the source ; did you mean to use the size of the destination ? "" <section> steps to reproduce the behavior : <number> . add - werror = sizeof - pointer - memaccess flag to compiler <number> . build <section> no errors <section> <url> <section> - os : oracle linux <number> <section> n / a <section> claudio olmi - <allcaps> nasa </allcaps> / <allcaps> metecs </allcaps>",0.0
"file age check logic is wrong produces ~ <number> files in <number> minutes when requesting <number> file per minute <section> <number> . enable a <number> file per minute config <number> . watch ~ <number> files get produced <section> <number> file per minute when configured to do so <section> the problem is how file age is accumulated . w / the default config , <number> seconds are added every hk message , and another second is added every <number> second sb timeout . so within the typical <number> second scheduled hk request the file age gets incremented by <number> seconds ( <number> from hk processing and <number> from sb timeouts ) . <url> <url> really the time accumulation logic is broken since it ' s going to vary based on receiving any other command that would cause sb not to timeout . likely needs a functional test update to catch this issue . <section> independent of system <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , adds null termination to software bus messaging - fixes # <number> <section> make build & lcov on local dev machine <section> no expected behavior changes <section> ubuntu <number> <section> n / a <section> n / a <section> justin figueroa , vantage systems",2.0
"ds_appprocesscmd - cyclomatic complexity of <number> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . ds_app . c : : ds_processcmd <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up ds_processcmd such that it has a cyclomatic complexity of <number> or less . <section> n / a <section> n / a <section> justin figueroa , vantage systems",2.0
"improper null termination on software bus message handling it is not guarenteed that the source or destination arguments of <code> for software bus message uses in ds / apps / fsw / src assure null termination . many standard functions such as strcpy , strlen , strcmp among others rely on arrays of characters to be null terminated . <section> from local ds repo , command <code> and view uses where argument is a software bus message . <section> no expected behavior changes . replace <code> with <code> <url> <section> the below code snips are ds strncpy uses that do not guarentee null - termination <url> <url> <url> this strncpy example in fm may help with null - terminated destination but does not guarentee null - terminated source : fm strncpy example <url> <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> the fm example above proves to assure null termination for the destination , however , it may be best approach to replace <code> with <code> <url> to consolidate handling of strings . <section> justin figueroa , vantage systems",2.0
"fix # <number> , adds ds_cmdremovemid requirement documentation - fixes # <number> <section> viewed the csv <section> added requirements in the requirements csv file . <section> view documentation change on github : <url> <section> n / a <section> if included , identify any third party code and provide text file of license <section> justin figueroa , vantage systems",1.0
"add documentation of ds_cmdremovemid requirements ds / docs / ds_functionalrequirements . csv is missing documentation of requirements associated with ds_cmdremovemid <url> . <section> open and view ds / docs / ds_functionalrequirements . csv <section> ds / docs / ds_functionalrequirements . csv contains requirements documented in <allcaps> jira </allcaps> for ds_cmdremovemid . the added requirements should be ds5018 , ds5018 . <number> , ds5018 . <number> , and ds5018 . <number> . <section> n / a <section> simply viewed through github : <url> <section> n / a <section> justin figueroa , vantage systems",1.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
"unused values and uninitialized variable static analysis warnings unused values set in ds_table . c , uninitialized variable warning in ds_file_tests . c <section> squash <section> none <section> static analysis license restricts sharing actual warnings <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"uninitialized string copy if move location is empty pathname is only set when move is not empty , but the copy is done outside that condition : <url> <url> <section> produce the packet with move empty <section> only copy over if pathname was set <section> observed , also flagged by static analysis <section> introduced with file complete tlm packet updates - # <number> , so does not impact draco - rc2 <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"buffer overflow possibility on command processing from <code> use and in <code> w / bad size to <code> pathname from cmd used in strcpy , could overflow table pathname if not terminated : <url> if destfile - > pathname is not null terminated garbage could be added to the workname which gets copied back to the file name : <url> <section> this was actually happening in the test , although the test overflowed the buffer to get this condition : <url> <section> only copy up to the size of the pathname . <section> see above <section> ci <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"send a message when new files are completed send a message when new files are completed in ds . <section> - initialize and send a message using <code> and <code> respectively . - define a new packet <code> for a single <code> payload . - define a new msgid . - may need to include logic that will use "" movename "" when ds_move_files = = <allcaps> false </allcaps> and use "" filename "" when ds_moves_files = = <allcaps> true </allcaps> . - this feature will be implemented at the close of a file within the <code> function . <section> none <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old ds clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template . md and contributing . md - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
"reports "" desc test = ok "" in ds_flt_tbl_eid even though no validation is being performed initiated from the following comment : <url> basically just could imply there ' s some validation of the descriptor text going on , which there currently is not . <section> could just remove that text , it ' s not added value . <section> leave as - is <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove cfe_psp_memset and cfe_psp_memcpy use on addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"static analysis issues relative to flight code handful of static analysis issues in the "" red "" identified ( non - style issues ) . need to resolve these . filter : - file : elf - file : ut - file : cfe - file : os - file : cf_ - file : _lab_app . c ! ( significance : style ) should resolve and / or disposition the higher ranked ones at minimum . note license restricts publishing issues . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"ds hash logic comments only applicable to v1 message ids if the v1 message id is not used , theoretically the hash could collide up to the entire length of the linked list . at minimum the comments should reflect the possibility for more hash collisions , but might be worth reconsidering implementation or reporting collision depth . imported from <allcaps> gsfccfs </allcaps> - <number>",1.0
"ds and fm use the same default subtype ds and fm both use "" <number> "" as the default file subtype ds / fsw / platform_inc / ds_platform_cfg . h : <hashtag> define </hashtag> ds_file_hdr_subtype <number> fm / fsw / platform_inc / fm_platform_cfg . h : <hashtag> define </hashtag> fm_dir_list_file_subtype <number> imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
ds could limit the maximum number of files the ds file table could be modified to ( optionally ) enforce a maximum number of files for each type of file . this could be useful for missions with file space constraints . currently ds will keep creating files until space is entirely consumed . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"ds should use cfe_fs_initheader ds initializes and populates the <allcaps> cfe fs </allcaps> header itself ( see ds_file . c , lines <number> - <number> ) this requires ds to understand the details of the header structure and could break if that structure changes . it should instead use the cfe_fs_initheader function which is designed to do exactly this . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"ds should ( optionally ) add a timestamp for each packet stored <allcaps> ccsds </allcaps> telemetry packets include a timestamp in the <allcaps> ccsds </allcaps> headers . command packets , on the other hand , do not . also , if <allcaps> ccsds </allcaps> timestamps are generated by something other than the local <allcaps> cpu </allcaps> , the timestamp may reflect when the packet was generated but not when the packet was received / stored by ds . thirdly , if the <allcaps> ccsds </allcaps> timestamp is generated using a different clock that is not in sync , the timestamps may not coincide . this is particularly important in multi - <allcaps> cpu </allcaps> environments , such as when cfs busses are connected via <allcaps> sbn </allcaps> . this will particularly help with replay using the ds_replay application as the timestamps will accurately reflect when ds received the packets and will be in the correct order . i suggest adding , for each packet stored in ds , a ds packet header containing a timestamp . this header could also include sequence count , message length ( although easy to compute using the <allcaps> ccsds </allcaps> header , a ds - generated length would make for easier access ) , byte position in file , or other fields . of course , all of this adds to the amount of data stored in ds files , so all should be optional . the ds file header should include the necessary metadata to determine what the ds packet header will contain . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"ds file header should include additional metadata ds currently stores a number of fields in the ds file header ( ds_fileheader_t ) , namely the time the file was closed , the file name , the file table index , and the file name type . when reading ds - created files on other platforms with other configurations , it is possible to tease apart platform / mission - specific information but it would be easier to store the configuration in the header for easier analysis of ds files . additional information should include , at least , the <allcaps> ccsds </allcaps> time format ( cfe_sb_packet_time_format ) , the <allcaps> ccsds </allcaps> secondary header ( cc , timestamp ) endian - ness , byte alignment , even the ds file header endian - ness for the close timestamp . also , as this will break compatibility with any ds - generated files from previous versions , including a ds header format version # should be included . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"ds should add a per - message and / or per - file checksum files generated by ds on a spacecraft may be subject to <allcaps> seu </allcaps> . as such , ds should add checksums to messages stored in the ds file , and / or store a checksum for the entire ds file at close time . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"ds file header values should be big - endian as with <allcaps> ccsds </allcaps> , which is standardizing on big - endian for message headers , the fields in the ds file header ( close time , filetableindex , filenametype ) should be stored in big - endian order . ( should the same be true for the <allcaps> cfs </allcaps> file header ? ) ( originally submitted to babelfish on <date> ) imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"error : unknown type name ' cfe_sb_cmdhdr_t ' i want to believe that i am missing a step in the documentation somewhere , but when i bring ds into my apps folder , i update my mission_global_applist with ds and attempt to build and get this error amongst others . / cfs / apps / ds / fsw / src / ds_msg . h : <number> : <number> : error : unknown type name ‘ cfe_sb_cmdhdr_t ’ is there a script or tool that should be running that i am unaware of ? the training documentation here does not imply any other steps in exercise <number> which is similar . <url>",0.0
"conditional compile macro uses wrong style of <allcaps> true </allcaps> in ds_file . c the line reading <hashtag> if </hashtag> ( ds_move_files = = <allcaps> true </allcaps> ) causes the subsequent section of code to always compile if <allcaps> true </allcaps> is not defined , and if ds_move_files is defined ; and ds_move_files is required to be defined by compiler directives in ds_verify . c . throughout the rest of ds code , the lower - case c keyword ' true ' is used , i . e ' <hashtag> if </hashtag> ( ds_move_files = = true ) . when ds_move_files is not set to ' true ' in ds_platform_cfg . h , the build fails because ' movename ' does not get defined in ds_table . h , and the code section in ds_file . c needs it to be defined .",0.0
"create version header file , update to x . x . <number> , report on execution",2.0
"automate generation of integration candidate branch <section> generating the integration candidate branch is a very straightforward process , although it can be highly time consuming . automating this process can result in significant time savings . <section> use a github workflow to automatically merge a set of pull requests into the integration candidate branch and push it to github . <section> scripts can be used to simplify this process as well , but it requires setup by the person maintaining the repository and is not as portable . <section> dylan baker / <allcaps> nasa gsfc </allcaps> <number>",2.0
"remove cast when starting timebase callback <section> the cast was originally hiding a bug , as described in # <number> . in # <number> comments , <user> suggested we remove the cast . the commit was made to remove this cast , but somehow the changes were lost . <section> <url> <section> jose f . martinez pedraza / <allcaps> gsfc </allcaps> <number>",0.0
"add missing doxygen to new ut assert <allcaps> api </allcaps> <section> cfs documentation workflow is failing with some undocumented parameters : <code> <section> add documentation <section> this unfortunately is not found by <allcaps> osal ci </allcaps> workflows , it was found by <allcaps> cfs </allcaps> workflows only after merging to main . potentially need to tweak workflows so this type of thing gets detected by the <allcaps> osal </allcaps> checks and / or a way to point the <allcaps> cfs </allcaps> workflow at the ic branch so it can be identified before merge . <section> joseph hickey , vantage systems , inc .",0.0
"add utassert_sizet_eq <section> in many cases the code uses <code> to check values that are actually <code> in the implementation . this is mostly ok as long as the sizes are < 4 gib , which is almost always the case on flight systems that usually do not have a lot of memory . <section> to support larger systems in the future , ut assert should have a macro that compares <code> values natively without converting down to <code> first . <section> continue using <code> comparisons , accept limitation that this cannot be used for objects / sizes greater than 4 gib . <section> intent is to be proactive , this will probably become a limiting factor to somebody at some point . plus it is more correct to be able to compare <code> values in a type - safe manner . <section> joseph hickey , vantage systems , inc .",2.0
stray remaining use of ' goto ' in test code <section> noticed a single stray use of <code> remaining in the test code . <section> use of <code> is advised against by most coding guidelines . preference is to use other method of flow control . <section> <url> <section> avi weiss <user>,2.0
"scrub for mismatched function prototype / implementation parameter names expected behavior * * while not a risk to behavior , these mismatched parameter names may cause compiler errors in the future on some systems , and can be confusing for maintenance and application programming . <section> cases identified : image <img> <section> avi weiss <user>",2.0
break up pc rtems bsp to support generic / configurable use <section> the <allcaps> pc rtems osal </allcaps> bsp references pc686 bsp specific calls and does not easily support reconfiguration . see <url> for more context . <section> break up the implementation to support source selection and allow for exclusion of bsp specific calls . could eventually make it generic - rtems w / bsp specific options . <section> add a new bsp . <repeated> but this ends up copying almost all the pc - rtems code . <section> i have got something in work but needs cleanup / discussion to ensure it ' s headed in the right direction . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
remove obsolete <code> <section> <code> is no longer used for anything . <url> <url> <url> <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add option to force rtems_floating_point on all tasks <section> even if a task itself does not use floating point , if the <allcaps> rtems </allcaps> kernel is compiled with floating point enabled underlying functions may use it . under the current scheme , there is not a way to force inclusion of the rtems_floating_point flag for all tasks . <section> add override option to always add flag regardless of the flags passed in to the function call . <section> i am not sure if this is a problem w / other systems . <repeated> could make the flag generic to os ' s ? <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add better support for pointer return values in ut assert <section> currently , ut assert only as built - in support for <number> - bit integer return values , in the form of <code> and <code> . the majority of <allcaps> cfe </allcaps> / <allcaps> cfs </allcaps> apis have a <number> - bit integer return value , so this has been good enough . however , there are also a fair number of <allcaps> cfe </allcaps> functions that return pointer values , and these <code> apis do not currently work for pointer returns . any stub that returns a pointer must have its own custom handler function to help set the return value , and so support is spotty . every function that has a pointer return may have a slightly different way to control the return value , and a different range of things that can be done by the test to modify its behavior . <section> add two new apis to ut assert : - <code> - <code> these would work like the current integer functions , respectively , but accept pointers with a size instead of an integer . this type of signature could support <allcaps> all </allcaps> types of return values , including <number> - bit , <number> - bit , <number> - bit , and potentially even larger structures ( even though code should not output large structures via return value , it could be done ) . <section> a halfway point could be to just add generic reusable handlers that return a pointer , and could be registered to any function . but that would not be as clean , and would still need a separate function for each type . <section> this can be added without breaking any currently - existing tests or stubs , because its only a new type of return record . it would not change anything about the existing logic , just extend it . <section> joseph hickey , vantage systems , inc .",2.0
"add doxygen dependencies to "" doc - prebuild "" abstract target <section> nasa / cfe # <number> adds an abstract target for dependencies of the documentation build . currently <allcaps> osal </allcaps> requires generating the file <code> before documentation builds are run , so this should be registered as a dependency . this only affects documentation builds of <allcaps> cfe </allcaps> and <allcaps> cfs </allcaps> apps that in turn include <allcaps> osal </allcaps> headers as part of the document . these are depending on some artifacts that are generated by the <allcaps> osal </allcaps> build recipe . <section> add dependencies so that <allcaps> cfe </allcaps> and <allcaps> cfs </allcaps> app documentation builds that refer to <allcaps> osal </allcaps> files will work . <section> see nasa / <allcaps> cfe </allcaps> # <number> and nasa / cf # <number> for more context <section> joseph hickey , vantage systems , inc .",2.0
variables declared mid - function expected behavior * * all variables should be declared at the top of the function . <section> avi weiss <user>,2.0
support for freertos <user> and <user> <url> i had this issue . can you please help me to get the support for freertos - <allcaps> cfs </allcaps> .,3.0
"cppcheck flagging ut_default_stub as unknown macro <section> in recent runs of cppcheck , the following error is being reported <code> <section> run static analysis workflow <section> should pass <section> github workflow <section> see <url> <section> joseph hickey , vantage systems , inc .",0.0
"cppcheck flagging <allcaps> bugcheck </allcaps> macro as syntax error <section> the use of the <code> macro with the second argument blank looks suspicious and it is reported as a syntax error by newer versions of the <code> tool : <code> <section> execute a recent version of <code> against <allcaps> osal </allcaps> source code - observed in version <number> . <section> should pass cleanly <section> ubuntu <number> <section> the second argument being blank here is intentional , because it is a return value and this is a void function , so it needs to be empty . the syntax is actually valid but it is just a bit unusual . <section> joseph hickey , vantage systems , inc .",0.0
"allow ut assert tests to specify default verbosity <section> by default , ut assert runs in verbose ( not debug ) mode , where all calls to any assert macro are added to a log , except for <allcaps> debug </allcaps> messages . this means there is a record of tests that <allcaps> pass </allcaps> , which is generally desired for coverage testing . however , if doing fuzz testing , the point is to run a test against a large , random data set and as such there may be thousands ( or even millions ) of assertions . this will result in a very large log file full of "" <allcaps> pass </allcaps> "" messages . ut assert does allow the verbosity to be set , but currently only via command line on a run - by - run basis . <section> allow a test to specify what its default verbosity is supposed to be . for fuzz testing this can be a lower value than the normal coverage testing default . <section> currently test cases that run in a loop or otherwise would generate a large number of <allcaps> pass </allcaps> results use a pattern where the result is checked directly in the test code , e . g . : <code> such that an assertion is only logged if it fails . however , a side effect of this means that the "" pass "" counter and total test counter does not increment to reflect that something was tested / checked - it only increments if it fails . in contrast , by using the normal assert macro but reducing the verbosity means that the counters will still increment , it just does not write a log entry for <allcaps> pass </allcaps> cases . furthermore , a user could manually _increase_ the log level if they actually do want to see them all . <section> joseph hickey , vantage systems , inc .",2.0
"add random number capability for <allcaps> osal </allcaps> and ut assert <section> there are some circumstances where software ( validly ) needs high - quality random numbers , such as for cryptographic algorithms . the <allcaps> iso c </allcaps> standard <allcaps> api </allcaps> is not sufficient , as functions like <code> are only psuedo - random and thus are not useful for algorithms where true randomness is necessary . furthermore , to support the notion of "" fuzz testing "" the ut assert framework should also have a facility to easily get random numbers . <section> many os ' s have a facility to interface with a true hardware random number generator or get much higher - quality random numbers through software by gathering entropy from a local platform - specific source ( like keystrokes or mouse movements , or electrical noise from an <allcaps> adc </allcaps> , etc ) . <section> initially , this can be as simple as calling <code> once during startup with an unpredictable value , or the system clock tick counter if no real random source is available . this way , if the application does call <code> , the numbers at least will not be the same every time . that would be good enough for low impact tasks like fuzz testing and things of that nature , but would not be sufficient for crypto . <section> to clarify - fuzz testing described here is a functional test concept , independent of coverage testing . for coverage testing using ut assert , it is important that the test case follows predictable branches , and thus random numbers should <section> be used there . fuzz testing , if implemented , would be done as a completely separate test . <section> joseph hickey , vantage systems , inc .",2.0
"fixed path mapping not always working <section> using the fixed path mapping function os_filesysaddfixedmap ( ) with paths like <section> will only work once . <section> os_filesysaddfixedmap ( , "" / ram0 / cf "" , "" / cf1 "" ); os_filesysaddfixedmap ( , "" / ffx0 / cf "" , "" / cf2 "" ); <section> both paths should be included in the object table <section> this is the part of code that generates a unique dev_name , but <url> <section> - hardware : aitech sp0 - os : vxworks <number> - versions : latest <section> <section> claudio olmi , <allcaps> nasa jsc </allcaps>",0.0
"direct use of <allcaps> posix </allcaps> permission setting in ut assert <section> the ut assert framework is supposed to be portable , and this should adhere to strict c99 . however , in the goal of squelching a bogus codeql warning - some <allcaps> posix </allcaps> - specific logic got added in # <number> . this seemed to work ( likely because it was never run on a non - <allcaps> posix os </allcaps> ) until it was changed to use a different <allcaps> posix api </allcaps> ( fstat / fchmod ) to address another bogus codeql warning . now , builds are failing because the apis used are marked as <allcaps> posix </allcaps> - specific but we are not compiling this code with <code> ( nor should we , because its supposed to be pure c99 ) . this is currently breaking the mainline build . <section> build ut assert - get the error : <code> this is directly from the validation workflow on a recent cf change . <section> ubuntu ( various ) <section> the codeql warnings about file permissions "" not being set "" are not really valid . <allcaps> unix </allcaps> still allows file permissions to be set by the user , in the form of the umask setting . so the permissions on a file created using pure c99 stdio calls ( <code> ) are not "" unset "" - they are just not set directly by the application , they are controlled externally . <section> joseph hickey , vantage systems , inc .",0.0
"potentially unsafe use of strcat <section> may cause buffer overflow since the size of the source string is not checked . <section> same behavior with check . <section> <url> <section> caught by codeql . severity is rated at critical . can remove since it is part of coverage testing . <section> ariel adams , <allcaps> mcsg </allcaps> tech",2.0
"add condition variable implementation for vxworks <section> pull request # <number> added a condition variable <allcaps> api </allcaps> implementation for <allcaps> posix </allcaps> , but <allcaps> rtems </allcaps> and vxworks were set to use the "" not - impl "" module , with a plan to implement in the future . <section> add an implementation of condition variables for vxworks <number> . x <section> only vxworks <number> . x is likely to be supportable , version <number> . x will still need to use the "" not - impl "" module because the underlying sync mechanism may not exist . <section> joseph hickey , vantage systems , inc .",2.0
"add condition variable implementation for <allcaps> rtems </allcaps> <section> pull request # <number> added a condition variable <allcaps> api </allcaps> implementation for <allcaps> posix </allcaps> , but <allcaps> rtems </allcaps> and vxworks were set to use the "" not - impl "" module , with a plan to implement in the future . <section> add an implementation of condition variables for <allcaps> rtems </allcaps> <section> joseph hickey , vantage systems , inc .",2.0
"complexity of <allcaps> argcheck </allcaps> macros trigger <allcaps> jpl </allcaps> rule <number> , multiple statements per line <section> consider reworking <allcaps> argcheck </allcaps> . although it reduces repeated lines in code , it does "" hide "" a return within the macro and is not really the simplest macro when combined with os_check_string or similar . note it works . <repeated> it ' s just not a trivial macro so ends up triggering coding standard warnings . <section> although we did just disable the warning in <url> it ' s a warning that would be good to apply to non - macro code at least . really this issue trades macro complexity with function complexity where there is no real right answer in my mind . the point if this issue is to at least document this for future consideration , not necessarily back out the changes . <section> leave as - is <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"standalone <allcaps> osal </allcaps> build should export a package for use by other builds <section> <allcaps> osal </allcaps> is not standalone software that is typically installed on a pc , but rather it is always a component that is intended to be used within a larger software application . currently the cmake build does work in a standalone fashion ( i . e . one can invoke <code> and build the software ) and the software can be compiled but the result is not really usable for inclusion in a larger app . that is , there is no easy way for another ( separate ) application that needs to use <allcaps> osal </allcaps> to reference the headers and static library . <section> cmake has a method for referencing a dependency through its import / export and packaging functionality described here : <url> <section> note this is _not_ necessary when building cfs - in that mode , <allcaps> osal </allcaps> is just included as a subdirectory within the larger build , and this should still be supported as an option for other ( non - <allcaps> cfs </allcaps> ) builds as well . that is , the user can simply call <code> from their application build , and link to the provided <code> library as a regular target . the export target is only useful in cases where <allcaps> osal </allcaps> is built as a standalone software application . <section> joseph hickey , vantage systems , inc .",2.0
"rtems should show task names when typing <code> <section> typing <code> in console should show rtems names . add the following bits to <code> in rtems <code> <section> rtems should register its name , so it shows up when using rtems commands . <section> if applicable , add references to the software . <section> - hardware microblaze - os : rtems <number> <section> better debug info in rtems <section> nasa",2.0
<allcaps> rtems </allcaps> osal queue mixed sizes <section> im using queues to send variable length messages . <allcaps> rtems </allcaps> queue get returns an error if the message queue returned size is not the max buffer size . <url> this does not match the posix implementation . <url> the above logic in <code> uses <code> if the queue size is greater than the buffer provided . <code> <section> steps to reproduce the behavior : visual inspection . <section> follow the posix logic . <section> see above <section> microblaze <section> add any other context about the problem here . <section> sam price,2.0
remove stray terminators <section> <url> <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"address alignment issue in vxworks <number> on <number> bit processor <section> the task control bock ( <allcaps> tcb </allcaps> ) has an element with a <number> bit alignment requirement on some processors , but the way the os_impl_task_internal_record_t is defined for vxworks <number> does not enforce <number> bit alignment on a <number> bit system . this causes taskinitialize to fail . note the use of a char array in the structure here : <url> used here : <url> <section> need to get into a situation where the internal task record ( and tcb since it ' s the first element ) is not on a <number> bit boundary , and get ' s passed into taskinitialize , on a system that errors out if a <number> bit structure element is not on a boundary . observed on gr712rc . <section> should initialize tasks successfully . as a quick test a <code> was added to the internal task record , forcing alignment and the task initialization worked . <section> - hardware : gr712rc - os : vxworks <number> - versions : should be observable in caelum or later <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"consider skipping / truncating symbol if name to long os - impl - sytab : : os_symtableiteratro_impl will exit a symbol table dump if it detects a symbol name that violates the maximum defined length . this results in an inability to dump the symbol map if a symbol does violate the max length . consider skipping the symbol or truncating it + notify user via entry in dump file . if ( memchr ( name , <number> , os_max_sym_len ) = = <allcaps> null </allcaps> ) { os_debug ( "" %s ( <sad> symbol name too long \ n "" , __func__ ) ; state - > statuscode = os_err_name_too_long ; return ( false ) ; } path to file : osal / src / os / vxworks / src / os - impl - sytab . c <section> dan knutsen <allcaps> nasa </allcaps> goddard",2.0
"read ( ) vs os_read ( ) clarification my application involves reading data from a serial device ( <allcaps> imu </allcaps> ) in a nonblocking fashion . furthermore , i am writing code for a particular linux architecture so benefits from the standpoint of enabling os abstraction are not really important . so , other than that : what is the difference between linux ' s read ( ) and os_read ( ) ? is there a specific one that is recommended given my situation ? if so , why that one ?",3.0
"<allcaps> osal </allcaps> wrapper around qt <section> qt is an operating system abstraction layer that supports several different operating systems . would like to wrap an osal wrapper around qt <section> get a wrapper around qt . <section> - boost <section> <url> current status is it builds / links against qt , unit tests start to run . following needs done - [ ] work through getting the unit tests to run / pass on mac - [ ] cleanup code / fix comments - [ ] work through getting unit tests to run / pass on windows <section>",2.0
comments incorrect on sockets <section> ' src / os / portable / os - impl - bsd - sockets . c ' shutdown comments refer to connecting . <code>,1.0
"bin sem test <section> working through the unit tests for a qt port . i hit a stumbling block on bin - sem - test . c function <code> . when a task is deleted it may have registered callbacks with resources . in case of qt the task with a binary semaphore ( qsemaphore ) in a waiting state that gets deleted . ends up stalling the system when that qsemaphore is written to . from what i gather free - rtos has a similar issue . <url> > releasing resources on task exit / delete > posted by rtel <url> on <date> > if a semaphore is held by a task , and that task gets deleted , then there is nothing in the code that will automatically release the semaphore . > > looking at the source code i don ’ t think there is an easy way around this . the mutex can be reset by passing its handle into xqueuereset ( ) , but then to make it a mutex rather than a queue you would need to call prvinitialisemutex ( ) too – and that function is not publicly accessible . > > perhaps , if you are <percent> sure there are no other tasks blocked on the mutex , it could be deleted then re - created ? <code> a ctrl + c shows backtrace as follows . ` ` <code> __psynch_mutexwait + <number> frame # <number> : 0x0 0 0 0 7 fff207f02ab libsystem_pthread . dylib <code> _pthread_mutex_firstfit_lock_slow + <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 0 1 8 5 e6c qtcore <code> qsemaphore : : release ( int ) + <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 0 0 1 2 3 6 e bin - sem - test <code> os_binsemgive ( sem_id = <number> ) at osapi - binsem . c : <number> <time> frame # <number> : 0x0 0 0 0 0 0 0 1 0 0 0 0 4 e50 bin - sem - test <code> ` ` <section> - hardware - os : qt <number> , mac os <section> i subclassed my qt thread from the qt class , and have been using the terminate call . i will try a different method to see if that allows qt to cleanup semaphores from deleted tasks . <section> full name and company / organization if applicable",3.0
add os_statustostring <allcaps> api </allcaps> to support consistent status format representation in strings <section> related to <url> providing an <allcaps> api </allcaps> ( and using it ) would resolve inconsistency in string representation of osal_status_t . <section> add <code> <section> none <section> - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add abstraction for condition variables <section> <allcaps> posix </allcaps> condition variables can be useful for implementing worker thread pools , allowing worker task ( s ) to pend for work and dispatcher / manager tasks to unblock those workers once a job becomes available . <section> abstraction of something like <allcaps> posix </allcaps> condition variables via <allcaps> osal </allcaps> apis . <section> some of the worker pool concepts may be implemented with simple semaphores , but those are not ideal for some use cases : - a counting sem needs a <number> : <number> relationship between gives and takes , so it is not ideal for cases where work can be "" batched "" - either where a single input can unblock multiple worker jobs , or multiple inputs can be handled by a single worker job . - a binary sem helps the second case by capping the semaphore count at <number> , such that multiple "" gives "" on the dispatch side only cause a single worker run . but it does not allow for a dispatcher to unblock multiple workers , nor can it act on other conditions than a simple boolean . note that in the <allcaps> posix osal </allcaps> the binary semaphore is , in fact , implemented using condition variables underneath - where the condition is just a single boolean value . but only this limited use - case is exposed / available to applications . as a backward - compatible compromise of sorts - it may be possible to build on the current binary sem concept but allow the application to register its own "" condition test "" routine beyond the simple boolean . <section> vxworks support is not fully clear , i think vxworks <number> has the underlying apis to implement this , but <number> . x might not . <section> joseph hickey , vantage systems , inc .",2.0
"add os - impl - no - select . c for operating systems that do not have select ( <allcaps> rtems </allcaps> <number> with network off ) <section> <allcaps> rtems </allcaps> <number> . x removes the legacy network stack by default , and in doing so , removes the "" select "" call . now , when the <allcaps> osal </allcaps> osal_config_include_network option is set to <allcaps> false </allcaps> , the <allcaps> osal </allcaps> / cfs build fails because it still expects a select call . <section> i have implemented a src / os / portable / os - impl - no - select . c file along with the corresponding changes to the cmakelists . txt file that uses os - impl - no - select . c when the include_network option is <allcaps> false </allcaps> , otherwise it uses os - impl - bsd - select . c as usual . <section> alan cudmore / <allcaps> nasa gsfc </allcaps> / code <number>",2.0
"strict - type errors / exception when creating timebase callback on <allcaps> rtems </allcaps> during cfs init <section> a memory alignment exception occurs when running with <allcaps> rtems </allcaps> on gr740 board when compiling with <code> and <code> the exception occurs during cfs init , when starting the timebase callback task / thread : <url> the callback thread <code> function argument is of type <code> . <url> <allcaps> rtems </allcaps> expects the callback function argument to be of type <code> . the conversion from one type to another when starting the task causes the exception . <section> build for rtems5 - gr740 with <code> and <code> run cfs on gr740 board <section> successful cfs init . <section> - hardware : gr740 - os : <allcaps> rtems </allcaps> <number> - versions : draco <section> jose f martinez pedraza / <allcaps> gsfc </allcaps> <number>",0.0
function header documentation for os_objectidallocatenew ( ) is incorrect describe the bug the comments in the function header for os_objectidallocatenew ( ) is outdated / incorrect . i see that this was previously reported in # <number> but it appears that since then the function signature and implementation has again changed . <url> to reproduce n / a . only in the function comments . expected behavior description of the function should be with the function prototype as described in # <number> . in this case the removal of the inputs and outputs sections of the function header . reporter info nathan ohlson,1.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
strip mission source dir from doxygen path and provide common doxyfile to resolve references <section> - full path reported in doxygen generated stand - alone osal users guide - <allcaps> osal </allcaps> common doxyfile could be refactored to be used by any docs that reference <allcaps> osal </allcaps> <section> add the following to users guide <code> slight osal - common . doxyfile . in adjustments such that it can be used to resolve <allcaps> osal </allcaps> references . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
doxygen cleanup and convert from <code> to front page concept <section> see nasa / cfe # <number> <section> replace mainpage with a front page and refactor . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> per project request ping <user> - j - lin,1.0
"consider populating the "" name "" field of datagram socket entries <section> as noticed in previous issue # <number> , the datagram sockets are essentially name - less . this means that the <code> field of these entries is left unset , and will be <allcaps> null </allcaps> . this is different than most other <allcaps> osal </allcaps> resource types , which all have names . <section> stream sockets ( <allcaps> iirc </allcaps> ) generate a name consisting of the local ip address / port and remote ip address / port . datagram sockets are connectionless , but theoretically this field could still be populated with something unique , such that name - based apis could work . <section> leave as - is , where datagram sockets remain anonymous / nameless . <section> most name - based <allcaps> osal </allcaps> apis ( such as os_closefilebyname ) intentionally only operate on files - they check if the entry is a socket and ignore it if it is , so having a name associated with sockets if of limited usefulness unless we open that up , which also may not be a bad idea . ( i . e . one can get the name by calling os_fdgetinfo , then pass that name to os_closefilebyname or os_fileopencheck , etc ) . <section> joseph hickey , vantage systems , inc . based on <allcaps> ccb </allcaps> discussion of # <number> on <number> - <number> - <number>",2.0
"segfault when calling os_fdgetinfo on datagram socket id <section> sockets opened with os_socketopen get assigned an <allcaps> osal id </allcaps> which is of the same type / classification as file ids and shares the same global table . however , these ids do not have a name associated with them , and thus the <code> field of the global structure is <allcaps> null </allcaps> for these objects . the <code> will validate this type of id ( because it is a file type ) but will attempt to copy the name unconditionally , which results in a segfault because the pointer is <allcaps> null </allcaps> . <section> <number> . acquire a datagram socket id using <code> <number> . invoke <code> on that socket <number> . get segfault in <code> <section> should not segfault , rather the returned name should be empty . <section> offending call to strncpy is here : <url> <section> ubuntu <section> this code just needs to account for the name_entry being ( validly ) <allcaps> null </allcaps> on some types of entries . <section> originally found by <user> in <allcaps> osk </allcaps> implementation",0.0
"implement os_modulegetinfo_impl on <allcaps> rtems </allcaps> <section> es "" query application "" command cannot provide loaded object section addresses and sizes in <allcaps> rtems </allcaps> since the implementation of os_modulegetinfo_impl is a stub . <section> add an implementation of this using the <allcaps> rtems </allcaps> runtime loader <allcaps> api </allcaps> . <section> none <section> none <section> eric pollack - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add ut_assert to doxygen detailed design and fix warnings <section> ut_assert not included , and when it is doxygen warnings are produced <section> include in osa - detaildesign . doxyfile . in and resolve warnings <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"remove explicit file name references in doxygen file comments to avoid warnings <section> file comment without a filename implies the comments apply to the current file . adding the file name makes doxygen try to match that file . the issue is there ' s multiple files with the same name , so doxygen gets confused unless you add full path . really it ' s just overhead since the point is to comment the current file . sample warning if you <code> from the bundle : ` ` <code> os - impl - binsem . c ' supplied as the second argument in the \ file statement matches the following input files : / home / jhageman / cfs / cfs - github / osal / src / os / posix / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / rtems / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / vxworks / src / os - impl - binsem . c please use a more specific name by including a ( larger ) part of the path ! ` ` ` <section> easiest to just remove the name since for every case the comment applies to the current file <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
ensure memory is set in os_stat handler <section> risk of uninitialized variable use if buffer is not set in os_stat handler : <url> <section> initialize to zero if not fully set ( provides default behavior ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"type - safe implementation for osal_id_t <section> the <code> type is currently just a plain <code> to make it backward - compatible . the problem is that a plain number does not convey the purpose / intent of this id value . users can still do things like addition , subtraction , or interchange with other numbers , which are all invalid for a number being used as an id . as long as users are using the <code> type and the associated checks / conversions also provided by <allcaps> osal </allcaps> ( e . g . os_objectiddefined , etc ) then this should be transparent . <section> make <code> type - safe <section> this was the intent all along with creating a separate <code> typedef and using it across the <allcaps> cfe </allcaps> and <allcaps> psp </allcaps> . it does depend on having all the dependent code using the typedef , so probably want to stage this in using osal_omit_deprecated flag or similar , so we can find the things that are still broken in this regard . <section> joseph hickey , vantage systems , inc .",2.0
implement coverage test for <allcaps> rtems </allcaps> <section> coverage tests not implemented for <allcaps> rtems </allcaps> <section> add coverage tests <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , search global and local symbol tables <section> - fix # <number> - refactors symbol table searching to include both local and global symbol tables for <allcaps> posix </allcaps> - renamed global search to generic since there is not currently a use case for global only search <section> <allcaps> draft </allcaps> - not complete yet <section> improved portability , recovers prior behavior and will find symbols even if loaded as local only . <section> - hardware : i5 / docker - os : ubuntu <number> - versions : bundle main <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"optional support for symbol table dump and module address / size info on <allcaps> posix </allcaps> systems ( adds <allcaps> gnu </allcaps> extension dependence ) <section> currently checksum app does not work on systems that use os - impl - posix - dl - symtab . c since module address / size data is not filled in , nor is os_symboltabledump supported . <section> would add <allcaps> gnu </allcaps> extension dependence , but dl_iterate_phdr ( ) could be used to get the information required for both symbol table dump and module address / size . example for getting module address here : <url> <section> none <section> we have avoided <allcaps> gnu </allcaps> extension dependence , but if supported on the desired system it would be helpful to have the option for this functionality to work . another use case is when simulating a system that does have these functions implemented , it ' s likely desirable to support the capability . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<code> should also support local symbol lookup <section> getting symbol addresses are an integral part of mm and md . for systems that load modules with local scope this could still be easily supported by looping through the modules w / o requiring app changes . currently it just looks for global or static symbols : <url> <section> possibly just use os_foreach and loop through modules within os_symbollookup , but on systems where local symbol table lookup just calls the global version that would waste cycles if a symbol does not exist since it would end up searching the global table for every module . consider a slight refactor . <repeated> a generic os_symbollookup_impl could search just global on systems with only global , global and local on systems that support it . really does not seem to be a use case for os_globalsymbollookup_impl which only searches the global table . <repeated> possibly remove ? <section> none others . <section> see mm and md use of symbol lookup , helpful to get from global or local scope . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"utassert_stub_count missing a space in string output <section> example output : "" callcountcfe_evs_sendevent ( ) ( <number> ) = = <number> ( <number> ) "" <section> callcount cfe_evs_sendevent ( ) ( <number> ) = = <number> ( <number> ) <section> none <section> ( <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"new compile warnings with <allcaps> gcc </allcaps> <number> . x <section> the newer versions of <allcaps> gcc </allcaps> report new warnings . these appear to be mostly false alarms , but easy to fix nonetheless . <section> build <allcaps> osal </allcaps> using recent <allcaps> gcc </allcaps> <section> should compile without warnings or errors <section> <code> <section> ubuntu <number> , gcc <number> . <number> <section> joseph hickey , vantage systems , inc .",2.0
"add simpler / semi - automatic unit test handling for pointer returns from stubs <section> for implementation functions which return some form of <code> , the stub generator and default handler automatically makes this return <number> if nothing sets up anything else . the framework also provides a common method to provide alternate values . this <code> return was singled out because it is very common across <allcaps> osal </allcaps> , <allcaps> cfe </allcaps> , <allcaps> psp </allcaps> , and apps . the next most common return type ( aside from void ) is probably a pointer value . but this is not handled automatically , the user is required to provide a handler function just to be able to use the stub at all - even just to get it to return <allcaps> null </allcaps> . furthermore there is no common method to get any other return value either . currently on a <number> - bit platform one gets an error if attempting to use a generated stub "" out of the box "" because the framework sees a return type of size <number> which it refuses to translate from the int32 status value . <section> expand the automatic / int32 return paradigm to pointer returns . note on a <number> - bit platform this probably already happens implicitly , since a pointer an an int32 are probably the same size , and "" <number> "" can be easily translated to <allcaps> null </allcaps> . this is just two things : - provide equivalent of <code> and <code> but for pointers , so tests can have a common method to register a pointer return . - if the handler / hook does not set a return pointer / override , then grab the pointer from the registered value if its was set , or return <allcaps> null </allcaps> ( basically the same as is done for <code> currently ) . <section> leave as - is where tests must always implement a custom handler for every function that returns a pointer . <section> noted when developing cf unit tests , there are a number of <allcaps> fsw </allcaps> functions that return pointers , and it would be a good timesaver if one could simply run "" generate_stubs "" and use the stubs immediately as - is . while this is true for integer return codes , functions returning pointers all require extra work in order to use the generated stubs . <section> joseph hickey , vantage systems , inc .",2.0
"add uint8 and uint16 equivalents for utassert_uint32_ <comparison> macros <section> using a uint32 comparison for smaller uint types does not allow for roll - over situations that are considered a pass condition : <code> outputs : & <hashtag> x 1 f 534 </hashtag> ;[ <allcaps> fail </allcaps> ] <number> a_test . c : <number> - some_uint8_valueundertest ( <number> ) = = unknownstartvaluethathappenstobemax_uint8 + <number> ( <number> ) <section> a uint8 comparison could provide an output like this : & <hashtag> x 1 f 7 e 2 </hashtag> ;[ <allcaps> pass </allcaps> ] <number> a_test . c : <number> - some_uint8_valueundertest ( <number> ) = = unknownstartvaluethathappenstobemax_uint8 + <number> ( <number> ) additionally , use could be made of the _desc_ argument in the actual call ( utassert_genericunsignedcompare ) to distinguish it from a uint32 call and add pertinent information for the developer : & <hashtag> x 1 f 7 e 2 </hashtag> ;[ <allcaps> pass </allcaps> ] <number> a_test . c : <number> - compare uint8 : somevalueundertest ( <number> ) = = unknownstartvaluethathappenstobemax + <number> ( <number> ) <section> adding a typecast to every assert : <code> which does provide decent output : & <hashtag> x 1 f 7 e 2 </hashtag> ;[ <allcaps> pass </allcaps> ] <number> a_test . c : <number> - ( uint8 ) somevalueundertest ( <number> ) = = ( uint8 ) ( unknownstartvaluethathappenstobemax + <number> ) ( <number> ) <section> the requirement for adding a typecast becomes cumbersome over time , but writing a line like this is simpler : <code> and will provide just as much clarity , if not more . <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",2.0
"utassert_abort should support a format string like other calls do <section> sometimes , the utassert test macros are used to test not just the output of the unit under test , but to check for sanity in the test cases themselves ( e . g . that the appropriate preconditions were set , etc ) . if the condition is not true , then the user gets a regular failure report in the test log . this looks just like any other test failure , which is generally good enough in most cases ( attention is brought to it , so it can be fixed ) . but when using <code> or equivalent for this purpose , if checks fail , the test still continues to run . on occasion the value being check is critical enough that the test should actually stop early , such as if a pointer is <allcaps> null </allcaps> or a value would cause divide by zero , etc . utassert provides a <code> function , but this is an oddball in that in only accepts a single preformatted string message , <allcaps> not </allcaps> a printf - style format string like all other asserts do . <section> extend utassert_abort ( ) to make it accept a printf - style format string like other assert <section> test code should not use the system <code> for this , because a failure will not go through the proper reporting channels . utassert_abort ( ) is basically the equivalent idea , but its use was limited to some degree by the fact that it can not include detail information in the message ( at least not easily ) . <section> joseph hickey , vantage systems , inc .",2.0
give the utassert_ < type here > _ < comparison here > macros versions that can add user ' desc ' <section> output is generic and some additional information is desired . e . g . turn ' * received . runstatus ( <number> ) = = * test - > expected . runstatus ( <number> ) ' into ' cfe_es_runloop <kiss> received . runstatus ( <number> ) = = * test - > expected . runstatus ( <number> ) ' <section> take each of the macros in utassert . h <url> that are designed for these checks and add a second version that has _with_desc or something of that nature . <section> already written my own locally needed versions . <section> as an example for ut_unt32_eq would look like extended : <code> <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>,2.0
utassert_stringbufcompare output of strings could be put on top of each other for easier problem identification <section> differences in strings can be hard to identify when they are side by side . current output : <code> <section> stack strings for easier identification of malformations . for example : <code> <section> manual copy and paste into text editor . <section> n / a <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>,2.0
"generate_stubs . pl generated files put the comments from the . h file instead of identifying the stub file name <section> the top commenting from the header file being put into the stub file is stating that the generated stub file is the . h , because that is what the header states . <section> have the generated file identify itself as the stub file and if the . h comments are to be kept , have it identify them as such . <section> manually fixing it on every generated file <section> n / a <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",3.0
"randomize location of <allcaps> osal </allcaps> temp directories <section> when running unit tests in parallel or multiple instances of cfs in parallel on linux , sometimes things break due to / dev / shm / osal : <allcaps> ram </allcaps> * directories being at a fixed location . this is particularly a problem for our ci server which is not allowed to spin up a container for each run due to policy reasons . <section> a flag or environment variable or something to randomize / set this directory , and any other directories that may be hardcoded . <section> we have configured a lock on jenkins to prevent multiple instances of the tests from being run in parallel . <section> <section> john n pham , northrop grumman",2.0
"fix # <number> rename os_xxxtime to os_xxxlocaltime in comments . <section> - fix # <number> - rename comments from os_xxxtime to os_xxxlocaltime <section> steps taken to test the contribution : no code changed . <section> a clear and concise description of how this contribution will change behavior and level of impact . - or no impact to behavior <section> none <section> add any other context about the contribution here . <section> if included , identify any third party code and provide text file of license <section> full name and company / organization / center of all contributors ( "" personal "" if individual work ) - if <allcaps> nasa </allcaps> civil servant employee or <allcaps> gsfc </allcaps> contractor on <allcaps> ses ii </allcaps> - address / email / phone and contract / task information ( if applicable ) must be on file",1.0
"posix implementation comments refer to old time apis , update to os_getlocaltime and os_setlocaltime <section> a clear and concise description of what the bug is . <code> src / os / portable / os - impl - posix - gettime . c : * this file contains implementation for os_gettime ( ) and os_settime ( ) update comment to <code> / <code> <section> steps to reproduce the behavior : git grep os_gettime <section> a clear and concise description of what you expected to happen . <section> add any other context about the problem here . <section> sam price",1.0
"<allcaps> toctou </allcaps> bug for mkdir <section> calling function mkdir that uses local - > system_mountpt after a check function . this can cause a time - of - check , time - of - use race condition . <section> alternative is to call mkdir , without a stat , and just ignore the <allcaps> eexist </allcaps> errno if it happens . <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"<allcaps> toctou </allcaps> bug for chmod <section> calling function chmod that uses filename after a check function . this can cause a time - of - check , time - of - use race condition . <section> use fchmod as seen in os_filechmod_impl . <section> <url> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"copy of overlapping memory in snprintf <section> in the call to function snprintf , the object pointed to by argument local - > volume_name may overlap with the object pointed to by argument local - > system_mountpt . local - > system_mountpt is <number> bytes off of the address of os_filesys_table [ os_objectindexfromtoken ( token ) ] . local - > volume_name is <number> bytes off of the address of os_filesys_table [ os_objectindexfromtoken ( token ) ] <section> resolve possible overlap . <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"check return value for setsockopt <section> calling setsockopt ( impl - > fd , <number> , <number> , & os_flags , 4 u ) without checking return value . this library function may fail and return an error code . <section> check return value for setsockopt <section> <url> <section> coverity : <url> <section> possible solution <code> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"check return value of chmod <section> calling chmod ( filename , dststat . st_mode & 0 xffffffc0u ) without checking return value . this library function may fail and return an error code . <section> check the return value of chmod . <section> <url> <url> <section> from coverity : <url> possible solution : <code> <section> ariel adams , <allcaps> asrc </allcaps> federal",0.0
"update codename to caelum and license header for release , version <number> . <number> <section> development version still labeled as <number> . <number> ( whoops , should have been <date> ) . <section> upon official release , update relevant version / license info . <section> none <section> wait until official release <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"strict aliasing issue in vxworks "" intlib "" stub <section> when compiling with strict aliasing mode ( gcc w / <code> ) , a warning gets triggered in <code> as follows : <code> <section> build with new - ish gcc ( <number> ) w / <code> options and tests enabled ( so stubs are built ) . <section> should be clean . <section> ubuntu <section> could be argued that stubs should not be built with optimization + strict aliasing rules , but the fix is relatively easy to avoid this warning . <section> joseph hickey , vantage systems , inc .",0.0
"ut assert stub generator bypasses functions marked <code> <section> the <code> script ignores all contents inside <code> blocks . unfortunately , for header files which are made c + + - aware , it is typical to wrap c function calls in an <code> block which means it gets ignored by the tool . it does not understand the <code> surrounding it . <section> attempt to generate stubs against a header file which includes an extern "" c "" block . the prototypes inside the block are not processed . <section> should process prototypes inside the extern "" c "" block . <section> ubuntu . <section> prototypes were expected to all occur at the top - most scope but the <code> keyword for c + + changes this . really , the file needs to be run through the c ( not c + + ) preprocessor first , so the <code> here has the intended effect . <section> joseph hickey , vantage systems , inc .",0.0
"sem - speed - test : deadlocks sometimes when pthread_cancel is called on the threads that are actively using semaphores <section> this report is similar to # <number> and # <number> because a resource , in this case a thread , gets destroyed by <code> while another thread wants to <code> or <code> on semaphore that was just before <code> - d or <code> - d by waiting on by the destroyed thread . this is how the <code> called by <code> gets deadlocked on macos : ` ` <code> __ulock_wait + <number> frame # <number> : 0x0 0 0 0 7 fff203eaf60 libsystem_pthread . dylib <code> os_taskdelete_impl ( token =0 x00007ffee9ac08f0 ) at os - impl - tasks . c : <number> <time> frame # <number> : 0x0 0 0 0 0 0 0 1 0 6 1 4 ad9d sem - speed - test <code> semrun at sem - speed - test . c : <number> <time> frame # <number> : 0x0 0 0 0 0 0 0 1 0 6 1 4 2 8 3 9 sem - speed - test <code> os_application_run at utbsp . c : <number> : <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 6 1 5 4 fca sem - speed - test <code> start + <number> frame # <number> : 0x0 0 0 0 7 fff20404f3d libdyld . dylib <code> ` <code> pthread_cancelled <code> pthread_join <code> sem - speed - test <code> pthread_cancel <code> ` <code> ` <code> ` <code> ` <code> pthread_cancel <code> pthread_join ` does not block on macos . <section> this behavior is <percent> reproducible on macos , branch of the # <number> . i have also applied the clang ' s thread sanitizer to this and other tests . the thread sanitizer immediately complains about possible races related to unprotected access to the global variables managed by the tests . it could become a separate ticket when the more trivial issues reported so far are resolved . <section> stanislav pankevich ( personal contribution ) .",0.0
"queue - test : a message queue gets closed while still being used <section> this report is similar to # <number> because a resource , in this case a message queue , gets closed while it ' s still being used by another thread . this issue silently works on linux because of its <code> implementation details . the macos implementation of <code> in # <number> maintains a mutex in each of its methods including the <code> method . the deadlock results from the following collision : <number> ) main thread attempts to os_queuedelete that calls into <code> that wants to acquire the queue ' s mutex . <number> ) the task1 that has been deleted just before was still waiting on <code> holding the queue ' s mutex . <code> <section> one could argue that the <code> works on linux and therefore the macos implementation of <code> should accommodate . at the same time , similar to the # <number> , it looks like macos implementation actually highlights the fact that the <code> relied on undefined behavior . <section> for now , there is a custom hack to <code> on the mqueue ' s mutex before actually trying to close the mqueue . <code> <section> see the stacktrace of the blocked thread below . note that i cannot provide the second thread that holds the lock because that thread is pthread_cancelled by that point ( and the mutex has leaked ) . <section> stanislav pankevich ( personal contribution ) - - - stacktrace : ` ` <code> __psynch_mutexwait + <number> frame # <number> : 0x0 0 0 0 7 fff203e72ab libsystem_pthread . dylib <code> _pthread_mutex_firstfit_lock_slow + <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 7 6 e20af queue - test <code> mq_close ( mqd =0 x00007fdcc96040e0 ) at mq_close . c : <number> : <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 7 6 e00b7 queue - test <code> os_queuedelete ( queue_id = <number> ) at osapi - queue . c : <number> <time> frame # <number> : 0x0 0 0 0 0 0 0 1 0 7 6 d12e5 queue - test <code> uttest_run at uttest . c : <number> <time> frame # <number> : 0x0 0 0 0 0 0 0 1 0 7 6 d38f9 queue - test <code> main ( argc = <number> , argv =0 x00007ffee8532a08 ) at bsp_start . c : <number> : <number> frame # <number> : 0x0 0 0 0 7 fff20404f3d libdyld . dylib <code> start + <number> <code> / users / stanislaw / workspace / projects / code / osal / cmake - build - debug / tests / queue - test [ <allcaps> begin </allcaps> ] <allcaps> unit test </allcaps> [ <allcaps> begin </allcaps> ] <number> <allcaps> setup </allcaps> [ <allcaps> end </allcaps> ] no test cases [ <allcaps> begin </allcaps> ] <number> queuetimeouttest [ <allcaps> pass </allcaps> ] <number> queue - test . c : <number> - msgq create id = <number> rc = <number> [ <allcaps> pass </allcaps> ] <number> queue - test . c : <number> - task <number> create id = <number> rc = <number> [ <allcaps> pass </allcaps> ] <number> queue - test . c : <number> - timer <number> create id = <number> rc = <number> [ <allcaps> info </allcaps> ] queue - test . c : <number> : timer accuracy = <number> microseconds starting task <number> delay for <number> second before starting [ <allcaps> pass </allcaps> ] <number> queue - test . c : <number> - timer <number> set rc = <number> mq_timedreceive : lock mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> mq_timedreceive : unlock mq_timedreceive : lock <allcaps> task </allcaps> <number> : timeout on queue ! timer counter = <number> [ <allcaps> pass </allcaps> ] <number> queue - test . c : <number> - timer delete rc = <number> [ <allcaps> pass </allcaps> ] <number> queue - test . c : <number> - task <number> delete rc = <number> ` ` `",0.0
"coverage - vxworks - timebase : potential bug in the test implementation reported by clang address sanitizer on macos <section> when the address sanitizer is enabled in macos / clang , i get the following error in the <code> test . the reproducibility is <percent> . there are two more issues found using address sanitizer . i have linked them to this ticket in the form of a comment . <code> <section> enable address sanitizer in the root cmakelists . txt . <code> run the tests , including the <section> i suspect a memory management error that needs to be investigated . when the issue is fixed , the address sanitizer should report no issues . <section> <code> <section> - hardware mac - os : macos big sur - versions <url> <section> <code> <section> stanislav pankevich ( personal contribution )",0.0
"linkage problem on macos : ld : symbol ( s ) not found for architecture x86_64 <section> there is a solvable linkage problem on macos : <code> . <code> <section> the issue seems to be coming from the differences between <code> on linux and <code> on macos . the following simple modification makes the error to go away for the <code> symbol . <code> <code> and so on . <repeated> this change is implemented consistently in <url> <section> it does not seem to be possible to implement it differently on macos / clang . <section> this solution makes sense only if the macos <allcaps> osal </allcaps> is integrated into the <allcaps> osal ci </allcaps> . otherwise , it will not be obvious to a linux programmer that the practice of initializing the global variables has to be followed . <section> stanislav pankevich ( personal contribution )",2.0
"tests : calling sem_destroy ( ) on semaphores that are still being used <section> ( i would like to open this as a general discussion so using the feature ticket as the closest one ) running some of the <allcaps> osal </allcaps> ' s tests on macos results in <code> . instead of <code> macos ' s provides <code> and with some minor differences , the <allcaps> api </allcaps> is very similar . the above error message is a protection built in the implementation of semaphores to prevent a user from calling <code> on a semaphore that is still being used . <section> <number> of the current <allcaps> osal </allcaps> ' s test are hitting this error ( see appendix below ) and i am wondering if it would be practical to improve the design of these tests . i would also like to check with someone my understanding that destroying the resources while they are still being used results in undefined behaviour and that the undefined behaviour should be avoided even if the scope is test code , not the <allcaps> osal </allcaps> code itself . <section> for now , i am using an alternative implementation of semaphores found here <url> but i think it would be better to use the <code> as a more native implementation on macos . <section> <code> <section> stanislav pankevich , individual contribution . - - - # appendix : calling sem_destroy ( ) when a semaphore is still being used # # # <number> - osal_core_ut ( <allcaps> illegal </allcaps> ) ` ` <code> _dispatch_semaphore_dispose . cold . <number> + <number> frame # <number> : 0x0 0 0 0 7 fff202400bc libdispatch . dylib <code> _dispatch_dispose + <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 8 0 4 c130 osal_core_ut <code> os_countsemdelete_impl ( token =0 x00007ffee7bcf8d8 ) at os - impl - countsem . c : <number> : <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 8 0 3 f386 osal_core_ut <code> ut_os_count_sem_take_test at ut_oscore_countsem_test . c : <number> : <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 8 0 3 e4f9 osal_core_ut <code> os_application_run at utbsp . c : <number> : <number> frame # <number> : 0x0 0 0 0 0 0 0 1 0 8 0 5 1 5 4 a osal_core_ut <code> start + <number> frame # <number> : 0x0 0 0 0 7 fff20404f3d libdyld . dylib <code> ` <code> ` <code> ` <code> ` <code> _dispatch_semaphore_dispose . cold . <number> + <number> frame # <number> : 0x0 0 0 0 7 fff202400bc libdispatch . dylib <code> _dispatch_dispose + <number> frame # <number> : 0x <phone> c1f980 count - sem - test <code> os_countsemdelete_impl ( token =0 x00007ffeecff47c8 ) at os - impl - countsem . c : <number> : <number> frame # <number> : 0x <phone> c13156 count - sem - test <code> os_cleanupobject ( object_id = <number> , arg =0 x00007ffeecff493c ) at osapi - common . c : <number> <time> frame # <number> : 0x <phone> c160fc count - sem - test <code> os_objectiditeratorprocessentry ( iter =0 x00007ffeecff4898 , func =( count - sem - test <code> os_foreachobjectoftype ( idtype = <number> , creator_id = <number> , callback_ptr =( count - sem - test <code> os_foreachobject ( creator_id = <number> , callback_ptr =( count - sem - test <code> os_deleteallobjects at osapi - common . c : <number> : <number> frame # <number> : 0x <phone> c12c49 count - sem - test <code> uttest_run at uttest . c : <number> <time> frame # <number> : 0x <phone> c11979 count - sem - test <code> main ( argc = <number> , argv =0 x00007ffeecff4a08 ) at bsp_start . c : <number> : <number> frame # <number> : 0x0 0 0 0 7 fff20404f3d libdyld . dylib <code> start + <number> <code> _dispatch_semaphore_dispose . cold . <number> : movq % rsi , % rax subq ( % rdi ) , % rax leaq 0x 6 2 a5 ( % rip ) , % rcx ; "" <allcaps> bug in client of libdispatch </allcaps> : semaphore object deallocated while in use "" movq % rcx , 0x 6 0 4 a3566 ( % rip ) ; gcrannotations + <number> movq % rax , 0x 6 0 4 a358f ( % rip ) ; gcrannotations + <number> ud2 <code> * thread # <number> , queue = ' com . apple . main - thread ' , stop reason = exc_bad_instruction ( code = exc_i386_invop , subcode =0 x0 ) * frame # <number> : 0x0 0 0 0 7 fff2026d229 libdispatch . dylib <code> _dispatch_semaphore_dispose + <number> frame # <number> : 0x0 0 0 0 7 fff2023ec1a libdispatch . dylib <code> mac_sem_destroy ( psem =0 x <phone> f97bc8 ) at posix - macos - semaphore2 . c : <number> : <number> frame # <number> : 0x <phone> f78084 count - sem - timeout - test <code> os_countsemdelete ( sem_id = <number> ) at osapi - countsem . c : <number> <time> frame # <number> : 0x <phone> f6dd3d count - sem - timeout - test <code> os_foreachdocallback ( obj_id = <number> , ref =0 x00007ffee8c99870 ) at osapi - idmap . c : <number> : <number> frame # <number> : 0x <phone> f721dd count - sem - timeout - test <code> os_foreachdocallback at osapi - idmap . c : <number> ) ) at osapi - idmap . c : <number> <time> frame # <number> : 0x <phone> f722fa count - sem - timeout - test <code> os_cleanupobject at osapi - common . c : <number> ) , callback_arg =0 x00007ffee8c9992c ) at osapi - idmap . c : <number> <time> frame # <number> : 0x <phone> f72267 count - sem - timeout - test <code> os_cleanupobject at osapi - common . c : <number> ) , callback_arg =0 x00007ffee8c9992c ) at osapi - idmap . c : <number> : <number> frame # <number> : 0x <phone> f6dbb9 count - sem - timeout - test <code> os_api_teardown at osapi - common . c : <number> : <number> frame # <number> : 0x <phone> f6d279 count - sem - timeout - test <code> os_application_run at utbsp . c : <number> : <number> frame # <number> : 0x <phone> f7fada count - sem - timeout - test <code> start + <number> frame # <number> : 0x0 0 0 0 7 fff20404f3d libdyld . dylib <code> ` <code> ` <code> ` `",0.0
"potential aliasing warning in socket code <section> when using certain compiler versions and optimization flags , the address conversions in <code> may trigger warnings . <section> build using <allcaps> gcc </allcaps> <number> with <code> options example warning : <code> <section> should be clean . <section> <url> <section> ubuntu <number> <section> this is due to direct casting of the data , to be pedantically correct should probably memcpy the address value , rather than directly cast it , to be super safe . <section> joseph hickey , vantage systems , inc .",2.0
expand use of the <allcaps> bsp </allcaps> specific configuration registry across the rest of the resources <section> # <number> implements use of the registry for vxworks tasks but generically supports all resources . <section> add to all implementations / resources where implementation layer flags can be passed in . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> ? <allcaps> gsfc </allcaps>,2.0
"sp0 / vxworks6 . <number> <allcaps> spe </allcaps> unavailable exception encountered <section> apparently vxworks needs vx_spe_task defined for tasks on a <number> bit system if any <allcaps> spe </allcaps> instructions are inserted by the compiler . lacking this i hit "" <allcaps> spe </allcaps> unavailable exception "" from within a child task on the sp0 with vxworks <number> . side note - turns out under certain circumstances vx_fp_task behaves like vx_spe_task . flags are set here : <url> <section> run the cfe functional test on sp0 , observe the <allcaps> spe </allcaps> unavailable exception related to the testtblnonappcontext task started by testtablebadcontext in tbl_registration_test . c : <url> note - i am not sure how consistent this is , since it ' ll only occur if <allcaps> spe </allcaps> instructions are added by the compiler ( no clue why it happened w / this task ) . <section> no exception - could be achieved by allowing additional flags to be added from the <allcaps> psp </allcaps> build configuration ? <section> - hardware : sp0 - os : vxworks <number> - versions bundle main <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fcntl ( g_getfl ) fails on vxworks <number> <section> now that we check the return for fcntl , turns out it fails on vxworks <number> ( not implemented ) . used in os_socketopen_impl and os_socketaccept_impl : <url> <url> <section> consider trying ioctl if fcntl fails ? rumor has it ioctl is supported . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"typos in documentation , print statements , and comments <section> found multiple typos throughout the codebase <section> correct grammar and spelling errors <section> none <section> retroactively created for # <number>",1.0
typecast memcchr in os - shared - common . h <section> memchr is called and then assigned to a const char * without a cast . this causes failures on certain compilers ( llvm ) . <url> <code> in file <code> change <code> to <code> <section> - hardware - os : [ <allcaps> mac </allcaps> ] - versions [ <allcaps> osal </allcaps> hash 7 ebb463 ] <code> <section> sam price - <allcaps> gsfc </allcaps> image <img>,0.0
"add utassert bit field check macros <section> bit fields are a common method of storing multiple boolean values into a single data field . utassert should provide macros that aid in testing code that uses this type of storage . <section> add some new utassert macros to check bit fields . these macros should include in the log the raw value of the bit field being checked ( as a hex number ) as well as the specific mask bits being checked for . two forms should be included , one which passes if the bit ( s ) are set , and one which passes if the bit ( s ) are not set . this should be able to use the same underlying generic assert helper function , just with a different macro wrapper around it that checks a bit mask . <section> may use the existing utassert_uint32_eq / <allcaps> neq </allcaps> , in either of these forms : <number> . utassert_int32_eq ( bitfield , bitfield | check_bits ) <number> . utassert_int32_eq ( bitfield & check_bits , check_bits ) downsides : the resulting log is not quite as concise as it should be : - its not clear that this is a bitmask check - as it is logged as a normal value check . - only either the raw value ( form <number> ) or the bitmask value ( form <number> ) will be logged . it will not log both pieces of info . - values will be logged in decimal / base - <number> by default which is not easy to read when examining bit flags - base - <number> is preferable . all of the above should be solvable by simply making a different wrapper macro around the existing <code> function . <section> see nasa / cfe # <number> for a use case <section> joseph hickey , vantage systems , inc .",2.0
"utassert "" n / a "" test case type is slightly overloaded <section> there are a number of similar situations for which the "" n / a "" ( aka <code> ) log type is used , but have different nuances : <number> . when a certain functionality is not implemented at all ( e . g . network tests on a system without network stack , the <allcaps> api </allcaps> returns <code> ) . in this case a single "" n / a "" entry is used and the whole group of tests is skipped . <number> . when a certain functionality is implemented , but cannot be tested due to external factors , such as the state of the system , how it was booted , etc . ( e . g . in the "" <allcaps> cds </allcaps> "" test in es , when calling cfe_es_registercds ( ) , if the <allcaps> cds </allcaps> memory was not cleared before the test , the result may be "" cfe_es_cds_already_exists "" ) . in this case the "" n / a "" entry is used to advise the user that the test is <section> due these external factors , and that the user should take action to correct this and get a complete test result . <number> . when there is more than one possible acceptable result from a specific function call . in this case , the test code checks for each acceptable result , but are checked with <code> to indicate that although this value was checked and does not match , it does _not_ constitute a failure of the test ( the test can go on to check for the other possible acceptable results ) . <section> these three different "" n / a "" nuances should ideally have a different case type . ( specific words / abbreviations can be discussed ) . as the traditional meaning of "" n / a "" is "" not applicable "" , it likely line up best with the use case ( <number> ) above , where a test is truly not applicable on that platform / setup . for the other two , a separate casetype should be added to better convey the intent : for item ( <number> ) above is to warn the user that the results are incomplete due to external factors , and they need to take action to correct those external factors to get a complete result . this should not necessarily be a failure ; the test can still succeed in reduced form , but the report should be very clear that tests were skipped or not complete , and the user needs to take manual action to correct it . for item ( <number> ) above , the intent is allow a "" soft "" test - where multiple values are acceptable , it is necessary to "" <allcaps> pass </allcaps> "" ( and log it ) if a value _does_ match the acceptable value , but _not_ fail if the value does not match - because there are other acceptable values . typically these checks would not need to go in the log at all ; they may only be of interest to developers implementing the test , it does not provide much value in a final report log to see values that were checked for but did not match . ( in that sense , visibility of these tests should be similar to <allcaps> debug </allcaps> , but we should not overload <allcaps> debug </allcaps> either ) . <section> leave all these case types as n / a <section> existing overload of n / a is not horribly broken / wrong , but it makes the logs a little harder to process , and not as clear as to what action ( if any ) the user needs to take for the n / a reports . <section> joseph hickey , vantage systems , inc .",2.0
"migrate <allcaps> cfe </allcaps> generic integer assert tests to common ut assert <section> recently <allcaps> cfe </allcaps> added a number of useful generic test assertion macros , for greater than / less than , booleans , and other commonly needed checks in the <allcaps> cfe </allcaps> coverage test . it would be nice to use these same assertions in the functional test too , and perhaps other app / lib tests , since they are pretty generic . <section> migrate the code from <allcaps> cfe </allcaps> coverage test - specific area into general ut assert to be usable in the full range of test environments . currently the macros and code are in <url> thus private to <allcaps> cfe </allcaps> "" coverage "" test environment . <section> could copy the macros and functions into <code> so it can be used in functional tests , but then there would be two copies , and it would still be limited to <allcaps> cfe </allcaps> ( no app / lib tests could use ) . <section> putting them into ut assert itself allows for the single / common implementation for both coverage and functional and any other app / lib test . <section> joseph hickey , vantage systems , inc .",2.0
autogenerate utassert documentation <section> utassert headers have doxygen style comments but are not included in any of the current documentation generation paths . <section> either add a unique doxygen utassert users guide or add to an existing document . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"ut stub library missing "" shell "" <allcaps> api </allcaps> <section> the <code> file was not included in the <code> library , and hence apps needing to test shell functions will get a linker error due to this missing function . <section> attempt to build the unit test for an app that calls <code> <allcaps> api </allcaps> . link fails with the missing symbol . <section> build should succeed . <section> list is here . the "" shell "" stub file is there ( generated from header ) but was missed / omitted from the library somehow . <url> <section> joseph hickey , vantage systems , inc .",0.0
"unexercised code at the "" functional "" level of testing <section> although the coverage test which link directly to the implementation * . c file for all of these do fully exercise the functions , they are not called from the "" functional "" level of testing which links to the osal library ( and uses public include paths ) . so it ' s possible they could pass all current testing but not get linked / included properly in relation to the library . also a call at the functional level would cover alternative implementations , not just what ' s provided currently ( "" black box "" testing ) . helps even for the inlines / macros in headers , since they could move and get missed in the public includes ( not likely , but possible ) . os_getbuildnumber os_getversioncodename os_getversionnumber os_getversionstring os_objectidtoarrayindex inline : os_objectiddefined os_objectidequal os_objectidfrominteger os_objectidtointeger os_timeadd os_timeassemblefrommicroseconds os_timeassemblefrommilliseconds os_timeassemblefromnanoseconds os_timeassemblefromsubseconds os_timegetfractionalpart os_timegetmicrosecondspart os_timegetmillisecondspart os_timegetnanosecondspart os_timegetsubsecondspart os_timegettotalmicroseconds os_timegettotalmilliseconds os_timegettotalnanoseconds os_timegettotalseconds os_timesubtract <section> add a simple test for these at the functional level ( tests / unit - tests ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add utassert_mir macro ( similar to utassert_na ) <section> use of utassert_casetype_mir not standardized like na , leads to potential for misuse <section> add a similar macro as utassert_na <section> none <section> related to nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add typedef for <allcaps> osal </allcaps> status codes <section> in the recent versions of <allcaps> cfe </allcaps> , a typedef ( <code> ) is added and used for the return type on any function that returns a <allcaps> cfe </allcaps> status code , while <allcaps> osal </allcaps> continues to use a bare <code> return type . although the type does need to be integer in nature ( to maintain semantics of equality checks , etc ) , the typedef does still serve a useful purpose , in that it implies behavioral characteristics of the function i . e . that its return value should be checked against the set of defined status values for that module where certain values have defined meaning - as opposed to a generic number . <section> <allcaps> osal </allcaps> should define an <code> ( which can be a typedef to <code> ) and prototypes of functions returning a status value should be updated to <code> to more clearly indicate when the return value should be compared against the set of constants defined in <code> . <section> leave as <code> ( inconsistent with <allcaps> cfe </allcaps> ) . <section> in particular , having a separate type and macros helps identify cases where improper or incomplete type conversions are done , for instance see nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"<code> implementation wrt errors not consistent <section> in the <allcaps> rtems </allcaps> implementation if <code> fails ( over max int ) it ' ll wait <number> ticks , although comment is somewhat misleading since <number> is not a minimum . <repeated> passing in <number> would also cause no wait : <url> vxworks does not wait a minimum if <code> fails , just returns an error : <url> <allcaps> posix </allcaps> just converts to <code> and uses <code> . <section> technically <code> should be functionally tested with a <number> and max value input , not that i ' d ever want to wait that long ( although <allcaps> rtems </allcaps> and vxworks should return quickly due to the os_milli2ticks error response ) . it would be nice if behavior was consistent , although for <number> it looks to me like none of them would yield . if we really want a yield in all cases then it needs an update . <section> none . <section> from functional test scrub . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<code> not used <section> <code> error code is defined but not used anywhere . documented as a return code for both <code> and <code> apis . <section> use or remove . <section> could leave in if it ' s just not applicable to any of the open source os ' s , but seems strange it would not apply for at least one of them . <section> discovered in unit / coverage testing . relation to # <number> . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"return os_error if <code> fails in vxworks <code> <section> coverage test highlights somewhat unexpected behavior in the vxworks <code> where it will still return success if <code> does not return os_success . there is not a real case where <code> would fail that i know of , but the logic is a bit strange . <url> <section> return os_error if there is an error . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add <allcaps> osal </allcaps> prefix to network <allcaps> api </allcaps> group <section> fix # <number> - doxygen group name update <section> ci , doc only <section> none , updated doc <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
network id apis group missing <allcaps> osal </allcaps> prefix <section> missing prefix : <url> <section> add prefix . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"osal_timer_ut inconsistent on mcp750 / vxworks <section> the timer test does not have consistent results when run on the mcp750 + vxworks <number> platform <section> run "" osal_timer_ut "" and occasionally a failure occurs in the "" nominal "" timer case : <code> <section> test should pass reliably <section> this is partly related to the fact that the mcp750 implementation has something wrong with its timer implementation . the test reports these warnings : <code> this means there is increased jitter in the callbacks , which is then compounded by the rather crude delta check : <url> <section> mcp750 / vxworks <number> <section> other timer tests which average the counts over total time pass fine . but this one checks the delta on every interval , so one case of too much jitter and it fails . <section> joseph hickey , vantage systems , inc .",0.0
"vxworks osal_file_ut test does not pass with default config <section> the osal_file_ut uses a small ramdisk as its temporary file system to run the tests . however , with the default configuration of <code> at <number> , one gets the following error : os_fileopen_impl ( <sad> <number> : open ( ram3 : <number> / tmpfile26 . txt ) : errno = 0x 3 8 0 0 0 4 this errno correlates to <code> reducing the value of <code> to <number> , the test passes ok <section> run osal_file_ut on mcp750 / vxworks <number> with default config <section> test should pass with default config <section> if applicable , add references to the software . <section> mcp750 / vxworks <number> <section> the <allcaps> ramdisk </allcaps> only has <number> blocks , so this might be related . the other option , if acceptable , might be to document in the release notes that this particular test on this platform requires the osal_config_max_num_open_files to be reduced from its default value . <section> joseph hickey , vantage systems , inc .",0.0
"osal_core_ut hanging on mcp750 / vxworks <section> when i run <code> on the mcp750 , it seems to run fine until it gets to the <code> test . about <number> tasks into the process of creating os_max_tasks , output stops , and the test just hangs . here are the last few lines of output : <code> <section> run <code> on the mcp750 test platform <section> test should pass <section> mcp750 vxworks <number> <section> this test used to pass , so very confusing as to why it seems to be locking up now . <section> joseph hickey , vantage systems , inc .",0.0
"vxworks timebase still registers signal with <allcaps> rtos </allcaps> when sync function is not <allcaps> null </allcaps> <section> when calling <code> with the 3 rd argument ( external_sync ) non - <allcaps> null </allcaps> , it is supposed to use the external sync function rather than an register an <allcaps> rtos </allcaps> timer to implement the tick . however , the vxworks implementation still tries to register the <allcaps> rtos </allcaps> timer , which has a signal number of <number> , so it fails in <code> . <section> run timebase - api - test on vxworks , observe failure : <code> <section> test should pass <section> mcp750 , vxworks <number> <section> vxworks just needs to skip <code> and other <allcaps> rtos </allcaps> timer configs when assigned_signal is <number> . <section> joseph hickey , vantage systems , inc .",0.0
"network - api - test timeout still too short for mcp750 <section> the console / printf operations on mcp750 take a considerable amount of time ( only <number> baud serial ) . it appears some extra assert statements added in this test have made it so even 1 0 0 0 ms is not sufficient . ( looks like the serverfn might be timing out on a write while the client is printing a bunch of asserts , which then causes an error later when the client finally gets to the read ) . <section> run test on mcp750 , observe unexpected timeout error : [ <allcaps> fail </allcaps> ] <number> network - api - test . c : <number> - os_timedread ( ) ( - <number> ) = = <number> <section> test should pass <section> mcp750 vxworks <number> <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> rtems </allcaps> os_gettaskid_impl returns invalid value from root task <section> the "" root "" or initial task is technically not an <allcaps> osal </allcaps> task and does not have an <allcaps> osal id </allcaps> . if <allcaps> osal </allcaps> os_gettaskid ( ) is called , it should return os_object_id_undefined . however on <allcaps> rtems </allcaps> it returns a nonzero value which is not a valid task id . <section> run unit tests on <allcaps> rtems </allcaps> <section> os_gettaskid ( ) should return os_object_id_invalid if the "" rtems classic name "" is not actually an <allcaps> osal </allcaps> task id . <section> <allcaps> rtems </allcaps> <number> . <number> <section> joseph hickey , vantage systems , inc .",0.0
"timer "" reconfig "" tests do not work on <allcaps> rtems </allcaps> or vxworks <section> the "" reconfig "" tests were added to verify that timer config calls from the context of a timer callback are rejected . unfortunately the underlying mechanism that allows this to happen only works on <allcaps> posix </allcaps> ( via the pthread keys , which can do this ) . on <allcaps> rtems </allcaps> and vxworks , the mechanism which gets the task id ( <code> ) does not return the timer id when called from a timer task . <section> run timer tests on vxworks or <allcaps> rtems </allcaps> , timer reconfig tests will fail . <section> test should pass . <section> mcp750 vxworks <number> <allcaps> rtems </allcaps> <number> . <number> <section> might be fixable on <allcaps> rtems </allcaps> but probably difficult to fix on vxworks . may want to consider just skipping this test ? <section> joseph hickey , vantage systems , inc .",0.0
"ut symbol table dump size too small on mcp750 ( vxworks ) <section> the unit test case that verifies the <code> function has a size limit of only <number> bytes . the actual size of the symbol table on the mcp750 test platform is larger , and this returns an error . <section> run loader test on mcp750 , dump test will fail due to symbol table size limit getting reached <section> test should pass <section> mcp750 , vxworks <number> <section> joseph hickey , vantage systems , inc .",0.0
"add range to os_taskdelay test <section> when running cfs in a vm ( e . g . <allcaps> qemu </allcaps> ) the timings and the system clock is not as precise / predictable . as a result , i have occasionally seen the newly - added functional test for os_taskdelay fail as follows : <code> <section> execute osal_core_ut on a cfs system running in a vm <section> tests should pass reliably . <section> <allcaps> rtems </allcaps> <number> . <number> running in <allcaps> qemu </allcaps> <section> likely related to some sloppiness in how the emulated real time clock works under a hypervisor . suggestion is to just extend the acceptable range a big ( i . e . >= <number> instead of >= <number> ) <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , rename doc to docs <section> this is a simple rename of the <code> subdirectory , for consistency with other modules . also corrects various files where it referred to "" doc "" fixes # <number> <section> build cfe documentation <section> none , but will affect scripts / tools that look for a specific "" doc "" directory name <section> ubuntu <section> if accepted , this will likely need a corresponding update in the cfe / cfs bundle <section> joseph hickey , vantage systems , inc .",1.0
"provide file for cfe detail design <section> by default , when building cfe mission "" detail design "" document , the entire module directory is added to the doxygen input , which will recursively pick up all source files , but also everything else too . this can lead to conflicts with e . g . "" mainpage "" , where <allcaps> osal </allcaps> provides its own mainpage for its <allcaps> api </allcaps> guide , but this should <allcaps> not </allcaps> be used for other documentation that includes <allcaps> osal </allcaps> , like the detail design doc . <section> <allcaps> osal </allcaps> should provide a detaildesign template file that indicates which sources should be used , rather than everything . <section> cfe itself could exclude certain parts in its templates , but that means cfe must have knowledge of <allcaps> osal </allcaps> directory tree . <section> related to nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"rename "" doc "" to "" docs "" for consistency <section> most other cfs modules put the documentation in a <code> subdirectory , except <allcaps> osal </allcaps> and <allcaps> psp </allcaps> , which put it in <code> <section> be consistent , use <code> since this is what cfe and the majority of cfs apps use . <section> inconsistent naming means over complicated scripts and tools , that have to look in multiple different possible names / locations <section> joseph hickey , vantage systems , inc .",2.0
"set parameter on os_selectfdisset should be const <section> this function only checks bits ( read only ) , it does not modify the "" set "" argument <section> the pointer should be qualified <code> <section> # <number> ( part of <allcaps> cfs </allcaps> - <number> review ) corrected the internal function , but it looks like this one was missed . it is part of the public <allcaps> api </allcaps> but adding const here should not break anything . <section> joseph hickey , vantage systems , inc .",2.0
"use "" <allcaps> bsp </allcaps> "" lock to protect utassert globals <section> as originally noted in # <number> , the utassert global data structures are not protected against concurrent modification by multiple test threads . utassert * functions should not be invoked from child threads , but many tests do this anyway . although no observed failures can be traced directly to this , it is not correct . <section> the <allcaps> bsp </allcaps> lock that was originally implemented to clean up console output can also serve to protect these data structures . this lock can make it so utassert calls can be safely done from any test thread . <section> the tests which use child tasks could be redesigned to only assert from the main thread , but this can be difficult to do in some cases . <section> this is the second half of the request in # <number> , split into a separate work item . adding a mutex around the modifications is lower risk than changing the internal data structure initialization , and they can be implemented separately . <section> joseph hickey , vantage systems , inc .",2.0
"add test to validate priority - based wakeup on semaphores <section> <allcaps> osal </allcaps> semaphores should implement priority - based wakeup , as opposed to <allcaps> fifo </allcaps> . this currently is not validated by any test . <section> should implement a new unit test to confirm that priority - based semaphores are working as expected . basic procedure should be something like : <number> . create a semaphore with value <number> <number> . create a low priority task which blocks on the semaphore <number> . create a high priority task which also blocks on the semaphore <number> . give the semaphore <number> . confirm only high priority task woke up , low priority still blocked <number> . give the semaphore again <number> . confirm low priority task woke up <section> this test depends on actual task priorities being set in the os scheduler , which may not happen when running as a normal user and using os_config_permissive_mode option . this test would have to be bypassed in that case . <section> joseph hickey , vantage systems , inc .",2.0
"add workflow to locally build osal documentation <section> once <url> is merged we can now build the osalguide locally and check that prs do not break the osal docs . <section> create a "" docs "" workflow github actions workflow <section> figure out how to trigger the cfs bundle workflows from <allcaps> osal </allcaps> prs <section> none",1.0
"ensure all unit test cases for invalid id use <allcaps> undefined </allcaps> plus another value <section> when checking for proper id validation , the specific value <code> must be rejected as it is always invalid . however , the set of values that should be rejected is much larger than this - proper id validation should only permit a small subset of values to be accepted . <section> in order to confirm that id values are being validated properly , test cases checking for <code> should pass in <code> as well as some other value , which should be nonzero , but also _not_ in the valid range - to confirm that the implementation is doing the proper validation and not simply checking for equality with <code> . <section> this came up as part of return / status code validation efforts - test cases are currently inconsistent , some tests are only using <code> , while some only use <code> . <section> joseph hickey , vantage systems , inc .",2.0
"stub generator script filtering all "" extern "" strings <section> in order to parse the headers the "" generate_stubs . pl "" script needs to filter out "" extern "" keywords . problem is , it is filtering the "" extern "" string even if it appears inside a larger string , not just the keywords . <section> view the generated stub for "" os_timebasecreate "" . the last parameter should be <code> but it its appearing in the generated code as <code> instead . <section> should appear in the generated code as <code> , same as header . <section> <url> <section> ubuntu <section> joseph hickey , vantage systems , inc .",0.0
"include doxyfile templates in <allcaps> osal </allcaps> <section> currently the <allcaps> osal api </allcaps> is marked up with doxygen , but the required <code> config file / template exists in the <allcaps> cfe </allcaps> repo , not in the <allcaps> osal </allcaps> repo . <section> the <code> and other support / config files for the <allcaps> osal </allcaps> guide should exist in this repository , in the docs directory , so <allcaps> osal </allcaps> documentation can be generated on its own without <allcaps> cfe </allcaps> . <section> <allcaps> osal </allcaps> is supposed to be a standalone product , but currently only <allcaps> cfe </allcaps> users can generate <allcaps> osal </allcaps> documentation . it also makes management harder having certain config files in a separate repo . <section> joseph hickey , vantage systems , inc .",2.0
"occasional deadlock issue in tests that delete tasks <section> when running the unit tests repeatedly , occasionally some tests are getting into a deadlock . these tests are ones that : <number> . use sub - tasks to do various work <number> . those sub - tasks use os_printf ( ) <number> . use an asynchronous os_taskdelete during their cleanup / teardown in the event that the sub - task was in the midst of an os_printf ( ) call when os_taskdelete was invoked , the underlying <allcaps> bsp </allcaps> lock will not get released . observed in mutex - test , but others may have similar patterns . <section> run mutex - test repeatedly , may deadlock at some runs . ( it is a race condition , not <percent> reproducible ) <section> should run consistently . <section> ubuntu <section> this really just a symptom of a generic / known issue with os_taskdelete , in that other resources held by that task are not necessarily tracked or freed , depending on what it was doing at the time it was deleted . linux / pthreads does have a workaround but the issue is likely to exist on all os ' s <section> joseph hickey , vantage systems , inc .",0.0
implement os_mkdir access settings <section> see conversations in < <url>,2.0
"utassert should enforce newline on messages only if its missing <section> currently the <code> used by utassert appends a newline after every message , see here : <url> however , in many calls to <code> the test author already included a <code> in the format string , such as here : <url> as a result there is extra whitespace in the log , example here : <url> <section> the append of the newline in <code> should only happen if the message did _not_ have a trailing newline already . this will still accomplish the intent of making sure output messages end in a newline and do not run together , but will clean up extra unintended blank lines in the log files . <section> this is mainly just a nitpick / pet peeve about the extra blank lines that come with "" utprintf "" , but it also does potentially impact parsing log files with scripts . <section> joseph hickey , vantage systems , inc .",2.0
"return value of "" os_rmdir "" implementation not being passed through <section> the return value of <code> ( the low level implementation ) is not getting propagated back to the caller of <code> as it should be . <section> call <code> on a directory that should not be removable , e . g . if it is not empty . the <code> function fails and returns <code> , but the application gets returned <code> . <section> caller should get the error code , not <code> . <section> <url> <section> ubuntu <number> <section> noticed this when validating return codes in # <number> and # <number> <section> joseph hickey , vantage systems , inc .",0.0
"os_debug on vxworks needs to use same <allcaps> bsp </allcaps> facility as os_printf <section> the "" os_debug "" macro , when enabled , ends up calling <code> directly . on vxworks the characters from these debug statements get intermixed with other output from the async utility task / console writer . this makes it just about impossible to read . furthermore unit tests call the <allcaps> bsp </allcaps> function directly , so there is potentially a third task writing chars at the same time during tests , making it worse . <section> run functional / unit tests on vxworks . <section> output should be at least decipherable / readable . adding some sort of mutex on os_bsp_consoleoutput_impl ( ) would probably help greatly . <section> mcp750 , vxworks <number> <section> here is a cut and paste of some output from the "" network - api - test "" that i am currently looking into for other issues . this is not even the worst example i have seen . but it is very hard to see what ' s actually going on here . <code> <section> joseph hickey , vantage systems , inc .",2.0
""" network - api - test "" does not run successfully on vxworks <section> running the "" network - api - test "" on vxworks fails with several issues . the fcntl <code> / <code> calls return errno <code> followed by other failures . <section> run the "" network - api - test "" program on mcp750 w / vxworks <number> . various failures are reported . eventually the test hangs because a timeout test is reached , but timeouts do not function correctly due to issues with the previous fcntl f_getfl calls . <section> test should pass . <section> mcp750 w / vxworks <number> <section> this is partly related to modifications in pr # <number> / issue # <number> which was a product of the <allcaps> cfs </allcaps> - <number> review . previously it would not check the result of the <code> calls so the "" selectable "" flag was always set . now the result is checked and the "" selectable "" flag only gets set if the flags were set . so the fcntl was always failing on vxworks but it was previously ignored . but even if the o_nonblock flag does not get set , <code> should still be usable . the flag is mainly set as a protection in case two tasks call a blocking <allcaps> api </allcaps> at the same time . <section> joseph hickey , vantage systems , inc . ( on behalf of <allcaps> jsc </allcaps> team )",0.0
"update <code> documentation related to it being an <allcaps> api </allcaps> , inconsistent documentation in implementation <section> <code> is an external <allcaps> api </allcaps> : <url> yet internally there ' s a few style patterns and references that treat it like it ' s internal : <url> <url> note the implementation file itself has some inconsistencies : <url> <url> <url> <url> <section> update comments , make sure headers are in the right place <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
differentiate hook and handler function filenames <section> from <allcaps> ccb </allcaps> : <number> - <number> - <number> <url> in <url> <section> rename * hooks . c as * handler . c for stubs <section> none <section> see nasa / cfe # <number>,2.0
"add tests for object id inline functions <section> <code> , <code> , <code> , <code> are missing tests . <section> add tests . since these are inline they can be completely exercised via explicit coverage tests ( suggest adding to coveragetest - idmap . c ) . note these can be trivial , just need to convert a to and from a range of id ' s ( note these are just to / from integers , <allcaps> not </allcaps> indexes . <repeated> ) , check each for equal to itself but not equal to the others , check that os_object_id_undefined results in undefined and the rest are defined . this also ensures an id did not "" wrap "" by exercising array index conversions from array index <number> and max for each type ( as defined in configuration ) . <section> could be added to a "" functional / full stack "" test but no point since they do not have any external dependencies . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"improve consistency in the result reporting in "" unit - tests "" <section> in order to be able to cross check and confirm that the unit tests are actually checking for the status codes that they should be , the test cases need to be clear about the <allcaps> api </allcaps> being called and the return value / status code being tested for in that test case . however , the functional tests are currently not consistent in how results are reported . <section> example from the binsem test , which is better because it at least uses a macro that includes both the function name / <allcaps> api </allcaps> being called ( <code> ) as well as the status code being tested for ( <code> <sad> <url> which translates to a line like this in the log file : <code> however a similar test case from os_moduleload displays neither : <url> the latter translates only to a line like this in the log file , which does not say much at all : <code> a clear and concise description of what you want to happen . <section> this is a prerequisite to completing # <number> - the information in the log file needs to be made more like the binsem case , so it can be cross referenced back to confirm the functional tests are checking for the items they are supposed to be checking for . <section> joseph hickey , vantage systems , inc .",2.0
"return for a timeout is negative <number> <url> not sure which layer of abstraction to report this but the comment states that a timeout should return <number> . however , on linux / portable <allcaps> bsd </allcaps> . <repeated> the eventual call to os_doselect is returning os_error_timeout ( - <number> ) and flowing that all the to the os_timedread <allcaps> api </allcaps> . i would prefer it to be "" caught "" and returned as <number> at some point but . <repeated> more than anything . <repeated> just need the comment to match .",1.0
wrong token name used in accept call <url> this is a bug . i think it should be conn_token . <repeated> not sock_token,0.0
"add utassert method to verify expected stub argument value ( s ) <section> in some tests cases it is desired to not only verify that a specific stub function was called , but also to verify the specific arguments that the stub function was called with . this is currently possible by writing a hook function to check the argument values , but that requires writing a specific hook for every <allcaps> api </allcaps> . <section> provide a more generic facility such that a test case can pre - assemble an object ( similar to the context object which is passed to the hook ) that has the _expected_ argument names + values . then provide a generic method to compare those to the _actual_ argument values when the function is called . the latter bit can be done by common code at the same time the user - defined hooks are invoked . <section> a scaled - back alternative might be to provide a facility to register a persistent hook that is called for every function , and is not forgotten / unregistered when the stubs are reset like other hooks are . this would allow a test case to register a function to be called with _every_ stub on _every_ test without having to re - register it every time . calling this an alternative because the test case can then implement its own generic argument value check hook , but this would simplify the process by allowing it to apply universally and persistently . <section> joseph hickey , vantage systems , inc .",2.0
"why does utprintx have an infinite loop in it ? <section> any use of utprintx results in an infinite printing of the given memory and length . <section> steps to reproduce the behavior : <number> . put utprintx in a unit test , give it an address and size ( from <number> to max uint32 ) <number> . run tests <number> . enter loop <section> <number> . print the number of bytes given as _length_ starting at the given address _memory_ ( with newline at end ) <number> . return <section> <url> <section> - <allcaps> rhel </allcaps> <number> <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",0.0
"cannot find recommended method ( utmemset ) suggested in comments <section> utmemset is not found in ut - assert , but it suggested to be used in comments from utassert . h and uttools . h <section> <url> <url> <section> other comments in the same files suggest to use methods that do exist , utmemfill and utmem2binfile . <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",1.0
"fix # <number> , update <allcaps> osal </allcaps> config guide link <section> fixes github link in <allcaps> osal readme </allcaps> . <section> - went to <url> in firefox to render markdown - clicked "" configuration guide "" link at bottom of document - confirmed that firefox navigated me to valid doc link : <url> fixes # <number> <section> link now properly navigates users to config guide documentation . <section> - hardware : pc - os : ubuntu <number> - versions : firefox <number> ( <number> - bit ) <section> n / a <section> n / a <section> ross peters",1.0
"<allcaps> osal </allcaps> configuration guide link is broken in <allcaps> readme </allcaps> <section> the link to the <allcaps> osal </allcaps> configuration guide is broken in blob / main / <allcaps> readme </allcaps> . md . <section> go to <url> and then click on the "" configuration guide "" link near the bottom of the file . it navigates to the old <allcaps> pdf </allcaps> file link . <section> i expected the link to take me to the markdown file in the repo . <section> ` see the configuration guide <url> . <section> documentation only . <section> n / a <section> ross peters",1.0
add socket shutdown <allcaps> api </allcaps> <section> no support for graceful shutdown of <allcaps> tcp </allcaps> sockets <section> add shutdown <allcaps> api </allcaps> <section> none <section> stakeholder request <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user>,2.0
"impossible to test os_console_async false case <section> now that os_console_async is defined locally , it ' s impossible to functionally test false case or get full branch coverage on <code> without modifying the code under test : <url> <url> <section> either need to be able to exercise this option or remove it . <section> none <section> prevents full branch coverage <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"utassert improvements for multiple test invocations <section> utassert currently assumes that there will only be one test set to execute . after booting , a set of tests is collected , then executed , and once the test is complete the process will end ( either by simply exiting the process on linux debug environment , or stopping the parent vm / container , or doing a processor reset if on real hardware ) . the newly added <allcaps> cfe </allcaps> functional test now permit more than one test set to run , based on commands . a test can be started , completed , and then another test can be started , all in one "" lifetime "" of the utassert global data structures . although this generally works there could be some improvements <section> at the end of a test run the list is destroyed , and it leaves the list pointer as <allcaps> null </allcaps> . this means no additional tests can be registered after a call to uttest_run . ( luckily re - invoking uttest_earlyinit is a workaround - this is risky though because if any tests were in the list already , early init will drop them and leak the memory , it does not check for this ) . preferably this should leave the structure in a state where more tests can be registered without a complete re - init . <section> neither of these suggestions are critical at this time - would be nice to have , but nothing that prevents <allcaps> cfe </allcaps> functional test from basically running , using the workaround of re - invoking <code> between every test cycle . the biggest risk is the fact that re - invoking uttest_earlyinit does not protect against clobbering already - registered tests , but this should not happen if the proposed test pattern is followed ( its more of something that is not protected against happening , not something actually happening ) . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> # <number> # <number> , adds local makefile and bundle / local unit test actions with coverage verification <section> fix # <number> - adds local makefile ( trivial single build sample , can use different build directories for multiple platform ) fix # <number> - adds bundle and local unit test run and coverage verification fix # <number> - added missing line coverage <section> self testing ! also checked distclean and install independently . <section> runs the unit tests again , both from the context of the bundle config and local <allcaps> osal </allcaps> config . verifies <percent> line coverage . <section> - hardware : local docker container - os : ubuntu <number> - versions : cfs bundle main + these commits <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> rtems </allcaps> fails to build with shell enabled <section> the prototype for the os_shelloutputtofile_impl ( ) function has gotten stale and needs an update . unfortunately this is not built as part of any regularly - run test routine . <section> change <allcaps> osal </allcaps> config to enable shell build on <allcaps> rtems </allcaps> <section> build should pass <section> <url> <section> <allcaps> rtems </allcaps> <number> . <number> target , ubuntu <number> host . <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> osal </allcaps> should have an inverse function to os_api_init ( ) <section> once <allcaps> osal </allcaps> is initialized , normally it runs forever until rebooted , or the process exits in the case of linux . in that light , resources obtained during os_api_init ( ) cannot directly / simply be released via the <allcaps> api </allcaps> - there is no opposite / inverse routine defined . however under testing conditions , and for general completeness of <allcaps> api </allcaps> , it is useful to have an inverse function to tear down the <allcaps> api </allcaps> structures and return the system to the state it was prior to the <code> call . this can ( _almost_ ) be done with the current <allcaps> osal api </allcaps> , but it must be done in two parts : <number> . <code> will clean up any remaining user - instantiated objects in the tables . <number> . <code> will cause any internal resources , such as the console utility task , to also self - exit . the combination of these two basically leaves the system in a state similar to what it was before <code> was run . ( its not perfect , but its close ) . but its not ideal because a user should not have to call two functions ( one of which also has a parameter ) to undo the init call . <section> implement a <code> routine which would be just be a wrapper around these two currently - existing functions , to make it simpler to do this . importantly , being a void / void routine means that it can be easily used with unit tests and the <code> routine . <section> leave as - is <section> issue # <number> which calls for something like this that unit tests can use . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> osal </allcaps> timer ut failing intermittently <section> on my virtual machine running ubuntu <number> , osal_timer_ut fails roughly <percent> of the times i run it . specifically the os_timerset test . <section> run make test <section> it should pass <percent> of the time . <section> here is the printout <allcaps> begin </allcaps> ] <number> os_timerset [ <allcaps> pass </allcaps> ] <number> ut_ostimer_timerio_test . c : <number> - # <number> invalid - id - arg [ <allcaps> info </allcaps> ] <number> ut_ostimer_timerio_test . c : <number> - # <number> internal - error [ <allcaps> info </allcaps> ] ut_ostimer_timerio_test . c : <number> : os_timerset ( ) - # <number> interval - too - short ( clk_accuracy = <number> ) [ <allcaps> pass </allcaps> ] <number> ut_ostimer_timerio_test . c : <number> - # <number> interval - too - short [ <allcaps> info </allcaps> ] ut_ostimer_timerio_test . c : <number> : os_timerset ( ) - # <number> nominal condition ( clk_accuracy = <number> ) [ <allcaps> fail </allcaps> ] <number> ut_ostimer_timerio_test . c : <number> - # <number> nominal [ <allcaps> end </allcaps> ] <number> os_timerset <allcaps> total </allcaps> : : <number> <allcaps> pass </allcaps> : : <number> <allcaps> fail </allcaps> : : <number> <section> ubuntu <number> <section> alex campbell <allcaps> gsfc </allcaps>",2.0
"shell - test does not appear to work on vxworks <section> the "" shell - test "" program attempts to run the following command : echo - n "" valuetoechointhefile "" but this does not appear to work correctly on vxworks <number> . the test reports : <code> <section> enable shell and run "" shell - test "" on mcp750 <section> test should pass <section> mcp750 vxworks <number> <section> i am not familiar enough with vxworks , it seems the interactive shell does not even have an "" echo "" command so i am not sure how this is expected to work to begin with . if run directly on the shell as a test , i get : <code> so it is not clear to me how this is expected to work . <section> joseph hickey , vantage systems , inc .",0.0
"improve compliance with public coding standards ( and document non - compliance ) <section> cfs core has been developed and maintained utilizing internal coding standards , which is not much help to the wider community when the question of coding standards come up . lacking documented compliance and there ' s a few easy fixes that could be implemented to improve compliance . <section> could document compliance against public standards ( <allcaps> jpl </allcaps> / power of <number> / etc ) . some easy updates where we could improve compliance : - ( ) around <section> macros : currently not on constants - ( ) for precedence : currently rely on precedence rules in many cases - a handful of elements could be file static - a handful of elements could be local static - side effects in expressions : there ' s a handful that could be expanded warnings we monitor and minimize occurrences : - conditional compilation : still have cases to support alternate configurations - recursion : avoided in general , carefully analyzed ( current identified cases are <number> level of recursion in debug support and one other that is protected from occurring ) - pointer type inside typedef : in general minimized ( function pointers , etc ) - complex macros : minimized ( although utilized in debugging / testing ) - definitely use function pointers ( callbacks , etc ) , but to satisfy requirements areas we do not comply and debatable value : - unchecked parameter dereferences in helper functions and "" false alarms "" based on status return checks ( we check status return and skip logic , but do not explicitly check a provided pointer is not <allcaps> null </allcaps> ) - function too long : could be a topic of future refactor but heritage / working code should trade value vs risk - not enough assertions : style difference - basic numerical types used : we use fixed width types where appropriate , but do not strictly disallow basic types where they make sense other non - compliances identified are analyzed and dispositioned ( internally ) , examples : - cast alters value : all over in print statements to print hex ( unsigned ) status ( signed ) values - many false alarms for various rules ( all confirmed false ) - redundant conditions , unreachable code , useless assignments to support configurability ( would not be if configuration changes ) <section> none <section> note - marking for discussion to trigger input . nothing "" breaking "" or "" critical "" identified . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user>",2.0
non - distinct identifiers <section> vxworks defines <code> in time . h conflicts with : <url> <url> vxworks defines <code> in unistd . h conflicts with : <url> <url> <url> <section> deconflict <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"file api unit test uses osal_id_t as integer <section> the type <code> should not be used as an integer , and normal integer operations or comparisons should not be used with this type . however it looks like a couple cases in file <allcaps> api </allcaps> test were recently added which are comparing this to a <code> type directly . <section> build <allcaps> osal </allcaps> with a type - safe osal_id_t , fails to build in <code> <section> build should succeed . <section> comparisons to uint32 : <url> <url> <section> ubuntu <number> <section> should use <code> inline function to test . <section> joseph hickey , vantage systems , inc .",0.0
"make os_strnlen public <section> the os_strnlen ( ) wrapper could be useful for apps , because <code> is not a standardized function , but many times this behavior is needed / desired when reading fixed size string buffers . an inline function exists in <allcaps> osal </allcaps> to provide a substitute but it is currently in an internal header . <section> move the function to the public header so apps can also use it . <section> leave as is <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> rtems </allcaps> silently discards non - selectable file handles in os_selectmultiple ( ) <section> the conversion from the <code> to the internal <code> inside os_fdset_convertin_impl ( ) will ignore filehandles for which the <code> flag is not set . the select ( ) is then called _without_ this file included in the set , and the result is returned . this is misleading because the user is not aware that the implementation ignored one ( or more ) if the filehandles in the set . if the user requested it by including in the set , it should return an error to the caller , not silently ignore . <section> now exposed by unit tests in the current ic ( this makes the function no longer return os_err_operation_not_supported and the test that should be skipped is not actually skipped because of this ) . <section> return an error instead of silently ignoring the handle for which select ( ) cannot be done . <section> <allcaps> rtems </allcaps> <number> . <number> <section> joseph hickey , vantage systems , inc .",0.0
"fd_set coversions in select impl can read beyond the end of os_impl_filehandle_table <section> the loop inside os_fdset_convertin_impl and os_fdset_convertout_impl is limited by <code> , which itself is sized to accommodate os_max_num_open_files as a bit mask . the problem is that the size is ( necessarily ) padded up to a multiple of <number> bits . if os_max_num_open_files was not a multiple of <number> , and some of these "" padding "" bits are set as <number> , these functions will attempt to read entries beyond the end of <code> . <section> in normal use cases where the correct <allcaps> api </allcaps> is used ( e . g . <code> ) it is not possible to set these extra bits - as the os_selectfdadd ( ) checks if the filehandle is valid before setting the bit . but in coverage tests , the structure is <code> to all ones ( 0 xff ) which causes undefined behavior as it will end up reading beyond the end of the array . <section> must not read beyond the end of the array even if extra bits are set . <section> ubuntu <number> <section> observed as failure in <url> this issue was not introduced by those merges , it just so happens that it changed the preconditions such this became exposed . <section> joseph hickey , vantage systems , inc .",0.0
comments on header guard endif do not match ifdef <section> for example : <url> <url> <section> comments should be consistent w / code <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"move osal guide into this repository <section> the osal guide currently "" lives "" inside the cfe repo in the <code> <url> directory . it would make more sense to keep the documentation files in the osal repository . <section> move <code> and <code> files to this repository . will need to add a script that builds those in a standalone fashion . <section> keep as is . move <allcaps> all </allcaps> docs to the bundle repository . <section> none",1.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the <allcaps> osal </allcaps> repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the <allcaps> osal </allcaps> repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"report timer_gettime error in os_timebaseset_impl <section> if timer_gettime fails the rounding error will not be reported , silently ignored : <url> <section> report error , return failure <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"report symeach errors in os_symboltabledump_impl <section> errors not reported : <url> <section> check for non - <allcaps> null </allcaps> , report error ( write to file ? ) , return error . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"os_shelloutputtofile_impl in vxworks is not thread safe <section> filename is common : <url> <section> at minimum document . consider refactor for shell safe implementation . although current cfs concept is to use a single app and even this should be avoided when possible ( direct shell use is discouraged in production ops ) . <section> deprecate / remove . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"return error on moduleinfoget error in vxworks <section> <code> always returning success in vxworks : <url> <section> return error . it ' s not like the other cases where other info is not available and success makes sense . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove mcp750 specific <allcaps> ata </allcaps> device mapping <section> this code is out of <allcaps> osal </allcaps> scope : <url> <section> move to <allcaps> psp </allcaps> or similar . <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove os_binsemflush <section> leads to race conditions , should not be used . also other flushes are not implemented , so consistency . <url> <section> deprecate / remove <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove impossible to reach ( operationally ) code <section> os_mutsemtake_impl will block until this thread owns the mutex , check would require os error : <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"inconsistent os_max_module limit / documentation <section> comments do not match check : <url> <section> fix implementation ( if needed ) , fix comments ( if needed ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"os_fs_getphysdrivename should take a buffer size <section> os_fs_getphysdrivename assumes buffer size : <url> <section> update / replace with <allcaps> api </allcaps> that takes buffer size <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"refactor excessive logic / side effects in return statement <section> excessive logic in os_filesys_findvirtmountpoint return statement . this is not coding standard compliant and takes a while to sort out when first observed : <url> <section> refactor / comment to make more clear . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"<hashtag> define </hashtag> or configurable copy block size <section> hard coded copy block size : <url> <section> make a <code> with clear documentation that it could be adjusted for page size or whatever , performance , etc . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"replace questionable enum use <section> could conflict configurable os_max_count_semaphores and os_object_type_os_countsem <url> <section> adjust implementation . <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove rogue while loop <section> leftover while loop : <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"convert long switch ' s to static const array / jump tables / function pointer tables <section> do not really need a switch , could use a function pointer table , aka jump table ( as long as you are ok using function pointers . <repeated> <sad> <url> <url> <url> could be static const array : <url> <url> <section> convert to function pointer table <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"return success on multiple os_api_init calls <section> os_api_init writes error to the syslog and returns error if called multiple times . does not really cause any issues , could just write to the syslog and return success . <url> <section> consider returning success <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"improve performance of os_debugprintf <section> os_debugprintf checks the level and does not do the work , but the caller still sets up the variable arguments . it ' s better to have a table of function pointers that change when the level changes to either the debug printf or a no - op . <url> <section> table of function pointers <section> leave as - is ( future work ) , this is debug code which would not typically be included in production <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"update os_u32valuewrapper_t name and consider using uintptr_t <section> confusion in name where <code> is used for a union that ' ll hold a <code> . also recommendation to consider using <code> <section> consider rename / <code> use . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"scrub for include < > vs "" "" use ( < > should be system only ) <section> < > used on non - system header includes . example : <url> <section> full scrub / fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"better error code for <allcaps> espipe </allcaps> lseek failure ( not os_err_not_implemented ) <section> os_err_not_implemented error code used for <allcaps> espipe </allcaps> lseek error : <url> <section> replace error code with something more appropriate <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"scrub use of ( ) in return statements <section> inconsistent use of ( ) , style . example below but should fix all . <url> <section> fix . <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"add generic circular buffer implementation <section> console circular buffer not unique , could utilize a generic implementation <section> implement generic circular buffer <section> leave as - is ( future work ) <section> none <section> jacob hageman <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove addrlen switch duplication <section> switch to get addrlen repeated multiple times : <url> <url> <url> <url> <section> calculate once and store or implement once and inline <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"check fcntl return status or explicitly ( void ) <section> return status not checked / reported <url> <section> add check and debug error output or explicitly void . need to resolve w / documentation research . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"rationale for select right after connect ( or remove ) <section> rationale for select ( ) right after connect ( ) ? if the socket is selectable , then it wasn ' t made non - blocking . ( see line <number> ) connect blocks until the connection is made or an error occurs . <url> <section> justify ( add comment ) or remove . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"use compile time assert on address length check in bind <section> known at compile time : <url> <section> use compiletimeassert <section> what if sizeof ( struct sockaddr_in6 ) is > os_sockaddr_max_len but only af_inet is used ? not really an error ? maybe only really known if os_network_supports_ipv6 is not defined ? <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"move set of so_reuseaddr to bind / listen <section> opening every socket as so_reuseaddr is not needed : <url> <section> move to more appropriate function <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"consolidate switch logic in os_socketopen_impl <section> duplicate switch cases that could be consolidated : <url> <url> <section> consolidate <section> was separate if future domains were added . <repeated> but is currently awkward looking . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"add check for <allcaps> eagain </allcaps> in os_doselect loop <section> on some other <allcaps> unix </allcaps> systems , select ( ) can fail with the error <allcaps> eagain </allcaps> if the system fails to allocate kernel - internal resources , rather than <allcaps> enomem </allcaps> as linux does . <allcaps> posix </allcaps> specifies this error for poll ( <number> ) , but not for select ( ) . portable programs may wish to check for <allcaps> eagain </allcaps> and loop , just as with <allcaps> eintr </allcaps> . <url> <section> add check for <allcaps> eagain </allcaps> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"fix math in os_doselect <section> imagine simplified example with decimal value : now = <number> , and end = = <number> . that means we should sleep for <number> seconds . using the above logic , we get : tv . tv_sec = <number> tv . tv_usec = - <number> so , tv . tv_usec < <number> : tv . tv_usec now becomes <number> ( correct ! ) tv . tv_sec now becomes <number> ( huh ? ) so now we wait <number> seconds instead of <number> maybe we need a - - tv . tv_sec ? <section> confirm / fix if needed . remove bug if not real . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",0.0
"use pselect in os_doselect to avoid needed conversions <section> could avoid timespec to timeval conversion : <url> if pselect was used here : <url> <section> use pselect , need to check vxworks / <allcaps> rtems </allcaps> support <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"add assert for fd_set_size in relation to osal_set <section> fd_set has limits : <url> <section> should respect the fd_set_size limit ( prefer compile time error ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"const correctness on input parameters <section> missing const for a few parameters . osal_set : <url> final_id ( need to confirm ) : <url> <section> add const <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"either deprecated or require os_taskregister <section> os_taskregister has comments that it is obsolete , but never got officially deprecated . <section> need to either officially deprecate or officially support . <section> none <section> impacts apps , better now in a major release than later for removal . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"deprecate os_networkgetid and os_networkgethostname <section> os_networkgetid and os_networkgethostname are not really all that useful in an os agnostic sense . <section> deprecate / remove <section> leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove duplicate prototype definition <section> duplicated prototypes for os_networkgetid and os_networkgethostname : <url> <url> <url> <url> <section> remove from osapi - sockets . h <section> deprecate / remove ( see issue # <number> ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"wider adoption of <number> bit interval ( generic timekeeping ) pattern <section> some <allcaps> api </allcaps> ' s and implementations still use msec : <url> <url> <url> consider refactor of timebase init with same pattern : <url> <section> consider wider adoption of the generic <number> bit interval pattern <section> leave as - is ( future work ) . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"implement os_printf / console at shared <allcaps> osal </allcaps> level <section> entire os_printf / <allcaps> osal </allcaps> console implementation could be handled at the <allcaps> osal </allcaps> level and not via implementation . every os needs a thread , a circular buffer , and a semaphore to wake that thread and write to console . all we really need is for that thread to call printf ( ) . there ' s a vxworks specific impl and there ' s a <allcaps> posix </allcaps> impl , etc . it seems it could be <allcaps> osal </allcaps> only using all <allcaps> osal </allcaps> primitives and standard c . <section> use <allcaps> osal </allcaps> primitives at shared level <section> leave as - is ( future work ) > <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"os_mutsemgive - add unique error code for attempted release by non - owning thread <section> attempt to release by non - owning thread is a useful error to identify uniquely ( and it ' s already checked ) : <url> <url> <section> add unique error code <section> currently allowing the os to decide if it ' s an error or not , could leave as - is ( future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"move os_mount and similar platform specific ( or even pre - load of cfs actions ) outside <allcaps> osal </allcaps> <section> os_mount is more in - line with <allcaps> psp </allcaps> concept . occasionally done by os before even loading cfs . <section> consider moving / removing from <allcaps> osal </allcaps> <section> leave as - is , not critical ( consider for future work ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"typo , copy / paste , comment clean - up <section> general issue to capture typo , copy / paste cleanup from <allcaps> osal </allcaps> code review . extra space : <url> add comment to justify numbers : common pattern to represent <number> obtjects in a byte ( single bit ) <url> clarify in comments if os_taskdelay is a "" busy "" wait or scheduled ( sleep ) : <url> document input parameter as actually in / out : <url> make capitalization consistent output - > output : <url> clarify comment - explicitly zero for consistency in operations and to avoid confusion : <url> clarify comment - test for existence and is a directory <url> duplicate function comments : <url> check_mode - > lock_mode : <url> comment cleanup , vsnprintf also does the format , <code> : <url> data_size - > max_size : <url> clarify constants in comments : <url> <url> <url> justify constant return - <code> : <url> clarify - <code> : <url> justify constants ( + <number> / <number> ) rounds : <url> <section> fix <section> none <section> no impacts <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove os_direntry_name macro <section> os_dirent_t is exposed , do not really need a macro to get to the element <url> <section> remove references , deprecate , remove . <section> leave it , provides a layer of abstraction if names change . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"clarify os_getlocaltime / os_setlocaltime use in relation to osal_gettime_source_clock <section> not really clear / consistent on os_setlocaltime and os_getlocaltime in relation to osal_gettime_source_clock . currently defaulted to clock_monotonic , so a os_setlocaltime may fail . really need to clarify intent of the design / apis to be more clear on how they should be used since the osal_gettime_source_clock is used in both and the setting has different impacts in the different contexts . <section> may benefit from individual configuration parameters , or maybe os_setlocaltime should never be clock_monotonic . add a bit more context to <allcaps> api </allcaps> / configuration documentation . use cases ? <section> anything to clarify / explain intent . <section> debated "" bug "" , could switch . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"clean up endian temporary compatibility macro <section> missing an else ( likely error ) case ( or ! defined ( __byte_order ) ) <url> it ' s also a misnomer ( <allcaps> byte </allcaps> not <allcaps> bit </allcaps> ) , and one of many various patterns ( see nasa / cfe # <number> ) <section> at minimum add the error case , ideally clean / remove / consolidate . <section> none <section> nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"remove redefine of <allcaps> null </allcaps> <section> the following code will <section> redefine / define <allcaps> null </allcaps> which wasn ' t the intent <url> <section> remove , <allcaps> null </allcaps> is standard c <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"benchmark replacing strncpy use with local / safe version ( s ) <section> strncpy null <section> when not always needed , and does not guarantee <allcaps> null </allcaps> termination . <section> benchmark current implementation against local inline implementation ( s ) that always <allcaps> null </allcaps> terminates , consider option to null fill or not , etc . strlcpy flavor with a fill option ? may differ per compiler / platform / etc . <section> leave as - is . <section> might be a good new user / intern project - <user> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , <allcaps> osal </allcaps> code review",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for <allcaps> osal </allcaps> or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing <allcaps> osal </allcaps> or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / osal is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / osal while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"always initialize file descriptor in os_opencreate <section> numerous false alarms on possible uninitialized variable with os_opencreate use . <section> initialize the file descriptor to os_object_id_undefined : <url> <section> could initialize before passing in from each call , but this would provide consistency <section> static analysis warnings ( on use ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
c + + comment style and commented out code violations <section> c + + comment style and commented out code violates style guidelines <url> <section> clean up <section> none <section> alex campbell <allcaps> gsfc </allcaps>,2.0
"comment copy / paste errors in os - shared - idmap . h <section> various comments are not right : <url> <url> <url> <url> just examples , needs full scrub <section> prefer removal of the function name in the comment , and update the actual comment to match purpose . even better is switch to doxygen comments . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"<allcaps> osal </allcaps> should have a "" os_getversionstring ( ) "" function <section> currently the <allcaps> osal </allcaps> version is a string that is made available as a macro - <code> - which defined in <code> the problem with this is that because its a preprocessor macro - the replacement is done at the point the macro is _referenced_ and therefore the value ends up getting built into the binary code for whatever referenced this ( in <allcaps> cfe </allcaps> use case this is <code> ) this means if that code is later linked with a different / updated <allcaps> osal </allcaps> library ( but the <allcaps> cfe </allcaps> code using <allcaps> osal </allcaps> is <section> recompiled ) it will still report the original <allcaps> osal </allcaps> version string , which is wrong . <section> there should be a function call into <allcaps> osal </allcaps> to get the version string , rather than a macro in a header . therefore if / when re - linking without recompilation , it will report the correct value . <section> in summary - the <allcaps> osal </allcaps> version string should be stored within the <allcaps> osal </allcaps> library binary file , rather than stored within the <allcaps> cfe </allcaps> library binary file . this is confirmed via the "" strings "" tool that right now its in the wrong place : $ strings build / native / default_cpu1 / cfe - core / libcfe - core . a | grep osal cfs versions : cfe v6 . <number> - rc1 + dev348 , osal v5 . <number> - rc1 + dev262 , psp this shows that the actual string showing the <allcaps> osal </allcaps> version as reported by the cfe event is baked into the <allcaps> cfe </allcaps> library , not the <allcaps> osal </allcaps> library where it should be . <section> joseph hickey , vantage systems , inc .",2.0
"minor redundancy cleanup from static analysis warnings <section> two minor redundant logic / checks : <url> <url> no actual issues , just minor cleanup . <section> remove first , refactor second so the bound is just checked in one place <section> none <section> static analysis warnings <section> jacob hageman - <allcaps> nasa </allcaps>",2.0
"unreasonable size argument - os_createsocketname static analysis warning <section> static analysis warns when using sizeof ( sock - > stream_name ) in os_strnlen check and later math <code> passed to snprintf which out of context could then be a negative number ( but is not because os_socketaddrtostring_impl limits to os_max_api_name , so this is a false positive ) : <url> <section> truncating the port while fully adding the parent name or possibly even truncating both seems like it could be confusing . just truncate at the end . <section> could use os_max_api_name to limit len in first check , but seems like overkill since the size is os_max_path_len . <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
local stub helper update to match macro behavior <section> custom call to <code> do not match standard macro behavior ( <allcaps> null </allcaps> terminate for functions not including va list ) . <section> match macro ( avoids static analysis warning ) <section> none <section> none <section> jacob hageman,0.0
"work # <number> , # <number> , # <number> , minor fixes to osal config guide <section> i noticed a few things missing from the documentation . there were also duplicate entries in one of the tables partially addresses # <number> , # <number> , # <number> <section> ( none ) <section> no impact to behavior <section> gentoo linux - amd64 <section> andrei tumbar ( <allcaps> nasa jpl </allcaps> ) <email> / <email>",1.0
"<allcaps> rtems </allcaps> build broken due to format mismatch ( again ) <section> somewhere a printf in "" queue_test . c "" got changed without the requisite cast , now generates a warning on <allcaps> rtems </allcaps> . <code> <section> build for <allcaps> rtems </allcaps> <number> with default config <section> should build successfully <section> <allcaps> rtems </allcaps> <number> . <number> target on ubuntu <number> build host . <section> need to always remember to always cast args in printf when using fixed - width types . this breaks very frequently . <section> joseph hickey , vantage systems , inc .",0.0
convert from strlen to strnlen where appropriate <section> per security standards strlen should be avoided if possible : <code> <section> replace with strnlen where possible . <section> none <section> security analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"os_shelloutputtofile_impl in src / os / rtems / src / os - impl - shell . c issues <section> - does a strncpy to loadcmd , then a snprintf to localcmd - does not check for no truncation prior to sending so could do strange things - cmd could take up more than allotted space <section> remove the strncpy ? check the full command fit prior to execution ? <section> already can be optionally excluded from build . <repeated> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
improper null termination <section> a few cases of possible missing termination : <url> <url> <section> terminate . <section> none <section> secuity analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
unreachable code in posix os_binsemcreate_impl <section> can not reach : <url> <section> refactor to eliminate dead code . <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
network - api - test fails if osal_config_include_network is false <section> set all includes to false and network - api - test failed <section> should cleanly handle os_err_not_implemented <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"select - test fails if network is not included <section> select - test hung when run with all the include options being false , suspect it ' s due to osal_config_include_network <section> select test should handle either configuration ( check for os_err_not_implemented and skip tests that do not apply ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"os - impl - no - symtab . c out of date <section> conflicting types for the implementations <section> attempt to compile w / os - impl - no - symtab . c : osal_config_include_dynamic_loader <allcaps> false </allcaps> <section> should compile <section> many of the implementations do not match , sample : <code> <section> - hardware : cfs dev server - os : ubuntu <number> - versions cfs bundle <section> seen when adding a coverage test for this code (# <number> ) , # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"os - impl - no - sockets . c out of date <section> conflicting types for the implementations <section> attempt to compile w / os - impl - no - sockets . c : osal_config_include_network <allcaps> false </allcaps> <section> should compile <section> many of the implementations do not match , sample : <code> <section> - hardware : cfs dev server - os : ubuntu <number> - versions cfs bundle <section> seen when adding a coverage test for this code (# <number> ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"update coverage tests for vxworks at minimum to include reporting of all code that could be included in build <section> currently os - impl - bsd - socket . c can be included ( and is by default ) in the vxworks build : <url> but it ' s not included in coverage testing or reported as part of status <url> so although code coverage reports <percent> , we are <allcaps> not </allcaps> covering the possible <allcaps> fsw </allcaps> <percent> . <repeated> so it ' s a bit misleading . <section> all possible code should be reported for coverage . short term is just to add tests ( track by hand ) but eventually may benefit from a quick check that all the files included in the build are included in coverage analysis . <section> none <section> illuminated by investigation into # <number> , unreachable code wasn ' t being reported even though it was in the core build . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"unreachable code in os - impl - bsd - sockets . c : <section> 2 nd set of default cases are unreachable , since there ' s a return from a prior check : <url> specifically line <number> and <number> are legitimately dead code . <section> refactor to eliminate dead code <section> none <section> static analysis warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"return code not passed back in os_consoleapi_init - static analysis warning <section> os_consoleapi_init always returns success , but could error . inconsistently implemented ( if return_code is being recorded , return it . <repeated> if it is not needed why set it ? ) <section> either do not have a return value , or return the actual status . in test / coverage the expected return value should be confirmed . <section> none <section> static analysis warning since return_code is unused <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , resolve coercion alters value warnings <section> fix # <number> - fixed two locations with local return code defined as uint32 , should be int32 ( or eventually the status type ) <section> build and execute unit tests , passed <section> no functional change , just resolves warnings <section> - hardware : cfs dev server - os : ubuntu <number> - versions : cfs bundle main + this commit <section> static analysis warning <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"coercion alters value - static analysis warnings <section> a few locations where a type is incorrect ( just listing an example here , see pr for all fixes ) : <url> note returns status which is int32 , but return_code is uint32 . no real bugs identified yet , but cleaning up warnings makes it easier to spot real issues in the future . <section> fix types where needed . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"remove commented out code where it does not have a benefit <section> pages of commented out code warnings show up in static analysis . <section> general scrub and removal where it ' s not necessary . <section> none , any valuable comments will be retained <section> codeql warnings <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"refactor to avoid possible uninitialized local variables <section> <url> <url> <url> note the only one in non - test code is a false alarm so i am not marking as a bug and not critical , but easy to squash : <url> <section> fix . <section> none <section> codeql warnings <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"unterminated variadic call in ut tools , codeql warning <section> codeql warning on : <url> <url> <section> terminate list with <allcaps> null </allcaps> in macro <section> none <section> codeql warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
file created without restricting permissions in unit test tools <section> codelql security warnings against following code : <url> <url> <section> <url> <section> none <section> codeql analysis results <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"local variable hides global in queue - test . c , bin - sem - timeout - test . c , bin - sem - test . c <section> <url> <url> similar in bin - sem - timeout - test . c and bin - sem - test . c <section> preference is to implement a style such that it ' s easy to differentiate global vs local variables ( local lower case , global camel or similar ) or put global variables in a structure ( easy to init / clear ) . <section> none <section> codeql warning <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"osc_inum_to_ivec stub returning stack allocated memory <section> codeql warning on line <number> ( returning vectbl ) : <url> <section> make dummyvec static <section> remove , no longer used in <allcaps> osal </allcaps> testing but could be used by <allcaps> psp </allcaps> implementations . leaving in for now . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove deprecated code ( release candidate prep ) <section> <code> elements exist to help with upgrade / transition and reduce frequency of breakage . <section> remove deprecated code for major release . <section> could tag before removal for any user that would benefit from a "" gentle "" transition . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"apply style formatting ( release candidate prep ) <section> code has diverged from automated style . <section> apply automated style formatting . <section> none <section> suggest adding as a check in workflow until release . style has been very stable , should be manageable to enforce at least in the short term ( release candidate and release prep ) . could enforce just on rc branch ( es ) if there ' s an issue w / general enforcement . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> api </allcaps> ' s null pointer check in void methods <section> some pointers are used in methods that return void so the os_check_pointer function does not work in those methods since it returns an error code . there needs to be a way to check that pointers are valid inside void methods . <section> need to discuss the best solution <section> related to # <number> , that branch has this comment marking everywhere it comes up . /* <allcaps> todo </allcaps> : void pointer , <url> */ <section> alex campbell <allcaps> gsfc </allcaps>",2.0
"cfs fails to start if executed off of a large <allcaps> nfs </allcaps> home directory <section> if cfs is executed off of an <allcaps> nfs </allcaps> home directory , an output similar to the following is created : <code> - cfe_es_startup . scr cannot be found . <section> execute linux cfs binary off of an <allcaps> nfs </allcaps> home directory <section> cfs reads cfe_es_startup . scr successfully <section> <url> <section> linux ( rhel7 ) , <allcaps> osal </allcaps> <number> . <number> - rc1 + dev184 <section> john n pham , northrop grumman",3.0
"testreadwritelseek has off by one error <section> testreadwritelseek calls strlen but fails to account for null terminator , causing garbage characters to be written to test log <section> build and run file - api - test depending on the contents of memory , bogus characters may be written to build / [ arch ] / default_ [ cpu ] / testing / temporary / lasttest . log <section> valid characters in lasttest . log <section> should be <code> <url> <section> linux <section> john n pham , northrop grumman",0.0
"<allcaps> osal </allcaps> tests fails under various conditions <section> osal_loader_ut would fail while running on the target , since the utmod / * files are not installed along w / the test executable to build / exe / * in addition , under certain circumstances , the following tests may fail , i . e . if another user has run the tests and files are left in / dev / shm ( the tests do not clean up the files ) : file - api - test select - test <section> for the first case , run test out of build / exe / [ cpu ] for the second case , run file - api - test / select - test once , chown the files under / dev / shm / <allcaps> ram </allcaps> [ n ] to some other user , and run again . <section> tests should succeed <section> should have an install line for the test modules here : <url> should test if actual directory is writable , not just if the parent tmp directory is writable , <url> this alone would not solve the issue though , just punt it to the next available tmp directory . you ' d probably also want to use mkstemp ( ) or similar to generate a randomly named directory under the tmp folder . <section> - linux <section> john n pham , northrop grumman",0.0
"typo in osapi . h <section> typo in osapi . h causes compilation failure when included into a c + + file <section> include osapi . h into a c + + file <section> successful compilation <section> the following line is missing its corresponding <code> and fails to build under c + + : <url> appears to be introduced in <url> <section> linux <section> john n pham , northrop grumman",0.0
""" select test "" still hanging <section> select test can still sometimes get stuck and hang forever . # <number> fixed one cause but this is a different way it can happen . it ' s caused because it is waiting for a subtask to finish but if for whatever reason that subtask never even starts , then it gets stuck waiting forever <section> run the test over and over until you see it happen . <section> test should never under any circumstance hang forever . <section> if applicable , add references to the software . <section> the ci <section> alex campbell <allcaps> gsfc </allcaps>",0.0
"output format string as debug message in os_printf stub <section> os_printf stub is silent , more helpful when debugging tests to see at minimum the format string <section> output the format string as a debug messae similar to cfe_evs_sendevent <section> could put in a hook , but this is general and useful enough to add <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"scrub <allcaps> api </allcaps> ' s for null pointer checks <section> all pointers should be checked for <allcaps> null </allcaps> prior to accessing , a few cases where this was observed have been fixed but need to do a complete scrub . <section> scrub and add any missing null pointer checks <section> none <section> use the new macros . <repeated> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"re - add static code analysis for pull requests <section> the travis ci runner ran cppcheck which we do not have anymore <section> submit pull request , notice that travis ci does not run anymore . <section> a success or failure report of a cppcheck run . <section> check from travis . yml <code> <section> n / a <section> part of ongoing travisci to github actions migration",0.0
"<allcaps> rtems </allcaps> <number> needs size_t type to build <section> there are a few methods that will not build in rtmes <number> because they use uint32 instead of size_t relevant files and line numbers : bsp_console . c <number> os - impl - network . c <number> os - impl - queues . c <number> , <number> os - impl - tasks . c <number> <section> build for <allcaps> rtems </allcaps> <number> per instructions and default config . build fails . <section> build should succeed . <section> ubuntu <number> as build host for <allcaps> rtems </allcaps> <number> . <number> <section> alex campbell <allcaps> gsfc </allcaps>",0.0
resolve cppcheck redundantassignment failure <section> running - <code> results in - <code> <section> resolve <section> none <section> travis ci no longer running on main repo <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add actions in workflow to replace former ci implementation <section> ci no longer running for pr ' s in nasa repo <section> implement ci as github actions <section> none <section> similar to transition in nasa / cfs <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
users guide generation warning <section> generated from user ' s guide action from cfs <code> <section> resolve warnings <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"update ut_setdefaultreturnvalue comment while i agree with the new function name , the comments are duplicated from the ( now deprecated ) <code> , i suggest a re - write of the comments for this important function . <url>",1.0
"<number> different ways of identifying file systems <section> unlike other <allcaps> osal </allcaps> resources , the file system related calls ( os_mount / unmount / mkfs / rmfs / initfs etc ) identify the target by string rather than as a numeric id . aside from being inconsistent , this is also ambiguous and confusing because the are actually <number> different possible strings use here : <number> . device name ( e . g . "" / ramdev0 "" ) <number> . volume name ( e . g . "" <allcaps> ram </allcaps> "" ) <number> . system mount point ( e . g . "" / dev / shm / osal : <allcaps> ram </allcaps> "" ) <number> . virtual mount point ( e . g . "" / ram "" ) furthermore not all functions use the same name . when implementing os_filesysstatvolume i noticed that the old os_fs ( bytes | blocks ) free ( ) and os_chkfs use virtual mount point ( <number> ) , while the others use device name ( <number> ) . the os_fs_getphysdrivename ( ) actually returns the system mount point ( <number> ) not the actual device ( <number> ) that other calls require . <section> ideally , change these apis to work with ids rather than names because ids are not ambiguous . one can also find / lookup an id based on any of the names ( lookup functions do not all currently exist but easy to add ) . <section> if <allcaps> api </allcaps> changes are not possible at this stage , then then we should at least be consistent and choose one name to use . probably the device name ( <number> ) should be the one , as it seems the one used by most calls currently . <section> the fact that <code> uses a virtual mount point should probably be considered a bug , as it implies the file system is already mounted at the time the call is done . most os ' s do not permit a file system check of a mounted device . <section> joseph hickey , vantage systems , inc .",2.0
"deprecate os_fsblocksfree and os_fsbytesfree <section> as noted in # <number> these functions return the value directly , which does double duty as an error code and therefore is limited to being <code> - but this type is not big enough for large file systems . <section> deprecate these functions in favor of <code> added in pr # <number> , which returns the information as a os_statvfs_t object containing all relevant information . <section> references to these functions within <allcaps> osal </allcaps> tests need to be fixed / replaced , as well as references in <allcaps> cfe </allcaps> / apps . this is a follow - on / completion of the fix for # <number> / pr # <number> . deprecation has to be done separately because the new function needs to exist before the refs can be changed . <section> joseph hickey , vantage systems . inc .",2.0
"fix # <number> , correct utassert_zero description typo <section> fix # <number> - typo fix <section> ci - comment change only <section> none <section> n / a <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"more test failures related to "" chmod "" implementation <section> the current <code> on <allcaps> posix </allcaps> has some issues / limitations : <number> . a while back this was changed from using the filename based calls to using a file descriptor , which "" protects "" against a theoretical issue where the file may get renamed while the operation is in progress . however this introduced a potential for a file descriptor leak - - if the <code> call fails , the <code> is returned , but the file descriptor is left open . <number> . any failure is reported as the generic <code> . <repeated> this should do a better job of translating the <code> to a more specific error code . in particular , not all file systems support unix - style file permissions - such as the very common fat32 / <allcaps> dosfs </allcaps> - and in this case the <code> call is likely to return - <number> with <code> set to something like <code> or <code> . <number> . also a file system can be mounted read only , which also prevents chmod ( ) from working . the main issue of <number> + <number> above is that the generic <code> code causes the chmod unit test to fail . <section> run the chmod test on vxworks using a <allcaps> dosfs </allcaps> mounted filesystem ( e . g . cf : <number> on the mcp750 test platform ) . <section> the chmod test cases should be skipped without failing the overall test in cases where the mounted file system does not support / allow permission to be changed . <section> vxworks <number> on mcp750 <section> so this is just a matter of translating the <code> values for these conditions into <code> instead of <code> , because the test is already implemented to check for and skip the rest of the test when it gets this return code . <section> joseph hickey , vantage systems , inc .",0.0
"race condition in "" select "" test <section> running the <allcaps> osal </allcaps> select test , i ran into a deadlock situation where the "" multi "" test got stuck and never finished . <section> hit or miss . <repeated> run test repeatedly on a system with other loads ( e . g . parallel builds ) <section> test should complete <section> checking the test status / backtrace it looks like two tasks ( main + "" server_fn "" ) are waiting on the binary sem . in particular the server_fn is stuck here : <url> while the main task is waiting in the teardown code ( the <code> has completed , and it has invoked <code> which in turn invokes <code> here ) : <url> <section> ubuntu <number> <section> this is likely related to the use of <code> . we should probably deprecate this function , as i cannot see how this can ever be used safely without it being a race condition . vxworks offers it which ( i think ) is why <allcaps> osal </allcaps> also offers it , but its a fundamentally broken concept . i can confirm that looking at the traceback in gdb , the flush_count is indeed already <number> - meaning the flush had already happened by the time the server_fn entered the bin sem take routine . <section> joseph hickey , vantage systems , inc .",0.0
"tests that use network stack do not run on <allcaps> rtems </allcaps> <section> the <allcaps> rtems </allcaps> network stack needs to be explicitly initialized in a platform - specific manner . however , the barebone / minimal <allcaps> bsp </allcaps> that runs the unit tests does not do this initialization . therefore when running the network tests , it just gives an immediate error : <code> <section> not clear at this point . the network init is quite board specific ( refers to a specific nic driver ) so probably does not fit as part of the <allcaps> osal bsp </allcaps> . suggest just documenting this limitation . <section> as the network tests only use the loopback address ( <number> . <number> ) it might be possible to bring up the <allcaps> rtems </allcaps> network stack with only this interface and no "" real "" nic . that might be a possibility to get these tests to run without making the <allcaps> bsp </allcaps> too complicated . <section> joseph hickey , vantage systems , inc .",2.0
"unlock globals during create / delete ops <section> for a number of resource create / delete operations , they may take some non - deterministic amount of time to execute in the system , and may require obtaining some type of mutex in the underlying c library too ( e . g . if something invokes malloc ) . this is especially true of creating and deleting tasks , which may need to malloc ( ) memory for the stack , and need to create a new task resource in the kernel . because of this , <allcaps> osal </allcaps> should not hold its own global table mutex while the whole operation takes place , as this will also prevent _other_ unrelated ops from completing . <section> these operations should reserve an entry in the table but mark it as reserved , not with a normal id ( so distinct from a normal entry ) . it can then unlock the global table and complete the non - deterministic parts of the operation , then re - lock when complete . <section> this is required for # <number> , already have it implemented but felt it was worth splitting into a separate issue / commit for tracking purposes . <section> joseph hickey , vantage systems , inc .",2.0
"replace remaining loops through all objects with iterators <section> previous changes introduced the concept of an iterator in the <allcaps> osal </allcaps> shared layer to iterate across all objects of a particular type . however there remains a few cases where code is still doing a "" for "" loop through each index . <section> for consistency of operation , these should be converted to iterators . <section> importantly the iterator handles locking of the global table . using the iterator ensures that this is done consistently , and provides the appropriate token object for any calls to other functions . <section> joseph hickey , vantage systems , inc .",2.0
"clean up inconsistent implementation of os_lock_global_impl / os_unlock_global_impl <section> only the "" shared "" layer invokes these impl ( low level ) apis - they are not invoked directly by applications , and the shared layer has already done its error checking . therefore they should never be invoked with a bad object type , and there is no recourse if the implementation fails . <section> - make sure "" shared "" layer is doing the appropriate scrubbing of object type before calling "" impl "" layer . - remove duplicate / unnecessary error checking in "" impl "" layer that was already performed at "" shared "" layer . - make "" impl "" functions return <code> - these should never fail , and there is no feasible recovery if they do . the only way they can fail is if they were not initialized properly . the os_debug message that is printed is the only recourse . <section> error checking should be consolidated at "" shared "" layer , layer whenever possible , as this keeps "" impl "" layer simpler , and also ensures that the same error checking is done on all platforms - so all platforms work the same . right now the error checking in these functions is not quite the same between <allcaps> posix </allcaps> / vxworks / <allcaps> rtems </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"build broken on <allcaps> rtems </allcaps> <number> <section> a recent change has broken the build for <allcaps> rtems </allcaps> ( again ) . these are printf format warnings . <code> appears to be added by pr # <number> . <repeated> <section> build for <allcaps> rtems </allcaps> <number> per instructions and default config . build fails . <section> build should succeed . <section> ubuntu <number> as build host for <allcaps> rtems </allcaps> <number> . <number> / pc686 <allcaps> bsp </allcaps> . <section> joseph hickey , vantage systems , inc .",0.0
"build broken for vxworks on <allcaps> rhel </allcaps> <number> <section> the newest <allcaps> rhel </allcaps> <number> comes by default with cmake version <number> . <number> in the official os repos . however the "" version_greater_equal "" comparison was added in <number> . thus the build became broken on this platform after merging # <number> . <section> attempt to build for vxworks using <allcaps> rhel </allcaps> <number> . x as the host platform . make file generation fails immediately with : <code> <section> build should succeed . <section> <url> <section> red hat enterprise linux workstation release <number> ( maipo ) <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , create <allcaps> osal </allcaps> security policy markdown <section> fixes # <number> created a draft of a security policy markdown file for <allcaps> osal </allcaps> . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"<allcaps> osal </allcaps> should separate task allocation from task activation <section> currently <code> both allocates and activates a task . however in embedded software it is often useful to pre - allocate a task - which creates the stack and id and anything else that might fail - but hold it stopped in the kernel scheduler while other initialization is completed . when the app is ready , it makes a separate call to activate the previously - allocated task . the benefit is that the activation step does not do any new allocation so it is very unlikely to fail ( simplifying error clean up ) , as well as being fast to execute as it just unblocks the task . most <allcaps> rtos </allcaps> ' s actually do it this way internally , where vxworks uses <code> followed by <code> , and <allcaps> rtems </allcaps> uses <code> followed by <code> . notably <allcaps> posix </allcaps> / pthreads does not separate these two actions , but easy to mimic / replicate via the new os_waitforstatechange ( ) function . <section> add two new functions : - <code> , similar to os_taskcreate but without starting the task - <code> , which starts the task the existing <code> becomes just a combination of the two . which it really as it is today anyway , but the two are coupled down in the <code> layer and therefore cannot be invoked separately in <allcaps> osal </allcaps> user applications . this would bring it up one layer and ( optionally ) allow the app developer to leverage it , if they want . <section> the "" timebase "" objects on vxworks also would benefit from having a separate allocate / start . <section> joseph hickey , vantage systems , inc .",2.0
"incorrect assertions in network - api - test <section> the test is not correctly checking the return value in a few places . for example : <url> <url> <section> make the subject code return something other than os_success or os_err_not_implemented . assert statement will still be true . <section> probably should be <code> <section> n / a - inspection <section> joseph hickey , vantage systems , inc .",0.0
"combine initialized and shutdown flags into one <section> the <allcaps> osal </allcaps> global state structure has two flags , one for "" initialized "" ( set during os_api_init ) and one for shutdown ( set during os_applicationshutdown ) . although similar in purpose , they are defined and work differently . <section> should combine these into just one state variable , which should be <number> prior to initialization ( i . e . such that the application loader provided by the os will zero it before <allcaps> osal </allcaps> loads ) , then set to a nonzero value for normal runtime , and another special nonzero value for shutdown . <section> just a suggestion for cleaning up / simplifying what is already there . <repeated> structure defined here : <url> using a full <number> bit value with all bits - even though there are only a few states - provides protection in case of a random bit flip . at least in the case of an application shutdown , the entire system operation should not be dependent on a single bit in memory . this is why the current "" shutdown flag "" is not just a simple <number> / <number> . so this should be preserved , but it should be trivial to combine this with the "" initialized "" field . <section> joseph hickey , vantage systems , inc .",2.0
"implement macro to facilitate argument checking <section> <allcaps> osal </allcaps> and <allcaps> cfe </allcaps> contain many argument checks at the beginning of functions . these would benefit from a macro to keep them consistent and readable in the application code , as well as offer alternative implementations / options for controlling how these are handled on an application - wide basis . <section> provide assert - style macros in <allcaps> osal </allcaps> that can facilitate argument checking , bug checking , and error handling . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , use errno in clock_getres error reporting <section> fix # <number> - now uses errno instead of status return from clock_getres with strerror reporting <section> built and ran unit tests on linux , which does not mean much since it does not include this code in functional or coverage testing . requesting retest from <user> - nasa <section> fixed error message <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"<allcaps> osal </allcaps> not reporting correct error string if clock_getres ( ) call in os_posix_timebaseapi_impl_init fails <url> from clock_getres man pages : > clock_gettime ( ) , clock_settime ( ) and clock_getres ( ) return <number> for success , or - <number> for failure ( in which case errno is set appropriately ) . the return value of <code> is just <number> or - <number> . if it returns - <number> in the event of a failure , it sets <code> , so the <code> line should use <code> , not <code> , otherwise it always reports : <code>",0.0
"file chmod test failing on <allcaps> rtems </allcaps> <section> when running unit tests against the latest baseline , there is a new failure on <allcaps> rtems </allcaps> : <code> <section> build with unit tests and execute on <allcaps> rtems </allcaps> <number> + pc686 + <allcaps> qemu </allcaps> as documented in <allcaps> readme </allcaps> . the chmod test fails . <section> test should pass . <section> <allcaps> rtems </allcaps> <number> . <number> , pc686 <allcaps> bsp </allcaps> , running in <allcaps> qemu </allcaps> <section> appears to be introduced in pr # <number> reinforces need ( again ) for ci script that runs the <allcaps> rtems </allcaps> build . <section> joseph hickey , vantage systems , inc .",0.0
"implement better wait for status change in vxworks / <allcaps> rtems </allcaps> <section> as a follow on to previous pr # <number> , this implements a new "" impl "" function which waits for a global table change to complete using an os - specific primitive . but only <allcaps> posix </allcaps> / pthreads was initially updated to use a proper wait primitive for this operation . for vxworks and <allcaps> rtems </allcaps> , these continue to use a simple unlock - task delay - re - lock and poll for the change . this works but can potentially introduce noticable extra / unnecessary delay . in particular , during task startup the parent task is using the accessing record at the same time the child starts up and also needs to access the same record . therefore the child task will hit this wait condition . on <allcaps> posix </allcaps> the child resumes immediately once the parent task has completed its use of the record . but currently for vxworks and <allcaps> rtems </allcaps> they must wait for the task delay to expire . <section> need to investigate / consider the various sync primitives that the os provides , and use something more appropriate that will not add extra unnecessary delay or polling . <section> keep polling . it is not "" broken "" in a strict sense - the contention should be resolved and the right thing will happen after the delay expires . it ' s just not what the user might expect ( that is , there might be a millisecond or two delay between os_taskcreate returning and the user task actually running ) . <section> <allcaps> rtems </allcaps> barrier might be an option . however i do not see any way to sync a barrier with a condition ( like a <allcaps> posix </allcaps> condition variable ) - so these leave open the possibility that the other task finishes its operation _just before_ the current task is about to wait - meaning it will end up waiting for an event that has already happened . but so long as a timeout is _also_ used , that means it will just fall back to the timeout - so if this happens its not worse than what is implemented now . originally discussed in review of # <number> at <allcaps> ccb </allcaps> <number> - <number> - <number> <section> joseph hickey , vantage systems , inc .",2.0
convert doc / <allcaps> osal </allcaps> - configuration - guide . doc to markdown <section> doc and <allcaps> pdf </allcaps> not github friendly <section> convert to markdown and remove doc / pdf <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"implement better way to wait for status change <section> if the object exists but is not in the correct state to access it , then the <code> will simply loop / retry the operation using <code> . this is not ideal and likely creates more delay than what is really needed . <url> <section> should use a proper primitive to wait until the underlying state changes and wake up the task immediately . <section> continue using polling w / task delays ( still an option for os types which do not have the proper primitive ) <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> posix </allcaps> unnecessarily setting signal masks in global lock <section> as part of the global lock the <allcaps> posix </allcaps> implementation is setting the signal mask of the parent process . however , the signal mask which is being set is the same mask that was already set in the parent process during the initialization . <section> n / a <section> the signal mask is already configured during initialization , so it should not be re - configured when locking / unlocking the global object tables . <section> locking : <url> unlocking : <url> <section> ubuntu <number> <section> i have investigated and i cannot find any justification for this anymore . in older versions of <allcaps> osal </allcaps> the signal ( s ) were not blocked and therefore e . g . <allcaps> sigint </allcaps> , <allcaps> sigalrm </allcaps> etc could be handled by any thread . in this design it was likely important to make sure that a timer / interrupt does not get processed while internal <allcaps> osal </allcaps> ops are being performed . but in the current <allcaps> osal </allcaps> design all of these signals are blocked initially in the main task - which all normal tasks then inherit . so this is only resetting the same mask that was already configured . <section> joseph hickey , vantage systems , inc .",2.0
"add a stand - alone example build with osal ( modernize src / examples / tasking - example ? ) <section> difficult for new user to set up a new trivial build using just <allcaps> osal </allcaps> . <section> helpful to include a simple cmake setup and a bare - bones c file to show simplest version of <allcaps> osal </allcaps> use . there ' s src / examples , but it ' s not set up to build / run out of the box . also update the instructions in the users guide . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> - stakeholder request",2.0
"osal core test is not a good example of how to write tasks <section> the <code> refers to task functions that are actually defined ( not just declared ) in <code> furthermore , these tasks just implement a tight loop : <url> multiple problems : <number> . against coding standards to implement code in a header . <number> . same function is defined <number> times . <number> . the task has no blocking statement at all , so it spins using <percent> cpu after it is started . <number> . on some operating systems ( e . g . <allcaps> posix </allcaps> ) , unless async task cancellation is enabled this also means the task also cannot be deleted , because it will never execute a cancellation point . although the <code> program passes and attempts to delete these tasks , in reality they keep running on <allcaps> posix </allcaps> and do not actually exit . <section> view in a debugger after creating + deleting these tasks - the threads are still there . <allcaps> cpu </allcaps> usage is also very high ( e . g . <percent> ) for the remainder of the test because these tasks are spinning and do not exit . <section> there is no need to redefine the same function . recommend to use the <code> function ( which already exists ) for all of these tasks . this function also uses <code> so it does not consume max <allcaps> cpu </allcaps> and also this serves as a cancellation point thus allowing the task to be deleted normally . <section> ubuntu <number> <section> this becomes a bigger issue when # <number> is done , as the tasks effectively are un - deletable . <section> joseph hickey , vantage systems , inc .",0.0
"add check of sem_wait / rtems_semaphore_obtain in console loop <section> console loop could spin if the semaphore returns error . <section> check for real errors ( not just interrupted ) , and exit loop if needed . <section> none . <section> mentioned in # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , exit console loop on shutdown <section> fix # <number> replaced condition on forever loops to end on shutdown . <section> built and ran unit tests for posix , built on vxworks ( planning to build on rtems using the latest setup instructions . <repeated> ) <section> - loop will exit on shutdown <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this change <section> what about also checking for a semaphore error on posix / rtems ( or at least non - interrupt ) ? would make it consistent with vxworks . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"incorrect parameter type in timebase sync callback <section> timebase sync callback prototype is currently defined as : typedef uint32 ( * os_timersync_t ) ( osal_index_t timer_id ) ; /* *< <user> timer sync */ but indices ( table position ) is an internal <allcaps> osal </allcaps> value that should not be used externally from <allcaps> osal </allcaps> . more importantly , it is easy to alias , and cannot be differentiated if an object is deleted and then created again . <section> use the full id value , not the index . so the prototype would be : typedef uint32 ( * os_timersync_t ) ( osal_id_t timer_id ) ; /* *< <user> timer sync */ <section> leave as is . <section> i was going to roll this into a larger change , but figured this technically qualifies as an "" <allcaps> api </allcaps> change "" so writing it as a separate issue for specific awareness . however , nothing outside of <allcaps> osal </allcaps> itself ( and the included tests ) actually implements a sync callback . psps could , but none currently do , so this really should not have any current impact to users . but if users do start using this option , better to have the full id value than just the index . <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> osal </allcaps> does not build cleanly with conversion warnings enabled <section> <allcaps> osal </allcaps> does not build cleanly if <code> warnings are enabled . in the <allcaps> cfe </allcaps> builds this warning is neither enabled nor disabled so it is left with the compiler default . most gcc cross toolchains currently used disable it by default , but with the toolchain provided in vxworks <number> this is enabled by default , so this difference becomes apparent . <section> first needs <allcaps> ccb </allcaps> discussion as to whether we want to be "" conversion clean "" . downside is that it requires a bunch of extra type casting for things that would normally work implicitly without issue - which makes code ugly - and the casts can become outtdated / stale if the underlying type changes and that does not always generate a compiler message but can cause problems due to multiple conversions and / or changing for equality of wrong types . so unnecessary extra type casts can be a real risk to behavior , not just readability . upside is that every now and then it will identify a truncation or sign conversion issue that might be a real problem . once decided one way or the other , we should explicitly set the <code> or <code> setting in <allcaps> cfe </allcaps> so that it is consistent and not dependent on compiler default . <section> originally identified in # <number> - split to separate issue ( not limited to just vxworks <number> - that ' s just what brought it up ) <section> joseph hickey , vantage systems , inc .",3.0
"consider limiting size of read / write / seek to int32_max <section> the <allcaps> osal api </allcaps> returns results as <code> , and this includes the size of data read / written from operations like os_read and os_write . however it is possible to read / write a larger buffer than what can be expressed as <code> . if this overflow happens then the result is likely to become negative and be interpreted as an error . <section> <code> and <code> should probably cap the amount they will transfer in a single call to be <code> . this should in turn limit the size of the result that would need to be returned to the caller . os_lseek ( ) returns the file offset , so this probably does not work with files bigger than 2 gb . <section> use a larger data type e . g . <code> as return , but this is potentially slow on <number> bit cpus where <number> bit values may need to be emulated by the c library . <section> if <code> ( buffer size parameter ) is <number> bits and the return value is <number> bits ( usable ) then there is a large set of potential values which are not representable . however - this problem has existed even when the input size was <code> rather than <code> . <repeated> because anything bigger than <code> is a problem - so this is not new , its just potentially more of a concern with large files . / file systems and <number> bit platforms . read / write actions should always be allowed ( per <allcaps> api </allcaps> ) to transfer fewer bytes than the request was for - app should retry with the remainder . so capping at <code> should not be a problem - no app should expect an extremely large transfer like that to happen in one go . <section> joseph hickey , vantage systems , inc .",0.0
"vxworks build failure in os_filechmod_impl <section> failure occurs on a vxworks <number> build : <code> looks like this was recently introduced in the <number> - <number> - <number> ic in via # <number> . <repeated> <section> build for mcp750 / vxworks <number> platform using standard method and default config . <section> build succeeds . <section> looks like vxworks <number> does not implement <code> per <allcaps> posix </allcaps> specs - it only has the <number> argument form ( with mode ) and not the <number> argument form . <section> vxworks <number> <section> hopefully we can get a ci that includes vxworks . <repeated> <section> joseph hickey , vantage systems , inc .",0.0
"vxworks stack address calculation should use unsigned type <section> the vxworks task create implementation calculates a stack base address which involves adjustment such as rounding and accounting for whether the stack grows up or down ( per vxworks requirements of <code> . this does the calculation as integers , and currently uses the <code> type . the risk is that if the address happens to lie in the negative range of this type , then the rounding / adjustments may need to go in the opposite direction . <section> the address calculations should use <code> instead of <code> just to ensure that all rounding and base address adjustments behave the same way in the event that the addresses lie in the upper half of memory ( i . e . start with a <number> bit ) which would put it in the negative range of a <code> type . <section> this is really just a suspicion of a possible issue - can not really confirm / test because we do not have direct control of where these stack buffers get allocated in memory . but either way using <code> would be more correct anyway - and would simply avoid the possibility that the operation works differently depending on its value . it probably used <code> in the first place only because that is what the arguments to <code> are declared as . <section> joseph hickey , vantage systems , inc .",0.0
"os_chmod is requiring read access <section> if you do not have read access to a file then os_chmod will not be able to change it . this is most likely caused by chmod opening the file as a way to avoid filename race potential , see the code snip . <section> <number> ) set the file access to write only . <number> ) try to change the access using os_chmod <number> ) will get an os_error <section> you should be able to change the permissions of a file without read access . <section> <url> <section> ubuntu <number> <section> alex campbell <allcaps> gsfc </allcaps>",0.0
"incorrect call to os_objectidcompose_impl in os_timerdelete <section> <allcaps> osal </allcaps> has an incorrect setting of <code> when deleting timers . <url> the second argument to <code> is a serial number , not a table index . these are only the same value until table entries start to be re - used , after this they become different , and this will start to fail . this should really not be using <code> at all here . <section> - create and delete several timebases - at least <code> - such that table entries start to be re - used . - create another valid timebase for the test ( do not delete ) . - create at least two timers based on this timebase - delete one of the timers . at this point the id in the timebase callback ring ( <code> member ) may refer to an invalid entry - a timebase id which does not exist . <section> should look up the <code> from the actual table entry instead - do not re - compose the id , because <code> is a table index , not a serial number . <section> ubuntu <number> <section> it is only possible to trigger this after a rather extensive sequence of creating and deleting these resources . so this is probably unlikely to ever occur in a real system where timers are typically created and run forever . should still be fixed though . this was initially discovered by enforcing type - safety in the <code> and <code> - during this scrub it revealed that this was passing an <code> to a function which is supposed to accept a serial number . so type safety = good . <section> joseph hickey , vantage systems , inc .",0.0
"scrub <allcaps> osal </allcaps> for direct array references <section> in <allcaps> osal </allcaps> there are quite a few places with direct array references to an index , such as : <url> in many functions this is repeated many times over ( i . e . makes several accesses into the table entry for the given item ) . <section> this should be separated to use local pointer ( s ) to the entry / entries in use . first do a lookup , e . g . : stream = osal_table_entry ( os_stream_table , local_id ) ; then use <code> to refer to that entry from there on , e . g . : if ( stream - > socket_type ! = os_sockettype_stream ) <section> this makes the code a lot more readable and more maintainable . the <allcaps> cfe </allcaps> was already scrubbed for this , so it makes sense for <allcaps> osal </allcaps> to also do the same . <section> joseph hickey , vantage systems , inc .",2.0
"some "" close "" operations not doing standard delete procedure <section> all close / delete ops should go through <code> so things are cleaned up consistently . but there remain a couple places where this is not done - <code> and its variants e . g . <code> and <code> <section> this is apparent if there is some action in the <allcaps> psp </allcaps> handler for deallocation . it will not get invoked for these close ops because it does not go through the common delete path . <section> should go through common path . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"os_taskexit ( ) on vxworks causes task table owner to be the deleted task <section> os_taskexit ( ) calls os_objectidfinalizedelete ( ) . this function sets the task ' s record - > active_id to <number> , which is also being used as the task id on vxworks . objectidfinalizedelete ( ) subsequently calls os_unlock_global , which errors out and does not clear the owner , as the task id is now zeroed out and does not match the owner of the table . this does not occur on linux <section> steps to reproduce the behavior : on vxworks , call cfe_es_exitchildtask with osal_config_debug_printf enabled <section> error message should not be printed out <section> <url> <url> <url> <url> <section> - sp0 - os : vxworks <number> - versions : <allcaps> cfe </allcaps> <number> , <allcaps> osal </allcaps> <number> . <number> - rc1 + dev16 , <section> see attached screenshots for stack traces image <img> image <img> <section> john n . pham , northrop grumman",0.0
remove os_pack define <section> should not use non - standard packing options . really should scrub the list . <url> <section> remove / scrub <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"os_taskdelete is not synchronous on <allcaps> posix </allcaps> <section> the current <allcaps> posix </allcaps> implementation of <code> uses <code> . this is a cancellation _request_ but the target thread continues to run until it hits a cancellation point . as a result , when the os_taskdelete ( ) function returns , it is likely that the target thread is actually still running for a short period of time . but if the intent is to actually unload the module , as is done in the <allcaps> cfe </allcaps> "" restart "" and "" reload "" commands , it is critical to ensure that all uses / references to code within the to - be - unloaded module have actually been released . so it is important to make sure that the cancellation request has been executed and the task is actually deleted before proceeding to the <code> call . currently with the <allcaps> posix </allcaps> implementation , there is no way to guarantee this , so this becomes a race condition during restart / reload operations on this platform . <section> not directly reproducible in current code - this race condition is currently masked by the fact that modules are loaded with <code> , so if the runtime loader still sees the module being referenced using its internal refcount , it does not actually unload it when <code> is called . so in this case the task finishes up normally and there is no apparent problem . but when this is fixed - such as when using <code> as suggested in # <number> - then this race condition becomes a problem , and as a result a <allcaps> cfe </allcaps> reload or restart command sometimes triggers a segmentation fault in the event that <code> gets called before the task has fully been deleted . <section> <code> should ensure that the task has been fully removed , not just pending removal , before it returns to the caller . suggestion to achieve this : - keep threads in the attached ( joinable ) state by default - use <code> to wait for the cancelled task to actually exit . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"add os_moduleload flags to indicate symbol table visibility <section> on <allcaps> posix </allcaps> platforms with a real dynamic loader / shared object implementation , using the <code> flag to dlopen ( ) can make it tricky or impossible to unload modules later . this flag makes the symbols globally available to satisfy other relocations , and unloading of the module will be deferred or prevented entirely as long as the runtime loader thinks a symbol is being used . this ultimately causes a requirement failure on this platform as documented in nasa / cfe # <number> - because the module is not _actually_ unloaded when <code> is called , and even though the new / replacement app module was loaded , <allcaps> cfe </allcaps> will end up restarting the original code , not the new ( reloaded ) code . loading a module with <code> instead seems to prevent this issue - because the symbols are simply not made available for other modules / entities to use . this ensures that when the time comes to unload the module , nothing else is referencing the module , and <code> actually does unload it . but this <allcaps> local </allcaps> flag cannot be used for all modules , because libraries do need their symbols added to the global table , or else it will not be possible to load apps that depend on those libraries <section> add a "" flags "" parameter onto the existing <code> <allcaps> api </allcaps> , so it becomes : int32 os_moduleload ( osal_id_t * module_id , const char * module_name , const char * filename , uint32 flags ) the "" flags "" parameter can be used to indicate the symbol visibility . a flag value of <number> should map to "" global "" - which is what the current implementation does - to make an easy transition for existing code . in order to be able to look up an entry point in a module loaded with this option , this necessitates another new <allcaps> api </allcaps> : int32 os_modulesymbollookup ( osal_id_t module_id , cpuaddr * symboladdress , const char * symbolname ) which is the same as <code> but accepts a module id value and operates on that module , rather than on the global scope . this should be the id that was returned from the os_moduleload call . for <allcaps> rtos </allcaps> implementations that do not have this symbol visibility option they can ignore the flag , continue to map everything into the global symbol table as they currently do , and <code> and <code> become equivalent . <section> note that most all other <allcaps> osal </allcaps> "" create "" functions ( tasks , queues , semaphores , etc ) already have a "" flags "" parameter on the <allcaps> api </allcaps> , reserved for future use . unfortunately , this flags parameter was not part of the original <code> <allcaps> api </allcaps> definition , making it an exception to the pattern . so by adding this , although it is a breaking change , it makes it more consistent with the rest of the apis . the alternative would be to define a separate <code> <allcaps> api </allcaps> , but this pattern does not exist anywhere else , so it would continue to be an exception with respect to the overall <allcaps> osal api </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> osal </allcaps> configuration guide - osal_includedir not found <section> the <allcaps> osal </allcaps> configuration guide mentions osal_includedir in section <number> . <number> , variables that must be specified . this <allcaps> cmake </allcaps> variable is not found in any files nor reported issue . <section> update the <allcaps> osal </allcaps> configuration guide if osal_includedir is no longer in use . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"os_moduleunload ( ) for statically loaded module may segfault <section> calling <code> on a statically loaded module will still attempt to call <code> but the handle is <allcaps> null </allcaps> because no module was loaded . at least on linux / glibc this actually causes a segmentation fault . <section> using the <allcaps> cfe </allcaps> framework switch any app ( e . g . sample_app ) from a regular dynamic app to a static app . build and run <allcaps> cfe </allcaps> , then shutdown with <allcaps> ctrl </allcaps> + c . the shutdown ends up calling <code> which in turn will trigger this bug - one gets a segfault instead of a clean exit . <section> should shutdown cleanly . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"more consistent types for <allcaps> osal </allcaps> resources <section> <allcaps> cfe </allcaps> issue nasa / cfe # <number> describes mismatched types used across <allcaps> cfe </allcaps> for certain items , such as stack size and priority of tasks . to help resolve this <allcaps> osal </allcaps> should provide a typedef for the "" right "" types to use when interfacing with <allcaps> osal </allcaps> . <section> should add at least : - <code> - type used for <allcaps> osal </allcaps> task priority - <code> - type used for <allcaps> osal </allcaps> stack pointer <section> this will identify the correct type to use , instead of the mishmash currently seen in <allcaps> cfe </allcaps> as described in nasa / cfe # <number> . <section> joseph hickey , vantage systems , inc .",2.0
resolve sem_value_max not defined test issue <section> was a <allcaps> fixme </allcaps> : <url> <section> address / disposition as an issue . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
file / socket can be closed while actively inside a os_selectmultiple ( ) call in another thread <section> converting <allcaps> fixme </allcaps> into an issue : <url> <section> address / disposition as an issue . <section> none <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , update utassert macros with dynamic string formatting <section> changed all utassert macros to take variable string arguments , feature request # <number> <section> steps taken to test the contribution , cfs / main branch commit 2 0 0 9 7 ef64e455ace25a1535ea43090a739eb7c0c : <url> <number> . make clean <number> . make enable_unit_tests = <allcaps> true simulation </allcaps> = native <number> . make test <number> . all cfe unit tests pass <section> a clear and concise description of how this contribution will change behavior and level of impact . utassert_true wrapper around call will no longer be necessary to accommodate dynamic string output , thus removing the double assert . utassert macros will now be able to offer more information by themselves . <section> pc , <allcaps> rhel </allcaps> <number> <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",2.0
"in utassert . h allow all utassert macros to use utassertex and __va_args__ for dynamic output strings <section> i have to add utassert_true as an outer shell to any of the asserts that do not use dynamic arguments . <section> update all the macros ( except for utassert_simple ) to use utassertex as the base function , removing description and adding __va_args__ . <section> utassert_true wrapper around calls , but this results in two asserts per check which is unnecessary . <section> wrote up the change and did not see any issues while building or running tests . <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",2.0
"fix # <number> , apply standard formatting <section> fix # <number> - apply standard formatting <section> build / run unit tests , all pass . <section> none , whitespace only <section> - hardware : cfs dev server - os : ubuntu <number> - versions : current bundle w / this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"apply standard formatting <section> various formatting styles in codebase <section> apply standard formatting , if it ' s an improvement then submit for fasttrack ( minimize impacts to open work ) . if standard format requires hand mods , update such that application of standard format in the future does not require repeat modification . <section> leave as - is if not an improvement . <section> preparation activity for certification code review . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add os config option for fast mutexes <section> currently <allcaps> osal </allcaps> always creates recursive mutexes , with no option to control this . <repeated> normal or non - recursive mutexes are more efficient than recursive mutexes . <section> add an os config compile time option to elect "" fast "" or non - recursive mutexes . <section> this is a follow - on to issue # <number> <allcaps> cfe </allcaps> currently will not run with non - recursive mutexes due to known issues . but as long as the default remains to be recursive mutexes , then this option can be added for future use without breaking anything . obviously this option could not be enabled for <allcaps> cfe </allcaps> until the known issues are fixed . <section> joseph hickey , vantage systems , inc .",2.0
"add os_debug warning if task locks a mutex multiple times <section> as noted in nasa / <allcaps> cfe </allcaps> # <number> , there are cases in <allcaps> cfe </allcaps> where a mutex may be taken by the same task more than once . this is technically allowed because <allcaps> osal </allcaps> enables recursive mutexes for all supported os types . but my concern is that : - recursive mutexes are not guaranteed to be provided - i . e . some minimal <allcaps> rtos </allcaps> ' s might not have this facility at all . - if recursive mutexes are provided , they are slower than the normal ( non - recursive ) counterpart . - anything that depends on recursive mutexes generally indicates deeper code design flaws - i . e . insufficient separation of internal vs . external apis , function loops , circular subsystem dependencies , etc . <section> start by introducing an <code> warning if the same task takes a mutex more than once . this can help identify the issues , and it is very easy to add . it also will not be displayed unless <allcaps> osal </allcaps> is compiled with debug messages enabled . <section> a future / follow up change , once dependencies on recursive mutexes are fix , could be to allow the user to optionally elect to use non - recursive / fast mutexes via an osconfig option . <section> joseph hickey , vantage systems , inc .",2.0
"freertos port hi , it seems that you only provide the <allcaps> osal </allcaps> for linux , rtems and vxworks . however you regularly mention freertos in your documentation . do you plan to share the sources for the freertos port ? not sure the amount of work such operation require and the limitations ( especially concerning the file system ) . it would be great to have more information about this point . thanks in advance ! <section> jonathan michel , master student at the university of applied science of western switzerland working on <allcaps> chess </allcaps> <url> .",3.0
"update <allcaps> rtems </allcaps> osal to use osal_id_t typedef <section> while fixing # <number> i noticed that the <allcaps> rtems osal </allcaps> is still using <code> for its ids . <section> this should be changed to use the <code> typedef instead . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> rtems </allcaps> build broken <section> needs updates to fix issues related to <code> - missing prototype - references to old function prototype still exist in some <allcaps> rtems </allcaps> source files . <section> build default configuration for <allcaps> rtems </allcaps> <number> . fails to compile with errors such as : <code> <section> should compile cleanly . <section> ubuntu <number> ( host ) cross buiding for <allcaps> rtems </allcaps> <number> . <number> / pc - <number> <allcaps> bsp </allcaps> <section> typo noted in # <number> but there are more problems than just that . <repeated> <section> joseph hickey , vantage systems , inc .",0.0
"fixed typo in rtems binsem timeinticks variable name <section> this addresses a typo in the rtems os - impl - binsem . c file for a variable name . fixes <url> <section> compiled using rtems toolchain , but not run on hardware . <section> prior to this change , compilation failed for an rtems platform . the code should now compile for rtems . <section> - hardware : dell latptop ( build machine ) - <allcaps> aac </allcaps> sirius ( host machine ) - os : ubuntu <number> ( build machine ) - <allcaps> rtems </allcaps> <number> ( host machine ) - versions : <allcaps> osal </allcaps> main <section> adam st . amand - personal",0.0
typo in <allcaps> rtems </allcaps> binsem . c variable name <url> i believe the line is meant to read the following : <code>,0.0
"add support for vxworks <number> <section> cfs traditionally has supported vxworks <number> . there are projects interested in using vxworks <number> with cfs , so support must be added . this requires work in <allcaps> psp </allcaps> and <allcaps> osal </allcaps> . <section> an ideal solution is to support both vxworks <number> and <number> with as little cloning of old vxworks <number> as possible . on <allcaps> psp </allcaps> , the current work is to copy mcp750 - vxworks for the working platform . ( <number> ) <allcaps> osal </allcaps> ' s goal is to have the vxworks osal support both <number> and <number> . <section> <section> <section> steven seeger / embedded flight systmes , inc . / <allcaps> gsfc </allcaps> code <number>",2.0
"add <allcaps> osal </allcaps> debug messages for cases where multiple error conditions result in the same return code <section> there are multiple functions in which multiple error conditions result in the same return code . for instance , in os_filerename_impl , the return code os_error is used for any failure of the rename ( ) function . this obscures the cause of the error and makes debugging more challenging . <section> add an os_debug statement in these cases to provide additional information ( such as errno value ) describing the specific cause of the error . <section> alternatives include : - adding unique return codes - > this would greatly bloat the number of return codes . - using some kind of future event mechanism ( see <allcaps> osal </allcaps> # <number> ) <section> <section> elizabeth timmons / <allcaps> nasa gsfc </allcaps> code <number>",2.0
"add support for <allcaps> rtems </allcaps> <number> - <allcaps> rtems osal </allcaps> and pc - rtems <allcaps> osal bsp </allcaps> updates <section> the cfs bundle currently supports <allcaps> rtems </allcaps> <number> . now that <allcaps> rtems </allcaps> <number> has been released , i would like to update the necessary components to support <allcaps> rtems </allcaps> <number> on the pc - rtems platform . this involves minor modifications to the cfe repository , the <allcaps> psp </allcaps> repository , and the <allcaps> osal </allcaps> repository . these changes can be done in such a way that preserves the current <allcaps> rtems </allcaps> <number> support and adds <allcaps> rtems </allcaps> <number> support . <section> i would like to add support for <allcaps> rtems </allcaps> <number> while maintaining compatibility with the existing <allcaps> rtems </allcaps> <number> support . for the <allcaps> osal </allcaps> repository there are a few minor changes needed to allow support of <allcaps> rtems </allcaps> <number> and <allcaps> rtems </allcaps> <number> : - minor changes in the <allcaps> osal </allcaps> pc - rtems <allcaps> bsp </allcaps> - minor changes in the <allcaps> rtems osal </allcaps> implementation files <section> alternatives include : - not supporting newer versions of <allcaps> rtems </allcaps> , but several projects will depend on <allcaps> rtems </allcaps> <number> support . - dropping <allcaps> rtems </allcaps> <number> support and just making the changes needed for <allcaps> rtems </allcaps> <number> , but there may be projects that depend on <allcaps> rtems </allcaps> <number> . we can consider dropping <allcaps> rtems </allcaps> <number> support on a future release . <section> <section> alan cudmore / <allcaps> nasa gsfc </allcaps> code <number>",2.0
"cast - align warning in os_taskgetid_impl for vxworks <section> <code> recreate by building on ubuntu <number> , set <code> in <code> and prep with <code> <section> resolve warnings . <section> none <section> observed on ubuntu <number> w / cast - align = strict <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , add ut_assert address equal macro <section> fix # <number> - adds the macro <section> used the macro in work related to nasa / cfe # <number> ( built and ran unit tests locally using it ) <section> additional macro available <section> - hardware : cfs dev server - os : ubuntu <number> - versions : main bundle + this commit <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add ut_assert address equal macro <section> address equal macro would be handy . <section> add it . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , remove os_tick2micros and internalize os_milli2ticks <section> fix # <number> - removed os_tick2micros implementation , tests , stubs , references - moved prototype from <allcaps> api </allcaps> to internal for os_milli2ticks - updated os_milli2ticks to return status - added check for rollover in os_milli2ticks - os_milli2ticks now sets and limits ticks as int - updated all internal use of os_milli2ticks to check for error and returns immediately on error ( will not wait maximum amount ) - coverage tests updated to check for new error cases - os_milli2ticks stub updated ( default implementation ) <section> built and ran unit tests , all pass , coverage maintained ( although not <number> due to previous lapses , see # <number> ) <section> <allcaps> api </allcaps> ' s no longer exposed . <repeated> no known uses identified so should not be an impact <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
code coverage for shared dropped below <percent> ( again ) <section> shared / src / osapi - common . c : os_deleteallobjects missing coverage shared / src / osapi - idmap . c : os_objectidfinalizedelete not covered <section> <number> . add coverage back in <number> . enforce <percent> coverage in ci <section> at minimum add coverage back . <repeated> ci really should enforce or we will keep missing code coverage . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"utassert_zero in utassert . h doxygen brief incorrectly states nonzero <section> what appears to be a copy paste error , the assert zero states it is checking for nonzero . this mimics the assert nonzero brief above it . <section> <url> <section> state "" confirm an integer value is zero "" instead . <section> see above . <section> n / a <section> n / a . <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",1.0
"<code> should be a signed type <section> <code> is used for <allcaps> osal </allcaps> coverage testing to replace the c library <code> type as used in e . g . <code> this is being substituted with an unsigned type , but really should be a signed type . <section> suggested change in pr # <number> exposes the mismatch : <url> coverage test fails due to later comparison for ( result < <number> ) which is impossible with unsigned type . <section> ubuntu <number> <section> using <code> instead fixes it . <section> joseph hickey , vantage systems , inc .",0.0
"<allcaps> ttf </allcaps> ( test teardown failure ) not reported in individual or full test summary <section> <allcaps> ttf </allcaps> only indicated during the test run , not included in the individual or full summary . <section> include <allcaps> ttf </allcaps> in summaries <section> <allcaps> fail </allcaps> / <allcaps> tsf </allcaps> / <allcaps> ttf </allcaps> are all failures . <repeated> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"promote the internal <code> function to the public <allcaps> api </allcaps> <section> currently <allcaps> osal </allcaps> only provides a public <allcaps> api </allcaps> for <code> which operates indiscriminately on any object type . for instance , if passed a task id , it returns a value in the range of <code> and if passed a queue id it will return a value in the range of <code> and so forth . but code using this function is using it to index an array of a specific object type ( e . g . tasks ) . so this creates an opportunity for error if passed the wrong object id - the caller may get a successful conversion but still get an index that is beyond the range of their local table . <section> the <code> function is better because it first enforces that the passed - in id actually refers to the intended object type . the public <allcaps> api </allcaps> is actually just a wrapper around this that _defeats_ the type check . for some reason this got relegated to an internal <allcaps> api </allcaps> . <section> keep as is , accept risk of getting an index outside the expected range if ids get mixed . <section> as the function already exists it should be just a matter of putting its prototype into the public <allcaps> api </allcaps> , and providing a ut stub for it ( easy ) . <section> joseph hickey , vantage systems , inc .",2.0
"add tracking for order of stub calls during a unit test <section> it can sometimes be important to know that calls in a function are done in a proper order ; i . e . ability to verify that a message is timestamped before it is sent . <section> an addition that allows a stub to report that it was called to a central location and this information accessible to a unit test for verification . add this to the default stub implementation , but have it be available to stubs that do not use the default . <section> write local hooks for all stubs used in unit testing that use a local version of this concept . <section> example of situation that requires this : <code> <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",2.0
"add functional test for "" one - shot "" timer <section> spawned from the conversation on # <number> . <allcaps> api </allcaps> documentation specifies behavior that is not covered by the current functional tests ( one - shot ) . <section> add a one - shot timer test <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"es reports version <number> . <number> in hk telemetry , when built off a development branch <section> misidentifies version <section> look at version in es housekeeping packet . <section> system should report a consistent version number at startup , from noops , and in tlm . could go back to the old way where development versions all report a revision of <number> . <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle . <section> got out of sync with new versioning scheme <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"possible <allcaps> osal </allcaps> bug in os_filesysaddfixedmap not allowing fs_based mapping on vxworks <section> unable to add a arbitrary filesystem path mappings with os_filesysaddfixedmap <section> call os_filesysaddfixedmap w / parameters & fsid , "" / "" , "" / "" , and it ' ll fail <section> entry added to os_filesys_table <section> it looks like the error code from line <number> is propagated improperly to line <number> instead of just being used to set flags on <number> , causing the finalization step to fail . <url> <section> - sp0 - s - os : vxworks <number> - <allcaps> cfe </allcaps> <number> . <number> + dev292 , <allcaps> osal </allcaps> <number> . <number> + dev247 , <allcaps> psp </allcaps> <number> . <number> + dev76 ( w / additions for sp0 - s ) <section> attempting to add a mapping to / for netbooting off of <allcaps> ftp </allcaps> on sp0 - s <allcaps> psp </allcaps> . mapping / cf / to / cf / used to work earlier this year . in addition , os_filesys_findvirtmountpoint appears to fail to map to "" / "" if it ' s in the table ( although i suppose it ' s not desirable to map / in production anyway , since it ' d override all other mappings ) . <section> john n pham , northrop grumman",0.0
"ut_assert header files not included in ' make osalguide ' <section> when building the osal guide with ' make osalguide ' the ut_assert header files are not included <section> steps to reproduce the behavior : <number> . make osalguide <number> . browse guide , no ut_assert files present <section> ut_assert files included in osal guide <section> <url> <section> <allcaps> rhel </allcaps> <number> <section> adding : <code> after osconfig - example in the above code includes ut_assert headers in the guide . <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>",1.0
"[ <allcaps> moved </allcaps> ] document nested usage of ut_add_test and clarify nomenclature for individual versus groups of tests # # describe the problem the <code> call has some limitations as addressed in nasa / cfe # <number> . some solutions are discussed in that pr . # # proposed solutions <number> . have <code> handle "" nested "" unit tests , or <number> . develop a nomenclature for unit test functions that explicitly indicates whether there are nested unit tests and then rename unit tests accordingly , or <number> . document the anti - pattern , or <number> . split up all unit tests to ensure only one test per function and make this a design pattern . # # additional context _originally posted by <user> in <url> > related to nasa / osal # <number> . individual tests are added w / the ut_add_test call . some tests are grouped at a lower level ( test_msg_ccsdsext is a group of tests ) , and those functions are called directly . same pattern is used in <code> : > > <url>",0.0
"adding unit tests from with a unit test not a supported pattern <section> possibly related to # <number> ( reverted to v5 . <number> - rc1 and they ran ) . adding tests after starting to run tests ( adding a test within a test ) is not a supported pattern , and they will not actually get run ( they do get added to the front of the individual list , but the merged test list does not not handle them ) . <section> add a unit test from within a unit test , build / execute and the added unit test will not execute . <section> did not know <allcaps> not </allcaps> to do this . <repeated> just do not do it . <section> just do not do it . document limitations and proper usage . <section> uttest . c - see the adding and merging <section> - hardware : cfs dev server - os : ubuntu <number> - versions checked latest integration candidate and v5 . <number> - rc1 , problem does not exist in v5 . <number> - rc1 <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
utassert_message doxygen comments should include params <section> there are no param items listed in the utassert_message method in utassert . h <section> n / a <section> add param descriptions . <section> <url> <section> <allcaps> rhel </allcaps> <number> <section> n / a <section> alan gibson <allcaps> nasa gsfc </allcaps> / <number>,1.0
"os_fsblocksfree returns a <number> - bit value , but os_statvfs_t . blocks_free is <number> bit os_fsblocksfree returns a <number> - bit value , but os_statvfs_t . blocks_free is <number> bit .",0.0
"filesize in os_fstat_t is uint32 , should be 6 4 bit friendly filesize in os_fstat_t is uint32 , but should be off_t like in <allcaps> posix </allcaps> . on <number> - bit systems . it ' s a <number> - bit value and this causes conversion issues .",2.0
"time and timeouts have no consistent type in <allcaps> osal </allcaps> in <allcaps> osal </allcaps> , time and timeouts are represented typically by both int32 or uint32 . this convention is used in many places . it might make sense to have a consistent type for time . perhaps even absolute and relative time . there are wconversion issues with uses of these types .",2.0
"os_statvfs_t types do not match corresponding <allcaps> posix </allcaps> types when building for <number> - bit , wconversion shows issues with os_statvfs_t ' s types . they do not match the types in struct statvfs on <allcaps> posix </allcaps> systems . it may be worth a discussion to change these types of just handle the conversions in the specific implementation .",2.0
"sysconf can return - <number> on error in posix / src / os - impl - tasks . c sysconf ( ) is used . its storage is into a type size_t , but sysconf ( ) can return - <number> . we should change the storage to ssize_t to accommodate this , or we should check for - <number> and then store a non - negative value to posix_globalvars . pagesize . sysconf ( ) should not return - <number> when passed _sc_pagesize , so this may be low priority .",0.0
"os_taskprepare should propagate return code . <section> in the internal <code> routine , it calls a low - level implementation routine but does not propagate the return code . <section> more theoretical than real . in <allcaps> posix </allcaps> this depends on the underlying <code> routine returning an error , of which the only documented error ( at least per <allcaps> posix </allcaps> ) is <code> . however that does not mean that there could not be other implementation - specific errors on other systems . <section> if the <code> fails , this result should be propagated up the stack and prevent the task from starting . <section> see here : <url> <section> <section> if this fails then it means dependent routines like <code> will also be broken , so it really should block startup of the task and return the error to the caller . catching this type of error early , when possible , is usually better than getting an obfuscated error later . <section> joseph hickey , vantage systems , inc .",0.0
"consolidate cleanup code into a separate "" finalizedelete "" routine <section> all <allcaps> osal </allcaps> objects share a basically common pattern for finalization after creation and deletion . for creation the finalization was consolidated into a <code> routine , but the deletion finalization is basically repeated as it only involved clearing a single global . <section> even though deletion is currently trivial , it is beneficial to consolidate this code as it could become less trivial , as in issue # <number> <section> this was split from # <number> this is a necessary prerequisite in order to implement any sort of common / generic handling without repeating the code everywhere . it also makes deletion more of a mirror - image of creation , which is really the way it should be . <section> joseph hickey , vantage systems , inc .",2.0
"remove <allcaps> osal </allcaps> deprecated code for next release <section> now that the "" <number> . x "" release branch has been created , the next release should remove all code / functions that are currently marked as deprecated . <section> removal of all code currently contained within an <code> conditional compile switch . <section> the removal only applies to "" main "" branch - not the <number> . x release branch , where it will continue to exist for that release series . this assumes the next release ( main ) will become version <number> . there are other changes currently in development which do break some deprecated items - hence why i ' d like to remove this sooner rather than later , as it saves the work of updating / fixing this old code if the intent is to remove it anyway . <section> joseph hickey , vantage systems , inc .",2.0
"ut_setforcefail is a misnomer <section> ut_setforcefail assumes that the value given , that is being set as return value , is a fail condition . there may be sometimes that a function returns more than <number> value that is not considered a fail . <section> use in a unit test where there is a stubbed function with more than <number> "" successful "" return value . <section> change to something like ut_setforcedreturnvalue to make it more generic . <section> n / a <section> <allcaps> rhel </allcaps> <number> <section> not a required or debilitating situation , but a name change may be make the function ' s effects more clear . <section> alan gibson <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps> / <number>",0.0
"cleanup - remove os_objectidmap / unmap internal prototypes <section> the functionality provided by os_objectidmap and os_objectidunmap has been replaced by other functions and these are neither used nor defined in the current <allcaps> osal </allcaps> , but they are still declared / prototyped in <code> <section> remove unused / leftover prototypes <section> joseph hickey , vantage systems , inc .",2.0
"deprecate os_open and os_creat <section> for historical / backward compatibility reasons , the <allcaps> api </allcaps> of these two functions does not follow the typical flow . rather than providing a <code> id output buffer as the first argument with a separate int32 return code , they return the <allcaps> osal id </allcaps> cast as an <code> on success . for these functions , the caller is expected to check if the result is negative , and if so , consider it an error code . whereas if it is non - negative , the caller is expected to cast it back to a <code> type and interpret it as an <allcaps> osal id </allcaps> . <section> these should be like all other <allcaps> osal </allcaps> apis and pass back the id separately from the return / error status . <section> leave as is . but these two functions present a challenge when making a distinct type for <allcaps> osal </allcaps> ids . <section> in the current implementation , . these are just compatibility wrappers anyway . they both call <code> internally , which provides both open ( existing file ) and creat ( new file ) based on the flags it was passed . the <code> function _does_ follow the correct pattern so one option would be to just expose this to the public <allcaps> api </allcaps> . the other option is to create a new version of os_open and os_creat which follow the correct pattern . but in order to provide a transition they would have to use different names . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> osal </allcaps> should provide a typedef for "" id "" values <section> the <allcaps> osal api </allcaps> uses <code> type to identify objects / resources in an abstract way . <section> there should be a typedef for this . for instance : typedef uint32 os_id_t ; this typedef can then be used in all apis rather than using <code> directly . <section> keep using <code> . <section> providing a typedef is generally accepted as good practice in terms of future proofing the code . this would not change anything immediately , as the type will remain <code> as it currently is . <section> joseph hickey , vantage systems , inc .",2.0
"lengthen allowable unit test names <section> not sure if it is a bug , but why is the testname length based upon os_max_api_name * <number> in utglobal . h ? <section> steps to reproduce the behavior : <number> . write a unit test with a name longer than os_max_api_name * <number> <number> . run tests and see that the test name is truncated <section> provide enough space for long ( descriptive ) test names . <section> <url> char testname [ os_max_api_name * <number> ]; <section> - pc - rhel <number> - current ' master ' branch <section> this is only an issue because i use long descriptive test names . <section> alan gibson <allcaps> gsfc </allcaps> , code <number>",3.0
"use a changelog to keep track of changes instead of having them in the readme <section> the version history in the readme file clutters useful information <section> move the "" version history "" from <code> to <code> and start following this spec : <url> <section> move changelog section in the readme to a section at the very bottom of the file <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
doxygen warning : file argument matching multiple files <section> doxygen produces multiple ambiguous file warnings when building the documentation using <code> at the bundle level . for example : ` ` <code> os - impl - binsem . h ' supplied as the second argument in the \ file statement matches the following input files : / cfs / cfs / osal / src / os / posix / inc / os - impl - binsem . h / cfs / cfs / osal / src / os / rtems / inc / os - impl - binsem . h / cfs / cfs / osal / src / os / vxworks / inc / os - impl - binsem . h please use a more specific name by including a ( larger ) part of the path ! ` ` <code> sample_defs <code> ` <code> ` <code> cfs / build / doc / warnings . log <code> ` <code> ` <code> ` <code> ` ` <section> ubuntu running on docker <section> none <section> gerardo e . cruz - ortiz,1.0
"add uttest_teardown ( ) to ut_assert <section> i would like to have a "" teardown "" that runs at the end of the unit tests test - runner file . much like the uttest_setup runs at the start . <section> add a uttest_teardown ( ) that is called after all the tests have run . <section> not having it , which is the current state . <section> this is a common feature with most unit test frameworks . <section> alan gibson <allcaps> nasa </allcaps> goddard code <number>",2.0
"ut_assert - typo in readme , some clarifications of stub functions <section> there ' s a typo in the ut_assert readme , plus some of the stub function comments are not very clear and could use a bit of cleanup . <section> <email>",1.0
"documentation updates <section> <number> . in osapi - os - net . h , os_socketaccept lists addr as an [ in ] parameter where as it is an [ out ] parameter . this is where a new connection ' s incoming address is stored as an output to the function call and is not an input to the function . ( file location : osal / src / os / inc / osapi - os - net . h ) <number> . in osapi - os - core . h , os_taskcreate notates the input parameter "" stack_size "" as "" stack_size : the size of the stack , or <number> to use a default stack size "" . a <number> input here is not valid and should be appointed an appropriate stack size . ( file location : osal / src / os / inc / osapi - os - core . h ) <number> . in osapi - os - filesys . h , os_timedread / os_timedwrite . while the documentation is clear that these functions are used primarily with sockets , it is unclear how a socket may be used as an input parameter . the first input parameter "" filedes "" is notated as "" the handle id to operate on "" but i think it would be prudent to add an additional comment to explain that this is also the socket id . perhaps these two functions should also be defined with the rest of the network functions in ( osal / src / os / inc / osapi - os - net . h ) instead of with functions used for file operations ( osal / src / os / inc / osapi - os - filesys . h ) for further specified use and clarity . it was not easily clear on how to send messages back and forth between a <allcaps> stream </allcaps> connection , as it is with <allcaps> datagram </allcaps> connections . ( file location : osal / src / os / inc / osapi - os - filesys . h ) <section> cfs dev server os : ubuntu <number> versions : <allcaps> osal </allcaps> <number> . <number> <section> add any other context about the problem here . <section> yasir majeed khan <allcaps> nasa gsfc </allcaps> / emergent space",1.0
<allcaps> datagram </allcaps> network function os_socketsendto segfault <section> os_socketsendto ( ) segfaults when passed in <allcaps> null </allcaps> for remote address ( last parameter ) and all the other parameters are valid . <section> cfs dev server os : ubuntu <number> versions : <allcaps> osal </allcaps> <number> . <number> <section> y . m . k . emergent,0.0
"add os_getmoduleidbyname ( ) to return id of a module given the name <section> if es loads a module ( such as a library that an app uses ) , but an app wishes to unload that module , that app has no way to find the id to send to the unload function . <section> add an os_getmoduleidbyname ( ) function that returns ( via an out param ) the id of the module given its name . <section> <email>",2.0
"<allcaps> osal </allcaps> event callback framework for platform - specific handling <section> many platforms support extra non - standardized features , but <allcaps> osal </allcaps> cannot make use of these . this includes items such as setting the processor affinity in a multi - processor system , or propagating the user - friendly task name at the os level , as was suggested in # <number> . <section> an event callback framework could help solve this problem , allowing those platform - specific features to be invoked from the <allcaps> psp </allcaps> / <allcaps> bsp </allcaps> layer while keeping <allcaps> osal </allcaps> itself standards - compliant . <section> use <code> conditional compiles for platform - specific features ( ugly and not as maintainable ) . <section> joseph hickey , vantage systems , inc .",2.0
"incorrect install / staging location for coverage test binaries <section> typo in cmake file - the loop variable when installing coverage binaries is <code> but the <allcaps> destination </allcaps> refers to <code> . <section> build with multiple cpus sharing the same target + platform config . <section> binaries should be installed for everything in install_target_list . <section> <url> <section> ubuntu <number> <section> the <allcaps> cfe </allcaps> scripts also do set <code> in other places so it by chance had a leftover value that happened to be the same thing , and therefore this would not be noticed when building for a single target ( the default case ) . <section> joseph hickey , vantage systems , inc .",0.0
"overall tests pass even with a <allcaps> tsf </allcaps> <section> the software is set up such that overall tests pass even if there is a test case that <allcaps> tsf </allcaps> . i have had individual tsfs , and yet the overall tests showed everything passed . see code here : <url> <section> cfs dev server os : ubuntu <number> versions : <allcaps> osal </allcaps> <number> . <number> <section> y . m . k . emergent",0.0
"new buffer size warning in ut assert <section> after moving the utassert_dotestsegmentreport ( ) function , it has triggered a new warning when building with optimization enabled ( <allcaps> buildtype </allcaps> = release ) . <code> <section> build with gcc9 + and <code> flag . <section> should build cleanly . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"vxworks os_countsemcreate unit test fails <section> the os_countsemcreate unit test , "" # <number> initial - count - too - high "" , fails . this is because the vxworks <allcaps> osal </allcaps> , as written , does not check the initial count . rather , it passes it directly to the os call . <section> it should pass . <section> - aitech sp0 - s - os : vxworks <number> - <allcaps> osal </allcaps> <number> . <number> - bv <section> mathew benson windhover labs",0.0
"scrub all <allcaps> osal ut </allcaps> stub functions <section> need to scrub all <allcaps> osal </allcaps> unit test stub routines , similar to nasa / cfe # <number> but for <allcaps> osal </allcaps> . <section> - all functions prototyped in the <allcaps> osal </allcaps> public <allcaps> api </allcaps> headers ( the <code> dir ) should also have a stub defined . - all arguments should be registered in the context so the complete context is available within ut hook functions . - the argument names should always match the prototype . <section> joseph hickey , vantage systems , inc .",2.0
os_api_init ( ) failure due to <number> stack size <section> os_api_init ( ) fails on generic - linux due to a stack size of <number> being used for the console task . <section> <number> . build the provided example using the ' generic - linux ' <allcaps> bsp </allcaps> . <number> . execute the provided example . <section> the three test tasks should execute . <section> os_api_init ( ) fails with the following error message ( debug messages enabled ) : <code> <section> the error occurs on the following call to pthread stack size in os_posix_internaltaskcreate_impl ( <sad> <code> the reason it fails is because the stacksz is set to zero in os_consolecreate_impl ( <sad> <code> <section> - hardware : dell precision <number> laptop - os : wsl2 ubuntu <number> . <number> <allcaps> lts </allcaps> - versions : <allcaps> osal </allcaps> master <section> this issue is resolved by using a stack size of pthread_stack_min instead of <number> : <code> <section> adam st . amand,0.0
"copyright / license update for current master <section> copyright / license update for current master , relative to apache <number> approval <section> update . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
copyright / license and <allcaps> readme </allcaps> update for <number> release <section> old markings and documents need to be updated for release <section> update <section> n / a <section> n / a <section> jacob hageman <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"release processing <number> . <number> <section> license and readme updates to version <number> . <number> fix # <number> <section> nominal unit test and build from bundle . see <allcaps> vdd </allcaps> in cfs for full test description of release . <section> no impact , header and document updates <section> - hardware : cfs dev server - os : ubuntu <number> - versions : <number> bundle <section> switched to apache <number> license <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"second parameter of pthread_mutex_timedlock should be absolute time not timeout in src / os / posix / src / os - impl - binsem . c , there are three calls to pthread_mutex_timedlock , each time with & os_posix_binsem_max_wait as the second parameter where os_posix_binsem_max_wait has a value of <number> seconds . because the second parameter of pthread_mutex_timedlock should be an absolute time and is not a timeout , if the mutex is not immediately available , pthread_mutex_timedlock will return with <allcaps> etimedout </allcaps> resulting in the os_binsemflush_impl , os_genericbinsemtake_impl , or os_binsemgive_impl call returning os_sem_failure . here ' s a code snippet of the "" as is "" : if ( pthread_mutex_timedlock ( & sem - > id , & os_posix_binsem_max_wait ) ! = <number> ) { return ( os_sem_failure ) ; } it should look something like : struct timespec timeouttime ; clock_gettime ( clock_realtime , & timeouttime ) ; timeouttime . tv_sec + = os_posix_binsem_max_wait . tv_sec ; timeouttime . tv_nsec + = os_posix_binsem_max_wait . tv_nsec ; if ( pthread_mutex_timedlock ( & sem - > id , & timeouttime ) ! = <number> ) { return ( os_sem_failure ) ; } reproducing this issue is tricky as the cfs application has to run long enough to have a mutex not immediately available for the lock . the behavior i am seeing in my installation is the background task terminates and ctrl - c can no longer be used to terminate the application . i am running in a centos <number> virtual box machine . jonathan c . brandenburg <allcaps> metecs </allcaps> <email>",0.0
"use of hardcoded numbers for bad ids in <allcaps> osal </allcaps> unit tests <section> some unit tests pass a hardcoded magic number i . e . <number> to <allcaps> osal </allcaps> functions to evoke a bad id error , such as the case here : <url> as the <allcaps> api </allcaps> does not specifically dictate what constitutes a good id vs . a bad id , there is a possibility that in some <allcaps> osal </allcaps> implementation this value <code> might actually be a valid id . this is a concern for black box tests which are supposed to be implementation - agnostic , but need to validate that the correct error is returned when called with a bad id . <section> the <allcaps> osal api </allcaps> should define macro to provide a value which is guaranteed to always be a valid id . unit tests can use this symbol instead of the magic number . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> osal </allcaps> unit tests terminate before the console thread prints the results <section> most of the <allcaps> osal </allcaps> unit tests terminate before the console thread is allowed to execute and write the results to the console . <section> steps to reproduce the behavior : <number> . build with unit tests , i . e . the initial build created using the instructions in the cfs repository . <number> . run the unit tests manually , not with ctest . ctest hides the console output anyway . <section> running osal_core_ut should look like : <code> instead , depending on the timing of the target under test , you might see : <code> <section> the easiest fix is to add : <code> to the end of the function "" void ut_os_teardown ( const char * testsuitename ) "" in file "" ut_os_stubs . c "" . this will ensure the caller thread pends for long enough time ( hopefully ) for the console thread to release and complete printing to the console . however , this is not <percent> bullet proof since it still relies on the console thread starting and completing the print in the time provided to the os_taskdelay ( ) function . for example , if you are stepping through code with your debugger inside the os_consoleoutput_impl ( ) function on the last call in the unit test , you have <number> seconds to get whatever information you need to get before the process is terminated . <section> - virtualbox virtual machine - ubuntu <number> - <allcaps> osal </allcaps> <number> . <number> - bv <section> most platforms ( all platforms i know of ) use a separate , kernel created thread , to print to the console already . the <allcaps> osal </allcaps> provided console thread just adds a third thread to <number> already existing threads . i am not sure why the additional thread needed to be added . but if it wasn ' t there , this problem is resolved by calling fflush , which pends until the output has successfully been sent out . aside from making the <allcaps> osal </allcaps> more complicated , i am not sure what problem the new console thread is solving . <section> mathew benson owner windhover labs , <allcaps> llc </allcaps>",0.0
"vxworks <number> does not provide <code> type <section> a new compiler error has appeared on the vxworks - <number> build : <code> <section> build using the vxworks <number> toolchain <section> should build successfully <section> vxworks <number> , gcc <number> . <number> on gs582w - cfelnx lab machine . <section> joseph hickey , vantage systems , inc .",0.0
"idmap <allcaps> api </allcaps> test needs to use real task stack size and priority <section> although linux allows the stack size to be zero ( it uses a nonzero default ) other os ' s do not have this fallback . the <code> attempts to create a task with zero stack and this fails on <allcaps> rtems </allcaps> . <section> run ' idmap - api - test <code> os_taskcreate ( ) ` fails ( reports as <allcaps> tsf </allcaps> ) but then other failures occur related to this . <section> should pass . <section> <allcaps> rtems </allcaps> <number> . <number> running in <allcaps> qemu </allcaps> . <section> should consider forcibly making every os fail ( i . e . enforce in shared layer ) if passed a zero stack . <section> joseph hickey , vantage systems , inc .",0.0
"time base <allcaps> api </allcaps> test introduced new format warnings <section> new warnings noted when building for <allcaps> rtems </allcaps> : <code> <section> build code using <code> toolchain . <section> should build cleanly . <section> cross compile for <code> on ubuntu <number> host . <section> needs cast whenever fixed - width types are used with printf . <section> joseph hickey , vantage systems , inc .",0.0
"add int32 ut assert macro <section> a very common use case in unit testing is to assert on an <code> value , as this is a common return value type for error codes and status values . ut assert provides a generic <code> macro which can certainly test for integer equality , but it is still very repetitive and test cases may not include all the relevant information . for instance , the framework should encourage / require that the actual values are printed in addition to the pass / fail status , and the generic macro being totally free - form does not enforce this at all . <section> add a macro <code> to check for equality of two values as <code> types . other types could be added too , but <code> is by far the most commonly needed as it is the return type of many <allcaps> api </allcaps> calls across <allcaps> osal </allcaps> and <allcaps> cfe </allcaps> . <section> continue using the generic <code> macro . <section> many test programs already use their own macros for testing return values . they have already evolved to be similar but different ( e . g . <allcaps> cfe sb </allcaps> has <code> , and <allcaps> osal </allcaps> coverage testing has <code> ) . it would be worthwhile to put more of these in ut assert itself so these do not need to continue being duplicated . <section> joseph hickey , vantage systems , inc .",2.0
"offer secondary target for ut assert library that can be dynamically loaded <section> the current ut assert is designed to be statically linked as an <allcaps> osal </allcaps> application . to support a <allcaps> cfe </allcaps> functional test environment that uses the same ut assert reporting methods , the library should offer a target that can be linked as loadable module . <section> the differences are : - compile as position independent code ( <allcaps> pic </allcaps> ) so it can be linked into a dynamic module . - separate out the os_application_startup and os_application_run - as this will be loaded into a larger app , not a standalone app , and these symbols are already defined . - consolidate global variables into a common structure and make early init / reset of these variables into a separate routine from os_application_startup . <section> this dynamically - loadable variant can be a separate target , so it should not change anything about the existing apps / tests that link with the existing static "" ut_assert "" library . <section> joseph hickey , vantage systems , inc .",2.0
"linux <allcaps> bsp </allcaps> should not trim first argument <section> as part of command line processing the logic for linux <allcaps> bsp </allcaps> is to prune the first argument which is the command name , to be consistent with other ( e . g . <allcaps> rtems </allcaps> ) platforms that do not pass the command name to begin with . however the <allcaps> cfe psp </allcaps> passes the argument list to the c library <code> and this expects the first argument to be the command name , so this breaks . <section> pass arguments ( e . g . <code> - i ` to force a test failure on the spacecraft id value and it did not work . <section> joseph hickey , vantage systems , inc .",0.0
"file descriptor signed or unsigned ? <section> os_open ( ) returns an int32 file descriptor , os_socketaccept ( ) takes a uint32 pointer for the file descriptor . they should be the same type . ( the socket code should probably use / take int32 . ) <section> <email>",2.0
"missing stub function for os_filesysaddfixedmap <section> coverage unit tests being added for the <allcaps> psp </allcaps> will likely require a stub of this function . <section> provide the stub function as part of the <allcaps> osal </allcaps> stub library <section> n / a - all public <allcaps> api </allcaps> functions should have ut stubs . this one was overlooked / missed . <section> joseph hickey , vantage systems , inc .",2.0
"race condition in new idmap tests <section> the <code> routine occasionally fails , because it creates one of its semaphores in a sub task , but does not actually wait for that sub task to run . <section> run idmap test , in particular a single core machine seems to reproduce it more reliably . <section> need to add a wait loop of some type in main task to make sure child task has executed . <section> task started here : <url> might want to employ a loop similar to what is done here to make sure the child task has executed : <url> <section> centos <number> vm ( single core ) <section> joseph hickey , vantage systems , inc .",0.0
documentation - - objectid architecture description <section> would be good to put some words / pictures into the doxygen documentation ( or . md ? ) describing the way object id ' s are managed in <allcaps> osal </allcaps> . <section> <email>,1.0
"document that <code> id of new obj is > <number> <section> the os_ <obj> create ( ) functions always generate an id as an "" out "" parameter and that id is always > <number> when the creation succeeds . this is useful as users of these <allcaps> api </allcaps> ' s as they can assume <number> is not a valid id ( such as in arrays or variables that are not always referring to valid objects . ) <section> should describe , in the comments for all os_ <obj> create functions , that id will always be > <number> . <section> <email>",1.0
"ut assert argument name association <section> ut assert passes "" static "" function arguments to hook functions as an array of opaque pointers , based on the order of calls to the <code> <allcaps> api </allcaps> inside the stub . this is basically equivalent to argc / argv on a command line . this requires test cases to "" know "" which position the argument they need to access is in , and basically hard - code that number . this could become more problematic if hook functions are used more frequently . <section> offer a variant of <code> that also stores the argument name , and offer a "" getter "" that a hook function can use in order to get by that name . registering and retrieving values by name will provide greater stability as the apis and test cases evolve over time . the downside is that its slower and uses more memory to look up based on name , but that does not matter much for ut . <section> leave as is using number / sequence based args . it works but concerned it ' s too easy to get out of sync . <section> could also use some macros to make both the register ( stub - side ) and get ( hook - side ) operations a little more user - friendly . <section> joseph hickey , vantage systems , inc .",2.0
"add shared layer <allcaps> api </allcaps> for handling global mutex <section> currently the shared layer calls <code> and <code> directly when locking / unlocking the internal tables within <allcaps> osal </allcaps> . this does not offer a place to : - check return code of operation - track ownership of resource in case of not being freed . <section> should implement <code> and <code> wrappers at the shared <allcaps> api </allcaps> level , which can provide a common place to check status , handle failure , and track resource usage . <section> in # <number> , the global table lock was correctly returning an error but nothing ever checked the return code . rather than adding a specific return code test everywhere this is used , simpler and better to add a wrapper . <section> joseph hickey , vantage systems , inc .",2.0
"global lock for "" timecb "" objects missing <section> the internal table mutex for the timer callback ( timecb ) object type is missing / not implemented . this leave a potential race condition as timer callbacks are registered . <section> not observed in real execution at this time - but theoretically possible if two timers are registered by two tasks at the exact same time . <section> should be protected . <section> ubuntu <number> <section> the global lock table is simply missing an entry for this object type . <section> joseph hickey , vantage systems , inc .",0.0
"scrub reference counting for possible task deletion issues <section> the <allcaps> osal </allcaps> shared layer employs a reference counting scheme for long running / blocking operations , such as file read / write , and socket operations . this reference count prevents deletion while these operations are still in progress . however , the possibility exists that the task is deleted while this operation is occurring , which means the reference count may never get decremented . <section> whenever possible / relevant , the <allcaps> osal </allcaps> should "" wrap "" the long running operation in a cancellation cleanup handler as was done for binary sems in # <number> . for <allcaps> posix </allcaps> , this may be needed for anything that invokes a cancellation point : - read / write / open / close ( files ) - send / recv / connect / accept ( sockets ) - select - mq_receive / mq_send ( queues ) <section> leave as - is and accept a risk that there may be dangling references when tasks are deleted . <section> there is no way for the <allcaps> osal </allcaps> to know about and handle inter - relationships between resources that the application may impose ( i . e . using a mutex to control access to a shared memory or a reference count of its own ) and therefore this cleanup / recovery can never be bulletproof . while <allcaps> osal </allcaps> could potentially do better at handling its own reference counts in the context of task deletion , there will still be other remaining risks of unreleased resources after tasks being deleted for things it cannot track . <section> joseph hickey , vantage systems , inc .",2.0
"order of operations on os_deleteallobjects <section> os_deleteallobjects ( ) is used when shutting down the system , such as after an exception , a commanded processor restart , or <allcaps> ctrl </allcaps> + c , etc . this simply deletes resources based on their numeric <code> value , meaning tasks ( <number> ) are first , followed by queues , bin / count , semaphores , mutexes , etc . and eventually timers ( <number> ) . a recent issue described in nasa / cfe # <number> observed a potential problem with this . as the task and semaphore are deleted , a timer could still be running . if that timer executes during shutdown , it may interrupt the deletion , and attempt to use semaphore objects . normally this should not be an issue because <allcaps> osal </allcaps> will return an error and reject the call . however due to an underlying issue in binary semaphores (# <number> ) after task cancellation , this caused deadlock . <section> it would be preferable to delete timers first , then tasks , then semaphores , files , and other resources . this should be a safer ordering in general , as it will reduce the potential for resources to be used as they are being deleted . <section> leave as - is . <section> the real fix for # <number> prevents deadlock , this is just more future - proofing . <section> joseph hickey , vantage systems , inc .",2.0
"binary semaphore locked after thread cancellation <section> on <allcaps> posix </allcaps> systems using the binary semaphore <allcaps> api </allcaps> , there is a risk that threads can become deadlocked after deleting a task that was executing an <code> <allcaps> api </allcaps> call . <section> - create two tasks and one binary semaphore . - task a calls <code> at some event / interval . - task b waits on the binary sem using <code> then delete task b while it was pending in <code> . the semaphore resource is now inoperable , because the condition mutex was "" owned "" by task b at the time it was deleted , and is never released , thereby preventing any other task from using the mutex . <section> the semaphore should continue to be usable by other tasks after deleting task b . <section> ubuntu <number> <section> this was originally reported / observed in nasa / cfe # <number> , during shutdown where timers were used . <section> joseph hickey , vantage systems , inc . ( after diagnosis / investigation of issue reported by <user> in above ticket )",0.0
"update unit tests to provide consistent directory map <section> the "" file - api - test "" and "" osal_loader_ut "" unit tests rely on a real fs_based directory map that is provided by the <allcaps> bsp </allcaps> . this creates an undesired dependency on the <allcaps> bsp </allcaps> volume table in these test cases , in that they must provide a map for <code> . <section> test should be <allcaps> bsp </allcaps> - agnostic . a map for the directory used by the test case can be provided locally as part of this test setup . a relative system directory can be used ( e . g . "" . / test "" ) to make this platform - agnostic . <section> this will allow to run unit tests without a <allcaps> bsp </allcaps> - provided volume table . <section> joseph hickey , vantage systems , inc .",2.0
"update <allcaps> rtems </allcaps> implementation to dynamically create <allcaps> ram </allcaps> disk block devices <section> the current <allcaps> rtems bsp </allcaps> predefines the <allcaps> ram </allcaps> disks by way of the <code> which is set at compile time . however the <allcaps> osal </allcaps> model is to create these block devices at runtime based on memory segments that are allocated externally . the workaround up to this point was to preallocate the ram disks , and then attempt to correlate the address in the os_mkfs / initfs request to one of the preallocated blocks . however this is not possible when the compile - time config and ramdisk allocation are done by separate libraries ( <allcaps> bsp </allcaps> and <allcaps> cfe psp </allcaps> , respectively ) . <section> <allcaps> rtems </allcaps> can support dynamically - created <allcaps> ram </allcaps> disks using <code> which better aligns with the way things are supposed to work . <section> this is necessary as part of decoupling the volume / filesystem table from the <allcaps> osal bsp </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"improve <allcaps> abort </allcaps> handling in <allcaps> rtems </allcaps> unit test <section> if an unit testing error occurs that causes the test to abort , the implementation just calls the system <code> function . in <allcaps> rtems </allcaps> , this causes the entire system / kernel to shutdown . this leaves no ability to use the shell to check the system state or diagnose what went wrong . <section> defer handling of the abort to the <allcaps> bsp </allcaps> . in <allcaps> rtems </allcaps> , when the shell is available , this should just suspend the calling task to stop the tests , allowing the shell to continue being used . <section> this used to be the case , but probably an artifact of merging the <allcaps> ut bsp </allcaps> with regular <allcaps> bsp </allcaps> that this got lost in translation , and it only shows up if an abort failure occurs . fairly trivial / easy to add it back in though . <section> joseph hickey , vantage systems , inc .",2.0
"filesystem should differentiate between fs_based ( known ) and unknown filesystem types <section> the existing <code> type is used to cover basically any filesystem mapping that does not directly fall into the other categories ( e . g . normal_disk , volatile_disk , etc ) . this includes the traditional <code> types , which just map to another existing place in the filesystem . <section> the code should provide a unique value for <code> maps , which is a valid mapping type , as opposed to not knowing what mapping is being used . <section> distinction between known fs types and unknown types is required for running without volume table in <allcaps> bsp </allcaps> . <section> joseph hickey , vantage systems , inc .",2.0
"filesystem using wrong length for device_name field <section> the <code> field within the <code> is using a length of <code> , which is not correct / ideal . <section> the length should be <code> <section> this is an existing symbol defined in the <code> public <allcaps> api </allcaps> header file . noted when working on <allcaps> bsp </allcaps> volume table removal . <section> joseph hickey , vantage systems , inc .",0.0
"improve error code on <allcaps> rtems </allcaps> os_stat ( ) implementation <section> depending on the filesystem in use , the <allcaps> rtems </allcaps> <code> call might not be implemented at the filesystem level . in particular if it is called on the <allcaps> imfs </allcaps> filesystem type , it returns an error and sets errno to <code> . <allcaps> osal </allcaps> translates any error here to <code> , which is what gets returned to the application . ultimately this causes the filesystem unit test to fail when this filesystem type is in use . <section> preferable to return <code> in this case . in particular , unit tests already check for this , and will skip the test cases for this <allcaps> api </allcaps> , avoiding failure . this makes it a soft error . <section> joseph hickey , vantage systems , inc .",2.0
"portable select ( ) implementation needs to check filehandle "" selectable "" flag <section> not all file handles support the <code> <allcaps> api </allcaps> - - in particular on <allcaps> rtems </allcaps> it only works on sockets . the file implementation layer contains a boolean flag <code> for every file handle to indicate whether the file descriptor can be select ' ed upon . the implementation of this layer needs to confirm / check that the <code> flag is true before calling this <allcaps> api </allcaps> . <section> run the new <code> <allcaps> api </allcaps> unit tests on an <allcaps> rtems </allcaps> platform , which call this <allcaps> api </allcaps> on regular files . when it does so , this actually causes an exception and results in kernel panic / abort . <section> <allcaps> osal </allcaps> should return os_err_not_implemented or otherwise avoid calling <code> on filehandles which the kernel does not handle properly . <section> <allcaps> rtems </allcaps> <number> . <number> via <allcaps> qemu </allcaps> / pc686 <allcaps> bsp </allcaps> . <section> kernel panic result here is rather extreme - - one would have expected that the select ( ) call would simply return error and set an errno as usual . this probably also signifies an underlying bug in <allcaps> rtems </allcaps> . <section> joseph hickey , vantage systems , inc .",0.0
"add alternative source directory option for <allcaps> osal </allcaps> implementations <section> the <allcaps> osal </allcaps> build script always looks for <allcaps> bsp </allcaps> implementations in : <code> likewise it always looks for os implementations in : <code> this presents a challenge to for a user with a custom os / <allcaps> bsp </allcaps> implementation not within the mainline <allcaps> osal </allcaps> source tree , but wishes to use the github repo directly . <section> it should be possible to provide an external directory that the <allcaps> osal </allcaps> build can use . <section> create an <allcaps> osal </allcaps> fork or "" git subtree "" to assemble a full <allcaps> cfe </allcaps> / <allcaps> cfs </allcaps> repo , which allows one to add custom packages or patches they need . <section> the internal <allcaps> api </allcaps> between the <allcaps> bsp </allcaps> / os implementation components is not stabilized like the public <allcaps> api </allcaps> is , and can change any time . if directly using a "" master "" branch from github in conjunction with a locally - controlled implementation module , users may experience frequent breakage , as the component interface can change any time rendering it incompatible with their local version . in contrast , although the fork / subtree approach does have a similar issue , it does not happen "" automatically "" - it requires a specific user action to pull and merge the new "" master "" so it creates a buffer that avoids unsolicited breakage . this feature should come with a big disclaimer that says its for debug / development only , not to use it in production . <section> joseph hickey , vantage systems , inc .",2.0
"make bsps more generic <section> users requiring custom <allcaps> psp </allcaps> packages should not need to create both - - a <allcaps> cfe psp </allcaps> and <allcaps> osal bsp </allcaps> . the existing <allcaps> osal bsp </allcaps> should be used whenever possible . the "" mcp750 - vxworks "" <allcaps> bsp </allcaps> ( at least ) is not particularly hardware - specific and should be usable on any vxworks platform . likewise "" pc - linux "" should be usable on any generic linux platform . the main purpose of the <allcaps> osal bsp </allcaps> is just to provide an entry point to get into the common / modular code . <section> rename these bsps to be generic and allow use by many psps . <section> user needs to add a custom <allcaps> bsp </allcaps> for each board . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add check against os_max_queue_depth <section> the <code> function will now sanity check the depth parameter against the configured os_max_queue_depth value . if it is too large , an error will be returned . this is a hard limit and independent of the "" permissive "" mode . the os_max_queue_depth should be configured to the largest value that an application may reasonably request . fix # <number> <section> confirm <allcaps> cfe </allcaps> framework starts and operates normally ( but see nasa / to_lab # <number> ) confirm <allcaps> osal </allcaps> unit tests pass <section> <code> will return an error code if the depth parameter is larger than the configured <code> . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"more doxygen warnings <section> further doxygen warnings should be resolved <section> steps to reproduce the behavior : <number> . build documentation using <code> <number> . observe warnings in <code> <section> no warnings should occur <section> the currently observed warnings are recurring . we should baseline best practices so that these do not continue to recur <section> leor bleier , <allcaps> nasa gsfc </allcaps> \ code <number>",0.0
"os_converttoarrayindex and os_timebasegetfreerun <allcaps> segfault </allcaps> when passed in a <allcaps> null </allcaps> pointer <section> os_converttoarrayindex and os_timebasegetfreerun <allcaps> segfault </allcaps> when passed in a <allcaps> null </allcaps> pointer as the second input instead of handling the <allcaps> null </allcaps> pointer and returning an error . <section> steps to reproduce the behavior : <number> . checkout branch fix374 - <number> - object - utilities - missing - tests in osal <number> . go to path : cfs / osal / src / tests / idmap - api - test <number> . build and run with the following in the main function : os_converttoarrayindex ( bin_sem_id , <allcaps> null </allcaps> ); <number> . checkout branch fix380 - add - timebase - api - functional - tests <number> . go to path : cfs / osal / src / tests / time - base - api - test <number> . build and run with the following in the main function : os_timebasegetfreerun ( time_base_id2 , <allcaps> null </allcaps> ); <section> os_converttoarrayindex and os_timebasegetfreerun <allcaps> segfault </allcaps> when passed in a <allcaps> null </allcaps> pointer , should handle the <allcaps> null </allcaps> pointer and return an associated error code . <section> ( path : cfs / osal / src / tests / idmap - api - test ) uint32 bin_sem_id ; os_binsemcreate ( & bin_sem_id , "" binsem "" , <number> , <number> ); actual = os_converttoarrayindex ( bin_sem_id , <allcaps> null </allcaps> ); expected = os_err_incorrect_obj_type ; utassert_true ( actual = = expected , "" os_converttoarrayindex ( ) ( % ld ) = = % ld "" , ( long ) actual , ( long ) expected ); output : the following tests <allcaps> failed </allcaps> : <number> - idmap - api - test ( <allcaps> segfault </allcaps> ) <section> cfs dev server os : ubuntu <number> versions : <allcaps> osal </allcaps> <number> . <number> <section> yasir khan <allcaps> nasa gsfc </allcaps>",0.0
<hashtag> include </hashtag> < sys / signal . h > from os - posix . h causes compiler warnings in alpine linux <section> when trying to build the cfs bundle using alpine linux using the musl library we get a gcc error : <code> from my seaarches it seems that <code> is an older implementation . <section> build and run the following docker image <code> build and run the container : build : <code> docker run - it - - rm cfs - bundle : alpine <code> os - posix . h : <number> <code> <hashtag> include </hashtag> < sys / signal . h > ` <section> docker desktop <number> . <number> <allcaps> osx </allcaps> <number> . <number>,0.0
"deprecate ostask_id field from os_task_prop_t <section> this field is not necessarily applicable to all os types and it breaks the abstraction . <allcaps> osal </allcaps> should not be reporting the raw / unabstracted values back to the application . this field is fundamentally broken in any environment where the underlying os task id is not convertible to a <code> . this includes real systems , such as : - cygwin , where <code> is a compound data type , not an integer ( <allcaps> posix </allcaps> specifically allows this ) - systems where the task id is actually pointer to the <allcaps> tcb </allcaps> ( in which case it will be <number> bits on <number> bit systems ) currently this field serves one purpose , which is to allow the <allcaps> cfe es </allcaps> exception processing to find the <allcaps> osal </allcaps> task id associated with the exception . however , this design is being reworked in nasa / cfe # <number> where more of the exception processing is done in the <allcaps> cfe psp </allcaps> . with this , there should be no need for applications to ever use the <code> member . <section> the <code> member of <code> should be marked as deprecated . as a replacement , an new <allcaps> api </allcaps> can be added which can be invoked by the <allcaps> psp </allcaps> / <allcaps> bsp </allcaps> to aid in exception processing . this new <allcaps> api </allcaps> should use an abstract pointer and size , not assume that the task identifier information fits within a <number> - bit integer . <section> joseph hickey , vantage systems , inc .",2.0
"add double - lock detection for <allcaps> osal </allcaps> mutexes as a debug option <section> a recent issue in nasa / cfe # <number> was due to an application double - locking the same mutex from the same task . this wasn ' t detected during testing because <allcaps> posix </allcaps> allows this recursive locking . however , other <allcaps> rtos </allcaps> ' s do not allow it , nor is it intended behavior . <section> <allcaps> osal </allcaps> should check / enforce that a single task id only takes a mutex once , and must release it before locking again . violations of this pattern should be reported to the debug console , so they can be addressed by the developer . as there is a small overhead cost to doing this , it can be selectively enabled as a debug feature , and remain off by default . <section> see nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"simplify config by inferring osal_system_ostype from osal_system_bsptype <section> currently the build requires that the user specify both osal_system_bsptype and osal_system_ostype . this is redundant because each <allcaps> bsp </allcaps> only works with a specific os . <section> the user should be allowed to specify only osal_system_bsptype , and the correct os layer can be inferred automatically . <section> continue as is , which increases user config burden and risk of misconfiguration <section> see also nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"use a better time representation in os_stat call <section> the <code> call currently returns the file time as an <code> member within the <code> structure , as defined here : <url> this is not really documented in the <allcaps> api </allcaps> but the field is a traditional <allcaps> unix </allcaps> - style timestamp , which is seconds elapsed since <date> <allcaps> utc </allcaps> . this type of timestamp suffers from the "" year <number> "" bug , where the int32 value rolls over and becomes negative . although this is <number> years from now , at the timescales of space software development cycles , it is entirely possible that coding being developed now will still be in service at the time this happens , so it should be fixed sooner rather than later . <section> there are two fixes needed : <number> . use the <code> representation as used in <code> and <code> . this is just for consistency - should not use a different representation of time as the other <allcaps> api </allcaps> calls do . <number> . fix the <code> to accommodate larger timestamp values and / or use a different epoch ( latter would be risk but keep the structure the same size ) . <section> discussion regarding use of this field in nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",0.0
test_os_converttoarrayindex : tautological assertion <section> unit test <code> implements the following assertion : <url> this is a tautological assertion as it compares <code> with itself . <section> n / a ( code analysis ) <section> <code> should be compared with <code> : <code> <section> see above . <section> n / a ( code analysis ) <section> n / a <section> guillaume lethuillier - personal,0.0
"test # <number> : osal - core - test failure <section> test # <number> : osal - core - test fails . <section> steps to reproduce the behavior : note : this test was not readily repeatable , but it failed <number> / <number> times on this branch : fix413 - add - reference - to - osal - users - guide - from - readme <number> . go to branch stated above <number> . run build / exe / cpu1 / osal - core - test <section> the test failed <number> / <number> times . specifically , failure is due to the code snippet noted below in osal - core - test . c , line <number> where a small time delay is supposed to occur and the child task is perhaps not exiting before the os_taskdelete call happens , so it ' s returning success . <section> [ <allcaps> fail </allcaps> ] <number> osal - core - test . c : <number> - os_taskdelete , self exiting task <section> <allcaps> gnome vm </allcaps> os : ubuntu <number> versions : <allcaps> osal </allcaps> <number> . <number> <section> this may be due to the vm delay . <section> yasir khan <allcaps> nasa gsfc </allcaps>",0.0
"fix # <number> , add reference to osal user ' s guide from readme fix413 : added reference to osal user ' s guide from readme <section> steps taken to test the contribution : <number> . went to github to verify that that link added worked properly <section> none <section> - <allcaps> gnome vm </allcaps> - os : ubuntu <number> - versions : <allcaps> osal </allcaps> <number> . <number> <section> yasir khan <allcaps> nasa gsfc </allcaps>",1.0
separate cmake coverage logic and resolve clang support issue <section> - pg option is not supported by clang in <allcaps> os x </allcaps> <number> and later <section> consider a coverage . cmake implementation similar to the example : <url> see comments on # <number> . <repeated> ( really relating to # <number> ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"ci improvements - better support of local and cross - platform testing <section> command implemented in . travis . yml does not support local or cross - platform testing <section> implement as makefile , ansible playbooks , or invoke in a way that supports future build verification plan ( cross - platform / docker / <allcaps> qemu </allcaps> based ) . see <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"os_shelloutputtofile missing functional test <section> no functional test for os_shelloutputtofile <section> add functional test . needed for build verification for any system that includes this capability . <section> at one point discussed removing this <allcaps> api </allcaps> , but <allcaps> ccb </allcaps> decided to make it optionally included <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
add reference to <allcaps> osal </allcaps> user ' s guide from <allcaps> readme </allcaps> . md <section> user ' s guide is built and not included in repo <section> reference <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
implement coverage tests for posix <section> coverage tests not implemented for posix <section> add coverage tests <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , resolve doxygen warnings for main doc <section> fixes # <number> by removing a duplicate reference the doxygen warned about <section> steps taken to test the contribution : <number> . edited file in which error occurred <number> . rebuilt documentation using <code> <number> . observed no warning generated <number> . viewed relevant documentation page to verify correctness <section> leor bleier <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"break up osapi - os - core . h into more focused includes <section> spawned from # <number> discussion - osapi - os - core . h is a monolithic include covering a vast array of apis , which makes changes harder conceptually separate and manage . <section> break up osapi - os - core . h - could use the deprecation process to avoid breakage where osapi - os - core . h just includes all the more focused headers . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
fix doxygen warnings <section> doxygen generates warnings when building the documentation <section> steps to reproduce the behavior : <number> . do a <code> in the <code> directory <number> . observe the warnings in <code> <section> no warnings should be generated . <section> leor bleier <allcaps> gsfc </allcaps> \ <number>,1.0
"error code documentation updates related to enforcement / test <section> see # <number> for related issue / discussion . lacking documented approach for return code checking across functional tests . <section> <number> . update the error code list in <allcaps> api </allcaps> documentation to state : <code> <number> . typical return code documentation ( for just execution status ) : <code> <number> . scrub <allcaps> api </allcaps> error code documentation with the concept functional tests will verify the error codes explicitly defined , should just be a general set ( not implementation unique ) . <section> see discussion in # <number> <section> coverage tests are expected to verify every implemented return code ( white box ) . functional tests are <allcaps> api </allcaps> based . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"simplify unit tests with utassert . h macros <section> currently a lot of <allcaps> osal </allcaps> unit test code is like the following ( basically , run code , check the result , "" force "" an assert that it worked or did not work ) : <code> <section> instead , this can be simplified to : <code> <section> a clear and concise description of any alternative solutions or features you have considered . <section> add any other context about the feature request here . <section> <email>",2.0
"fix # <number> , make os_stream_state available with apis … it ' s needed by os_selectsingle ( ) <section> moves os_stream_state defines to os / inc / osapi - os - core . h as they are needed by os_selectsingle ( ) <section> can build unit tests ( being developed ) for os_selectsingle ( ) note that this is a prerequisite for # <number> and is related to # <number> all three should be pulled at the same time , or # <number> , # <number> then # <number> <section> <email>",0.0
"os_selectsingle ( fd , & selectflags , timeout ) users require os_stream_state_readable / os_stream_state_writable <section> in order to use os_selectsingle ( ) a user needs access to the <hashtag> defines </hashtag> for os_stream_state_readable and os_stream_state_writable but they are contained in osal / src / os / shared / os - impl . h not in osal / src / os / inc / . <repeated> <section> try to use the os_selectsingle <allcaps> api </allcaps> <happy> <section> these <hashtag> defines </hashtag> need to be moved to osal / src / os / inc <section> <email>",0.0
"os_selectfdzero / os_selectfdadd / os_selectfdclear / os_selectfdisset does not ensure set is ! = <allcaps> null </allcaps> <section> users of these <allcaps> api </allcaps> ' s will cause a seg fault if they call these functions with a null pointer . <section> call os_selectfdzero ( <allcaps> null </allcaps> ) , etc . <section> these <allcaps> api </allcaps> ' s should return an error code when provided a <allcaps> null </allcaps> pointer . <section> <code> <section> debian <number> <section> add any other context about the problem here . <section> <email>",0.0
"fix travis - ci config warnings <section> build config validation ( from travis - ci ) - root : deprecated key sudo ( the key <code> has no effect anymore . ) language : unexpected sequence , using the first value ( c ) root : missing os , using the default linux <section> see <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update <allcaps> osal </allcaps> configuration guide , build instructions , directory references , etc <section> build instructions in doc / <allcaps> osal </allcaps> - configuration - guide . doc and . pdf have instructions for classic build . also the section on building the unit tests requires use of the classic build . <section> a new section needs to be written for building unit tests under cmake and the old classic build section needs to be removed ( and refs to the classic build in the cmake section need to be stricken . ) also note in <number> . <number> , setup the <allcaps> osal </allcaps> source distribution , that the <allcaps> osal </allcaps> source distribution directories are not aligned with our current directories . for example , osal / src / make and osal / src / inc no longer exists . <section> none <section> related to # <number> , # <number> , # <number> <section> chris knight - <allcaps> nasa </allcaps> / <allcaps> arc </allcaps>",1.0
"use cmocka for stubs <section> the cmocka ( <url> framework provides much the same functionality as our unit test stub framework , and is apache licensed . i suggest we replace our stub framework with cmocka ( and contribute any required capabilities to the cmocka project if it does not currently cover all our needs . ) <section> use cmocka . <section> i am sure there are lots of other unit test frameworks . cmocka seems simple , capable , and easy to incorporate into cfs . <section> add any other context about the feature request here . <section> <email>",2.0
os_timeradd missing functional test <section> functional test missing for os_timeradd <section> add test <section> none <section> certification issue <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"timebase <allcaps> api </allcaps> missing functional tests <section> os_timebasecreate , os_timebaseset , os_timebasedelete , os_timebasegetidbyname , os_timebasegetinfo , os_timebasegetfreerun all missing functional tests <section> add tests <section> none <section> certification issue <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
os_filesysaddfixedmap missing functional test <section> missing functional test for os_filesysaddfixedmap <section> add test <section> none <section> certification issue <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
os_timedread and os_timedwrite missing functional tests <section> os_timedread and os_timedwrite missing functional tests <section> add tests <section> none . <section> certification issue <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"<allcaps> osal </allcaps> select apis missing functional test <section> os_selectmultipe , os_selectsingle , os_selectfdzero , os_selectfdadd , os_selectfdclear , os_selectfdisset all missing functional tests <section> add tests <section> none <section> certification issue . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add object utility <allcaps> api </allcaps> functional tests <section> os_identifyobject , os_converttoarrayindex and os_foreachobject missing explicit functional tests <section> add tests <section> none . <section> certification violation <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> osal </allcaps> network apis missing functional tests <section> seems there ' s not really any unit tests for the <allcaps> osal </allcaps> networking code . <section> should have unit tests . <section> not having unit tests ? <section> note that to do unit testing , it ' s likely we will need to stub out os - provided <allcaps> api </allcaps> ' s ( open , select , socket , bind , accept , close ( ) . ) do we have a standard framework for stubbing out os - provided functions ? <section> <email>",2.0
"<allcaps> osal </allcaps> fs defines scrub - deprecate os_volumetable and related symbols <section> fs_based , ram_disk , eeprom_disk , ata_disk , num_table_entries all missing os_ prefix os_chk_only and os_repair defined , but the input to the expected <allcaps> api </allcaps> is a boolean ( bool repair ) <section> add prefix , remove unused defines <section> none <section> do after # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add ut assert ability to set a buffer position <section> ut assert has a feature to associate data buffers with stub routines to facilitate data passing between the stub and the test case . for cases with "" random access "" requirements ( e . g . <allcaps> es cds </allcaps> , mem pools , etc ) cases there is a <code> <allcaps> api </allcaps> which also gets the current position within the buffer ( its tail ) , but there is no related <allcaps> api </allcaps> to actually set the position . <section> should add another stub <allcaps> api </allcaps> so that a stub routine can also directly set the tail position without needing to use <code> as a workaround . <section> setting the position can be done by calling <code> or <code> but this can can be ugly and convoluted in cases where the stub does not have actual data to copy . both of these copy data in addition to moving the tail position , so its less than ideal if the stub only needs to adjust the tail position and not copy data . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> api </allcaps> doxygen scrub <section> doxygen documentation out of date <section> format / layout changes : - table - fy return values ( and eliminate some pdf build errors / warnings ) - make links from text where appropriate - documented <allcaps> osal </allcaps> return codes - add parameter direction where missing - added explicit grouping where appropriate ( and group references ) - group <allcaps> api </allcaps> ' s and reference from main page - marked os_taskregister as deprecated in documentation ( no code change yet , that ' s # <number> ) - marked exception handling as deprecated in doc ( code change is # <number> ) - marked shmem as deprecated in doc ( code change is # <number> ) - added missing descriptions and parameter definitions - added clock address rounding comments related to # <number> ( partial resolution ) - delete old <allcaps> osal api </allcaps> doc and pdf information changes : - internal file descriptor not accessible ( recommend against mixing direct calls with osal apis ) - noted os_translatepath is available to use with open directly by an app <section> none <section> related issues : # <number> , # <number> , # <number> partial : # <number> , # <number> , # <number> , # <number> <section> full name and company / organization if applicable",1.0
""" duplicate symbol ' _main ' "" on macos when building tests <section> this is one of the issues addressed by # <number> . i am extracting it hereby to be considered separately from the rest of my work of macos port . i am getting linker errors on macos because the test targets link in <code> library that has a <code> function and they link <code> which has a <code> that launches tests . this causes a conflict with these test target ' own main ( ) function as follows : <code> <section> usually the cases like this resolved by extracting the main function from one of the conflicting libraries . in this case it could make sense to extract the <code> function from <code> to a separate library such as <code> or <code> to avoid any conflicts with test targets . that separate library would then not be linked to the tests and the conflict would go away . <section> there seems to be no alternative to this behavior on macos . you either have one <code> function or there is a conflict . <section> this is a more complete fragment of the output : <code> <section> stanislav pankevich",0.0
"os / shared / osapi - module . c : the return value of the call to os_moduleload_impl should be checked <section> i have noticed this issue while working on making the <allcaps> osal </allcaps> ' s tests pass on macos ( see # <number> ) . i am reporting this issue separately from the rest of the changeset suggested there . the issue is in the following fragment of code as found in the current master branch ( as of <url> <code> we can see that the return value of the <code> is not tested for <code> so the execution can continue even if the call to this function returns an error . this is a direct link to the line : <url> <section> most of the code in <allcaps> osal </allcaps> does check the return values : <code> or <code> so it makes sense to create such a check in this case too . i am going to create a pull request that addresses this issue . <section> to the best of my knowledge , a proper return value checking is the only way to get fast feedback from a call to the <code> if something goes wrong . <section> none . <section> stanislav pankevich , independent contribution .",2.0
"add os_queuegetname ( ) <section> cfe will have a function to get a pipe ' s name given its id , which will call down to <allcaps> osal </allcaps> to get the name from the queue . currently this is accomplished with os_queuegetinfo ( ) but that requires a pointer to a struct buffer . <section> a convenience function should be added to retrieve a queue ' s name given its id without the need to pass in a struct buffer ( instead passing in a string buffer . ) <section> could maintain the status quo , this is a convenience function . <section> add any other context about the feature request here . <section> <email>",2.0
"os_moduleload_impl function header does not match definition <section> when os_include_module_loader is not defined , the function header does not match the definition : <code> this issue was introduced in pr # <number> . <section> build with <code> not defined . <section> build succeeds .",0.0
"fix # <number> : make parameter const <section> when os_include_module_loader is not defined , the function header does not match the definition . this issue was introduced in pr # <number> . longer term : is there a continuous integration strategy to avoid this sort of situation happening in the future ? <section> build with module loader disabled with cfs master distribution . <section> none <section> - pc , ubuntu <number> <section> andrei - costin zisu of planetary transportation systems gmbh ( berlin , germany ) . company - wide <allcaps> cla </allcaps> is in the process of being signed and should be available soon .",0.0
"split shell code out to support optional inclusion <section> execute in shell functionality is undesirable for some security conscious applications . <section> allow for optional inclusion ( like network option ? ) , respond as not implemented when not included . <section> discussed security at length , diverse use cases require flexibility for user to decide . <section> <allcaps> posix </allcaps> issue found in <allcaps> lgtm </allcaps> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"<allcaps> wip </allcaps> : os / posix : port of the posix implementation to macos <section> this is an ongoing attempt to make the <allcaps> cfs </allcaps> / <allcaps> osal </allcaps> work on macos . i am opening this is as a work - in - progress pull request because there are many things that have to be addressed . rough plan of the work ( major points ) : - necessary ports : - [x ] mqueue ( based on memory - mapped files , portable but needs verification ) - [x ] pthread_setschedprio ( portable ) - [x ] sem_ * : - [x ] the mac_sem_ * implementation is based on pthread_mutex and pthread_cond ( portable ) - [x ] the mac_sem2_ * implementation is based on <allcaps> gcd </allcaps> semaphores ( macos specific ) - [x ] clock_nanosleep ( portable but needs verification ) - [x ] timer_ * ( portable , but the implementation is rather limited and tailored to what <allcaps> cfs </allcaps> does ) - [x ] all of the tests as found in the changeset ' s <code> are passing . one could use this makefile as a starting point for working with this changeset . - ] nasa / osal should have a proper ci and test scripts that could be used for verifying this work . this is still open and it looks like a dependency for this macos - related work : <url> until then , this pr uses a [ custom test suite <url> . - x] [ fix # <number> , fix memory corruption produced by misplaced memset ( ) <url> has to be merged . - [ ] decision has to be made if : <number> ) a separate folder for macos has to be created as a full copy of posix . or <number> ) macos support could be enabled with a number of <code> s . i would go with the approach <number> with a separate macos folder to maintain clear distinction between linux and macos given that macos will most likely always be only a development / simulation target which means that the lack of the <code> stuff on macos is not a problem and its simulation is ok . - x] <code> of src / bsp / pc - linux / src / bsp_start . c [ conflicts ] ( <url> with the <code> of the unit tests . open and fixed here : [ "" duplicate symbol ' _main ' "" on macos when building tests # <number> <url> . - ] this port only makes sense if the related [ elf2cfetbl # <number> <url> is approved and incorporated . otherwise it is not possible to run <allcaps> cfs </allcaps> and have correct <code> files on macos . - [ ] non - portable code coverage flag , opened here : <url> some important comments : - it is not the first time that i am trying to make something work on macos so i had some code in my pockets already . i have collected the <allcaps> posix </allcaps> functions which were missing on macos to a separate project : posix - mac - addons <url> . for now , i am simply copying the <code> contents of that project to the root of the <code> repository . please see the comments on the implemented functions on that project ' s <allcaps> readme </allcaps> page as well . - i have built this branch from <number> different macos machines and i can confirm that everything seems to work on my end : building them from a clean tree and running the tests . both are mojave though , so i cannot promise that everything will work on catalina ( many things are breaking for those who have upgraded so upgrading this changeset to catalina could be a separate action ) . - all of the tests as found in the changeset ' s <code> are passing . one could use this makefile as a starting point for working with this changeset . - i was not sure whether i should have created the <code> port or simply hack on top of <code> . i decided to go for latter because it is now easier to see on the diff what is different . however , if there is an interest in getting this merged , it is not clear to me what would be the right solution : keep <code> with lots of ifs or create a dedicated <code> one . - both implementations of the semaphores are passing the tests . this changeset is using the one which is <code> based on the <allcaps> gcd </allcaps> semaphores . the following important detail explains why the implementation is a bit more sophisticated . without this detail some of the tests are crashing . i guess , this could be fixed by simply ensuring that the semaphores in the tests are used in a balanced way . ` ` <code> <allcaps> bug in client of libdispatch </allcaps> <code> mac_sem2_ *< code > ` <code> posix - mac - addons <code> posix - mac - addons ` available as a standalone repository that will have a <allcaps> mit </allcaps> license . i would like to know your thoughts on if / how this third - party code could be integrated then . <section> stanislav pankevich , personal the signed individual <allcaps> cla </allcaps> has been sent to the email specified in the <allcaps> cla </allcaps> document .",2.0
"build instructions in top level <allcaps> readme </allcaps> are incorrect <section> followed the build steps as in the <allcaps> readme </allcaps> file but the build is not successfull . error : <code> <section> steps to reproduce the behavior : <number> . clone the latest build <number> ( <number> - jan - <number> ) or the commit 7 8 1 9 9 2 ce2c0df067ebd84779615bf1ebf6ef7de5 <number> . follow the build steps as mentioned in the <allcaps> readme </allcaps> file <number> . source setvars . sh <number> . cd build <number> . make config <number> . make <section> successful build <section> if applicable , add references to the software . <section> - hardware : pc - linux - os : [ ubuntu <number> ] - versions [ osal_5 . <number> ] <section> add any other context about the problem here . <section> waheed ejaz",1.0
"os_socketaccept fails <section> when using os_socketaccept on a stream ( <allcaps> tcp </allcaps> ) server socket , it fails because the accept code calls os_objectidgetbyid ( ) passing a os_lock_mode_refcount , but then os_socketaccept sees the refcount > <number> and fails out . <section> create code ( e . g . an app ) that creates a <allcaps> tcp </allcaps> socket server and try using os_socketaccept ( ) to receive the incoming connections . <section> os_socketaccept should work as expected / documented . <section> os_sockaddr_t addr ; int socket = <number> , clientfd ; int32 status = <number> ; os_socketaddrinit ( & addr , os_socketdomain_inet ) ; os_socketaddrfromstring ( addr , "" <number> . <number> "" ); os_socketopen ( & socket , os_socketdomain_inet , os_sockettype_stream ) ; os_socketbind ( socket , & addr ) ; status = os_socketaccept ( socket , & clientfd , & addr , <number> ); <section> debian <number> <number> - bit x86 <section> removing the check for refcount results in expected behavior , os accept ( ) call should be thread - safe so need not maintain lock through socketaccept ( ) function . <section> chris knight , <allcaps> nasa </allcaps> ames",0.0
"reevaluate signal handling in <allcaps> posix </allcaps> <section> there may be some inefficiencies / room for improvement in how <allcaps> posix </allcaps> is handling the signal masks , that should be evaluated and considered . for the rt signals , these are masked all the time and timers use <code> to synchronously receive them . however that potential to leave stray signals queued . this has been worked around by ensuing that no signals are queued before setting up a timer , but there may be a more efficient way to accomplish this . <section> consider setting all the unused signals to "" <allcaps> ignore </allcaps> "" such that the kernel will not even deliver them to the process , rather than masking them at the process . ~ signal masks are also changed as part of the global lock / unlock procedure what may not be necessary . this should be re - evaluated with the current <allcaps> osal </allcaps> design . historically this may have been necessary for async signals but the current <allcaps> osal </allcaps> now avoids async signals for all <allcaps> osal </allcaps> - created tasks . ~ already done in # <number> /# <number> <section> leave as - is . <section> see related issue # <number> <section> joseph hickey , vantage systems , inc .",2.0
"add <allcaps> osal </allcaps> library build , coverage test , and functional tests to ci <section> ci does not build or execute tests for <allcaps> osal </allcaps> related to conversation on <url> <section> ideally create a makefile with a set of rules to cover building , running tests , and reporting coverage ( pattern after bundle build ) which allows for users to easily do the same thing once created , put into ci <section> some of the actions are detailed in <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"os_dirent_t . filename uses os_max_path_len for array size typedef struct { char filename [ os_max_path_len ] ; } os_dirent_t ; it ' s probably the case that filename should be of os_max_file_name size instead . the use case is to build a filename from a path and a filename from an os_dirent_t . this path , including the filename , would be os_max_path_len .",2.0
"remove classic build artifacts <section> classic build no longer supported . <section> remove all associated artifacts : build directory , all * . mak directories , setvars . sh <section> none <section> makes # <number> obsolete <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"possible bug in os / posix / osapi . c when running osal - core - test / <allcaps> bsem </allcaps> tests . <section> i apologize in advance in case the issue i am reporting is caused by my misunderstanding of the <allcaps> osal posix </allcaps> code and the problem is rather somewhere on my end . i am trying to port the <allcaps> posix osal </allcaps> code to macos . it is a rather long adventure but it looks like there can be a happy end . by now i am going through all of the unit and integration tests in this repository in order to see which things have to be changed in order to run on macos . this issue i have first reported on stackoverflow because i thought the problem was on the macos side : calling pthread_cond_destroy results in “ function not implemented ” <allcaps> enosys </allcaps> on macos <url> . <code> results in <code> as i am running it on macos . looking at the code further i have found that there might be a bug in the <code> function along these lines : <code> i would like to highlight that the <code> happens <allcaps> after </allcaps> the <code> line which means that <code> corrupts the work that is done by <code> . if i put the <code> string <allcaps> before </allcaps> the <code> line , the <code> test passes . <section> i am reproducing this on a private fork of <code> and it is a very hacky branch to make it work on macos . at the moment i can only suggest to do a mental reasoning about the critical lines : <code> and <code> lines as i described above . <section> this is how the test log looks like with my change above and this is what i expect to always happen : <code> <section> if applicable , add references to the software . <section> - macbook pro ( <number> - inch , <number> , four thunderbolt <number> ports ) - os : macos mojave <number> . <number> ( 1 8 g87 ) - versions <allcaps> osal </allcaps> repository build from this commit : <code> <section> this is how the issue manifests itself ( i am only running the related tests ) . <code> this is the original stackoverflow report : ` ` <code> pthread_cond_destroy <code> pthread_cond_destroy <code> pthread_cond_ *< code > ` ` <section> stanislav pankevich",0.0
"osal_timer_ut periodic failure <section> osal_timer_ut periodically reports a failure on linux for the nominal os_timerset case <section> <number> . build and run <code> <section> should pass <section> see ut_ostimer_test . c for ut_os_timercallback ( the timer callback function ) see ut_ostimer_timerio_test . c line <number> for the failure location <section> - cfs dev <number> server - os : ubuntu <number> - versions : happened to be running the ic - <number> branches , but not unique ( historical issue ) <section> added after the tolerance check in the callback function : <code> failure result was seen due to unexpected first interval of <number> , where interval was set to <number> : <code> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"bin - sem - flush - test reporting work incorrectly <section> there is an issue in bin - sem - flush - test . c . within the binsemflushcheck function - lines <number> , <number> , <number> , and <number> contain the wrong variable name ( task_1_work as opposed to task_2_work & task_3_work ) . <section> run test . <section> expect "" task <number> / <number> work = % u "" to correspond with task_2 / 3 _work variables . <section> void binsemflushcheck ( void ) { int32 status ; /* at first , no task should have done any work yet ( all blocked ) */ utassert_true ( task_1_work = = <number> , "" task <number> work = % u "" , ( unsigned int ) task_1_work ) ; utassert_true ( task_2_work = = <number> , "" task <number> work = % u "" , ( unsigned int ) task_1_work ) ; utassert_true ( task_3_work = = <number> , "" task <number> work = % u "" , ( unsigned int ) task_1_work ) ; status = os_binsemflush ( bin_sem_id ) ; utassert_true ( status = = os_success , "" binsem1 flush rc = % d "" , ( int ) status ) ; /* after more delay the work done should be nonzero on all tasks */ /* <allcaps> note </allcaps> - there is a slight race condition here as the task could be blocked * by something else other than the bin sem . */ os_taskdelay ( <number> ); utassert_true ( task_1_work ! = <number> , "" task <number> work = % u "" , ( unsigned int ) task_1_work ) ; utassert_true ( task_2_work ! = <number> , "" task <number> work = % u "" , ( unsigned int ) task_1_work ) ; utassert_true ( task_3_work ! = <number> , "" task <number> work = % u "" , ( unsigned int ) task_1_work ) ; utassert_true ( task_1_failures = = <number> , "" task <number> failures = % u "" , ( unsigned int ) task_1_failures ) ; utassert_true ( task_2_failures = = <number> , "" task <number> failures = % u "" , ( unsigned int ) task_2_failures ) ; utassert_true ( task_3_failures = = <number> , "" task <number> failures = % u "" , ( unsigned int ) task_3_failures ) ; } <section> na <section> na <section> dan knutsen <allcaps> nasa </allcaps> goddard space flight center",2.0
"lgtm issues for os - impl - posix - files . c , osapi - filesys . c <section> os - impl - posix - files . c <code> osapi - filesys . c <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"assert return codes specified in <allcaps> api </allcaps> in functional tests i noticed that osal - core - test . c only tests if the function returns os_success or does <allcaps> not </allcaps> return os_success . it does not actually test that the return code is correct . for example , the test to ensure that the <allcaps> osal </allcaps> does not create a queue with a name that already exists does not actually test for os_err_name_taken . it merely passes if the return is not os_success . a quick spot check indicates this design pattern is systemic . these unit tests were used to certify ( per npr7150a ) the <allcaps> arinc </allcaps> <number> version of <allcaps> cfs </allcaps> . this requires requirements have tracing back to tests . testing the actual expected return code is a better pattern , but is required if there is an actual requirement defining the return codes .",2.0
"lgtm warning - misc . <section> reference issues # <number> posix / osfileapi . c <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"osal lgtm warning <section> reference issue # <number> . os - impl - bsd - sockets . c <code> shared / osapi - idmap . c <code> shared / osapi - sockets . c <code> shared / osapi - time . c <code> os - posix . h <code> <section> anh van , <allcaps> nasa </allcaps> goddard .",2.0
"recommended lgtm osal issues <section> recommended osal issues : osapi - os - core . h <code> osapi - module . c <code> shared / os - impl . h <code> posix / osnetwork . c <code> shared / osapi - select . c <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"sem - speed - test can run infinitely on some platforms <section> in the sem - speed - test , the main thread stops the test by doing a task delay and then deleting the worker tasks . when running on a hard real time kernel and a single processor system , if the worker threads are a higher priority than the main thread , then the main thread never gets <allcaps> cpu </allcaps> time to stop the test and it just runs infinitely . <section> run the test on a single - processor system such as vxworks or <allcaps> rtems </allcaps> where the originating ( shell ) task is a ( logically ) lower priority than <number> , which is the priority given to the worker tasks it creates . the test will never exit because the root task never gets <allcaps> cpu </allcaps> time again to cancel the worker tasks . <section> the test should never run infinitely , regardless of ( mis - ) configuration . <section> <allcaps> rtems </allcaps> <number> on i686 ( <allcaps> qemu </allcaps> ) <section> the worker tasks should employ some type of hard limit so they do not run infinitely even if the priority is higher than the root task . <section> joseph hickey , vantage systems , inc .",2.0
"coverage test failure in vxworks <section> the coverage test cases for <code> are failing : <code> <section> build <allcaps> osal </allcaps> coverage tests and execute <section> all tests should pass <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> this was probably some fallout related to the vxworks timer fixups that were done recently (# <number> , # <number> ) but never noticed because the <allcaps> osal </allcaps> coverage test is still separate ( that aspect is also being addressed ) . <section> joseph hickey , vantage systems , inc .",2.0
"exception / interrupt <allcaps> api </allcaps> issues in <allcaps> osal </allcaps> <section> when running unit tests on the <allcaps> osal </allcaps> for the vxworks , <allcaps> posix </allcaps> , and <allcaps> rtems </allcaps> environments , it revealed a few minor issues on the implementation side that should be addressed . these are all in the interrupt / fpu / exception <allcaps> api </allcaps> areas for which the <allcaps> cfe fsw </allcaps> does not really rely upon . <number> . for <allcaps> posix </allcaps> and <allcaps> rtems </allcaps> , the <allcaps> fpu </allcaps> exception apis should all return <code> , because these are in fact not implemented . returning <code> , as some did , implies that the behavior took effect when it did not ( this matters to ut ) . these are : - <code> - <code> - <code> - <code> <number> . <allcaps> rtems </allcaps> does not provide a direct equivalent for the os_intenable / os_intdisable <allcaps> api </allcaps> like vxworks has . the implementation had been using rtems_intterupt_enable / disable for this , but the semantics of those calls are different ( they are more appropriate for os_intlock / os_intunlock ) . the enable / disable implementation should just return <code> . <number> . the <allcaps> rtems </allcaps> <code> / <code> implementation should use the "" local "" variant of the <allcaps> rtems </allcaps> interrupt enable / disable function . this is documented as being identical on single - processor machines but only the local variant is applicable to multi - processor machines . <number> . the <code> <allcaps> api </allcaps> accepts a pointer as an output buffer , so to be consistent with all other <allcaps> api </allcaps> calls that accept a pointer , it should check for <allcaps> null </allcaps> and return <code> in that case . <section> execute the <allcaps> osal </allcaps> unit tests ( including changeset for # <number> to enable full testing ) and some failures are reported due tot his . <section> all unit tests should pass . <section> - ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( native / posix ) - <allcaps> rtems </allcaps> <number> on i686 / pc ( <allcaps> qemu </allcaps> - emulated target ) - vxworks <number> on <allcaps> ppc </allcaps> / mcp750 <section> joseph hickey , vantage systems , inc .",2.0
"add cppcheck to bsp and os <section> add cppcheck to osal / src / bsp and osal / src / os <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"code in "" unit - test "" should use ut assert <section> the tests in the "" unit test "" directory use an entirely different result reporting mechanism . although they do currently link with ut assert , they keep a local record of test cases and do not use any of the ut assert functions . this is a maintenance issue . the code makes extensive use of macros which makes it difficult to understand and also duplicates much of the logic that ut assert already has . furthermore , the tests do not run on all <allcaps> osal </allcaps> platforms ( e . g . <allcaps> rtems </allcaps> ) because the macros are incomplete , even though ut assert does support this platform . <section> build with enable_unit_tests = <allcaps> true </allcaps> and run all tests . the osal "" unit - tests "" produce entirely different log files than the rest of the tests . <section> the osal "" unit - tests "" should be more consistent in behavior and log file format with all the other tests . <section> - ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> this is becoming more of an issue due to a parallel effort to avoid clobbering <code> (# <number> ) . but this unit test build currently relies on <code> and os - specific definitions ( e . g . <code> , <code> , etc ) to pick the right macros to use . so this breaks the unit test if not setting <code> anymore . although it could probably be patched up again with some more hacks , it is probably worth some extra effort to just clean this up properly so it stops being a perpetual issue . since most things are macro based already , it is likely that simply changing the macro definitions to direct the output to ut assert instead of the local structure is probably sufficient . <section> joseph hickey , vantage systems , inc .",2.0
"<allcaps> osal </allcaps> cmake script should not force / overwrite cmake_c_flags <section> the <allcaps> osal </allcaps> build script currently configures several compiler flags by directly setting the <code> variable , and also setting it differently for unit test vs . <allcaps> fsw </allcaps> code . this was originally done for compatibility with very old cmake versions but this is no longer necessary , as any reasonable cmake version ( including v2 . <number> distributed in <allcaps> rhel </allcaps> / centos6 + ) have better commands to deal with target - specific flags ( e . g . target_compile_definitions , etc ) . overriding this variable is not ideal as it is expected to retain its value from the parent . <section> build <allcaps> osal </allcaps> using the current script and enable_unit_tests = <allcaps> true </allcaps> . cmake_c_flags is forcibly reset twice during the cmakelists . txt evaluation . <section> <code> should not be modified by the <allcaps> osal </allcaps> build script . it should preserve whatever value the parent had set ( if any ) and use the preferred commands ( e . g . target_compile_options , etc ) to manage the different flags required for ut and normal <allcaps> fsw </allcaps> code . <section> ubuntu <number> <allcaps> lts </allcaps> , <number> bit <section> joseph hickey , vantage systems , inc .",0.0
"cppcheck for os dir . <section> from issue # <number> <code> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"remove unsupported / untested bsps <section> old bsps are not within scope of the cfs framework and not tested <section> remove sis - rtems , mcf5235 - rtems , and sparc - vxworks6 . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cryptic failure when running <allcaps> cfs </allcaps> as non - root when running the <allcaps> cfs </allcaps> without elevated privileges , the output that indicates an os failure does not express errors with scheduler policy . the current output under these conditions is : <code> the origin of this issue comes from <url> a failure to set the schedule policy should probably have a special error message indicating both why it failed and the recommended course of action .",2.0
"compiler warnings in <allcaps> osal </allcaps> <section> some warnings still get triggered when building the coverage tests with high strictness flags , as they exercise some <allcaps> api </allcaps> calls that are not even used by the <allcaps> fsw </allcaps> code . so even though the <allcaps> fsw </allcaps> itself builds clean , when the coverage test is added it is no longer clean due to these issues . <section> build <allcaps> osal </allcaps> coverage tests with warnings / strictness flags , at least : <code> <section> should build warning free . <section> ubuntu <number> <allcaps> lts </allcaps> , <number> bit . <section> joseph hickey , vantage systems , inc .",2.0
"alternative approach to compile - time function substitutions for ut <section> currently , the <allcaps> osal </allcaps> coverage test overrides c library calls using a combination of a single "" override "" header file that correlates with the c library header file of the same name . this file declares stub versions of the same functions but with an <code> prefix . this is combined with a "" stub - map - to - real . h "" header that uses <code> statements to divert the original calls to the substitute ( <allcaps> ocs </allcaps> ) version at compile time . the c library calls need to be stubbed out in this manner , because they cannot be done at link time ( as the ut still needs to link with the real c library , unlike higher - level libraries ) . <section> put the <code> statements in the substitute header itself , rather than in a local map file , and move the <code> prototypes and declarations to a new , separate header file . <section> the existing method of using a separate map file to provide the substitutions , but this complicates the build of the source units under test as this file must be explicitly included somehow . <section> the change alleviates the need to inject the <code> file as part of the compilation of the source unit under test , as it gets the overrides implicitly though the include path instead , so it simplifies the build for ut that needs this feature . the trade - off is that it requires a _pair_ of override headers for each real header being overridden , i . e . one for the <code> replacements and one for the actual <code> statements to do the mapping . so for the <allcaps> osal </allcaps> coverage test , which override headers for about <number> different system headers , this adds quite a few files . <section> joseph hickey , vantage systems , inc .",2.0
"os_sockaddr_t alignment issue on some architectures <section> on some <allcaps> cpu </allcaps> architectures that have strict alignment requirements , the os socket address storage buffer triggers a warning / error about casts that increase alignment . for example : <code> <section> build on an architecture that has strict alignment requirements ( e . g . <allcaps> sparc </allcaps> , <allcaps> mips </allcaps> , etc ) <section> should build cleanly , no warnings . <section> - <allcaps> mips </allcaps> linux ( <allcaps> qemu </allcaps> ) <section> not likely to be a "" real "" alignment issue as this specific instance follows a uint32 value , so it will already have <number> bit alignment already . adding a union wrapper will squelch the warning though . <section> joseph hickey , vantage systems , inc .",0.0
"alternative entry point for ut - assert based test applications <section> applications which utilize the ut assert library to do testing ( either functional or coverage ) share the same entry point with "" normal "" <allcaps> osal </allcaps> applications , specifically the <code> function . for testing , this is not ideal as there is some extra setup / teardown when using ut assert . this prevents using the <allcaps> osal </allcaps> - provided <allcaps> bsp </allcaps> directly and necessitates an alternative <allcaps> bsp </allcaps> that includes the extra setup / teardown . if the ut assert based applications used a differently - named entry point , this could be properly layered and some duplicate logic in the <allcaps> osal </allcaps> bsps can then be removed . <section> build with enable_unit_tests = <allcaps> true </allcaps> , and observe that the system builds a ut - bsp in addition to the normal <allcaps> osal bsp </allcaps> . on pc - linux for instance , both of this libraries include a <code> function . the difference is that the ut - bsp includes extra ut assert setup / teardown logic before and after the call to os_application_startup ( ) . it also duplicates the <code> object . <section> the <code> routine and <code> should _not_ be duplicated . rather , the ut assert setup / teardown should be an extension layer to the normal <allcaps> bsp </allcaps> . <section> ubuntu <number> <allcaps> lts </allcaps> , <number> bit <section> joseph hickey , vantage systems , inc .",2.0
"expand resource object query options while integrating file manager app <number> . <number> with cfe <number> . <number> ( <allcaps> osal </allcaps> <number> . <number> ) i ran into an issue . fm has a command that allows users to receive a telemetry packt listing all of the open files . in order to do this fm needs to be able to query <allcaps> osal </allcaps> ' s file stream resource objects . the current implementation only allows a creator to query all of the resources objects by using os_foreachobject ( ) . i think having a more general query feature would be helpful . i added a new function os_queryobjecttype ( ) that allows anyone ( not restricted to the creator ) to query a resource type . the specific <allcaps> osal </allcaps> changes are below followed by the fm code that uses the function . these changes were made for openstakit <number> that can be found at <url> # # osapi - os - core . h : /* * * typedef for object query <allcaps> osal </allcaps> callback functions . a query does not * * have to be performed by the object creator . all fields of the * * query_record are completed . * * * * this may be used by multiple apis */ typedef struct { const char * name_entry ; uint32 creator ; uint16 refcount ; } os_query_record_t ; typedef void ( * os_objquerycallback_t ) ( os_query_record_t * query_rec , void * callback_arg ) ; / / dcm - added for <allcaps> osk </allcaps> /* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */ /* * * <user> query an object resource type maintained by the <allcaps> osal </allcaps> * * user supplied callback is called for all active resources of a particular type * regardless of whether the caller created the object . * */ uint32 os_queryobjecttype ( uint32 obj_type , os_objquerycallback_t callback_ptr , os_query_record_t * query_rec , void * callback_arg ) ; / / dcm - added for <allcaps> osk </allcaps> # # osapi - idmap . c : /* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - * * function : os_queryobjecttype * * purpose : implemented per public <allcaps> osal api </allcaps> * see description in <allcaps> api </allcaps> and header file for detail * * - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */ uint32 os_queryobjecttype ( uint32 obj_type , os_objquerycallback_t callback_ptr , os_query_record_t * query_rec , void * callback_arg ) { uint32 obj_index ; uint32 obj_max ; uint32 obj_id ; uint32 active_obj_cnt = <number> ; os_common_record_t * obj_rec ; obj_max = os_getmaxforobjecttype ( obj_type ) ; if ( obj_max > <number> ) { os_lock_global_impl ( obj_type ) ; obj_index = os_getbaseforobjecttype ( obj_type ) ; while ( obj_max > <number> ) { obj_rec = & os_common_table [ obj_index ] ; obj_id = obj_rec - > active_id ; if ( obj_id ! = <number> ) { query_rec - > name_entry = obj_rec - > name_entry ; query_rec - > creator = obj_rec - > creator ; query_rec - > refcount = obj_rec - > refcount ; /* * handle the object - note that we must un - lock before callback . * the callback function might lock again in a different manner . */ os_unlock_global_impl ( obj_type ) ; ( * callback_ptr ) ( query_rec , callback_arg ) ; os_lock_global_impl ( obj_type ) ; + + active_obj_cnt ; } + + obj_index ; - - obj_max ; } os_unlock_global_impl ( obj_type ) ; } return active_obj_cnt ; } /* end os_queryobjecttype ( ) */ # # fm_cmd_utils . c : static uint32 open_file_cnt = <number> ; static void loadopenfiledata ( os_query_record_t * query_rec , void * callback_arg ) { fm_openfilesentry_t * openfilesdata = ( fm_openfilesentry_t <wink> callback_arg ; cfe_es_taskinfo_t taskinfo ; if ( openfilesdata ! = ( fm_openfilesentry_t <wink> <allcaps> null </allcaps> ) { /* fdtableentry . path has logical filename saved when file was opened */ strcpy ( openfilesdata [ open_file_cnt ] . logicalname , query_rec - > name_entry ) ; /* get the name of the application that opened the file */ cfe_psp_memset ( & taskinfo , <number> , sizeof ( cfe_es_taskinfo_t ) ); if ( cfe_es_gettaskinfo ( & taskinfo , query_rec - > creator ) = = cfe_success ) { strcpy ( openfilesdata [ open_file_cnt ] . appname , ( char <wink> taskinfo . appname ) ; } } + + open_file_cnt ; } /* end loadopenfiledata ( ) */ /* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */ /* */ /* fm utility function - - get open files data */ /* */ /* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */ uint32 fm_getopenfilesdata ( fm_openfilesentry_t * openfilesdata ) { os_query_record_t query_rec ; open_file_cnt = <number> ; os_queryobjecttype ( os_object_type_os_stream , loadopenfiledata , & query_rec , ( void <wink> openfilesdata ) ; return open_file_cnt ; } /* end fm_getopenfilesdata */",2.0
"error compiling unit test : osprintf - test <section> error compiling osprintf - test <section> steps to reproduce the behavior : <number> . add osprintf - test in cfs / osal / src / unit - tests to cmakelists . example : add_subdirectory ( osprintf - test ) <number> . in cfs directory : <number> . make distclean <number> . make enable_unit_tests = <allcaps> true simulation </allcaps> = native prep <number> . make <number> . see error <section> - hardware - ubuntu <number> - cfs <number> <section> anh van , <allcaps> nasa </allcaps> goddard",0.0
"doxygen illegeal command <section> cfecmdmnems : <number> : warning : illegal command \ dd as the argument of a \ dd command . <repeated> . <repeated> cfetlmmnems : <number> : warning : illegal command \ sb_pipeoptsec as the argument of a \ c command <section> steps to reproduce the behavior : <number> . make usersguide <section> - hardware - ubuntu <number> - doxygen <date> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"cppcheck coverage check warning <section> reference issue # <number> osal / src / os / posix / osapi . c : <number> <url> shifting signed <number> - bit value by <number> bits is undefined behaviour osal / src / unit - test - coverage / shared / src / coveragetest - time . c : <number> <url> shifting signed <number> - bit value by <number> bits is undefined behaviour osal / src / unit - test - coverage / shared / src / coveragetest - timebase . c : <number> <url> shifting signed <number> - bit value by <number> bits is undefined behaviour osal / src / unit - test - coverage / ut - stubs / src / libc - stdio - stubs . c : <number> <url> uninitialized variable : actual osal / src / unit - test - coverage / ut - stubs / src / libc - stdio - stubs . c : <number> <url> uninitialized variable : actual <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"cppcheck unit test warning <section> references issue # <number> osal / src / unit - tests / oscore - test / ut_oscore_binsem_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_countsem_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_exception_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_interrupt_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_misc_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_mutex_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_queue_test . c : <number> <url> syntax error osal / src / unit - tests / oscore - test / ut_oscore_task_test . c : <number> <url> syntax error osal / src / unit - tests / osfile - test / ut_osfile_dirio_test . c : <number> <url> syntax error osal / src / unit - tests / osfile - test / ut_osfile_fileio_test . c : <number> <url> syntax error osal / src / unit - tests / osfilesys - test / ut_osfilesys_diskio_test . c : <number> <url> syntax error osal / src / unit - tests / osloader - test / ut_osloader_module_test . c : <number> <url> syntax error osal / src / unit - tests / osloader - test / ut_osloader_symtable_test . c : <number> <url> syntax error osal / src / unit - tests / osnetwork - test / ut_osnetwork_misc_test . c : <number> <url> syntax error osal / src / unit - tests / osprintf - test / ut_osprintf_misc . c : <number> <url> sprintf format string requires <number> parameter but only <number> are given . osal / src / unit - tests / osprintf - test / ut_osprintf_misc . c : <number> <url> snprintf format string requires <number> parameter but only <number> are given . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' varg ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' varg ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' varg ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ap ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / osprintf - test / ut_osprintf_offset . c : <number> <url> va_list ' ptr ' used before va_start ( ) was called . osal / src / unit - tests / ostimer - test / ut_ostimer_timerio_test . c : <number> <url> syntax error <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
replace <hashtag> include </hashtag> of c files with build system source selection <section> <hashtag> include </hashtag> of a c file is not acceptable flight coding style for some organizations and complicates formal verification processes <section> source selection should be done via build system <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"doxygen misc . warning <section> osal / src / os / inc / osapi - os - core . h : <number> : warning : the following parameters of os_converttoarrayindex ( uint32 object_id , uint32 * arrayindex ) are not documented : parameter ' arrayindex ' osal / src / os / inc / osapi - os - core . h : <number> : warning : argument ' milliseconds ' of command <user> is not found in the argument list of os_taskdelay ( uint32 millisecond ) osal / src / os / inc / osapi - os - core . h : <number> : warning : the following parameters of os_taskdelay ( uint32 millisecond ) are not documented : parameter ' millisecond ' osal / src / os / inc / osapi - os - core . h : <number> : warning : the following parameters of os_tasksetpriority ( uint32 task_id , uint32 new_priority ) are not documented : parameter ' new_priority ' osal / src / os / inc / osapi - os - filesys . h : <number> : warning : the following parameters of os_open ( const char * path , int32 access , uint32 mode ) are not documented : parameter ' mode ' <section> steps to reproduce the behavior : <number> . make usersguide <number> . see error <section> - hardware - ubuntu <number> - doxygen <date> , rc - <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"doxygen warning : expected <tr> <section> doxygen is giving warning : expected <tr> tag but found tk_lnkword token instead ! userguide_osal_expected_tr_warning . txt <url> <section> steps to reproduce the behavior : <number> . make usersguide <number> . see warning in build / doc <section> - hardware - ubuntu <number> - r . c - <number> . <number> <section> anh van , <allcaps> nasa </allcaps> goddard",0.0
"possible deadlock of timer callbacks <section> if the actual timer interval is larger than the requested timer interval , due to the system tick timer resolution , then it is possible for timers to become deadlocked . <section> configure a timer with <code> and <code> . configure the interval such that it must be rounded up to a whole number of system ticks . the timer works fine for a while , but then callbacks will cease once the first overrun occurs . <section> callbacks should continue until canceled by the application . <section> <allcaps> rtems </allcaps> <number> ( pc686 ) running in <allcaps> qemu </allcaps> mpc750 vxworks <number> <section> discovered as part of the fix for # <number> , submitted as a separate bug for review as it affects the shared / common layer . <section> joseph hickey , vantage systems , inc .",0.0
"incorrect printf format code in <allcaps> rtems </allcaps> debug message <section> incorrect printf format code in <allcaps> rtems </allcaps> debug message <section> build on <allcaps> rtems </allcaps> with debugging messages enabled and full warnings enabled ( - wall , - werror ) compiler generates an error about an incorrect format : <code> <section> code should build warning - free <section> ubuntu <number> . <number> <allcaps> lts </allcaps> ( build host for i686 - rtems4 . <number> ) <section> joseph hickey , vantage systems inc .",0.0
"sem - speed - test program creates tasks with zero stack size <section> for <allcaps> rtems </allcaps> and <allcaps> posix </allcaps> this is not an issue because these implementations will just use a minimum stack size , but vxworks actually creates the task with a very small stack . the worker tasks are then likely to overrun the stack , causing undefined behavior . <section> execute sem - speed - test on the mpc750 test platform observe inconsistent behavior during / after test ( sometimes it completes ok , sometimes errors , occasionally even a reboot ) . <section> the test should complete successfully . <section> mcp750 , vxworks <number> <section> joseph hickey , vantage systems , inc .",0.0
"incorrect time to first callback when using os_timercreate <allcaps> api </allcaps> <section> there discrepancies between the expected first callback and the time the first callback actually occurs , for timers created via <code> . this is with regards to the "" start_time "" parameter . <section> the <code> example program exposes this bug . it was never seen because on <allcaps> posix </allcaps> the difference is not substantial enough to cause failure , but on vxworks it does fail . general sequence is : create a timer via <code> set the timer using <code> with start_time = <number> ( <number> sec ) and interval_time = <number> ( 4 0 0 ms ) . the time between the os_timerset call and the first timer callback should be <number> seconds ( within system timer tick tolerances ) but it is approximately <number> seconds on <allcaps> posix </allcaps> . on vxworks the difference is even more substantial , causing failure of the timer - test example program . <section> the time between the os_timerset call and the first timer callback should be equivalent to the <code> parameter from the os_timerset call . <section> ubuntu <number> . <number> <allcaps> lts </allcaps> , <number> bit , using <code> <allcaps> osal </allcaps> build vxworks <number> on mcp750 , using <code> <allcaps> osal </allcaps> build both running the "" timer - test "" example program . <section> this appears to be limited to cases where the backward - compatible os_timercreate <allcaps> api </allcaps> is used . in this case an implicit timebase object is created just to service the single timer . in this mode , there is an initial condition issue in the wait routine , and the first interval therefore is not correct . if the timer callback is registered via <code> followed by <code> , then it is ok . <section> joseph hickey , vantage systems , inc .",0.0
"incorrect test of taskspawn result in vxworks implementation <section> the vxworks implementation is testing for an error result from the <code> <allcaps> api </allcaps> call by comparing with <code> . this is incorrect , the vxworks <allcaps> api </allcaps> documentation says that when taskspawn fails , it returns the value <code> , not <number> . <section> this can only be reproduced in unit test . <section> the error handing path should be taken when <code> returns <code> . <section> ubuntu <number> . <number> <allcaps> lts </allcaps> <number> bit ( running <allcaps> osal </allcaps> coverage unit tests ) <section> discovered when implementing the coverage error path unit tests in # <number> <section> joseph hickey , vantage systems , inc .",0.0
"remove vxworks6 coverage code , rename vxworks - ng to vxworks <section> for the <code> code , the directory names must match those of the actual implementation they are testing . the build scripts assume / require this name relationship . recently , the classic <allcaps> osal </allcaps> implementations were dropped and the "" - ng "" implementations replaced them in the main code tree , but the unit - test - coverage still has the old vxworks6 and new vxworks - ng directories . the old <code> should be removed and the <code> needs to be renamed to be <code> . <section> build coverage code using e . g . : <code> the subsequent <code> will fail because there is no longer an <allcaps> osal </allcaps> implementation named <code> , it is named <code> now . <section> the build should complete successfully <section> ubuntu <number> . <number> <number> - bit <section> joseph hickey , vantage systems , inc .",0.0
remove references to osal_opaque_object_ids and osal_abstract_filesys_types <section> references to removed <hashtag> defines </hashtag> remain in the unit test code . <url> <section> remove references <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update function header comments on "" ng "" implementation functions action item from vxworks - ng review held on <number> - <number> - <number> : across posix - ng , rtems - ng , and vxworks - ng , the implementation functions have header comments that were cut and paste from the original implementation and may not reflect the actual code anymore . this should be scrubbed prior to the <allcaps> osal </allcaps> release .",0.0
move os_fs_err_ * defines to common os error definitions os_directoryopen returns os_invalid_pointer if dir_id or path pointers are <allcaps> null </allcaps> . os_directoryread returns os_fs_err_invalid_pointer if dirent pointer is <allcaps> null </allcaps> . likely other cases of mixed use . suggest deprecation of the os_fs_err_ * defines and switch to common definitions .,2.0
"improve consistency and reduce duplication in various <allcaps> bsp </allcaps> / <allcaps> psp </allcaps> implementations currently in the <allcaps> cfe </allcaps> / <allcaps> osal </allcaps> world we have at least four different platform - specific abstraction methods , all of which basically do the same thing of getting common code to run on a different platforms . all of these provide three very basic bits of functionality , in different flavors : - provide a well - known entry point symbol for the platform ( main , init , etc ) - get the system into a proper state for running the app - invoke <code> - - or whatever the real app entry point is - do something for idle time while the app runs ( a shell , or just an idle loop ) . - shut it down when complete <section> : on the <allcaps> osal </allcaps> side this is provided by the "" <allcaps> bsp </allcaps> "" . it has genppc - vxworks6 . <number> , pc - linux , pc - rtems , sparc - vxworks6 . <number> , sis - rtems , and mcf5235 - rtems ( the latter <number> are somewhat unmaintained / untested ) . <section> : when running unit tests , an alternative <allcaps> osal bsp </allcaps> is used which has extra functionality for running the tests . the idea is that any platform capable of running applications should also be capable of running unit tests . unfortunately , to avoid changing existing <allcaps> bsp </allcaps> functions , this was "" cloned "" and therefore this has basically morphed into a second duplicate provider of the entry point / startup / shutdown logic , because ut needs a slightly different setup from a regular app . there still is , however , a considerable amount of overlap between the "" ut "" <allcaps> bsp </allcaps> and the regular application <allcaps> bsp </allcaps> . / / proposal / /: these should be made into an extension of the basic <allcaps> osal bsp </allcaps> . <section> : the <allcaps> cfe psp </allcaps> also provides many of the same services . on the <allcaps> cfe psp </allcaps> repo , there are "" pc - linux "" , "" pc - rtems "" , and "" mcp750 - vxworks6 . <number> "" . these are basically extended versions of the <allcaps> osal bsp </allcaps> , and also provide entry point / shutdown logic , but they also do <allcaps> additional </allcaps> configuration that is specific to <allcaps> cfe </allcaps> before calling the <allcaps> cfe </allcaps> entry point . / / proposal / /: like the unit tests , the <allcaps> cfe psp </allcaps> should be an extension of the <allcaps> osal bsp </allcaps> , not a replacement for it . the <allcaps> psp </allcaps> already defines a <code> entry point for itself , and this can be invoked as a second - stage after os_application_startup to do the additional startup tasks required for <allcaps> cfe </allcaps> . <section> : the <allcaps> jsc </allcaps> - provided unit tests residing in the <code> directory contain their own platform abstractions by way of preprocessor macros and alternate header / source files . the source / header file choice is based off the <code> , <code> , and <code> compile - time macros . in turn , this defines additional macros for platform - specific routines like sleep / logging / taskdelay , etc . these tests are already using an entry point provided by the ut - <allcaps> bsp </allcaps> described in ( <number> ) above , the macros supplement this . the problem is that not all platforms are provided . most notably , there is no implementation for _rtems_os_ , so these tests are currently unbuildable on pc - <allcaps> rtems </allcaps> . / / proposal / /: functions like sleep / delay and other platform - specific bits should be changed from a macro to an <allcaps> api </allcaps> call provided by the ut - <allcaps> bsp </allcaps> . logging functions are already provided by the ut - <allcaps> bsp </allcaps> . furthermore , all the test cases should use utassert calls to make the output consistent with everything else .",2.0
fix unused variables in <allcaps> rtems </allcaps> compiling with <code> noted two unused variables in <allcaps> osal </allcaps> for rtems - ng . these are simple fixes to clean up .,0.0
"remove unit test backwards compatibility in osapi - filesys functions flight code should have the right implementation , and unit test code should be fixed to match . current comments indicate the flight code is less than optimal to match unit test code . specifically : os_fs_error vs os_err_name_not_found returns .",2.0
remove <allcaps> osal </allcaps> dependencies on deprecated <allcaps> osal </allcaps> elements building with osal_omit_deprecated fails . first error : / home / jhageman / cfs / cfs - dev / osal / src / unit - tests / shared / ut_os_stub_platforms . h : <number> : <number> : error : unknown type name ‘ os_fdtableentry ’ extern os_fdtableentry os_fdtable [ os_max_num_open_files ] ;,0.0
"update backwards compatibility comments in the osapi - filesys functions really not backwards compatibility , but in support of abstraction and in the spirit of portability operations attempted on a fs_based file system that arn ' t actually allowed should no - op and return success .",0.0
deprecate endian temporary compatibility macors the bit_order defines in src / os / inc / common_types . h are marked as temporary and should be easily removed to check compatibility . check for use in cfs framework .,2.0
add bsp_ut functionality for genppc vxworks to be able to run unit tests need to be able to run unit tests on vxworks - ng for end - of - summer release .,0.0
"remove old <allcaps> mks </allcaps> flags in comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",0.0
"remove <allcaps> deprecated </allcaps> define in ut_assert , utmemset has been marked <allcaps> deprecated </allcaps> for <number> years , since [ changeset : 1 0 b7816 ] as part of ticket # <number> .",0.0
deprecate osalbool and boolean in favor of c99 bool eliminates unnecessary redefines .,0.0
"remove custom fixed size types option custom fixed size types in common_types . h requires assumptions outside required standards . remove this code in favor of stdint . h . for any platform without stdint . h the resolution is platform dependent and outside the scope of the cfs framework . remove _have_stdint_ logic from cmake recipe , and custom defines in common_types . h . see also [ cfs_cfe : <number> ] in cfs_cfe .",0.0
"use c11 ' s _static_assert for compiletimeassert when available it is straightforward to test the c version and define <code> using c11 ' s [ <url> _static_assert keyword ] this can be done e . g . {{{# ! c <hashtag> if </hashtag> __stdc_version__ >= 2 0 1 1 1 2 l <hashtag> define </hashtag> compiletimeassert ( condition , message ) _static_assert ( condition , <hashtag> message </hashtag> ) <hashtag> else </hashtag> <hashtag> define </hashtag> compiletimeassert ( condition , message ) typedef char message [ ( condition ) ? <number> : - <number> ] <hashtag> end if </hashtag> } } } this avoids polluting the type namespace with the magic typedefs used in the older implementation , and also produces better error messages if the assertion fails . it would also be possible to use c + + <number> ' s [ <url> static_assert keyword ] in a similar manner , but i am not sure if this is desirable ; this depends whether we want to officially support using this header in c + + code . i will create a branch containing the attached patch and update this ticket .",2.0
""" host_module_id "" in os_module_prop_t might be too small on <number> - bit machines the <code> structure ( output by <code> ) contains a field "" host_module_id "" which is a <code> type . this is possibly too small for some machines and can cause a warning , notably on <number> - bit builds where the host module is tracked natively as a <code> . suggest to either use a <code> type instead , or to remove this field altogether as it is really a crutch that should not be needed ( a good abstraction means that the app should not ever need to know this , and if the app actually does use it , then the app is not portable ) .",0.0
"avoid continuous looping in the time base callback thread as part of the "" timebase "" implementation , a high priority helper thread is used as the context for timer callbacks . this is supposed to block on a <code> or some other custom <allcaps> psp </allcaps> - supplied function until a tick arrives . however , if something goes wrong with the wait routine and it does <allcaps> not </allcaps> actually block for whatever reason , then a continuous loop is possible . because it is running as a high priority realtime thread , on a single core system this has the effect of locking up the <allcaps> cpu </allcaps> . in the case that the blocking function fails to block , this needs a failsafe to prevent hogging the <allcaps> cpu </allcaps> .",0.0
"add support for asynchronous console output in shared layer ( ng ) on some target boards , the console output from <code> needs to be buffered and sent to a separate task for output . this was enabled on several vxworks targets through the <code> directive , but generally was not implemented on <allcaps> posix </allcaps> or <allcaps> rtems </allcaps> targets , where os_printf was a simple wrapper around printf . this console output buffer will become necessary in order to support this paradigm for a vxworks - ng implementation . the basic framework for doing this is fairly simple , and may provide immediate benefit for any <allcaps> rtems </allcaps> or <allcaps> posix </allcaps> boards that might want to enable it , too .",2.0
"fix nonexistent symbol lookup in <allcaps> rtems </allcaps> in the event of a lookup on a nonexistent symbol , the <allcaps> rtems </allcaps> <code> implementation does not return <allcaps> null </allcaps> like the <allcaps> posix </allcaps> implementation does . this is intended to differentiate between a nonexistent symbol and a symbol that exists but actually has an address of <allcaps> null </allcaps> . unfortunately , this makes the <allcaps> osal </allcaps> symbol lookup <allcaps> api </allcaps> return "" success "" and a <allcaps> null </allcaps> address , which can cause the implementation to jump to <allcaps> null </allcaps> if e . g . a bad entry point name was supplied .",0.0
"clean up the "" os_shelloutputtofile "" implementation the implementation of this function is something of a kludge , generating a shell command string using redirection characters ( > ) to redirect the output to a file and then calling <code> using this string . as the intended output file is in fact already "" open "" by the local process , it is far cleaner and less error prone to invoke <code> directly , and simply <code> the filehandles to be stdout_fileno and stderr_fileno , then exec the shell process . this avoids a bunch of issues related to the system ( ) call .",2.0
"improve shared layer to support lookups by keys other than id the shared layer currently only supports object / resource lookups by id . the code locks the table , does a direct calculation of the table index using the id , and confirms that the id is correct . this supports the vast majority of <allcaps> osal </allcaps> calls where the subject resource is passed in using a <number> - bit resource identifier . however , there are other <allcaps> api </allcaps> calls which require lookup by name rather than id . some of these must continue to exist for backward compatibility , but still should use as much of the same infrastructure as possible .",2.0
"add semaphore speed test during discussions of the ng architecture , a recurring concern was regarding the additional function calls and possible increase in overhead related to this . rather than act on assumptions , it is better to actually benchmark the code in question to determine if optimizations are necessary , and if so , where those optimizations should be done .",2.0
"fix unit test coverage build during some recent unit testing , it was observed that the coverage flags ( - pg , - - coverage ) were not being correctly applied to code under test , and therefore the coverage report could not be generated . i tracked this down to a previous build change that reset all c flags to allow the unit testing to be performed with a different <allcaps> bsp </allcaps> than the main test . unfortunately as a side effect the ut coverage flags were also lost .",0.0
"os_cp cleanup looking at os_cp , which does a system call to the "" cp "" command , this is really ugly , not realtime - friendly , and probably a security risk ( if you could somehow inject a ' ; ' into the system call , which should not be difficult . <repeated> does not look like os_translatepath catches this . ) i suggest re - writing os_cp to do an open , a loop of read / write , and close ( with the appropriate checks to ensure errors are handled . ) also looks like os_translatepath does the check for <allcaps> null </allcaps> and length , so the os_ { cp | mv | remove | . <repeated> } should not do the same .",0.0
remove last - gen osals and replace with next gen removing last - gen with <allcaps> osal </allcaps> <number> . <number>,0.0
"osconfig . h os_queue_max_depth unused os_queue_max_depth is defined as <number> in osconfig . h for both pc - rtems and pc - linux , but the limit is not applied / checked / or even used within <allcaps> osal </allcaps> . queue depth is accepted as input by os_queuecreate with no limiting within <allcaps> osal </allcaps> . note cfe also has a max pipe depth ( cfe_platform_sb_max_pipe_depth ) that is applied by the cfe prior to calling os_queuecreate , but it ' s set to <number> . this limit seems arbitrary at the cfe level . linux depth limit by default is <number> on at least centos , would be nice if it worked out of the box .",2.0
"correct build errors in ut assert bamboo build for legacy configurations where the old type mapping is used in <code> , the ut assert library fails to build with the following errors . this is from the bamboo logs when building in the classic mode . / home / bamboo - remote - agent / bamboo - agent - home / xml - data / build - dir / <allcaps> cfs </allcaps> - <allcaps> cfscfe </allcaps> - ja / osal / ut_assert / src / utassert . c : <number> : <number> : error : unknown type name ' uint32_t ' / home / bamboo - remote - agent / bamboo - agent - home / xml - data / build - dir / <allcaps> cfs </allcaps> - <allcaps> cfscfe </allcaps> - ja / osal / ut_assert / src / utstubs . c : <number> : <number> : error : unknown type name ' bool ' this issue is causing bamboo to fail on the "" job a "" of both <allcaps> cfe </allcaps> and <allcaps> osal </allcaps> . other jobs that use the stdint . h based mapping are ok .",0.0
"requirement option to exit / abort on app load failure <allcaps> ccb </allcaps> <date> discussion relative to # <number> touched on a possible debug option to shut down / exit / abort on app load failure . in the context that there are some debugging hooks already , could add this as an extreme reaction ( avoids time spent searching for why the system is not working as expected ) . kicked up to the steering committee / requirements discussion to resolve if this is required optional behavior .",2.0
pthread_stack_min typo in <allcaps> posix </allcaps> / <allcaps> posix </allcaps> - <allcaps> ng osal </allcaps> both the <allcaps> posix </allcaps> and <allcaps> posix </allcaps> - ng osals contain the following in <code> : {{{# ! c <hashtag> if n def </hashtag> pthread_stack_min <hashtag> define </hashtag> pthread_stack_min <number> <hashtag> end if </hashtag> } } } i believe this is supposed to be <number> or <number> * <number> .,0.0
"port vxworks <allcaps> osal </allcaps> to shared / ng <allcaps> osal </allcaps> architecture this is a follow - on to # <number> . the original change set was merged to development branch as of the <number> - <number> - <number> <allcaps> ccb </allcaps> , without yet having an implementation for vxworks that uses the refactored architecture . before the next <allcaps> osal </allcaps> release , there should be an implementation for vxworks using the shared layer , to go with posix - ng and rtems - ng .",2.0
"improve coverage test for "" shared "" layer this is a follow - on to original ticket # <number> as part of the original change sets , a basic coverage test was added for the shared layer . it calls most functions in a nominal case , but does not yet cover a sufficient number of the error cases . for instance the module loader only has <percent> of line coverage . others are between <number> - <percent> but could still be improved ( files , queues , timers ) . it has been discussed in <allcaps> ccb </allcaps> meetings during the review for # <number> that we should make another pass through the coverage test logs to improve the error case coverage prior to releasing the next <allcaps> osal </allcaps> .",2.0
mqueue test program <allcaps> osal </allcaps> should include a simple mqueue test program to validate that the user has the correct settings and permissions to create / open / close / delete mqueues . often users stumble on mqueue configuration and it is more difficult to diagnose when it ' s wrapped in the entirety of <allcaps> osal </allcaps> / cfs .,2.0
"consider moving cpu usage code to <allcaps> osal </allcaps> currently , code to request cpu usage is included in the hs application . however , this requires hs to be modified to run on different operating systems . because the code to request cpu usage is os - specific , consider moving this functionality out of hs to the <allcaps> osal </allcaps> .",2.0
scrub cppcheck warnings in <allcaps> osal </allcaps> dev branch the bamboo continuous integration server runs cppcheck static analysis on every build . this ticket is for tracking any small / minor fixes to address concerns brought up by this tool . nothing here should change any functionality . ( anything bigger than a simple one or two - liner should probably have its own ticket for tracking ) .,0.0
clean up unneeded ut assert compatibility logic the <allcaps> osal ut </allcaps> assert framework has a number of functions to act as a bridge or compatibility layer for historical <allcaps> cfe </allcaps> unit test cases . with the current <allcaps> cfe </allcaps> these test cases should be fixed and therefore this compatibility code is no longer necessary . this should be cleaned up as part of the next <allcaps> osal </allcaps> / <allcaps> cfe </allcaps> release set .,2.0
os_timercreate ( ) callback functions & event messages event messages in callback functions seem to associate the event app id with timer id . the first timer created gets a timer id of zero and events in the callback are get associated with cfe_evs ( app_id = <number> ) . the second timer gets a <allcaps> tid </allcaps> of <number> so events are associated with cfe_sb ( app_id = <number> ) . i did not dig through all of the code to prove this and i observed this behavior on a linux deployment .,0.0
"bsp_ut updates to work with cfe <number> the associated changeset specifically addresses control code use , conditionally dependent on os .",0.0
"remove conditionally compiled code prior to next <allcaps> osal </allcaps> release as part of <allcaps> osal </allcaps> development several macros are utilized to allow the code to be merged in pieces without breaking existing code . before the next <allcaps> osal </allcaps> release is finalized , these conditional - compile macros should be removed and only the active branch should remain . at least these two macros should always be considered "" enabled "" in future versions : <code> <code>",2.0
"way to get raw os task priority / <allcaps> osal </allcaps> has too many priorities <allcaps> osal </allcaps> attempts to provide a uniform set of task priority by translating the given priority to a native os priority . this is often done by assigning bins that certain priorities can fall into . typically , applications can set their priorities far enough apart that this is not a problem . however , sometimes tighter control would be nice especially in systems where the number of available priorities is fewer than <allcaps> osal </allcaps> . ( for example , <allcaps> osal </allcaps> provides <number> priorities but <allcaps> posix </allcaps> only <number> . ) <allcaps> posix </allcaps> , for example , can see priorities squashed where tasks become round - robin instead of higher priority than one another . having to pick <allcaps> osal </allcaps> priorities when writing apps with many child threads based on what you know the characteristics of the underlying os to be defeats the purpose of <allcaps> osal </allcaps> . one way to fix this is to create a macro os_raw_prio ( x ) where the most significant bit of a priority is set , which has meaning to <allcaps> osal </allcaps> ' s thread creation mechanism . this would tell it to use the raw value instead of translating . another approach would be to lower the number of maximum <allcaps> osal </allcaps> priorities to a number lower than most rtoss ( like <number> or so ) so that there can always be unique priorities in any underlying os . or , this could be made configurable when building the system .",2.0
"<allcaps> osal </allcaps> needs a concept of event one useful primitive missing from <allcaps> osal </allcaps> is an event concept . in <allcaps> posix </allcaps> , this could be implemented via pipe ( ) where an event is signaled by writing to the write pipe , and cleared by reading from the read pipe . this is useful because multiple events can be blocked upon using select ( ) . ( <allcaps> osal </allcaps> supports select ( ) , so this makes sense . )",2.0
"osal needs blocking timer <allcaps> api </allcaps> the current <allcaps> osal </allcaps> timer <allcaps> api </allcaps> calls callbacks in an unknown context to the user when the timer event fires . this removes flexibility from the user to manage their own threads . a new <allcaps> api </allcaps> ( or addition to existing one ) should be created where the user can read from the timer , which will block until the event fires . as this would be a periodic timer , the user should also be able to be informed of overruns that occurred . this functionality mirrors <allcaps> posix </allcaps> timerfd / read ( ) .",2.0
"os_queuedelete ( ) has too small of a char name buffer looks like a copy / paste error but the "" name "" variable used to figure out a unique name for mq_open ( ) & mq_unlink ( ) calls is of different sizes between os_queuecreate ( ) and os_queuedelete ( ) . in os_queuedelete ( ) , change : char name [ os_max_api_name + <number> ]; to : char name [ os_max_api_name * <number> ]; the result is memory clobbering when deleting a queue of a longer name .",0.0
"posix - ng / posix os_moduleload flag inconsistency in the <allcaps> posix osal </allcaps> , modules are loaded by <code> with a flags value of <code> whereas in posix - ng the flags value is <code> . changing from <code> to <code> alters the behavior of <code> . it may be desirable to make that change , but it should be consistent between the <allcaps> posix osal </allcaps> implementations .",0.0
"please provide va_list variants of variadic functions variadic functions in c can not easily be wrapped in another variadic function . to resolve this issue , the c standard library provides variants of its variadic functions that take a { { { va_list } } } . for example , { { { printf } } } has the { { { vprintf } } } variant . please provide similar variants for the <allcaps> osal </allcaps> ' s variadic functions . the implementation would be simple : the majority of the function ' s logic can reside in the { { { va_list } } } version , and the variadic function can become thin a wrapper around the { { { va_list } } } version . at the time of submitting this issue , the only variadic function in <allcaps> osal </allcaps> is <code> . see also [ cfs_cfe : <number> cfe issue <number> ] .",2.0
"<allcaps> osal </allcaps> boolean should use actual c99 bool type on c99 + platforms that have the builtin <code> type , this should be used for the <allcaps> osal </allcaps> boolean typedef rather than <code> . two major benefits : <number> . smarter implicit conversion semantics . during <allcaps> cfe </allcaps> <number> testing there was one case discovered where an ( nonzero ) <code> was directly passed to a function taking <code> , which was implicitly truncated to <number> bits and became zero ( false ) because the <allcaps> lsb </allcaps> was zero . when using the actual builtin boolean type , this remains true . <number> . better warnings . in newer version of <allcaps> gcc </allcaps> it will flag warnings on suspicious expressions used as truth values ( such as an assignment ) .",2.0
"posix : use rtld_default instead of <allcaps> null </allcaps> in dlsym in { { { os_symbollookup } } } defined in { { { osloader . c } } } in the <allcaps> posix osal </allcaps> , [ <url> dlsym ] is used to obtain the address of the specified symbol : { { { function = dlsym ( ( void <wink> <number> , symbolname ) ; } } } the behavior of { { { dlsym } } } when called with a null pointer for the first argument is not defined by <allcaps> posix </allcaps> . on <allcaps> gnu </allcaps> / linux , this value corresponds to { { { rtld_default } } } , as found in { { { / usr / include / dlfcn . h } } } . { { { # define rtld_default ( ( void <wink> <number> ) } } } when called with { { { rtld_default } } } as a first argument , "" the identifier lookup happens in the normal global scope ; that is , a search for an identifier using handle would find the same definition as a direct use of this identifier in the program code . "" this appears to be the intended behavior in the <allcaps> osal </allcaps> . however , the value of { { { rtld_default } } } is implementation - defined according to <allcaps> posix </allcaps> . the macro , rather than the value it happens to have on <allcaps> gnu </allcaps> / linux , should be used . this would address part of # <number> .",2.0
"clean up <allcaps> osapi </allcaps> prototypes there are still several functions , mainly in the filesystem area , where input string parameters are missing the <code> qualifier . these prototypes should be fixed . note that adding <code> typically will not affect user code , as it is ok to pass non - const into const , just not the other way . this will fix warnings on the <allcaps> cfe </allcaps> side .",0.0
"enhancements to ut assert testing framework the ut assert framework stub <allcaps> api </allcaps> supported only "" consumable "" data buffers , which works well for calls such as read / write , where the buffer is filled with each call . it does not work as well for such things as the critical data store ( <allcaps> cds </allcaps> ) in cfe_es , which require a stub to mimic "" random access "" behavior . for this , the stub would have to retain the buffer between calls . this ticket is to add all the necessary enhancements to allow full testing of <allcaps> cfe </allcaps> / <allcaps> cfs </allcaps> .",2.0
add symmetric multiprocessing ( <allcaps> smp </allcaps> ) support flight and ground computing platforms contain multiple processing cores . symmetric multiprocessing ( <allcaps> smp </allcaps> ) support must be added to the <allcaps> osal </allcaps> to fully utilize these platforms .,2.0
"pointer handed to pthread_setspecific is not a pointer the pthreads "" setspecific "" and "" getspecific "" apis are used to associate a pointer value , specific to the current thread , with a key value indicating what it represents . the <allcaps> posix </allcaps> implementation of <allcaps> osal </allcaps> uses this facility to store the thread - specific index of the thread ' s task in the task table , and it does so by casting the small integer value to have a pointer type . it would be safer , instead , to store a pointer to the actual row of the task table as the thread - specific data ; this would not violate the expectation that a pointer is either <allcaps> null </allcaps> or represents the address of valid data . extraction of the table index then becomes a range check followed by a pointer subtraction , rather than a combination of memory copies and masks that make unportable assumptions about sizes and endianness . marked as "" minor "" priority as existing code accidentally works on <number> - bit systems and little - endian <number> - bit systems where sizeof ( int ) = = <number> , which accidentally covers current use cases .",0.0
"document method on linux to modify user priority limits the posix osal can set priorities in linux . out of the box , this only works if you run <allcaps> cfs </allcaps> as root . in a lab environment , with many developers using shared lab workstations , root access for everyone is not an option . this method allows <allcaps> cfs </allcaps> apps , running as standard privileged users , to use the priority settings in the startup script ( . scr file ) . <number> ) as root , set the following config : update "" rtprio "" in / etc / security / limits . conf for a user or group . <code> <number> ) the following changes to the currently released <allcaps> osal </allcaps> <number> . 1 a will need to be applied to osal / src / os / posix / osapi . c . add this include to osal / src / os / posix / osapi . c . <hashtag> include </hashtag> < sys / resource . h > /* danny strauss / aa2 - for getrlimit ( ) */ in osal / src / os / posix / osapi . c : : os_taskcreate ( ) , replace the following code : /* * * test to see if the user is running as root . * * root is required to set the scheduling policy , stack , and priority */ if ( geteuid ( ) = = <number> ) with this code : /* danny strauss / aa2 : remove geteuid check to allow all users to set task * attributes ( priority , etc . ) and replace it with a check of user ' s * allowed system rt priority limit */ struct rlimit rl ; getrlimit ( rlimit_rtprio , & rl ) ; printf ( "" os_taskcreate : setting %s priority % d . "" , task_name , os_priority ) ; if ( os_priority > ( int ) rl . rlim_cur ) { printf ( "" os_taskcreate : <allcaps> warning </allcaps> priority not set because you are limited to priority % d \ n "" , ( int ) rl . rlim_cur ) ; } else { printf ( "" \ n "" );",1.0
"pthread_cond_wait ( ) spurious wakeup in os_binsemtake in os_binsemtake ( ) in the posix osal , a call to pthread_cond_wait ( ) is used for signaling from the task giving the semaphore . however , it is possible for pthread_cond_wait ( ) to return in the event of a spurious wakeup , without the condition it was actually waiting on becoming true . to fix this , the call to pthread_cond_wait ( ) should be wrapped in a while loop that checks the condition after the calling task is woken up . e . g . { { { while ( os_bin_sem_table [ sem_id ] . current_value < os_bin_sem_table [ sem_id ] . max_value ) { ret = pthread_cond_wait ( & ( os_bin_sem_table [ sem_id ] . cv ) , & ( os_bin_sem_table [ sem_id ] . id ) ); } } } }",0.0
"mq_open has invalid data in struct mq_attr os_queuecreate uses mq_open , and it passes a partially - initialized struct mq_attr as the last parameter . this structure should be initialized to <number> as two fields in it contain junk .",0.0
"os_translatepath ( ) does not handle mountpoint equal to virtualpath discovered while using cfs_fm app , if one were to get a directory listing for "" / cf "" , then <allcaps> osal </allcaps> will report this does not exist because of a bug in os_translatepath ( ) . you are required to ask for "" / cf / "" because the code is looking for a required trailing slash . this seems to be true of all volumes listed in one ' s volume table ( cfe_psp_voltab . c ) . this trailing slash should not be required . two diff outputs with fixes are enclosed . <repeated> one for vxworks6 and one for posix . { { { diff - - git a / cfs_osal / src / os / vxworks6 / osfilesys . c b / cfs_osal / src / os / vxworks6 / osfilesys . c index 0 2 e0a3c . <repeated> 4 8 6 3 6 d3 <number> - - - a / cfs_osal / src / os / vxworks6 / osfilesys . c + + + b / cfs_osal / src / os / vxworks6 / osfilesys . c @ @ - <number> + <number> @ @ int32 os_translatepath ( const char * virtualpath , char * localpath ) if ( os_volumetable [ i ] . freeflag = = <allcaps> false </allcaps> ) { path_on_device = skip_prefix ( virtualpath , os_volumetable [ i ] . mountpoint ) ; - if ( path_on_device & & ( ' / ' = = * path_on_device ) ) + if ( path_on_device & & ( ( ' / ' = = * path_on_device ) || ( ' \ <number> ' = = * path_on_device ) ) ) { <hashtag> if def </hashtag> os_debug_printf printf ( "" numchars : % d \ n "" , path_on_device + <number> - virtualpath ) ; } } } { { { diff - - git a / cfs_osal / src / os / posix / osfilesys . c b / cfs_osal / src / os / posix / osfilesys . c index ef92ce9 . <repeated> a6f9a15 <number> - - - a / cfs_osal / src / os / posix / osfilesys . c + + + b / cfs_osal / src / os / posix / osfilesys . c @ @ - <number> + <number> @ @ int32 os_translatepath ( const char * virtualpath , char * localpath ) if ( os_volumetable [ i ] . freeflag = = <allcaps> false </allcaps> ) { path_on_device = skip_prefix ( virtualpath , os_volumetable [ i ] . mountpoint ) ; - if ( path_on_device & & ( ' / ' = = * path_on_device ) ) + if ( path_on_device & & ( ( ' / ' = = * path_on_device ) || ( ' \ <number> ' = = * path_on_device ) ) ) { <hashtag> if def </hashtag> os_debug_printf os_printf ( "" numchars : % d \ n "" , path_on_device + <number> - virtualpath ) ; } } }",0.0
"( re ) create <allcaps> osal </allcaps> for <allcaps> osx i </allcaps> use <allcaps> osx </allcaps> as a development environment and , while i can easily use a vm of linux , it would be nice to be able to compile / run cfs in <allcaps> osx </allcaps> natively . there are a couple issues with using the posix <allcaps> osal </allcaps> on <allcaps> osx </allcaps> : * there is no timer interface . * pthreads does not include the priority control <allcaps> api </allcaps> ' s * there are no "" _init "" or "" _fini "" externs for stack introspection . * no vfs . h * dlsym takes special rtld_ * handles to define its namespace search behavior ( <allcaps> null </allcaps> does not work . )",2.0
readme and makefile updates for <allcaps> osal </allcaps> <number> . <number> the various readme ' s skipped steps and were confusing when trying to stand up and run a clean set of tests on <number> - bit pc - linux . ( if it bit some experienced folks multiple times then others will be bit as well . ) included a quick unintrusive fix for # <number> in tended for pc - linux builds .,0.0
"pc - linux osloader unit test builds wrong test files (x 8 6 _64 ) on x86_64 linux platforms , the pc - linux osloader unit test builds the eeprom1 module test files for the x86_64 platform - even when you are building with the - m32 flag in the osal - config . mak file . all other tests and binaries are properly built as <number> - bit with that osal - config . mak change so the osloader unit tests fail to load <number> - bit modules . the current workaround is to : { { { cd osal / build / unit - tests / osloader - test make - f modules . mak clean make - f modules . mak # and continue testing . / osloader - test . bin } } }",0.0
update version number for <allcaps> osal </allcaps> <number> . <number> release the version number information in the osapi - version . h file needs to be updated to reflect the <number> release as follows : <hashtag> define </hashtag> os_major_version ( <number> ) <hashtag> define </hashtag> os_minor_version ( <number> ) <hashtag> define </hashtag> os_revision ( <number> ) <hashtag> define </hashtag> os_mission_rev ( <number> ),2.0
<allcaps> osal </allcaps> <number> . <number> version description document review cycle please see the attached <allcaps> osal </allcaps> <number> . <number> <allcaps> vdd </allcaps> open for <allcaps> ccb </allcaps> review ( <allcaps> osal </allcaps> <number> . <number> version description document - initial . docx ) and provide review comments / approval .,0.0
black box unit tests do not ensure resources are cleaned up between tests unit tests should utilize a setup and teardown approach to ensure each test runs in an expected and known configuration . the teardown function needs to ensure that all test objects and resources have been deallocated and cleanup .,2.0
"functional timer test hard codes configuration value the functional timer test ( / src / tests / timer - test / timer - test . c ) hard codes the number of timers to <number> , which may be higher than the os_max_timers configuration set in osconfig . h . it is recommended to update the test to use the os_max_timers configuration macro or add protection with an <hashtag> if </hashtag> guard .",2.0
"vxworks <allcaps> osal </allcaps> uses potentially unsafe "" strcpy "" operations in at several locations the vxworks <allcaps> osal </allcaps> is using <code> and <code> functions to copy strings between string buffers that are sized using different macros . at least one of the sizes in play , the <code> comes from the user - configurable "" osconfig . h "" file . other sizes , such as <code> are specified in the local headers and are <section> user - configurable . in some functions , such as <code> ( but not limited to this ) , a local buffer of size <code> is copied into a global buffer of size <code> . however , because the <code> is configurable via the osconfig . h file , it is not guaranteed that <code> is less than or equal to <code> .",0.0
"missing documentation on howto build / run unit and functional tests at a minimum a simple readme file should be included under the functional , black box , and white box unit test directories to provide users with some guidance on how to build and run each set of tests .",1.0
"posix does not alert users of undefined symbol during load the posix <allcaps> osal </allcaps> implementation of the os_moduleload <allcaps> api </allcaps> simply returns os_error when a bundle fails to load . this return error code provides no information for users to troubleshoot the cause of the load failure . in many cases the load error is due to an undefined symbol in the load bundle . the undefined symbol name may be captured in the string returned by the dl_error ( ) function . the information captured in the call to dl_error ( ) should be printed via the os_printf function and / or easily made accessible to users for troubleshooting . note : the vxworks <allcaps> osal </allcaps> implementation of the os_moduleload <allcaps> api </allcaps> ( when os_debug_printf is defined ) will print information to the console when a module cannot be loaded . specifically the following os_printf statement is used : os_printf ( "" <allcaps> osal </allcaps> : error , cannot open application file : %s \ n "" , translated_path ) ;",2.0
"provide useful output upon posix osloader failure the posix osloader . c ' s os_moduleload ( ) fails ' ' ' very ' ' ' tersely providing absolutely no help in figuring out _why_ a module failed to load . { { { <number> /* <number> * * open the loadble bundle . <repeated> just opening it loads it into the system . <number> */ <number> function_lib = dlopen ( translated_path , rtld_lazy | rtld_global ) ; <number> dl_error = dlerror ( ); <number> if ( dl_error ) <== = "" oh so many reasons why "" <number> { <number> os_module_table [ possible_moduleid ] . free = <allcaps> true </allcaps> ; <number> return ( os_error ) ; <number> } } } } various reasons include ( but are not limited to ) : missing file , bad filename , bad path , bad path mapping , missing symbol , bad / typo entry point in the startup script , etc . this wastes developer time and frequently forces you into a debugger . a fix like this helps immensely : { { { + + + b / osal / src / os / posix / osloader . c @ @ - <number> + <number> @ @ int32 os_moduleload ( uint32 * module_id , const char * module_name , const char * fi if ( dl_error ) { os_module_table [ possible_moduleid ] . free = <allcaps> true </allcaps> ; + /* <allcaps> fixme </allcaps> - debugging */ + os_printf ( "" os_moduleload ( ) ' s dlopen failed for translated path : %s \ n "" , ( char <wink> translated_path ) ; + os_printf ( "" os_moduleload ( ) ' s dlopen error : %s \ n "" , dl_error ) ; return ( os_error ) ; } } } }",2.0
"posix queue depth differs : mqueues vs sockets running the <allcaps> osal </allcaps> oscore - test unit test with mqueue vs . sockets ( appropriate <hashtag> define </hashtag> changed in osconfig . h ) shows a difference with sockets that wasn ' t there with mqueues . { { { test # <number> queue - full [ <allcaps> failed </allcaps> ] <allcaps> failed </allcaps> [ ] os_queueput - # <number> queue - full } } } apparently the socket implementation does not implement queue depth checks with the same semantics . the socket os_queuecreate ( ) queue_depth arg is ignored : { { { int32 os_queuecreate ( uint32 * queue_id , const char * queue_name , uint32 queue_depth , uint32 data_size , uint32 flags ) } } } the socket os_queueput ( ) looks at the bytes sent , returned from sendto ( ) , and compares them to the message data size , but this results different "" depth "" semantics based on the socket behavior . the unit test fails because it is expecting the <allcaps> api </allcaps> to honor the queue depth limit and error out on os_queueput ( ) , but it does not .",0.0
"version_info . cmake looks for wrong tags in the current repo we are tagging <allcaps> osal </allcaps> releases in the form "" osal - rel - xx "" . however , the version_info . cmake file , which instructs the cmake build system how to filter tags when building the version strings , is looking for "" <allcaps> osal </allcaps> - xx "" ( caps ) . minor fix .",0.0
"posix socket os_queueget ( ) timeout fails we have linux platforms where the linux mqueue is not available and we have to use sockets . however , we are seeing a problem when using sockets vs . mqueues . when os_queueget ( ) is called with an actual timeout value ( msec ) the socket implementation appears to always return without properly reporting a message is present . sb messages pile up . the outreach drone is one such platform and we see this in our centos linux vm simulation platform ( <allcaps> osal </allcaps> configured the same for consistency ) . ( i have a unofficial report from another developer who encountered this as well . ) i think i have seen this on is with the open - source release <allcaps> osal </allcaps> as well as the current development branch . ( likely the default event filters prevented folks from seeing this if they were not looking at the sb telemetry directly . ) - - - - - - - steps to reproduce : <number> ) create a clean / pristine cfs build . ( i used a bootstrap script : <url> but it should not matter . ) ( i used all the development branches as of <date> <time> central time . ) <number> ) source setvars . sh <number> ) cd build / cpu1 <number> ) make config <number> ) remove all sb event filters ( to see on command line ) , as in : { { { @ @ - <number> + <number> @ @ * * this filtering applies only to sb events . * * these parameters have a lower limit of <number> and an upper limit of <number> . */ - <hashtag> define </hashtag> cfe_sb_filtered_event1 cfe_sb_send_no_subs_eid - <hashtag> define </hashtag> cfe_sb_filter_mask1 cfe_evs_first_4_stop + <hashtag> define </hashtag> cfe_sb_filtered_event1 <number> + <hashtag> define </hashtag> cfe_sb_filter_mask1 cfe_evs_no_filter - <hashtag> define </hashtag> cfe_sb_filtered_event2 cfe_sb_dup_subscrip_eid - <hashtag> define </hashtag> cfe_sb_filter_mask2 cfe_evs_first_4_stop + <hashtag> define </hashtag> cfe_sb_filtered_event2 <number> + <hashtag> define </hashtag> cfe_sb_filter_mask2 cfe_evs_no_filter - <hashtag> define </hashtag> cfe_sb_filtered_event3 cfe_sb_msgid_lim_err_eid - <hashtag> define </hashtag> cfe_sb_filter_mask3 cfe_evs_first_16_stop + <hashtag> define </hashtag> cfe_sb_filtered_event3 <number> + <hashtag> define </hashtag> cfe_sb_filter_mask3 cfe_evs_no_filter - <hashtag> define </hashtag> cfe_sb_filtered_event4 cfe_sb_q_full_err_eid - <hashtag> define </hashtag> cfe_sb_filter_mask4 cfe_evs_first_16_stop + <hashtag> define </hashtag> cfe_sb_filtered_event4 <number> + <hashtag> define </hashtag> cfe_sb_filter_mask4 cfe_evs_no_filter <hashtag> define </hashtag> cfe_sb_filtered_event5 <number> <hashtag> define </hashtag> cfe_sb_filter_mask5 cfe_evs_no_filter } } } <number> ) cd exe and run core - linux . bin & wait for <number> - <number> seconds as expected , running with mqueues by default , there will be no significant event messages after : { { { es startup : cfe_es_main entering <allcaps> operational </allcaps> state } } } now , to switch to sockets and show the problem : <number> ) edit build / cpu1 / inc / osconfig . h as : { { { @ @ - <number> + <number> @ @ * * this define sets the queue implentation of the linux port to use sockets * * commenting this out makes the linux port use the <allcaps> posix </allcaps> message queues . */ - /* <hashtag> define </hashtag> osal_socket_queue */ + <hashtag> define </hashtag> osal_socket_queue /* * * module loader / symbol table is optional } } } <number> ) make clean ; make <number> ) cd exe and run core - linux . bin & wait for <number> - <number> seconds , you will see : { { { <number> - <number> - <time> . <number> es startup : cfe_es_main entering <allcaps> operational </allcaps> state warning : system log full , log entry discarded . <allcaps> evs </allcaps> port1 <number> / <number> / cfe_time <number> : stop <allcaps> flywheel </allcaps> <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 0 8 , pipe es_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 0 8 , pipe es_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 0 8 , pipe es_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 8 5 , pipe ci_lab_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 8 3 , pipe sample_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 0 8 , pipe es_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 8 5 , pipe ci_lab_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 8 3 , pipe sample_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 0 8 , pipe es_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 8 5 , pipe ci_lab_cmd_pipe , sender sch_lab_app <allcaps> evs </allcaps> port1 <number> / <number> / cfe_sb <number> : msg limit err , msgid 0x 1 8 8 3 , pipe sample_cmd_pipe , sender sch_lab_app } } } each of these apps / services invokes cfe_sb_rcvmsg ( ) with a timeout value : * cfe es : 1 0 0 0 ms * ci_lab & sample_app : 5 0 0 ms they delegate to cfe_sb_readqueue ( ) and to os_queueget ( ) with a timeout value .",0.0
"os_translatepath using "" %* s "" where "" % . *s "" is correct while resolving cppcheck messages , a <code> inside <code> was replaced by an <code> call . unfortunately , the intended <code> format string was typo - decayed into a <code> resulting in the value of <code> including more of the virtual path than intended . fortunately , the use of <code> later prevents this from actually generating incorrect results . to prevent anyone from picking up this <code> call and using it as a model for other <code> replacement code , i would like to fix the format string . <repeated> for the record , the original code was : { { { strncpy ( devname , virtualpath , numchars ) ; devname [ numchars ] = ' \ <number> ' ; /* truncate it with a <allcaps> null </allcaps> . */ } } } the modified code was supposed to be : { { { snprintf ( devname , os_max_path_len , "" % . *s "" , numchars , virtualpath ) ; } } } the code as actually committed was : { { { snprintf ( devname , os_max_path_len , "" %* s "" , numchars , virtualpath ) ; } } } <allcaps> note </allcaps> : os_translatepath could also be refactored to eliminate the need for internal buffers to hold copies of the input , but that is a larger and longer task ( prototype working but needs testing and more testing ) .",0.0
create a configuration file loader <allcaps> api osal </allcaps> should provide an <allcaps> api </allcaps> for loading text configuration files ( akin to tables ) .,2.0
"cmake separate flags for c + + builds when building <allcaps> osal </allcaps> applications that use c + + , it is required to use a separate variable for the compiler flags , because sometimes these are incompatible with c compiler flags . cmake has a separate "" cmake_cxx_flags "" variable for c + + compiler commands . most importantly this issue becomes apparent if you use <code> . g + + rejects this option and it needs to be <code> ( or whatever ) instead .",0.0
"os_symbollookup function prototype variable names do not match implementation the os_symbollookup function prototype ( in osapi - os - loader . h ) defines the prototype to be : int32 os_symbollookup ( cpuaddr * symbol_address , const char * symbol_name ); while the implementations of this function declares the function with variable names that do not match the prototype : int32 os_symbollookup ( cpuaddr * symboladdress , const char * symbolname ) this could result in compiler errors / warnings on certain platforms . it is recommended to update the prototype variable names to match the implementations .",0.0
"implement osapi - os - net . h <allcaps> sbn </allcaps> , and other applications , would benefit from an <allcaps> osal </allcaps> layer over network interfaces . per the <allcaps> ccb </allcaps> action item <number> , "" update <allcaps> sbn </allcaps> to use the new <allcaps> osal </allcaps> network / socket apis "" . but there is no implementation of the osapi - os - net . h interfaces .",2.0
trick <allcaps> osal </allcaps> there is growing interest in being able to use the trick <allcaps> osal </allcaps> / <allcaps> psp </allcaps> so that a <allcaps> cfs </allcaps> build can be executed within a trick simulation - basically allowing developers to fly unmodified <allcaps> fsw </allcaps> within an all sw simulation environment on their desktop . the approach was used extensively and successfully on the morpheus project . the trick <allcaps> osal </allcaps> / <allcaps> psp </allcaps> were developed a few years ago . some work will be necessary to get them up and running again with the latest <allcaps> cfs </allcaps> .,2.0
"<allcaps> osal </allcaps> <number> version description document review cycle attached <allcaps> osal </allcaps> <number> <allcaps> vdd </allcaps> is open for <allcaps> ccb </allcaps> review . please attached any tracked changes / comments with initials included in document filename i . e . "" <allcaps> osal </allcaps> <number> . <number> version description document - sls . docx "" . following the <allcaps> ccb </allcaps> review cycle , when all changes have been reviewed / accepted or rejected , the document will be open for signature and release .",2.0
allow c99 code in <allcaps> osal </allcaps> . update compiler flags to allow c99 code to be used everywhere in <allcaps> osal </allcaps> .,0.0
update version number for <allcaps> osal </allcaps> <number> release the version number information in the osapi - version . h file needs to be updated to reflect the <number> release as follows : <hashtag> define </hashtag> os_major_version ( <number> ) <hashtag> define </hashtag> os_minor_version ( <number> ) <hashtag> define </hashtag> os_revision ( <number> ) <hashtag> define </hashtag> os_mission_rev ( <number> ),2.0
"os_readdir cannot be called with a closed handle ut_osfile_dirio_test . c closes a directory handle with os_closedir but then uses it again with os_readdir to perform a test . this causes a memory issue on vxworks . ( either the osal should return some id from a table that guards against this , and that id should never be used again to prevent double - free , or the test is invalid . )",0.0
ostimer unit test uses os_idleloop but not os_application_shutdown this prevents the unit test from successfully returning . [ changeset : ea1fcdd ] ready for <allcaps> ccb </allcaps> review,0.0
vxworks <allcaps> osal </allcaps> implementation needs os_idleloop and os_application_shutdown [ changeset : facd2b3 ] ready for <allcaps> ccb </allcaps> review,0.0
"timer - test . c has a difficult time obtaining a count for timer4 due to the start delay . i increased the loop count of the os_taskdelays , which can be interrupted by signals . on vxworks this allows the test to pass . [ changeset <tong> 8 e8bb ] ready for <allcaps> ccb </allcaps> review",0.0
"vxworks <allcaps> osal </allcaps> implementation should use static initialization where possible <allcaps> osal </allcaps> has a concept of tables of resources , where the user can configure some maximum amount of those resources . for example , the binary semaphore table could contain the static bytes of memory for the semaphore itself ( using vx_binary_semaphore or an array of size vx_semaphore_size taking care to maintain proper alignment ) and then use sembinitialize on that memory when the <allcaps> osal </allcaps> wants to create a binary semaphore instead of allocating one from the resource pool . the user configures the maximum number of resources of each type , so it ' s ok to use the memory . this enhancement would increase determinism in the system while maintaining the current <allcaps> api </allcaps> .",2.0
"os_api_init ( ) does not correct cleanup resources on error os_api_init initializes several os primitives but is made with a pattern of exiting as soon as any initialization fails without cleaning up previous successful initializations . for example : os_task_table_sem = semmcreate ( sem_q_priority | sem_inversion_safe ); if ( os_task_table_sem = = <allcaps> null </allcaps> ) { return ( os_error ) ; } os_queue_table_sem = semmcreate ( sem_q_priority | sem_inversion_safe ); if ( os_queue_table_sem = = <allcaps> null </allcaps> ) { return ( os_error ) ; } if os_task_table_sem successfully initializes , but os_queue_table_sem does not , then os_task_table_sem will become a leaked resource .",0.0
posix impl should use timer_t instead of uint32 for host_timerid the <allcaps> posix </allcaps> implementation of <allcaps> osal </allcaps> uses timer_create in ostimer . c but stores the timerid in a uint32 instead of a timer_t as per the posix specification . this would also deal with any size issues ( <number> - bit vs <number> - bit ) that may occur when building . i have checked in a fix [ changeset : 5 7 7 3 e4faf0 ],0.0
"add unit test baseline results and log files the unit test baseline ( specifically for the posix and vxworks implementations that have undergone unit testing for the <number> . <number> release ) needs to be included and delivered with the release . it is recommended to create a "" results "" directory under / src / unit - test - coverage / os for each os implementation that has been unit tested for this release .",0.0
os_api_init ( ) should be called before any <allcaps> osal </allcaps> calls are used in the unit tests the unit tests vary in how ( or if ) they call os_api_init ( ) before any <allcaps> osal </allcaps> calls are used .,0.0
ostimer unit test needs non - zero stack size parameter passed to os_taskcreate the call to os_taskcreate in ostimer - test . c needs a non - zero stack - size .,0.0
"<allcaps> osal </allcaps> <number> configuration guide updates <allcaps> osal </allcaps> <number> will be delivered with cmake and ut assert library stubs and hook functions . the <allcaps> osal </allcaps> configuration guide should be updated to provide instruction for using cmake . the ut assert library and coverage tests should be mentioned in the "" <allcaps> osal </allcaps> source distribution directories "" table under section <number> . <number> .",2.0
function declaration is not a prototype cppcheck messages : { { { src / ostimer . c : <number> : warning : function declaration is not a prototype } } } note that this is the <code> in the unit - test - coverage tree .,0.0
"uninitialized variables ( initial cppcheck detection ) <allcaps> note </allcaps> : as cppcheck gets more interesting stuff in cppcheck . cfg we may uncover more independent instances of uninitialized variables . <allcaps> tbd </allcaps> whether they lump in with this ticket or get a new one . probably a new one if we close these promptly , which we should . <repeated> cppcheck messages : { { { src / unit - tests / oscore - test / ut_oscore_queue_test . c : <number> : error : uninitialized variable : queue_data_out src / unit - tests / oscore - test / ut_oscore_queue_test . c : <number> : error : uninitialized variable : queue_data_out } } }",0.0
same expression on both sides of a binary operator cppcheck message : { { { src / unit - tests / osfile - test / ut_osfile_fileio_test . c : <number> : style : same expression on both sides of ' ||'. } } } this can helpfully point out copy - paste - edit errors where an expression was copied and pasted but not actually edited .,0.0
"repeated assignments without using the value ( real code edition ) cppcheck messages : { { { src / os / vxworks6 / osnetwork . c : <number> : performance : variable ' retval ' is reassigned a value before the old one has been used . src / os / vxworks6 / ostimer . c : <number> : style : variable ' status ' is assigned a value that is never used . } } } recommended fix methods , <allcaps> pick one </allcaps> : <number> . actually check the status variables to see if an error was returned <number> . put a <code> cast on the function call instead of storing the data that is not actually ever going to be looked at . this advertises to maintainers and to the compiler and to static analysis that we are purposefully ignoring the return value of the function . it would be a good idea to check the posix and rtems implementations to see if they have the same construct in this place . see ticket # <number> for the same problem occurring very frequently in unit test code .",0.0
"readdir is not reentrant cppcheck messages : { { { src / os / posix / osfileapi . c : <number> : portability : non reentrant function ' readdir ' called . for threadsafe applications it is recommended to use the reentrant replacement function ' readdir_r ' . } } } be sure to check vxworks and rtems implementations , they may also need fixing .",0.0
"test for unsigned variable less than zero cppcheck messages : { { { src / os / posix / osapi . c : <number> : style : checking if unsigned variable ' sem_initial_value ' is less than zero . src / os / posix / osapi . c : <number> : style : checking if unsigned variable ' sem_initial_value ' is less than zero . } } } <allcaps> note </allcaps> : be sure to check the vxworks and rtems versions , they may also need fixing .",0.0
"unreachable flow control cppcheck messages : { { { src / tests / osal - core - test / osal - core - test . h : <number> : style : consecutive return , break , continue , goto or throw statements are unnecessary . } } } yes , the code does have two return statements in a row ( this is not the case where cppcheck was getting hideously confused in a header ) .",0.0
"strncpy may not ' \ <number> ' - terminate cppcheck messages : { { { src / os / posix / osfileapi . c : <number> : warning : the buffer ' localcmd ' may not be null - terminated after the call to strncpy ( ) . src / os / posix / osfilesys . c : <number> : warning : the buffer ' filename ' may not be null - terminated after the call to strncpy ( ) . } } } joe looked at this during the <number> - <number> - <number> <allcaps> ccb </allcaps> meeting and indicated that the code involved needs fixing . joe , i am sending this to you in case you want to punch it out ; otherwise , just toss it back and we can queue up the issue normally .",0.0
"osloader_testcase code cleanup and resolution of cppcheck results cppcheck messages : { { { osloader_testcase . c : <number> : style : struct or union member ' testcopysymbolrecord_t : : symbolname ' is never used . osloader_testcase . c : <number> : style : struct or union member ' testcopysymbolrecord_t : : symboladdress ' is never used . } } } this structure exists in order to take the size of the structure containing these fields , so our code will be retaining the fields and will not be referring to them . we need to tell cppcheck that , in these two specific cases , it is perfectly ok for these members to be unused . <allcaps> edit </allcaps> - ticket diverged to also clean up function pointers , memsets , test logic suggestions , etc",2.0
"usleep is obsolete the exact cppcheck message , apparing for these lines { { { src / unit - tests / oscore - test / ut_oscore_misc_test . c : <number> src / unit - tests / oscore - test / ut_oscore_misc_test . c : <number> src / unit - tests / oscore - test / ut_oscore_misc_test . c : <number> } } } in the current development tree , is { { { obsolete function ' usleep ' called . it is recommended to use the ' nanosleep ' or ' setitimer ' function instead . } } }",0.0
"may need - rdynamic the symbolapitest reports that , if we do not use - rdynamic when linking , modules may not include all of the symbols that they expect to export . ticket # <number> reduces the invasive patching of the build rules being done by the bamboo support scripts ; that patching was forcing - rdynamic into one of the headers . with that invasive patching gone , symbolapitest now fails . alternatives to pick from : <number> . always use - rdynamic ( for the platform where it is meaningful ) <number> . change symbolapitest to not need it to be specified <number> . reinstantiate bamboo code that forces the flag to be used . need to look at the exact effects of - rdynamic and decide when these are needed versus when they are undesirable .",0.0
"reconcile diffs between unit test makefiles and <allcaps> jsc ut </allcaps> makefiles here is a summary ( from joe hickey ) of what i see as differences between the <allcaps> jsc </allcaps> oscore - test linux makefile ( attached above ) and what we currently have in the "" build "" subdirectory in <allcaps> osal </allcaps> ( this changeset ) . this is what would have to be reconciled before the <allcaps> jsc </allcaps> makefile and the <allcaps> osal </allcaps> makefile could be called "" compatible "" again : variable / macro value settings : * <code> : <allcaps> jsc </allcaps> uses <code> vs . <code> in <allcaps> osal </allcaps> * <code> : <allcaps> jsc </allcaps> uses externally defined $( osal_ut_flgs ) and $( ut_cov_flgs ) make variables , the <allcaps> osal </allcaps> makefile actually sets this blank * <code> : <allcaps> jsc </allcaps> makefile only specifies the one object specifically under test , <allcaps> osal </allcaps> makefiles specify all <allcaps> osal </allcaps> objects here . * <code> and <code> : <allcaps> jsc </allcaps> references externally - defined $( mission_home ) , $( cfs_mission_inc ) , $( osal_tst_src ) variables . <allcaps> osal </allcaps> makefiles are all based on $( osal_src ) included sub - makefile component pathname differences : * ' ' ' osal - config . mak ' ' ' : <allcaps> jsc </allcaps> has <code> and <allcaps> osal </allcaps> makefiles have <code> * ' ' ' debug - opts . mak ' ' ' : <allcaps> jsc </allcaps> has <code> and <allcaps> osal </allcaps> has <code> ( note the lack of "" osal - "" prefix in addition to the relative path difference ) * ' ' ' compiler - opts . mak ' ' ' : <allcaps> jsc </allcaps> has relative path <code> and <allcaps> osal </allcaps> has an absolute path <code> * ' ' ' app - rules . mak ' ' ' : <allcaps> jsc </allcaps> has relative path <code> and <allcaps> osal </allcaps> has absolute path <code> target differences : * <allcaps> jsc </allcaps> overrides the default rule for <code> * <allcaps> jsc </allcaps> defines a <code> target that actually executes the test - <allcaps> osal </allcaps> makefile does not define this * <allcaps> jsc </allcaps> defines a <code> target that calls <code> and scrubs the output . <allcaps> osal </allcaps> makefile does not define this .",2.0
add <allcaps> sparc </allcaps> - vxworks6 . <number> <allcaps> bsp </allcaps> need to add a <allcaps> sparc </allcaps> vxworks <number> <allcaps> osal bsp </allcaps> so that the <allcaps> osal </allcaps> unit tests for vxworks can build and run right from the <allcaps> osal </allcaps> directory out of the box ( assuming that you have an installation of the <allcaps> sparc bsp </allcaps> and vxworks <number> tool chain ),2.0
"resolve "" - m32 "" <allcaps> osal </allcaps> classic build issues the classic <allcaps> osal </allcaps> build historically built for <number> - bit x86 linux , on <number> - bit x86 linux build machines . building on a <number> - bit x86 linux server requires the use of the "" - m32 "" flag , but <allcaps> only </allcaps> when the target is the classic <number> - bit x86 linux . this also requires that the server has <number> - bit goodies , often "" multilib "" is the thing you need to google if this is busted . currently , inserting this flag where it is missing or removing it where it is present requires editing files , which is a speedbump for developers and a blocker for automatic systems when building both <number> - bit x86 and any other target . need to set up the classic makefiles so that we default to - m32 not being present , and allow it to be inserted on demand from the command line or via an environment variable ( at the developer ' s option , both need support ) .",0.0
"expand cppcheck application the initial "" cppcheck "" configuration has been running for a while and looks both useful and stable , but is not using the full power of cppcheck . i need to research the more advanced features of <allcaps> cppcheck </allcaps> and how to make them useful in our environment . this is likely to require someone ( probably me ) to evaluate each function exposed in each <allcaps> api </allcaps> for the documented intent of the function with respect to these features , and encode them in the <code> file . this task may take a significant amount of time . in the interest of getting utility out of the effort quickly , i will break it up into smaller chunks that can be managed independently - - and once the ball gets rolling , with luck , allow more than one person to generate configuration file data . my plan is to identify one <allcaps> cppcheck </allcaps> feature at a time , write a comment on this ticket about the feature , then open a separate ticket to track setting up that feature .",2.0
"<allcaps> osal api </allcaps> documentation should be doxygen based the <allcaps> osal api </allcaps> documents are currently available as separate word and . pdf documents . the <allcaps> api </allcaps> ' s are defined and maintained in the source code . any changes or new findings to the <allcaps> api </allcaps> ' s can easily get left undocumented , creating a disconnect between the source code and what is stated in the <allcaps> osal api </allcaps> word and . pdf documents . it is highly recommended to couple the documentation with the source code via doxygen .",2.0
support insertion / integration of third party / bridge libraries missions / projects may have the need / requirement to use specific implementations of functions provided by third party libraries i . e . <allcaps> arinc </allcaps> <number> does not include a printf function . third party libraries cannot legally be included within an official release of the <allcaps> osal </allcaps> . the <allcaps> osal </allcaps> currently does not provide a generic means of integrating third party libraries into the <allcaps> osal </allcaps> . see ticket # <number> for more details,2.0
"fix up pointer subtraction ( do not cast to integers ) pointer subtraction works . code that casts the pointers into integer types differs from the correct code only in its obfuscation . additionally , where pointer subtraction is used to determine the length of a string , the entire sequence should be replaced by a call to strlen ( ) . on a side note , dividing by "" sizeof ( char ) "" is also mere obfuscation as the standard defines that sizeof returns the size in ( char ) units . note that when attempting to compile for <number> - bit targets , these will usually be flagged as "" casting pointer to wrong sized integer "" - - this may help to find problematic code . start with os_check_name_length ( ) .",0.0
"<allcaps> jsc </allcaps> : general code cleanup originally implemented as part of trac # <number> and isolated for <allcaps> ccb </allcaps> review purposes . general code clean up modifications : * make all if / then / else as compound statements * add "" void "" to functions that do not take parameters * add final "" else "" to all "" else if "" constructs * make sure all cases in switch stametents have break * add explicit casting where the compiler may emit warnings * add "" static "" and "" extern "" keywords where needed",0.0
<allcaps> jsc </allcaps> : change fpu get / set mask function return code originally done as part of trac # <number> and isolated for <allcaps> ccb </allcaps> review purposes . changes the return code of the <code> and <code> functions to return <code> for builds that do not have such a mask register .,0.0
<allcaps> jsc </allcaps> : use fixed width types originally part of trac # <number> and isolated for <allcaps> ccb </allcaps> review purposes . replace use of native <code> with fixed - width <code> typedef .,0.0
"<allcaps> jsc </allcaps> : audit vxworks6 global table protections originally part of trac # <number> , isolated for <allcaps> ccb </allcaps> review purposes . audit the usage of <code> / <code> calls surrounding global table accesses and adjust where needed .",0.0
<allcaps> jsc </allcaps> : add static initializers to all local variables originally done as part of trac # <number> and split off for <allcaps> ccb </allcaps> review purposes . only affects vxworks6 <allcaps> osal </allcaps> .,0.0
"<allcaps> jsc </allcaps> : replace "" <allcaps> uninitialized </allcaps> "" macro with "" os_uninitialized "" originally part of trac # <number> and split off for review purposes . only affects vxworks6 .",0.0
integrate <allcaps> jsc </allcaps> audit of parameter and return code checking originally part of trac # <number> and split off for <allcaps> ccb </allcaps> review purposes . <allcaps> jsc </allcaps> has done an audit of input parameter checking and intermediate return code checking and added multiple checks / returns . primarily affects vxworks6 but some posix code was touched as well .,0.0
"<allcaps> jsc </allcaps> updated <allcaps> api </allcaps> tests integrate <allcaps> jsc </allcaps> updates to <allcaps> api </allcaps> ( black - box ) tests . originally implemented as part of trac # <number> , split off for <allcaps> ccb </allcaps> review purposes",2.0
"add <allcaps> jsc </allcaps> coverage tests ( originally # <number> ) separated from original trac # <number> - add "" white box "" coverage tests for vxworks6 <allcaps> osal </allcaps> .",2.0
"improve cppcheck configuration for <allcaps> osal </allcaps> the initial level of support for "" cppcheck "" within the <allcaps> osal </allcaps> build plan is a simple implementation using default checking , widened to maximize coverage but not otherwise tuned . while any individual mission or project using <allcaps> osal </allcaps> may decide to do this work , this is only mildly in their direct interest , but it is very much in the interest of the <allcaps> cfs </allcaps> community as a whole that it gets done . we can make cppcheck more useful , both for checking the <allcaps> osal </allcaps> itself and for checking code that uses it , by setting up a configuration file that tells cppcheck as many details as possible about the intended interfaces . for example : - indicating functions that acquire and release resources so that cppcheck can attempt to report failures to release a resource ; this is not just memory allocation but includes lock aquisition and anything else managed using one function to acquire ( or open or connect . <repeated> ) and another to release ( or close or disconnect ) . - indicating where a function requires that a pointer , passed as a function parameter , must point to initialized memory , so that cppcheck can report things like "" trying to strcopy where the source array has not been initialized . "" there are other details we can also express in the cppcheck library configuration file , generally of flavor similar to the above .",2.0
"cppcheck warns us that strncpy behavior is obscure . as reported by cppcheck warning : if the source string ' s size fits or exceeds the given size , strncpy ( ) does not add a zero at the end of the buffer . this causes bugs later in the code if the code assumes buffer is null - terminated . this message is present in <number> files : { { { osal / src / os / posix / osfileapi . c osal / src / os / posix / osfilesys . c osal / src / os / vxworks6 / osfileapi . c osal / src / os / vxworks6 / osfilesys . c } } } need to examine the fingered bits of code , see if any of them need fixing , and figure out how to get cppcheck to be happy . when checking this , our official stand on telemetry records is that arrays in telemetry records containing text have fixed size and that consumers of the data must not assume that they contain a terminating <code> character . this is the classical case where this strncpy behavior on data overflow is desired as defined .",0.0
"value stored is never used as reported by cppcheck style : variable % is assigned a value that is never used . this message is present in <number> files : { { { osal / src / os / vxworks6 / ostimer . c osal / src / unit - tests / oscore - test / ut_oscore_task_test . c osal / src / unit - tests / osloader - test / ut_module . c } } } need to examine the fingered bits of code , see if any of them need fixing , and figure out how to get cppcheck to be happy .",0.0
"unreachable flow control statements as reported by cppcheck style : consecutive return , break , continue , goto or throw statements are unnecessary . the second statement can never be executed , and so should be removed . this message is present in <number> files : { { { osal / src / os / vxworks6 / osapi . c osal / src / tests / osal - core - test / osal - core - test . h } } } need to examine the fingered bits of code , see if any of them need fixing , and figure out how to get cppcheck to be happy .",0.0
"overwriting unused buffer content as reported by cppcheck performance : buffer % is being written before its old content has been used . reported against : { { { src / unit - tests / osfile - test / ut_osfile_fileio_test . c : <number> src / unit - tests / osfile - test / ut_osfile_fileio_test . c : <number> src / unit - tests / ostimer - test / ut_ostimer_test . c : <number> } } } . <repeated> and a bunch of places in ut_os_stubs . c need to examine the fingered bits of code , see if any of them need fixing , and figure out how to get cppcheck to be happy .",0.0
readdir is not reentrant as reported by cppcheck portability : non reentrant function ' readdir ' called . for threadsafe applications it is recommended to use the reentrant replacement function ' readdir_r ' . reported against : osal / src / os / posix / osfileapi . c,0.0
"<allcaps> gcov </allcaps> results for "" osapi "" obscured . the "" make gcov "" target for the "" osapi "" coverage test feeds the output of <allcaps> gcov </allcaps> through some <allcaps> sed </allcaps> scripting that was originally constructed to handle <allcaps> gcov </allcaps> output for a single source file . for the <allcaps> osapi </allcaps> case , however , <allcaps> gcov </allcaps> is being handed data that covers both the adapter source file and the original source file . the sequence of line joins and line edits provided does not produce correct output for this case : it does manage to generate the coverage line for the adapter source , but the heuristic deals badly with the remainder of the file . it would have worked if the second "" file "" line happened to fall on an odd line number .",0.0
"add <allcaps> gcov </allcaps> summary report we are running <allcaps> gcov </allcaps> on the <allcaps> osal </allcaps> / unit - tests - summary / programs and preserving the details , but there is no coverage summary available from a central location .",0.0
standardize version numbering ( in <allcaps> osal </allcaps> ) bring version number management within <allcaps> osal </allcaps> into line with the cfs standards documented at <url>,2.0
"posix message queues leak . during testing , i notice that i sometimes get <allcaps> msgq </allcaps> test failures despite having the "" queues per process "" configuration set to a high enough value , and rebooting fixes the issue . after one spate of reboots , i went and did some digging , and we do seem to be actively leaking posix message queues , at least during testing : posix message queues have identities , and can stick around when nobody has them open , and of course there is a finite limit to them in the system . fortunately , / dev / mqueue shows us all of the queues that exist in the system , and if you remove the entry in / dev / mqueue , the message queue itself is removed . i have implemented code in my testing scripts that aggressively watches for message queue leaks during testing . what i am seeing so far : - the <allcaps> cfe </allcaps> "" run the core until the deadman timer trips "" test can leave behind many queues . - the <allcaps> osal </allcaps> "" queue timeout test "" can leave behind a queue . it would be worthwhile to assure that only operations unique to unit testing ( such as "" kill - <number> $cfecore "" . <repeated> ) leak these .",0.0
"simplify function pointer manipulations there are a number of places within the <allcaps> cfs </allcaps> projects where the usage of function pointers is somewhat obfuscated by the inclusion of redundant operators . removing those operators can improve the clarity of the code . the redundancies are based on code that , when written , did not properly base itself on the following aspects of function pointers in the c programming language . <number> . function names decay into function pointers in the same way that array names decay into pointers to their first elements , which means that an <code> operator is redundant when setting a pointer to point at a function . for the classical example of this , see most <code> examples , where no <code> is applied to the comparison function when passing it as the last argument , which has type ' ' pointer to function . <repeated> ' ' <number> . the function call operator <code> ' ' args ' ' <code> operates on a function pointer - - so every function call you see actually is invoking the above decay semantics . this means that the <code> operator is ' ' not ' ' needed when calling a function via a function pointer . happily , this also often means that you also do not need an extra level ( or two ? ! <repeated> ) of parentheses to asure that the <code> is applied to the function pointer and not to the return value . <number> . calling a function pointed to by a structure member is a very common operation , and with the above in mind , note that there is no parsing or evaluation order ambiguity ; no extra parentheses are required to assure that <code> and <code> and the function call operator are evaluated in the proper order . my task - - embodied in this ticket - - is to seek out cases in the <allcaps> osal </allcaps> source code where redundant operations are applied to function pointers ( at assignment sites ' ' and ' ' at call sites ) , and provide recommended changes to improve clarity . specific examples will accumulate in the comments below . ticket to be closed when my scan of the project is complete , and all call sites have been resolved ( whether the resolution is to improve them now , file a ticket for later improvement , or where we will be leaving the code unchanged ) . ' ' ( this also makes the code robust against the rare but troublesome case where an external function changed from a function to a function pointer . <repeated> we may never do this , but it is always good to foster good code hygene . ) ' '",2.0
"vxworks osapi . c utility task does not exit the vxworks osapi . c has an optional task that is started in os_api_init ( <sad> <code> however , this utility task implementation has a while ( <allcaps> true </allcaps> ) loop with no exit logic . for a "" load and forever run it "" scenario this may work , but for any other scenario where an orderly shutdown is desired by the user this means the task is never killed . one can get kernel crashes if the vxworks module is unloaded while that thread is still writing to output . the forever loop thread also makes line coverage difficult . we need a robust method to always end this thread and to ensure the parent thread does not return to os control while this thread is still hanging out there .",0.0
os_translatepath ( ) has unused variables devicelen and filenamelen of os_translatepath ( ) are function - local variables that are written to but never used .,0.0
"osfilesys . c mixed return types in osfilesys . c , some functions return os_success ( from osapi . h ) and some functions return os_fs_success ( from osapi - os - filesys . h ) .",2.0
"os_unmount ( ) & os_chkfs ( ) do not catch os_translatepath ( ) failures in osfilesys . c os_unmount ( ) , the return value from os_translatepath is not checked .",0.0
"os_rename ( ) does not first check if a file is in use the osfileapi . c <section> does not check if a file is in use or not ( in an entry in the global os_fdtable ) before it makes the system call to rename the file . however , this is in contrast to <section> - which do check if the file is open ( according to the os_fdtable entry ) . if those functions see that the file is open then they return and do not alter the filesystem . so this behavior seems quite different for functions at affect a file . the documentation of the <allcaps> osal api </allcaps> does not explicitly mention any behavior tied to a file that is in use by the <allcaps> osal </allcaps> for any of these functions ( although the implementation is very clear for those other three functions . ) discovered in # <number> , as part of # <number> unit testing .",1.0
"vxworks os_getphysdevicename ( ) problem with max volume name length the vxworks os_getphysdevicename ( ) in osfilesys . c may have a problem when the volume name length is at its maximum length . see test_os_getphysdevicename_maxvolname ( ) in osfilesys_testcase . c , part of testing form trac - <number> branch , [ changeset :0 f36fb6 ] .",0.0
"vxworks os_getphysdevicename ( ) does not handle null pointer the vxworks os_getphysdevicename ( ) in osfilesys . c does not check for a null pointer in its arguments . discovered with testing form trac - <number> branch , [ changeset :0 f36fb6 ] .",0.0
"vxworks os_fs_geterrorname ( ) errors the vxworks os_fs_geterrorname ( ) in osfilesys . c does not check for a null pointer argument . discovered with testing form trac - <number> branch , [ changeset :0 f36fb6 ] .",0.0
"vxworks os_translatepath ( ) does not handle truncated path properly the vxworks os_translatepath ( ) in osfilesys . c does not detect and properly handle when the mount point and given virtualpath arg are too long . discovered with testing form trac - <number> branch , [ changeset :0 f36fb6 ] .",0.0
"vxworks os_fsblocksfree ( ) misreports the vxworks os_fsblocksfree ( ) can mis - report the free blocks value . discovered with testing form trac - <number> branch , [ changeset :0 f36fb6 ] .",0.0
"vxworks os_initfs ( ) logic errors testing form trac - <number> branch , [ changeset :0 f36fb6 ] revealed logic errors in the os_initfs ( ) of osfilesys . c . when running down off - nominal paths and handling the os_volumetable [ idx ] . freeflag . this ticket is to fix those errors .",0.0
"vxworks os_mkfs ( ) logic errors the vxworks osfilesys . c os_mkfs ( ) has a number of logic errors uncovered by trac - <number> branch , [ changeset :0 f36fb6 ] involving error paths and handling the os_volumetable [ idx ] . freeflag . this ticket is to fix those errors .",0.0
"vxworks osfilesys . c functions not thread - safe during trac # <number> unit testing it was found that many functions in the vxworks osfilesys . c are not using the semaphore to access the shared table . demonstrated on the trac - <number> branch , [ changeset :0 f36fb6 ]",0.0
"some vxworks osfileapi . c functions not handling string length correctly there were multiple problems identified in the osfileapi . c ' s string handling . this issue wraps them all up together for convenience . problem <number> : strlen check (>= ) is different than os_check_name_length strlen check ( > ) for the same variable . the check in os_check_name_length should be (>= ) . affects : ( function , rough line number ) * os_creat <number> * os_open <number> * os_stat <number> * os_remove <number> * os_rename <number> * os_rename <number> * os_cp <number> * os_cp <number> * os_mv <number> * os_mv <number> * os_rmdir <number> problem <number> : strlen check ( > ) should check for (>= ) , assuming os_max_path_len includes the terminating null character . affects : ( function , rough line number ) * os_opendir <number> * os_check_name_length <number> identified with # <number> white - box coverage testing .",0.0
"vxworks osfileapi . c functions not using semaphore multiple functions in the vxworks osfileapi . c are not taking the semaphore when accessing the shared table . os_close , os_read , os_write , os_lseek , os_remove , os_rename , os_cp , os_mv , os_shelloutputtofile , os_fdgetinfo . identified with # <number> white - box coverage testing .",0.0
vxworks osapi . c os_geterrorname ( ) missing codes os_geterrorname ( ) is missing a few codes . <repeated> error code not returned for os_error_address_misaligned error code not returned for os_invalid_sem_value error code not returned for os_err_file error code not returned for os_err_not_implemented error code not returned for os_timer_err_invalid_args error code not returned for os_timer_err_timer_id error code not returned for os_timer_err_unavailable error code not returned for os_timer_err_internal identified with # <number> white - box coverage testing .,0.0
vxworks osapi . c os_milli2ticks ( ) problems two problems found : <number> ) os_milli2ticks ( ) returns type ' int32 ' from variable declared as ' uint32 ' . <number> ) there are no limit checks on input value . the calculation may generate overflow on the resulting output type . identified with # <number> white - box coverage testing .,0.0
vxworks osapi . c functions not using semaphore multiple functions in the vxworks osapi . c are not taking the semaphore when accessing the shared table . identified with # <number> white - box coverage testing .,0.0
"vxworks os_symtableiterator ( ) unchecked write ( ) in os_symtableiterator ( ) write ( ) is used . it returns the # of bytes actually written . however , the # of bytes is not actually checked by this code . only if a - <number> was returned . an assumption is made that the entire set of sizeof ( symbolrecord_t ) is copied . from the vxworks kernel programmer ' s guide , <number> . pdf : ' ' "" the write ( ) routine ensures that all specified data is at least queued for output before returning to the caller , though the data may not yet have been written to the device ( this is driver dependent ) . the write ( ) routine returns the number of bytes written ; if the number returned is not equal to the number requested , an error has occurred . "" ' ' from the vxworks <number> write ( ) man page : { { { <allcaps> returns </allcaps> the number of bytes written ( if not equal to nbytes , an error has occurred ) , or <allcaps> error </allcaps> if the file descriptor does not exist , the driver does not have a write routine , or the driver returns <allcaps> error </allcaps> . if the driver does not have a write routine , errno is set to <allcaps> enotsup </allcaps> . } } } <allcaps> btw </allcaps> , that ' s two error return codes , not just a - <number> . recommend : checking the return val vs . desired # of bytes , then erroring out the same path .",0.0
"vxworks os_symtableiterator ( ) name arg too long the os_symtableiterator ( ) name arg could be too long and could be strncpy / copied without a terminating null into symbolrecord_t ' s char symbolname [ os_max_sym_len ] ;. this unterminated null would then be written into the os_sym_table_file_fd . see osloader . c , ln <number> . recommend : an explicit name length check : { { { if ( strlen >= os_max_sym_len ) { return ( <allcaps> false </allcaps> ); } } } } before strncpy . ( discovered as part of # <number> coverage testing . )",0.0
"vxworks osloader . c functions not using mutex the osloader . c functions do not properly protect the os_module_table , os_sym_table_file_id , and os_symbol_table_size with the os_module_table_mut . these items are being read from and changed outside of the mutex . ( discovered as part of # <number> coverage testing . )",0.0
vxworks os_moduleload ( ) module_name arg too long if the module_name argument for osloader . c ' s os_moduleload ( ) is too long ( compared to os_max_api_name ) then an unterminated string can be copied into the os_module_table [ i ] . name field . the <allcaps> osal api </allcaps> doc & source comments specify the following return values : * os_error if the module cannot be loaded * os_invalid_pointer if one of the parameters is <allcaps> null </allcaps> * os_err_no_free_ids if the module table is full * os_err_name_taken if the name is in use * os_success if the module is loaded successfuly the osapi . h os_err_name_too_long would be a more descriptive return code . <repeated> but if we do not want an <allcaps> api </allcaps> change then the best thing to do would be to check the argument length ( with terminating null ) and return os_error . ( discovered as part of # <number> coverage testing . ),0.0
"classic build broken mike scott ( <allcaps> aso </allcaps> project at ames ) reports that with the most recent update to development , his build process that uses the classic build of <allcaps> osal </allcaps> is no longer working . the initial failure is being unable to find osconfig . h i started looking into this , and there are further issues that prevent the classic <allcaps> osal </allcaps> build instructions from working now , and will document each issue ( and its repair ) here .",0.0
"fix "" utbsp . h "" not found failure when building on some platforms testing on other platforms revealed an issue regarding the include path for the utassert header files . in particular , the latest ubuntu ( <number> ) failed to build due to "" utbsp . h "" not being found . ( this may be related to the more recent cmake v3 . <number> )",0.0
"rtems ostimer . c functions not using semaphore in the <allcaps> rtems </allcaps> version of ostimer . c , some functions are not using the semaphore with accessing the os_timer_table . see # <number> , and # <number> for similar issue in other osals . ' ' ' os_timersignalhandler ( ) , os_timerset ( ) , os_timergetidbyname ( ) ' ' ' do not touch the semaphore but do access or modify the table . ' ' ' os_timercreate ( ) ' ' ' obtains & releases the semaphore , but is modifying the table after releasing the semaphore .",0.0
"posix ostimer . c functions not using semaphore similar to trac # <number> , the posix version of ostimer . c is not properly protecting its os_timer_table via a mutex . { { { pthread_mutex_t os_timer_table_mut ; } } } many of the issues seen in trac # <number> are in the posix version as well . full branch coverage unit tests , in trac # <number> , were used to fix trac # <number> ( vxworks ) . the posix ostimer . c will likely need similar coverage tests to ensure this is fixed properly .",0.0
"enhancements to <allcaps> osal ut </allcaps> stub code in osapi_stubs this ticket reflects further testing with <allcaps> cfe </allcaps> unit tests . previous ticket # <number> is now integrated with <allcaps> cfe </allcaps> unit tests but some additional bits are needed to make everything right . since # <number> was approved at the last <allcaps> ccb </allcaps> , it is not going to be amended anymore , so this is a follow - on update . * hooks were not completely implemented - <allcaps> cfe </allcaps> needs this to make the latest version fully testable . * provide stubs for missing functions : { { { os_timercreate } } } , { { { os_timeradd } } } , { { { os_timerset } } } , { { { os_countsemcreate } } } .",2.0
"ostimer . c functions not using semaphore the vxworks ostimer . c has a static table and a semaphore to protect it , as in : { { { static os_timer_record_t os_timer_table [ os_max_timers ] ; static uint32 os_clock_accuracy ; /* * * the semaphore for protecting the above table */ static sem_id os_timer_table_sem ; } } } unfortunately , only os_timercreate ( ) , and os_timergetinfo ( ) use that semaphore . ' ' ' os_timercreate ( ) , os_timerset ( ) , os_timerdelete ( ) do not ' ' ' and they ' ' ' modify ' ' ' the table . ' ' ' os_timergetidbyname ( ) ' ' ' and the internal ' ' ' os_timersignalhandler ( ) ' ' ' also access ( read ) the table without using the semaphore . the os_timerapiinit ( ) creates the semaphore , the time conversion functions do not access the table . recommend fixing all the functions that access or modify the table to acquire the semaphore after passing input argument checks .",0.0
"os_open and file - api - test in conflict the test for os_open includes a clause that explicitly attempts to open , using os_read_write , a file that has never existed - - and expects an error . that is , the test presumes that os_open does not by default create files that do not exist . the implementation , on the other hand , includes o_creat except when opening read - only . the test needs to use os_read_only mode , if we want it to pass with the current implementation .",0.0
"os_open : <number> is not <number> the 3 rd parameter to os_open is the set of permission bits to be applied if a file is created . the typical value of these is <code> which is an <allcaps> octal </allcaps> constant representing read - write for owner , read - only for group and read - only for everyone else . in several places in the <code> the value <code> without the leading zero - - thus decimal <number> - - is passed , which would create a file using mode <code> octal , which is write - only to owner , no access to group and read - only access to everyone else . oh , and the sticky bit set . in most cases , these erroneous <number> values are not used , but it was used in one case . on the theory that bad code should be repaired , i propose fixing all of them when fixing the erroneous test .",0.0
"os_timercreate ( ) "" unfreed "" table entries after failure in ostimer . c , os_timercreate ( ) , ln <number> , if the timer_connect ( ) fails , the code attempts to delete the timer created by timer_create , but there is still an "" unfreed "" timer entry in the os_timer_table . this is a potential resource leak that would exhaust the timer table . { { { . <repeated> picking up at ostimer . c , os_timercreate ( ) , line <number> . <repeated> status = timer_create ( clock_realtime , <allcaps> null </allcaps> , ( timer_t <wink> & ( os_timer_table [ possible_tid ] . host_timerid ) ); if ( status < <number> ) { /* commentary : here this table entry is properly freed up . */ os_timer_table [ possible_tid ] . free = <allcaps> true </allcaps> ; return ( os_timer_err_unavailable ) ; } status = timer_connect ( ( timer_t ) ( os_timer_table [ possible_tid ] . host_timerid ) , os_timersignalhandler , possible_tid ); if ( status < <number> ) { status = timer_delete ( ( timer_t ) ( os_timer_table [ possible_tid ] . host_timerid ) ); /* commentary : no cleanup here before the return ! */ return ( os_timer_err_unavailable ) ; } } } } also noted : the timer_delete status is unused , and may not matter at this point .",0.0
"os_timercreate ( ) unterminated string ostimer . c maintains a static os_timer_table , and a char name [ os_max_api_name ] is an element of each table entry . in os_timercreate ( ) , ln <number> , ' ' ' the code could leave an unterminated string in os_timer_table [ i ] . name ' ' ' . and it appears as though all the other code is assuming it is a properly - terminated string . line <number> tests : { { { if ( strlen ( timer_name ) > os_max_api_name ) . <repeated> return error value } } } and later { { { strncpy ( os_timer_table [ possible_tid ] . name , timer_name , os_max_api_name ) ; } } } copies the string with os_max_api_name length . but if the timer_name argument is sized exactly os_max_api_name + <number> ( including the terminating null ) then it ' ll be copied over so that there is no terminating null in the table entry name . to fix : * the strlen if - test should account for the \ <number> in its length check { { { if ( strlen ( timer_name ) > os_max_api_name - <number> ) } } } * the documentation for this function should note the actual arg length limit with the null * ( nice to have ) it is not actually documented in osconfig . h whether the terminating string nulls are counted as part of the os_max_ * name and path limits . but it certainly does appear that the intent is that strings are properly terminated in the vxworks <allcaps> osal </allcaps> . ( written clairty on that convention would have helped some . )",2.0
"divide osconfig . h three ways the current osconfig . h ( present in <allcaps> bsp </allcaps> trees and , as a bonus , in the build / inc directory ) contains configuration items that are <allcaps> osal </allcaps> generic , plus configuration items that are <allcaps> bsp </allcaps> specified , and probably items that are os specified . the content of this file needs to be divided . items that are generic <allcaps> osal </allcaps> configurations need to be in a header file located centrally . items that are specified by the os should be kept in a header file within the appropriate <code> tree ; probably a good idea to have this file included by the generic configuration file , to provide "" sane defaults "" in the central file ( where there can be sane "" most os "" values ) , then have the os - specific file override those as appropriate . ditto for the <allcaps> bsp </allcaps> .",2.0
"add timebase <allcaps> api </allcaps> calls to existing osals for <allcaps> api </allcaps> compatibility to allow backward / forward compatibility once psps begin using the <allcaps> osal </allcaps> timebase <allcaps> api </allcaps> added in # <number> , the existing osals ( posix / rtems / vxworks6 ) need to have some implementation of these functions or else the link will fail . this just adds an implementation that returns { { { os_err_not_implemented } } } for all these calls for the <number> existing <allcaps> osal </allcaps> libraries , which allows the <allcaps> psp </allcaps> or other application code to determine at runtime if the functionality is available or not .",0.0
"incorrect logic in os_timespectousec in the vxworks and posix implementation of ' ' ' os_timespectousec ( ) ' ' ' , the algorithm logic is using the value of the ' ' ' output ' ' ' ( usec ) by mistake . ( this first if - test is the same if - test used by the opposite function , os_usectotimespec ( ) just above . i assume its a copy - paste error ) . { { { * * function : os_timespectousec * * * * purpose : convert a <allcaps> posix </allcaps> timespec structure to microseconds * * */ void os_timespectousec ( struct timespec time_spec , uint32 * usecs ) { if ( ( * usecs ) < <number> ) { * usecs = time_spec . tv_nsec / <number> ; } else { } } }",0.0
"osnetwork . c <allcaps> api </allcaps> discrepancies the vxworks osnetwork . c code differs from the <allcaps> osal </allcaps> library <allcaps> api </allcaps> documentation under some conditions . even more interesting , the posix and rtems <allcaps> osal </allcaps> implementations behave differently from the vxworks as well . in osal / src / os / vxworks6 / osnetwork . c , the documentation and code for { { { int32 os_networkgetid ( void ) } } } do not match when there is no network ( e . g . os_include_network is undefined in osconfig . h ) . the c source file function comments are : { { { returns : os_error if the host id could not be found a <number> bit host id if success } } } the <allcaps> osal </allcaps> library <allcaps> api </allcaps> . pdf has : { { { returns : os_error if the operating system calls fail os_success if success } } } ' ' ( that os_success looks like a copynpaste error , all implementations return the host id for successful behavior . ) ' ' but the vxworks code returns a ( valid ) host id of zero , instead of os_error ( a - <number> ) or os_err_not_implemented ( osapi . h ) . when looking at the osal / src / os / rtems / osnetwork . c , i see that it returns os_err_not_implemented when the os_include_network is undefined in osconfig . h . that return value is not documented in the <allcaps> osal </allcaps> library <allcaps> api </allcaps> . pdf or in any code comments . the posix osnetwork . c pays no attention to os_include_network and always makes the os - layer network calls ( unlike the rtems and vxworks osal ' s ) . other <allcaps> api </allcaps> surprises : { { { int32 os_networkgethostname ( char * host_name , uint32 name_len ) } } } can return os_invalid_pointer with a <allcaps> null </allcaps> pointer arg . good implementation , but needs documentation . note : i did not find a tie - breaker in the osapi - os - net . h because that common header had no comments . also , i was unable to find documentation ( pdf or code comments ) on the meaning of these osapi . h return codes . ' ' ' initial recommendations for this ticket : ' ' ' * all <allcaps> osal </allcaps> ( osnetwork . c ) implementations for os_networkgetid ( ) and os_networkgethostname ( ) should return os_err_not_implemented when the os_include_network is undefined and not even attempt to make os calls . * the <allcaps> osal </allcaps> library <allcaps> api </allcaps> . pdf function documentation should be updated to cover all possible return values . * the separate osnetwork . c documentation should be removed in favor of a common function description in the osapi - os - net . h , which all <allcaps> osal </allcaps> implementations use . its too easy to focus in on one . c source and not realize there is an <allcaps> api </allcaps> discrepancy . * document ( in the osapi . h and in the <allcaps> osal </allcaps> library <allcaps> api </allcaps> . pdf ) the meanings of these common <allcaps> osal </allcaps> return codes .",0.0
"<allcaps> osal </allcaps> timer tests may crash on <number> - bit linux i have seen changes between test runs of the same branch where sometimes the timer related test programs run ok and other times when they die with a <allcaps> sigsegv </allcaps> . test results need to be robust and repeatable . i suspect that these tests are sensitive to some condition that is not being adequately controlled on the test targets . i am making the initial assumption that this is going to require an update to the test scripts for <allcaps> osal </allcaps> , but debugging is going to require some tinkering inside <allcaps> osal </allcaps> to extract what is going on . so this bug is being filed in both <allcaps> osal </allcaps> and <allcaps> test </allcaps> .",0.0
"failure to test should be <allcaps> fail </allcaps> the bamboo test plan does not currently complain if it is unable to stage and run unit tests on a target , for the simple reason that our test list is currently entirely driven by parsing results returned by the target . if the target vm is offline ( as it was last weekend ) , there are no indications that the test programs did not run , and the presence of a few test results ( the ones from static analysis ) keeps bamboo happy . the plan itself , or its top level scripts ( same thing ) , needs to keep track of the list of test programs , and generate test failure reports for any such program for which it does not obtain results .",0.0
"combine "" pc - linux "" and "" pc - linux - ut "" <allcaps> osal </allcaps> bsps there is a separate <allcaps> bsp </allcaps> called { { { pc - linux - ut } } } that is used for unit testing . this differs slightly from the normal { { { pc - linux } } } <allcaps> bsp </allcaps> : * it does not block signals * it does not have an idle wait at the end of { { { main ( ) } } } having a different <allcaps> bsp </allcaps> violates the "" fly what you test , test what you fly "" philosophy . the unit tests driven by timers do not work with signals blocked , because these rely on signals working during { { { os_application_startup ( ) } } } in order to function . this is probably the reason for the alternate <allcaps> bsp </allcaps> . however , these tests can and should be fixed to operate using the normal <allcaps> bsp </allcaps> with signals blocked , as this will be more representative of what happens in a normal system . to fix these tests just requires creating a child thread to handle the test logic and allowing { { { os_application_startup } } } to complete normally .",0.0
"import ut - assert basics into <allcaps> osal </allcaps> portions of ut - assert will be very useful for unit testing within <allcaps> osal </allcaps> , and should be imported from the official release into the <allcaps> osal </allcaps> tree .",2.0
"os_taskdelete fails if the task ( pthread ) has already terminated on its own i am creating tasks with functions that execute for a period of time , then return ( terminate ) on their own . os_taskdelete tries to call pthread_cancel on the thread id , which fails . this results in the task table entry remaining and i am unable to re - use that task name .",0.0
"os_taskdelay has wrong nanosleep values in src / os / posix / osapi . c , lines <number> - <number> , os_taskdelay should use : waittime . tv_sec = ms / <number> ; waittime . tv_nsec = ( ms % <number> ) * <number> ; not waittime . tv_sec = ms / <number> ; waittime . tv_nsec = ( ms % <number> ) * <number> ;",0.0
"os_queuecreate failures the os_queuecreate test ( in test_msgq ) is failing on specific versions of specific branches where it previously passed . i observed that after a string of <allcaps> green </allcaps> builds , the nightly builds were in <allcaps> red </allcaps> status , with this test being the trigger for the failure , but only on one of the two test targets . rebooting the test target involved cleared the failure . this is not an acceptable long term solution ; testing should not induce resource leaks . this was observed on the <number> - bit x86 linux test target , but i suspect it will be common to all targets sharing that <allcaps> osal </allcaps> message queue implementation .",0.0
"os_check_name_length portability the os_check_name_length function triggers warnings when it casts pointers to integers . it then triggers refactoring when an engineer notices that it is calcualting the length of a string by casting pointers to int , subtracting , and dividing by sizeof ( char ) .",0.0
"fix warnings in vxworks support code take a few minutes to resolve the remaining compiler warnings generated when building for powerpc vxworks targets . three edits in / os / and one in / bsp / , all specific to the vxworks cross - compilation .",0.0
"fix simulataneous use of <allcaps> osal bsp </allcaps> + <allcaps> cfe psp </allcaps> compiler flags when building <allcaps> osal </allcaps> as a component of <allcaps> cfe </allcaps> , the compiler flags for both the <allcaps> cfe psp </allcaps> and the <allcaps> osal bsp </allcaps> are used . with the current <allcaps> bsp </allcaps> / <allcaps> psp </allcaps> , the effect here is that "" - d_linux_os_ "" is included twice . this does not currently cause a problem , but it is incorrect , and it could cause a problem for future configuration where things may conflict . this only affects the cmake build .",0.0
"add user - space message queue library to the <allcaps> osal </allcaps> ( <allcaps> gsfc dcr </allcaps> <number> ) the <allcaps> gsfc atlas </allcaps> project developed an alternate queue library to use with <allcaps> posix </allcaps> to overcome a performance limitation with the linux posix message queues . incorporate this enhancement ( or similar enhancement ) into the <allcaps> osal </allcaps> for <allcaps> posix </allcaps> , <allcaps> rtems </allcaps> , and vxworks .",2.0
add vxworks <allcaps> rtp </allcaps> / memory protected port ( <allcaps> gsfc dcr </allcaps> <number> ) this vxworks <number> . x port is available from a <number> <allcaps> irad </allcaps> effort . it will support running code in a memory protected process under vxworks . this port will not affect other <allcaps> osal </allcaps> ports .,2.0
"<allcaps> osal </allcaps> library <allcaps> api </allcaps> document cut and paste errors in the "" <allcaps> osal </allcaps> library <allcaps> api </allcaps> "" document : <number> . the description of the os_write function is a cut and paste of the os_read function . <number> . in the description of the os_binsemtimedwait "" function , the syntax section states "" os_binsemtimewait "" ( without the ' d ' ) .",1.0
consider adding a timed wait function to the mutex <allcaps> api </allcaps> ( <allcaps> gsfc </allcaps> <number> ) the <allcaps> osal </allcaps> does not include a mutex wait with a timeout . this was originally requested by <allcaps> apl </allcaps> . see also trac ticket # <number>,2.0
"<allcaps> posix </allcaps> - consider using "" sched_rr "" instead of "" sched_fifo "" for realtime threads although <allcaps> osal </allcaps> defines <number> priority levels ( <number> - <number> ) , most typical <allcaps> posix </allcaps> systems will have considerably fewer than <number> priority levels for task scheduling . a typical linux system offers priority levels ranging from <number> to <number> . to handle this , the <allcaps> posix </allcaps> layer combines multiple <allcaps> osal </allcaps> priorities into a single <allcaps> posix </allcaps> priority bucket , evenly spreading the <allcaps> osal </allcaps> range into the available <allcaps> posix </allcaps> priority range . when combined with the sched_fifo policy , this may have unintended consequences in the case that two <allcaps> osal </allcaps> tasks are created with priority values that cause them to be mapped into the same <allcaps> posix </allcaps> bucket . to illustrate : consider two <allcaps> osal </allcaps> tasks , created with priority levels "" <number> "" and "" <number> "" . if both get mapped into the same bucket ( likely ) then the os will treat them as equal for scheduling purposes . assuming the task at priority "" <number> "" becomes ready - to - run first , it can use the <allcaps> cpu </allcaps> indefinitely even if the task with priority "" <number> "" also becomes ready - to - run . this is because task <number> will be behind task <number> in the <allcaps> fifo </allcaps> queue . using the round - robin ( rr ) scheduling policy can be an improvement here , since the kernel will time - slice the two tasks rather than allowing task <number> to indefinitely preempt task <number> . although there is no ideal solution due to the lower number of actual priority levels in the kernel , the rr policy is arguably a better choice here .",2.0
"posix - optionally disable use of some realtime features for debugging it was discovered that the pthreads library supplied by xilinx for their microblaze platform does not properly support the pthread_prio_inherit attribute on mutexes . the problem occurs when a higher - priority thread becomes blocked on a mutex owned by a lower - priority thread , in this pthreads implementation the higher priority task starts "" spinning "" and ultimately uses <percent> <allcaps> cpu </allcaps> , locking out any other process , including the ability to kill or stop the process - reboot is the only recourse . this bug is a problem in the xilinx - supplied pthreads library , but until a real fix is done , we need to disable the pthread_prio_inherit option . disabling this feature may also be useful to others during debugging if another user runs into a similar issue . it was also useful to disable rt scheduling entirely while debugging this problem . this ticket will add compile - time macros that can be added to the "" osconfig . h "" file that will control these features . the default ( if nothing is defined ) will be to use the same features that are currently in place ( no change ) .",2.0
<allcaps> osal </allcaps> : os_eof macro is not defined ( <allcaps> gsfc dcr </allcaps> <number> ) <allcaps> eof </allcaps> can be defined differently for different platforms . the <allcaps> osal </allcaps> should define this value and make reference to this return value in the <allcaps> osal </allcaps> library <allcaps> api </allcaps> documentation .,2.0
<allcaps> osal </allcaps> : consider allowing root task ( caller of os_api_init ) to register and use <allcaps> osal </allcaps> services ( <allcaps> gsfc dcr </allcaps> <number> ) consider a model for the system root task where the caller to os_api_init ( ) is also a registration of the task with the <allcaps> osal </allcaps> . this can ensure that the root task can use <allcaps> osal </allcaps> functions . this also allows to <allcaps> osal </allcaps> to initialize <allcaps> cpu </allcaps> affinity for the root task and use that stored <allcaps> cpu </allcaps> affinity for inforcing <allcaps> cpu </allcaps> affinity policies when the root task spawns tasks .,2.0
"backtrace - tracking feature for debugging <allcaps> osal </allcaps> mutexes buggy code that takes a mutex but forgets to release it can be very difficult to debug - when the code is stopped in the debugger , it is clear that the thread is waiting on the mutex , but evidence of the real problem is long gone and it is impossible to tell which thread took the mutex but did not give it up . glibc has a { { { backtrace ( ) } } } function which can be extremely useful in debugging these situations . this will add an enhancement to the "" posix - ng "" build to __optionally__ obtain and store a backtrace with each successful "" take "" of a mutex . if at some point in the future another thread gets locked trying to obtain the mutex , the backtrace will point exactly to the code that obtained the mutex without releasing it . obviously this has some performance / memory implications ( although not much ) so it will not be enabled by default . this would be something the developer could enable when actually trying to debug mutex release issues .",2.0
enforce strict <allcaps> ascii </allcaps> replace all non - <allcaps> ascii </allcaps> characters ( i . e . copyright symbol ) with <allcaps> ascii </allcaps> equivalent .,0.0
"connect compiler warnings to test results parser after compiling , scan the resulting log for warning messages , and produce an output file presenting the warnings as "" test failures "" that can be observed ( and quarantined ) from within the bamboo interface . interesting design goals : * ability to configure patterns that group warnings that are closely related but scattered through the build logs ( i am ok with doing this by editing the warning - detecting <allcaps> awk </allcaps> script , at least initially ) . * ability to report "" test now passing "" for groups of warnings previously identified . * fall back to a reasonably sane organizational method to present any warnings not captured by patterns above ; <allcaps> gcc </allcaps> ' s "" - wsome - warning - type "" tags are suggested . requirements too obvious to state : * input is the "" warning "" lines from a compile * build area path needs to be stripped from the input * output is "" <allcaps> xml </allcaps> - ish "" files for bamboo ' s junit parser yes , i am already tinkering with a prototype <wink>",2.0
add xenomai <allcaps> osal </allcaps> add xenomai <allcaps> osal </allcaps> v1 . <number> as delivered from matt benson / odyssey space research on <date>,2.0
"implement user - selectable compiler warning switches it has become apparent that a "" one - size - fits - all "" approach to compiler warnings may not be sufficient going forward . in general , most developers should be using "" - werror "" in addition to "" - wall "" , "" - pendantic "" , etc to catch any coding issues at first sight . however , the specific set of warnings for any given piece of code is dependent on the specific compiler version , target architectures , and optimization level in use at the time of build . this can mean code that builds without warnings on one build can fail miserably on a different build . this could be an major issue for a novice who clones the latest code from the community repository , and builds it with the latest version of <allcaps> gcc </allcaps> ( i . e . one that we may not have tested yet ) and finds a new warning that causes the entire build to fail unexpectedly . as a compromise , the following is proposed : * always use "" - wall "" switch to enable the most reasonable warnings ( incidentally , this is not __all__ warnings , it leaves out the ones most likely to generate false positives ) . * do not put "" - werror "" in the official build scripts , so if compiling with a new <allcaps> gcc </allcaps> version or a different target architecture than the what has been officially tested , the build will not fail if a new warning is triggered . * also leave out "" - pedantic "" from the official build as this , by definition , tends to warn on constructs that are generally ok in practice but violate some ( possibly esoteric ) aspect of the c standard . the thought behind this is that plenty of old existing code out there may work fine but might not compile cleanly using "" - pedantic "" , so we should not force this switch upon users by default . * add a mechanism by which developers can easily add extra <allcaps> cflags </allcaps> to a build , without modifying a makefile ( or cmakelists ) file . this way , any users that want to may enable "" - werror "" or "" - pedantic "" on their own builds , all the time , without having to maintain a private branch of the build script . the automatic builds done by bamboo , these will be built __without__ "" - werror "" but the build log will be checked for warnings , and the presence of any new warnings will be logged as a unit test error so they can be fixed before moving the code forward .",2.0
add locking during test runs the build support scripts presume they have unique ownership of the test target . this assumption may be violated if the script is run manually . this can be resolved by using the flock ( <number> ) command to set up an advisory lock within the shell script .,2.0
"add osprintf to <allcaps> osal jsc </allcaps> has developed a known and understood version of printf that has been code reviewed and unit tested . it can be used on platforms that do not provide a printf ( such as arcin653 ) or as a known , trusted implementation of the printf function on other oss . currently , versions ( there are small variations in the implementation between oss ) for the posix , vxworks6 , and arinc653 osals are available . need to add branch with <allcaps> osal </allcaps> / src / os / posix , vxworks6 , arcin653 / osprintf . c and <allcaps> osal </allcaps> / src / os / inc / psprintf_priv . h , osprintf . h",2.0
"<allcaps> api </allcaps> additions to formalize common routines in <allcaps> osal </allcaps> during unit testing and for "" restart "" actions in a real system ( either processor or power - cycle restarts ) it is necessary to have a method of cleanly shutting down the system . currently , support for shutdown operations is left up to the <allcaps> bsp </allcaps> , and it is not consistently handled between the various bsps or not handled at all in some cases . <allcaps> osal </allcaps> needs to have formal procedures for a normal shutdown since there is often some clean up work to do , including but <section> : * sanely exit all running tasks , or collect resources from tasks that have exited already * delete queues , mutexes and semaphores ( this is particularly necessary on systems where this is a limited resource and may affect the ability to implement a warm restart ) * unmount any non - volatile filesystems that may have been mounted * delete shared memory segments this ticket will add some basic <allcaps> api </allcaps> calls to formalize the procedure and provide the hooks necessary to do this cleanup . the <allcaps> posix </allcaps> layer needs this with the highest priority , as it is used extensively for testing where a sane shutdown / restart procedure is important .",2.0
"adjust usage of feature support macros for glibc / posix glibc ( de - facto standard c library for <allcaps> gnu </allcaps> / linux ) uses compiler macros to select features from the various c standards out there . at a bare minimum , the <allcaps> posix </allcaps> build currently relies on some features in xpg5 and <allcaps> posix </allcaps> . 1 c ( <number> ) . in order to ensure these are enabled , the osapi . c file <hashtag> defines </hashtag> "" use_unix98 "" immediately before including pthread . h . this is not the proper way to do this - - use_unix98 ( with underbars ) is an internal macro defined by the glibc headers based on <allcaps> other </allcaps> macros that were specified . it should also be done in such a way that all source files adhere to the same general standard ( for sanity sake ) . = = recommended fix = = use "" xopen_source = <number> "" across the entire build . this will enable xpg6 features . xpg6 adds some more realtime features that are likely to be useful to applications such as this , e . g . clock_nanosleep ( ) and some others .",0.0
"<allcaps> osal </allcaps> public / private data structure delineation this ticket was originally part of ticket # <number> but the change was independent and significant enough to warrant breaking this out into a separate review item . this will fix some issues with the os module <allcaps> api </allcaps> : * <allcaps> cpu </allcaps> addresses must be stored using the "" cpuaddr "" type , not uint32 . * the "" os_module_record_t "" should be made into an os - dependent structure , as the different os layers may have different sets of data that they need to retain for loaded modules . this will also make it more consistent with the other apis - - e . g . tasks , queues , semaphores all define their internal record structures in the os - specific implementation and not part of the public <allcaps> api </allcaps> . * the os_moduleinfo ( ) call should return a standardized structure and not the direct internal record . this will also be more consistent with the way the other apis do this where they have a separate "" prop "" structure that is returned that is defined as part of the public <allcaps> api </allcaps> .",2.0
"fix <allcaps> osal </allcaps> timer test id usage the <allcaps> osal </allcaps> timer test implementation assumes that timer ids will always be issued in sequential order starting with "" <number> "" . it incorrectly assumes that the timer id will be suitable for an array index . an intermediate lookup table is required here , which has os_max_timers entries , to correctly map the id supplied during the create call back to a local array index .",0.0
"add pc - rtems <allcaps> bsp </allcaps> to <allcaps> osal </allcaps> for development under <allcaps> rtems </allcaps> it is helpful to have a basic <allcaps> bsp </allcaps> that does not require any special development boards . the <allcaps> rtems </allcaps> project provides this via the "" pc686 "" <allcaps> bsp </allcaps> . this makes it possible to boot and run an <allcaps> rtems </allcaps> application on ordinary commodity pc hardware . this also boots and runs in virtual machines i . e . <allcaps> qemu </allcaps> which is very desirable for testing . this ticket will add a "" pc - rtems "" <allcaps> bsp </allcaps> to <allcaps> osal </allcaps> that can be used for this purpose .",2.0
"do not block synchronous hardware - generated signals in pc - linux <allcaps> bsp </allcaps> as of <allcaps> osal </allcaps> <number> , __all__ signals are blocked during execution of the os_application_startup ( ) call , then unblocked before entering the wait loop . there is some valid logic behind this - - * by definition , a signal is directed to a process , not a thread . in a multi - threaded process , each thread gets its own signal mask and "" normal "" signals may be delivered to __any thread__ within that process that has the signal unmasked . * by masking all signals during os_application_startup ( ) , any threads created during this time will automatically inherit the mask and therefore have all signals blocked . * signals will then be unblocked only in the original ( main ) thread , therefore any signals generated will be delivered only to this thread . the issue here is that some signals on linux are generated by the underlying hardware and the kernel forwards these ( synchronously ) to the specific __thread__ that was executing on the <allcaps> cpu </allcaps> when the actual signal was triggered . the set of hardware - generated signals : <allcaps> sigsegv </allcaps> , <allcaps> sigill </allcaps> , <allcaps> sigbus </allcaps> , <allcaps> sigfpe </allcaps> should <section> be blocked at any time by any thread . for instance , if a thread causes a segmentation fault by using a bad pointer while <allcaps> sigsegv </allcaps> is blocked , the thread will continue running , but results are undefined .",0.0
"clean up "" - d "" compile time macros used in pc - linux build this is the equivalent of trac <number> in the <allcaps> cfe psp </allcaps> - - see [ <url> the same build flags are duplicated in the <allcaps> osal bsp </allcaps> . the "" pc - linux "" <allcaps> osal bsp </allcaps> defines the following to be added to the compiler <allcaps> cflags </allcaps> : { { { - d_el - <allcaps> dendian </allcaps> = _el - dsoftware_little_bit_order - d__ix86__ - d_ix86_ - dposix - <sad> 8 6 pc - d_reentrant - d_embed_ - dos_debug_level = <number> } } } these were brought into the cmake build from the original build scripts in order to be consistent just in case any code required it . however , they are unnecessary , many are not even used anywhere in <allcaps> cfe </allcaps> / <allcaps> osal </allcaps> , and potentially even wrong . the reality is that with linux , the "" pc - linux "" is a general purpose <allcaps> psp </allcaps> that can most likely be used on __any__ general - purpose development machine that runs linux . it is not limited to only x86 pc ' s , and in fact works just fine on <allcaps> arm </allcaps> , powerpc , and microblaze targets too . i have successfully used the ( unmodified ) pc - linux <allcaps> bsp </allcaps> to execute unit tests on a beaglebone black ( <allcaps> arm </allcaps> ) as well as an emulated powerpc <number> based development machine . in all these cases , the "" x86 "" macros are wrong , and on the powerpc , the el / <allcaps> endian </allcaps> / software_little_bit_order are wrong too . to summarize - i recommend removing <section> of these macros from the pc - linux build when using the cmake scripts ( the old makefiles can stay as - is ) .",0.0
"write <allcaps> xml </allcaps> files for bamboo we use the atlassian ' ' bamboo ' ' system to automatically build the project , run the test , and present the results , but the system is not an oracle : it requires test results to be in one of the several forms for which it has parsers . i was able to construct <allcaps> xml </allcaps> files that bamboo ' s "" junit results "" parser was able to handle . this commit introduces a simple implementation of a file writer for those files . this is a ' ' bare - bones ' ' implementation , onto which we can hang future enhancements . note that there are rules for quoting data in strings , and text not within <code> tags ; the simple approach taken here is merely to completely avoid the use of any character that needs quoting . my intention is to continue work on this when i get back from vacation on the 2 3 rd .",2.0
"improve bamboo builds of cfs <allcaps> osal </allcaps> tree the current bamboo plan for the <code> project compiles <allcaps> osal </allcaps> and runs both sets of tests , but only recovers test results from one of the two sets . work needs to be done to extend the test results recapture to pull in the results of the other tests .",2.0
"pthread_create 3 rd arg must be of right type os_taskcreate is handed an <allcaps> osal </allcaps> entry point , which is a pointer to a function taking no parameters and returning no return value . it passes it along to pthread_create which is expecting a pointer to a function that takes a single void pointer parameter , and returns a void pointer return value . the code as written triggers a compiler warning that we want to get rid of . casting the pointer gets rid of the warning , at the cost of presuming that the <allcaps> abi </allcaps> will do the right thing when the caller and callee disagree on the function signature . this has an associated technical debt : every implementation that uses this code has to be aware of the issue and assure that this kind of signature mismatch is ok . alternately , we can stash the pointer to the entry point somewhere , and hand pthread_create a pointer to a function of correct type , which is responsible for calling the entry point and returning a pointer . this has a runtime memory cost of one stack frame . doing nothing retains the potential failure , but also retains a warning about the potential failure . i suggest either doing the real fix , or leaving the code alone until - werror forces us to do the real fix . i will not automatically push this into the <number> - <number> - <number> integration candidate , as tempted as i am .",0.0
"os_moduleload ( ) 2 nd and 3 rd args need to be const the current integration candidate for cfs_cfe includes code that passes ( char const <wink> pointers as the 2 nd and 3 rd parameters to the os_moduleload ( ) function . in order for this to compile without warnings , these parameters of this function need to carry <code> qualifiers in the header defining the function and in the function itself . the function does not modify data pointed at by these parameters , so the <code> qualifier is appropriate . this change does not require changes to callers ( but does allow them to pass pointers to <code> data ) . this change will need to be included in the <number> - <number> - <number> integration candidate synchronized across all projects . ( i thought i had seen a ticket for this , but was unable to lay hands on it . )",0.0
update <allcaps> osal </allcaps> for class a & associated unit tests the currently released <allcaps> osal </allcaps> unit tests may not fully run with <allcaps> osal </allcaps> <number> . <number> . <allcaps> jsc </allcaps> has made updates so that they run with linux and arinc653 <allcaps> osal </allcaps> <number> . <number> . <allcaps> jsc </allcaps> is currently updating to work with vxworks <number> . these updates are being tracked in the <allcaps> jsc </allcaps> subversion repo and need to be pushed into a proper git branch and further work continued from there .,0.0
"<allcaps> osal ppc </allcaps> vxworks "" test runner "" independent of any other issues with building test code for the powerpc running vxworks - - it appears that i will need a small bit of "" helper code "" in order to make my testing environment a little bit more robust . currently , running a unit test requires someone , by hand , to do the following steps for each test : - observe the value of <code> - issue <code> command - watch out for any ' ' undefined symbol ' ' errors - verify that <code> changed - issue <code> command - monitor console output watching for the test to finish - perhaps reboot the target if things went horribly wrong running the tests by calling <code> directly from the shell introduces problems if the test program makes any changes in the task that disturb the shell - - most notably , if the task calls <code> all bets are off . what i want in a "" test runner "" is to have code that supervises loading of the program , detects any load errors , and assures that the loaded image provides a suitable entry point . if all is good , start the test as a subtask . the runner needs to then wait for the task to complete , which unfortunately requires it to periodically test to see if the task is still alive . a nice thing to have for this sort of facility is a timeout , which turns out to be pretty trivial given that we have to drop into a polling loop . if we loop too long , we can kill off the task and make appropriate log annotations . the initial runner i envision is simply an image to be loaded after the target boots , exporting a function that does the work for one test , coupled with a script that loads the image and calls the function for each test to be run .",2.0
"<allcaps> tsf </allcaps> : osloader os_moduleload # <number> the os_moduleload test case in the osloader unit test fails during the "" test setup "" loop . once the test was augmented to report the failing module name , it was discovered that this was due to not staging the "" <allcaps> module </allcaps> % d . so "" files to the target running the unit tests . repairs actually applied to the build script over in the cfs_test project ( cfs_test / osal / build . sh ) .",0.0
"fix <allcaps> osal </allcaps> build when using <allcaps> rtems </allcaps> "" pc686 "" <allcaps> bsp </allcaps> in the <allcaps> rtems </allcaps> distribution , the rtems_interrupt_catch ( ) function is not always defined . it depends on the <allcaps> bsp </allcaps> build - time options , specifically if the macro "" cpu_simple_vectored_interrupts "" is defined set to <allcaps> false </allcaps> then the <allcaps> api </allcaps> call is not available . this causes a link error when building with the "" pc686 "" <allcaps> bsp </allcaps> since os_intattachhandler ( ) calls rtems_interrupt_catch ( ) . this ticket will simply add a preprocessor check for the above condition , and if rtems_interrupt_catch ( ) is not available then os_intattachhandler ( ) should return os_err_not_implemented .",0.0
"<allcaps> osal </allcaps> should use ut framework similar to that of <allcaps> cfe </allcaps> with trac ticket # <number> ( and related # <number> ) now implemented , the <allcaps> osal </allcaps> tests can be used as one piece of a build verification tool suite . however , the implementation is currently very basic - it does not use any real testing framework , it simply counts errors using a global integer added to each test . <allcaps> cfe </allcaps> has a more sophisticated ut framework consisting of the following functions : * ut_text ( ) - informational / log file text printing function ; * ut_report ( ) - provides a common method to check for a condition , along with code to log <allcaps> passed </allcaps> / <allcaps> failed </allcaps> in a consistent manner ; * ut_setrtncode ( ) - ability to tailor the response code of stub functions in order to exercise error paths ; * ut_reportfailures ( ) - test summary generator <allcaps> osal </allcaps> could benefit from using the same framework to run its tests . most importantly , using the common "" ut_report ( ) "" <allcaps> api </allcaps> ensures that any errors that occur will be counted and logged in a consistent way . this is particularly important for automated tests , as a simple "" grep "" command can reliably find failures within log files containing thousands of test cases .",2.0
"os_pend and os_check are backwards for functions that have a "" timeout "" parameter , two special values are defined : "" os_pend "" can be used to wait forever , and "" os_check "" can be used to not wait at all / return immediately . the issue is that "" os_pend "" is defined as "" <number> "" and "" os_check "" is defined as "" - <number> "" . these should be the other way around . the problem is not so much when the special values are used but rather when they are <allcaps> not </allcaps> used and the timeout is computed by subtracting a current time from a deadline time . if the result of that computation happens to be zero , the <allcaps> osal </allcaps> will interpret this as "" os_pend "" and will end up waiting forever . simply swapping the definitions of os_check and os_pend would make the operation much more logical by making a computed timeout of zero get the behavior of os_check and not os_pend .",2.0
"alternate time references for <allcaps> osal </allcaps> timers <allcaps> osal </allcaps> currently has a timer <allcaps> api </allcaps> which references only to the real time clock in the <allcaps> cpu </allcaps> . all timers created using the os_timercreate ( ) / os_timerset ( ) <allcaps> api </allcaps> are always based on the same clock reference . however , in an embedded system , a local clock may not always be the real reference for events ; many systems derive their timing from an external entity which is <allcaps> not </allcaps> necessarily synchronized to the local <allcaps> cpu </allcaps> clock . this ticket will add a new type of <allcaps> osal </allcaps> object called a "" time base "" . by default a time base can be driven from the local <allcaps> cpu </allcaps> real time clock , which will mimic the current behavior of timers . however the <allcaps> bsp </allcaps> / <allcaps> psp </allcaps> may create additional time bases and synchronize them to e . g . an external timing interrupt . the same existing "" timerset "" <allcaps> api </allcaps> can be used to set the timers against the alternate time base and it will be transparent to the app .",2.0
"more lenient operation when "" <allcaps> simulation </allcaps> "" compile - time directive is defined when using the <allcaps> posix osal </allcaps> implementation under linux , certain things only fully work when running as root . specifically : * attempts to create <allcaps> posix </allcaps> queues at depths greater than / proc / sys / fs / mqueue / msg_max ( typically <number> ) will fail . * attempts to raise the priority of user threads will fail . the queue depth issue in particular is so frequently encountered that there is a special message printed if queue creation fails . however , the suggested workarounds require root access , and this would not typically be the case when using an official <allcaps> aces </allcaps> - issued linux workstation ( unless one has elevated privileges ) . in order to make it easier for someone to initially get up and running with <allcaps> osal </allcaps> / <allcaps> cfe </allcaps> , the <allcaps> osal </allcaps> should be more lenient and allow the operation to succeed even if all the parameters were not met due to being a normal user and not root . a workaround such as this can be employed if and only if compiling with the "" <allcaps> simulation </allcaps> "" flag , as this indicates the user is performing a debug build and not running on a real target . this way , the operation will still fail when performing a build for real hardware .",2.0
"<allcaps> api </allcaps> prototype changes to address compiler warnings these areas of the <allcaps> osal api </allcaps> need clean up . task <allcaps> api </allcaps> : * os_taskcreate ( ) stack pointer is declared const ( read - only ) . by definition , stack space should not be read - only . * os_taskinstalldeletehandler ( ) takes a "" void * "" argument rather than a function pointer . this should be a function pointer . module <allcaps> api </allcaps> : * to be consistent with the other <allcaps> api </allcaps> ' s , a separate property structure should be defined for use with os_moduleinfo ( ) . currently this returns the internal <allcaps> osal </allcaps> "" os_module_record_t "" , while all other <allcaps> api </allcaps> ' s return a dedicated property object . this is necessary to allow the internal implementation of the <allcaps> osal </allcaps> to change in the future while preserving the public <allcaps> api </allcaps> types . * the types should be changed to use the "" cpuaddr "" type rather than uint32 where a memory address is stored ( os_module_address_t , os_symbollookup ( ) ) general : * when passing character strings as input to functions these should preferably be declared as "" const char * "" whenever possible . this allows one to pass string literals into the function . otherwise a warning may be generated if a literal is used for a parameter declared as "" char *"".",0.0
"make file system <allcaps> api </allcaps> work more like the rest of <allcaps> osal </allcaps> in addition to the error code issue in ticket # <number> , other aspects of the filesystem <allcaps> api </allcaps> should be fixed to better integrate with the rest of <allcaps> osal </allcaps> : * the filesystem <allcaps> api </allcaps> is not a full abstraction , it is only a light wrapper around the <allcaps> posix </allcaps> / c library functions . similarly , the "" os_fstat_t "" , "" os_dirp_t "" , and "" os_dirent_t "" are directly typedef ' ed to the c library types and not abstracted in any way . the effect of this is that any application code written using the <allcaps> osal </allcaps> filesystem <allcaps> api </allcaps> is ultimately still dependent on the underlying system libraries and headers , and the particular <allcaps> posix </allcaps> / c standard variant it supported , and may not be portable to other os ' s . * due to the direct use of os - supplied types and implementation , this implicitly adds a limitation that any <allcaps> osal </allcaps> filesystem must also map to a "" real "" filesystem recognized by the underlying os . it is not possible to access a file storage device unless the os already recognizes its filesystem . * the <allcaps> api </allcaps> calls are defined differently and look / feel more like c library functions than the rest of <allcaps> osal </allcaps> . some fs functions return an "" int32 "" which serves as both an object id and error code . other fs function return a pointer and these have no way of returning a more descriptive error other beyond a <allcaps> null </allcaps> pointer . in the rest of <allcaps> osal </allcaps> , <allcaps> api </allcaps> functions pass back an object id separately from the error code via a separate "" uint32 "" parameter . this eliminates confusion of how to differentiate an error code from a valid object id . this can be fixed without breaking <allcaps> api </allcaps> compatibility with existing code : * the types which are currently directly typedef ' ed to the c library types can be properly abstracted . this will be transparent to application code as long as the names are preserved . * a new file <allcaps> api </allcaps> can be introduced that works more like the rest of <allcaps> osal </allcaps> , and wrappers implemented to mimic the current <allcaps> api </allcaps> so that existing code still works . to save code memory space , an optional compile time switch ( e . g . in osconfig . h ) can disable the wrapper functions once application code is updated .",2.0
"duplicate <allcaps> osal </allcaps> error codes and error string <allcaps> api </allcaps> osapi - os - filesys . h has its own set of error codes that overlap with and are <section> the rest of <allcaps> osal </allcaps> error codes . for example , "" os_fs_err_name_too_long "" is not the same as "" os_err_name_too_long "" . there are several codes that are redefined differently . at a minimum , this is confusing , but it can also cause real bugs if the wrong action is taken due to misinterpreting an error . furthermore , fs has a second implementation of os_geterrorname called os_fs_geterrorname ( ) that only translates the fs error codes . passing an error code from one of the filesystem functions into os_geterrorname will get the wrong string . this should be cleaned up - the fs error codes should be merged with the rest of <allcaps> osal </allcaps> error codes into a single set , with a single implementation of os_geterrorname ( ) to get them all .",0.0
"<allcaps> api </allcaps> versioning for <allcaps> osal </allcaps> the <allcaps> osal </allcaps> version id e . g . "" <number> . <number> "" can also be used by application code to determine <allcaps> api </allcaps> features in case they change over time . although the existing <allcaps> osal api </allcaps> is intended to remain stable across versions , new calls can ( and should ) be added when appropriate . however this presents a problem for backward compatibility as new code written against a new <allcaps> api </allcaps> cannot be compiled with an older version of <allcaps> osal </allcaps> . this is a common problem and is generally solvable by creating / checking a version macro . for example , glibc uses "" posix_c_source "" as an integer to define which version of <allcaps> posix </allcaps> it should behave like . the <allcaps> osal </allcaps> should do the same , and create an "" osal_api_version "" macro that application code can check to see what version of the <allcaps> api </allcaps> the current <allcaps> osal </allcaps> supports . application code can then adjust itself accordingly , either by compiling without the new feature or generate a compile error if that feature is required .",2.0
"add free - run tick counter <allcaps> api </allcaps> to <allcaps> osal </allcaps> many times it is simpler and more efficient to deal with a simple free - running tick counter than to deal with the full - blown time <allcaps> api </allcaps> . on some os platforms this is as simple as reading an internal timer tick register , but in the worst case it can always be generated from gettimeofday ( ) or whatever the os_getlocaltime ( ) already uses . the <allcaps> osal </allcaps> currently has an <allcaps> api </allcaps> call for os_getlocaltime ( ) that fills in an os_time_t structure . the problem with this structure is that it has two parts , seconds and microseconds , which makes it difficult to add and subtract from other os_time_t structures . even if this were c + + and the code could be "" hidden "" behind an overloaded + / - operator , there is still the issue of an extra function call and checking for overflow which makes it slow and inefficient no matter how you mask it . it can be argued that the majority of client code that calls functions such as this are really interested in "" relative "" time i . e . the amount of time elapsed since some prior event , as this is how timeouts and error handling are typically invoked . a simpler way to solve this is via a single ever - incrementing ( free - running ) integer counter that simply increments each period and wraps around if int_max is reached . the major advantage is fast and simple add / subtract / compare operations to acquire relative times . the disadvantage is that it is not easy to display as a human - readable time but this is typically not a problem - - the os_getlocaltime works for this . it also is not able to measure relative times more than <number> ^ <number> ^ ticks ( about <number> days for 1 ms period ) , but if time spans that long need to be measured then typically a <number> - second resolution is preferable anyway and that is already available via os_getlocaltime ( ) . as this is a new <allcaps> api </allcaps> call , it will not affect any existing code , it only provides a new call to simplify operations where it is more appropriate than os_getlocaltime ( ) .",2.0
"add <allcaps> osal </allcaps> abstraction for network / socket interface currently the <allcaps> osal </allcaps> has a very minimal abstraction for network / socket functions . network operations are a common requirement and the presence / type of network stack can vary , such as <allcaps> bsd </allcaps> - style sockets or the lightweight ip ( lwip ) stack . this is a prime candidate for addition to the <allcaps> osal </allcaps> . the abstraction layer should contain : * abstraction of os socket address ( sockaddr_in / _in6 for ipv4 and ipv6 at least ) * abstraction of stream / <allcaps> tcp </allcaps> & datagram / <allcaps> udp </allcaps> socket creation * bind / listen for <allcaps> tcp </allcaps> * sendto / recvfrom for <allcaps> udp </allcaps> * abstractions for the basic inet_aton ( ) / inet_ntop ( ) ip - address",2.0
"fix warnings in <allcaps> osal </allcaps> "" unit - test "" code the code in the "" unit - tests "" directory in <allcaps> osal </allcaps> has a number of warnings when it compiles and this is one thing preventing turning on the strictest compiler settings ( - wall - werror , etc ) during the build . many of the warnings are related to passing a non - const string directly to a printf function when logging test results .",0.0
"make <allcaps> osal </allcaps> tests more autonomous the <allcaps> osal </allcaps> tests ( in the "" tests "" directory , <allcaps> not </allcaps> "" unit - test "" ) provide reasonable "" black - box "" style testing of the <allcaps> osal </allcaps> features via the public <allcaps> api </allcaps> . however they are currently implemented with the expectation of being explicitly run by a user at the console , not from an automated script : * most run infinitely , requiring a <allcaps> ctrl </allcaps> + c to stop the test * they do not count errors or provide a status code to indicate whether the test worked as expected or not . in order to integrate with a continuous integration system , these tests need to be more automated . this ticket is to add a "" script - mode "" feature to the tests which : * checks for the expected conditions and maintains an error counter of any tests that did not satisfy expected conditions * limits the time of execution and exits the test automatically ( no <allcaps> ctrl </allcaps> + c ) * returns a non - zero exit code if any errors occurred ( for scripting ) ( note : this does not apply to the "" unit - tests "" directory which is more white - box style code coverage testing - - this will possibly need other tweaks to work with a ci system and that is a separate ticket )",0.0
"refactor common code between vxworks / posix / rtems into <allcaps> osal </allcaps> shared layer the <allcaps> osal </allcaps> library is essentially three separate libraries sharing a common <allcaps> api </allcaps> . the vxworks , rtems , and posix implementations do not share any code aside from the common osapi header files . depending on the os selection , one of the three libraries will be compiled . however , under the hood , many of the operations within these three libraries are very similar . although the final call down into the os differs , much of the "" housekeeping "" that <allcaps> osal </allcaps> performs is similar between all three implementations . each of them maintain internal tables that map os objects to names and numbers , and all the <allcaps> osal api </allcaps> calls check their arguments against these internal tables to see e . g . if an object by some id is valid or if an object by some name already exists . all this housekeeping / / really should be identical / / and it could be argued that any difference is really a bug and not a feature , as differences here could affect the portability of application code from one os to another . refactoring this "" common "" functionality into a layer which is actually shared among os implementations provides several benefits : * cuts down on the code in the actual os - specific portions by about <percent> , and the code that is left is much more direct and "" to - the - point "" . for instance , an implementation of creating a semaphore / / <allcaps> only </allcaps> / / needs to create the actual semaphore and return a success / fail code . all locking , table manipulation , error checking , and recovery is handled by the shared / common layer . * this makes additional operating system layers easier to implement and less costly to maintain in the future . * likewise , abstraction of additional os features ( such as network sockets ) is easier to implement and less costly to maintain in the future . * ensures that the housekeeping operations are done consistently across __all__ supported operating systems . this greatly reduces the chances of operations working differently on one os vs another . this is particularly true of error conditions that may not be exactly the same or recovered in the same way between current os implementations .",2.0
document available oss in trac wiki it would be helpful to construct a small wiki page corresponding to each operating system implementation giving a quick overview of the platform for which support is being provided . i suggest including hotlinks on each such page back into the doc subtree of the specific os for extended documentation - - as clones will obtain the content of the project sources but do not clone the trac wiki .,1.0
document available bsps in trac wiki it would be helpful to construct a small wiki page corresponding to each board support package giving a quick overview of the platform for which support is being provided . i suggest including hotlinks on each such page back into the doc subtree of the specific <allcaps> bsp </allcaps> for extended documentation - - as clones will obtain the content of the project sources but do not clone the trac wiki .,2.0
enhanced build system for <allcaps> osal </allcaps> this ticket is for the <allcaps> osal </allcaps> portion of the enhanced build system pushed out under the corresponding cfs ticket : ​ [ <url> the cmake script for <allcaps> osal </allcaps> can also be used to generate a standalone <allcaps> osal </allcaps> library for use with projects other than <allcaps> cfs </allcaps>,2.0
"<allcaps> osal </allcaps> "" common_types . h "" is not completely reliable on some systems ( particularly <number> - bit ) the types defined in <allcaps> osal </allcaps> "" common_types . h "" file do not always match their expected widths . there is currently a very helpful compile - time assert to catch this if it does go wrong but we need it to not go wrong in the first place . the best way to solve this is to leverage the c "" stdint . h "" file - this has been standard since c99 . for any c library that does not have this header it can fall back to using the existing defines .",0.0
"inline documentation on <allcaps> osal </allcaps> routines is incorrect / outdated in many places <section> the comments in the function headers of many of the <allcaps> osal </allcaps> calls have become outdated and incorrect . <section> n / a . this reflects source code comments only . most evident on the "" implementation "" files which copied the comment block from the external function call . <section> comment blocks should better reflect reality of what the code does . the "" real "" comment block that describes the function should reside with the function prototype . the definition should also have a comment block but primarily for visual differentiation in the source code . this block should not re - describe the function , as this results in multiple copies of the same description and thus could become stale / divergent again . <section> joseph hickey , vantage systems , inc .",1.0
"microsecond round up code does not round up . <section> spawned from # <number> the code comment claims it rounds up to never return zero . the formula implemented doesn ’ t actually round up in all cases , since generally when casting a float / double to an int you lose the fractional part ( truncation , not rounding ) . so the code is not self - consistent . it ’ s not a <allcaps> posix </allcaps> or os issue , it ’ s that the code doesn ’ t do what it says it does . the <allcaps> api </allcaps> document doesn ’ t specify a non - zero guarantee . <url> similar misleading comment at : <url> for what it ’ s worth , on linux ( our ubuntu dev system ) this code reports <number> ticks per second , and <number> usec per tick . but if you pass in high values for ticks per second , it does return zero when it claims to round up ( try <number> ticks per second ) . <section> steps to reproduce the behavior : <number> . compile <code> <number> . execute : <code> <section> expected code to match comment , round up to not equal zero . algorithm does not work as claimed in comment . <section> - cfs development server - os : <number> . <number> - <number> - generic # <number> - ubuntu - versions : n / a , sample code shows behavior ( although i poked in cfe to cause the same thing ) <section> add any other context about the problem here . <section> jacob hageman / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"return os_error if os_timerset is called with both parameters as zero <section> related to the discussion in # <number> <section> see title , as described in <url> <section> see # <number> comment thread <section> none <section> jacob hageman / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"update os_timerset <allcaps> api </allcaps> documentation for timer disable <section> as stated in # <number> , the os_timerset documentation does not match behavior . <section> <allcaps> api </allcaps> documentation should describe os_timerdelete ( ) as the method to cancel the timer ( not a start time of zero ) <section> none <section> none <section> jacob hageman / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
qnx osal does such exists in nature ?,3.0
test <code> does not compile <allcaps> osal </allcaps> fails to compile with a clean clone of the repo . <code>,3.0
"fix # <number> , adds local variables for command buffer processing a clear and concise description of what the contribution is . - fixes # <number> <section> error - free build <percent> lcov coverage <section> "" const - ness "" of command buffers are maintained . minimized undefined behavior by creating and localizing changes instead of changing const buffers . <section> - os : ubuntu <number> <section> n / a <section> n / a <section> justin figueroa , vantage systems",2.0
"fix # <number> , convert <code> return codes and variables to <code> testing performed * * github ci actions all passing successfully . <section> no change to behavior . <code> is more expressive and improves consistency with cfe / cfs . <section> avi weiss <user>",2.0
mm <code> return codes and variables should be converted to <code> expected behavior * * use the more expressive <code> and improve consistency with cfs . <section> avi weiss <user>,2.0
"fix # <number> , adds eventstring null termination a clear and concise description of what the contribution is . - fixes # <number> <section> * built app * tested lcov * ran passing cert_testbed <sad> code > test <section> null terminated <code> <section> - os : ubuntu <number> <section> followed similar null - terminated character array concatenation in : <url> <section> if included , identify any third party code and provide text file of license <section> - justin figueroa , vantage",2.0
"fix # <number> , use <code> for ' size ' variables testing performed * * github ci actions all passing successfully . <section> no change to behavior other than type changes outlined above . <section> avi weiss <user>",2.0
size variables should use the <code> type code snips * * <url> <url> <section> all size variables that can use <code> should do so - <code> is more expressive and more consistent with the relevant coding guidelines . <section> avi weiss <user>,2.0
mm command handlers cast away const several mm functions cast away const on their command buffer such that they can manipulate it internally . buffers should be copied to a local variable prior to manipulation . examples include : mm_loadmemfromfilecmd mm_dumpmemtofilecmd mm_symtbltofilecmd <section> audit mm and clean up . <section> dan knutsen <allcaps> nasa </allcaps> goddard,0.0
"fix # <number> , update initializations causing cppcheck failure testing performed * * github ci actions ( incl . build + run , unit tests etc . ) all passing successfully if separate issue <url> is suppressed image <img> the log from the successful build ( with the <allcaps> gcc </allcaps> suppressions that can not be included in this pr ) can be viewed here : <url> <section> no impact on code behavior . cppcheck now passes without error again . <section> avi <user>",2.0
new <allcaps> gcc </allcaps> warnings causing build failure [ - werror = stringop - overflow <happy> to reproduce * * run the build + run github action on the current main branch mm source code . <section> build + run workflow should run without errors . <section> avi <user>,2.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
"fix # <number> , use cfe_fs_initheader ( ) to initialize <allcaps> cfe </allcaps> header fix # <number> <section> unit testing <section> no impact to behavior <section> - os : ubuntu <number> <section> haven carlson - <allcaps> nasa </allcaps>",2.0
resolve issues building users guide with ubuntu <number> / doxygen <date> doxygen warnings for <code> <section> resove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
implicit padding being added to multiple mm commands some mm commands assume a <number> bit aligned header while others are offset by <number> bits . an example would be the peek vs poke commands . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old mm clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template a clear and concise description of what the contribution is . - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
use fixed sizes for memory addresses and offsets in tbl / cmd / tlm same as nasa / cs # <number> . using cpuaddr in tbl / cmd / tlm results in different sized structures ( and possibly different alignment / padding ) . <section> use <code> and <code> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset and cfe_psp_memcpy use on addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"mm messages - memory address being truncated to <number> bits on <number> bit machines <section> memory address ' s displayed in messages are ( sometimes ) being truncated to <number> bits on <number> bit machines <section> example from mm_app . c : cfe_evs_sendevent ( mm_sym_lookup_inf_eid , cfe_evs_eventtype_information , "" symbol lookup command : name = ' %s ' addr = 0x % 0 8 x"", cmdptr - > symname , ( unsigned int ) resolvedaddr ) ; <section> dan knutsen <allcaps> nasa </allcaps> goddard",0.0
"mm_fillmem does not call mm_segmentbreak like read from or write to file mm_fillmem writes memory in a tight loop here with no mm_segmentbreak : <url> both mm_loadmemfromfile and mm_dumpmemtofile do have a mm_segmentbreak ( example ) : <url> mm_fillmem is likely quicker , but should still support a break <section> add mm_segmentbreak <section> could leave as is , but large fill command processing could hog the <allcaps> cpu </allcaps> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"static analysis workflow fails due to strict cppcheck style warnings workflow failure , see <url> <code> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"static analysis issues relative to flight code handful of static analysis issues in the "" red "" identified ( non - style issues ) . need to resolve these . filter : - file : elf - file : ut - file : cfe - file : os - file : cf_ - file : _lab_app . c ! ( significance : style ) should resolve and / or disposition the higher ranked ones at minimum . note license restricts publishing issues . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
remove all mentions of <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts from documentation some of our doxygen docs still reference <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts . see cfs_mm repo : fsw / src / mm_msgdefs . h : l28 imported from <allcaps> gsfccfs </allcaps> - <number>,1.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
mm should include the status of the <allcaps> eeprom </allcaps> write enable in housekeeping telemetry mm includes commands to enable or disable writing to <allcaps> eeprom </allcaps> . that setting cannot currently be verified in telemetry . the status of the write enable for each <allcaps> eeprom </allcaps> bank should be added to the housekeeping packet . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"change order of size checks for optimization in mm_verifyloadwidparams , it is more efficient to check sizeinbytes before calling cfe_psp_memvalidaterange . this same optimization would be applicable in other functions . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
perf counter in mm_segmentbreak may be unnecessary the performance marker only wraps a task delay . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"mm clarify names of constants mm configuration parameters for sizes often do not include the word <allcaps> size </allcaps> , making their purpose a little less clear . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
function names mm_resethk and mm_writememwid are misleading imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
make mm memtype into an enum imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"mm_dumpineventcmd wastes event characters in mm_dumpineventcmd , including the "" 0x "" and trailing space on the hex digits unnecessarily limits how much can actually be dumped in the event . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"mm investigate use of static variables in mm_dumpineventcmd , eventstring is declared as static to keep it off the stack . need to investigate whether this is necessary . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
generally better to initialize return code to false imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"in mm_dumpmemtofilecmd , would be faster to checksum while writing imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
in mm_dumpmemtofile command could use cfe_fs_initheader imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
investigate whether eeprom and symtable handing belongs in mm some discussion needed in the future to reevaluate whether eeprom and symbol table handling belongs in mm since not every platform has them . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"mm intlock removed , no longer implements "" write with interrupts disabled "" requirement mm2003 historical - ( note the lock / unlock have been removed , see comments ) : memory manager uses os_intlock ( ) and os_intunlock ( ) . that ' s the only place any of the os_int * functions are used in the <allcaps> gsfc </allcaps> apps . these functions will likely be deprecated in the next <allcaps> osal </allcaps> release . i am guessing it does this with the intent of loading the mem block "" atomically "" with the hope of preventing another task from writing to it while this happens ? intlock / unlock has always been a no - op on <allcaps> posix </allcaps> , and furthermore even on platforms where it does something , it will not achieve that exclusivity effect on multi - core cpus , as it only locks the interrupts on the core which calls it , and other cores continue to run anyway , interrupt or not . probably worth re - evaulating what mm is trying to achieve with the intlock . <repeated> might be able to simply take it out with no loss of function . <number> - os_intloc and os_intunlock were removed as part of <allcaps> gsfccfs </allcaps> - <number> . although now requirement <allcaps> gsfccfs </allcaps> - <number> is not being met . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"mm unclear app configuration assumptions stakeholder : discovered and added comments to the config file that some app configuration values have assumptions on modulo - <number> or modulo - <number> sizes . for example , these <number> and <number> - bit dump routines would fail if these config <hashtag> defines </hashtag> are not set with the appropriate values . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
resolve issues building users guide with ubuntu <number> / doxygen <date> doxygen warnings for <code> <section> resove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
remove stray terminators <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old md clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template . md and contributing . md - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset use for addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"static analysis workflow fails due to style warnings strict cppcheck warnings cause static analysis workflow failure , see : <url> <code> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
two events in md_events . h have the same event id md_tbl_val_null_ptr_err_eid & md_update_tbl_sig_err_eid are both assigned event id <number>,0.0
remove all mentions of <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts from documentation some of our doxygen docs still reference <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts . see cfs_mm repo : fsw / src / mm_msgdefs . h : l28 imported from <allcaps> gsfccfs </allcaps> - <number>,1.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
md - consider reporting number of addresses being collected in md3001 typically md3000 will need to have a fixed total size of bytes such that the creation of the message ( md3001 ) will result in the same size . that means md3001 item c ) number of bytes sampled will typically always be the same on systems that required fixed size telemetry packets ( assuming a database change is not made every time a new table is needed ) and the address count will always be the max number of entries . consider <allcaps> fsw </allcaps> update to report the actual used address count ( those with nonzero byte counts ) . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"consider using an enum for md error codes in file md_dwell_pkt . c function md_getdwelldata , all the "" - <number> "" status values could be replaced with an enum . finding from code review . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"md - table configuration is not consistent with other applications md currently gets the dwell tables from the <allcaps> cds </allcaps> or zeros them out . the md table design is not consistent with other cfs applications : - the md task should allow the option to save or not save tables in the <allcaps> cds </allcaps> ( and therefore behave like the other applications ) . - the md task should allow the option to have default tables in <allcaps> eeprom </allcaps> ( and therefore behave like the other applications ) . - the default address to be used , should a table not be found , should be user defined . <number> may not be a valid address . - the md task does not use the cfe_tbl_manage feature . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"remove old <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",2.0
"create version header file , update to x . x . <number> , report on execution",2.0
"fix # <number> , removes error on format style differences - fixes # <number> - removes the exiting logic such that the workflow can not fail due to a claang difference . <section> observed that error does not happen when format - check is called and there is a claang - format - <number> style difference . <section> no error on style differences <section> - os : ubuntu <number> <section> n / a <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> justin figueroa , vantage",2.0
missing <allcaps> pus </allcaps> lib repo can anyone let me know where is the repository for cfs <allcaps> pus </allcaps> application - it used to be in the following location : <url>,3.0
"add option for "" build - run - app "" reusable workflow to include dependent libraries currently the "" build - run - app "" reusable workflow only checks out the app into the "" apps "" directory . however , some cfs applications , such as bp , also require inclusion of a support library ( e . g . bplib ) in order to build and run . <section> add an additional workflow input to specify additional library dependencies , which can be checked out and included in the build . <section> typically these would only libraries ( not other apps ) . <section> joseph hickey , vantage systems , inc .",2.0
"allow users to pass project args to the "" static - analysis "" cppcheck reusable workflow the issue observed in nasa / osal # <number> is due to the fact that cppcheck is being executed in each c source file in isolation . in this case it does not see the definition of <code> and thus does not know how to examine this line . <section> cppcheck allows command line options to specify various project - specific preprocessor settings , such as <code> and <code> options to specify if a macro is set or unset , respectively , as well as <code> option ( s ) indicating where to find include files . furthermore , with cmake , the <code> option causes cmake to export a json file containing the full include path being used , which can then be passed to cppcheck via the <code> option . with this , the code will be examined using the configuration that is actually being compiled . <section> <number> . skip checking of ut stubs in general ( but stubs could have bugs like uninitialized vars and things that cppcheck could flag ) <number> . remove use of <code> , as this will not be checkable unless the definition of this macro is also supplied . <section> using <code> causes cppcheck to be much more thorough in its results . in particular , it now "" sees "" the <code> file and the ifdef macros that exist in there , and it will check each macro both ways . the upside to this is it finds more potential issues , particularly with ifdef branches that are not regularly used , but the downside is that it significantly increases the runtime of cppcheck as it tests all the permutations . this may need to be limited if it becomes excessive . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , fetch documentation archives fixes # <number> <section> tested on fork image <img> tested locally in docker . <section> the issue is thrown at random times . thrown here : <url> but not here : <url> <section> fixes failing cfs documentation and guides workflow . it had an issue installing <allcaps> pdf </allcaps> generation dependencies . same behavior . <section> ariel adams , <allcaps> mcsg </allcaps> tech",1.0
"issues : questions cfs cannot find unit - test excecutables when attempting to run unit - tests on a cfs project with <number> custom application modeled closely after the sample_app template the output of running "" make test "" fails as it cannot find the test executable ' s . it would be great to know if the steps i am following below are insufficient to properly run the unit tests , or if the error in my log files below indicates another issue ? <section> steps to reproduce the behavior : <number> . make distclean <number> . make <allcaps> simulation </allcaps> = native enable_unit_tests = true prep <number> . make <number> . make test <section> all unit - tests pass . <section> - os : vmware ubuntu <number> - versions : cfs v6 . <number> . 0 a <section> the actual output i receive is the following for every possible test : lcov - - capture - - initial - - directory build / native - - output - file build / native / coverage_base . info capturing coverage data from build / native subroutine read_intermediate_text redefined at / usr / bin / geninfo line <number> . subroutine read_intermediate_json redefined at / usr / bin / geninfo line <number> . subroutine intermediate_text_to_info redefined at / usr / bin / geninfo line <number> . subroutine intermediate_json_to_info redefined at / usr / bin / geninfo line <number> . subroutine get_output_fd redefined at / usr / bin / geninfo line <number> . subroutine print_gcov_warnings redefined at / usr / bin / geninfo line <number> . subroutine process_intermediate redefined at / usr / bin / geninfo line <number> . found gcov version : <number> . <number> using intermediate gcov format scanning build / native for . gcno files . <repeated> geninfo : <allcaps> warning </allcaps> : no . gcno files found in build / native - skipping ! finished . info - file creation ( cd build / native & & ctest - o ctest . log ) test project / home / daniel / fp_cfs_vrcs / build / native start <number> : bin - sem - flush - test could not find executable bin - sem - flush - test looked in the following places : bin - sem - flush - test bin - sem - flush - test release / bin - sem - flush - test release / bin - sem - flush - test debug / bin - sem - flush - test debug / bin - sem - flush - test minsizerel / bin - sem - flush - test minsizerel / bin - sem - flush - test relwithdebinfo / bin - sem - flush - test relwithdebinfo / bin - sem - flush - test deployment / bin - sem - flush - test deployment / bin - sem - flush - test development / bin - sem - flush - test development / bin - sem - flush - test unable to find executable : bin - sem - flush - test <number> / <number> test # <number> : bin - sem - flush - test . <repeated> * * * not run <number> sec start <number> : bin - sem - test <section> <percent> tests passed , <number> tests failed out of <number> total test time ( real ) = <number> sec the following tests <allcaps> failed </allcaps> : <number> - bin - sem - flush - test ( not run ) <number> - bin - sem - test ( not run ) <number> - bin - sem - timeout - test ( not run ) <number> - count - sem - test ( not run ) <number> - file - api - test ( not run ) <number> - mutex - test ( not run ) <number> - osal - core - test ( not run ) <number> - queue - timeout - test ( not run ) <number> - sem - speed - test ( not run ) <number> - symbol - api - test ( not run ) <number> - timer - test ( not run ) <number> - osal_core_ut ( not run ) <number> - osal_loader_ut ( not run ) <number> - osal_filesys_ut ( not run ) <number> - osal_file_ut ( not run ) <number> - osal_network_ut ( not run ) <number> - osal_timer_ut ( not run ) <number> - my_app - my_app ( not run ) <number> - cfe_core_default_cpu1_es_ut ( not run ) <number> - cfe_core_default_cpu1_sb_ut ( not run ) <number> - cfe_core_default_cpu1_evs_ut ( not run ) <number> - cfe_core_default_cpu1_tbl_ut ( not run ) <number> - cfe_core_default_cpu1_time_ut ( not run ) <number> - cfe_core_default_cpu1_fs_ut ( not run ) errors while running ctest output from these tests are in : / home / daniel / fp_cfs_vrcs / build / native / testing / temporary / lasttest . log use "" - - rerun - failed - - output - on - failure "" to re - run the failed cases verbosely . make : * * * [ makefile : <number> : test ] error <number>",3.0
use custom container for workflows the documentation workflow and a couple of others keep failing sporadically due to dependency install failures . <section> a custom cfs - dependencies container that has the following toolkit - cmake - gcc - gcov - lcov - doxygen - latex - graphviz - etc . this will help with both dependency management and maybe even speed up some of our builds that install dependencies with every run . another benefit is that we can encourage the community to use these containers as their development environment . <section> use a standard doxygen container image for the documentation workflow <section> none <section> gerardo e . cruz - ortiz | <allcaps> nasa </allcaps>,2.0
"update <allcaps> cla </allcaps> information in apache <number> cfs app repositories have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
"add combined <allcaps> cla </allcaps> for cfs app repos we just received updated clas for the apache <number> licensed applications . <section> need to upload the new clas , add them to contributing . md and then add links to the new forms in each app repository . <section> migrate to new org and set up shared community info <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps>",1.0
"fix # <number> , add links to <allcaps> readme </allcaps> - fix # <number> skimmed the <allcaps> nasa </allcaps> repos and added links ( including <allcaps> sbn </allcaps> - client ) <section> none , doc only <section> n / a <section> n / a <section> none <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , updated broken links in <allcaps> readme </allcaps> updated the urls of the cfe and <allcaps> osal </allcaps> user guides in the <allcaps> readme </allcaps> file . - fix # <number> <section> clicked the links in the <allcaps> readme </allcaps> <section> no impact to behavior <section> browser <section> add any other context about the contribution here . <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> full name and company / organization / center of all contributors ( "" personal "" if individual work ) - note clas apply to only software contributions .",1.0
add <allcaps> sbn </allcaps> - client to <allcaps> readme </allcaps> references <url> may be a useful reference <section> add it to top level <allcaps> readme </allcaps> <section> none <section> none <section> jacob hageman / <allcaps> nasa gsfc </allcaps>,1.0
cfe and <allcaps> osal </allcaps> user guides links from the <allcaps> readme </allcaps> file are broken cfe and <allcaps> osal </allcaps> user guides links in the <allcaps> readme </allcaps> file are broken after recent update .,1.0
update reusable workflow documentation and diagram as we add new workflows we should keep documentation up to date <section> new diagrams and updated workflow summaries <section> remove documentation and maintain with each file <section> none <section> gerardo e . cruz - ortiz,1.0
"add guidance for coverage tests in contributing guide when improving coverage for code we should update the minimum coverage checks in the appropriate github workflow . <section> add a section to contributing guide <section> do nothing . include in wiki or other document <section> see yml change in <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps>",1.0
"add document build and deploy reusable workflow all apps will need a document build and deploy workflow <section> avoid duplication by implementing reusable workflow from cfs , also use it in cfs to avoid duplication in current documentation workflow . <section> none <section> - # <number> rather than duplicating workflow logic for another doc , just use the reusable workflow for each document . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> # <number> , deploy mission document from workflow by using reusable workflow - fix # <number> - fix # <number> note # <number> already added enforcement , so this just adds deployment . <section> ci that included nasa / cfe <user> , forced the deployment , and used current branch to get the reusable workflow results at <url> <section> deploys mission doc on push to main <section> ci <section> depends on nasa / cfe # <number> <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"apply latest contributor license agreements updated contributor license agreements and adds links in the pull request template to these contributor license agreements . <section> update <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"fix workflow documentation directory for <allcaps> osal </allcaps> dox updates nasa / osal # <number> simplifies doxygen documentation build directory structure , documentation workflow impacted <section> fix reference <section> none <section> nasa / osal # <number> and nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"update standard "" development "" version indicator to use 0 xff historically , setting the revision number to "" <number> "" indicates that the source code in question is a "" development "" version and thus has not been fully tested . in <url> we put this information in the mission_rev instead and set it to "" 0 xff "" . this pattern has a couple of problems : - it is not standard , cfe documentation needs to be updated - if a user changes the mission_rev while building on top of a development version , there is no way to know what the original version was by looking at source code . ( eg x . y . z . <number> is changed by a user to x . y . z . <number> ) kudos to <user> for this observation - older telemetry or "" ground "" systems may be used to the two - character legacy number of "" <number> "" instead of "" 0 xff "" and convert the value into a two - character string thereby cutting off the value . <section> <number> . revert to using the revision number <number> . move from <number> to 0 xff <number> . communicate the change to users <section> keep revision = <number> <section> need to open related issues in other cfs component repositories <section> gerardo cruz - ortiz , <allcaps> nasa </allcaps>",2.0
"the "" setvars . sh "" file is missing in v7",3.0
where are the new - app - generation scripts ? ( that used to exist in / tools ),3.0
<allcaps> cfs </allcaps> make error <number> i am trying to work on this repository for the <allcaps> nasa cfs cs </allcaps> challenge and i am implementing it using ubuntu and debian operating system . i am getting a make error when i follow the below steps . i have uploaded the picture of the error for your reference . thanks . <section> steps to reproduce the behavior : <number> . git clone <url> <number> . cd cfs_checksum_patched / cfs / <number> . git submodule update - - init - - recursive <number> . make <number> . make install <section> - raspberry pi / beagleboneblack - ubuntu <number> / debian <number> <section> kaushik varma rudraraju colorado state university make error <number> <img>,3.0
"fix # <number> , combine deploy documentation jobs fixes # <number> combines users guide and osal guide build jobs . combines users guide and osal deployment jobs . <section> tested on fork : <url> documents : <url> <section> no race condition <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , use <allcaps> svg </allcaps> image for workflows <allcaps> readme </allcaps> fixes # <number> use <allcaps> svg </allcaps> image instead of <allcaps> png </allcaps> <section> tested on fork : <url> <section> no change in behavior <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"use <allcaps> svg </allcaps> image for workflows readme the <allcaps> readme </allcaps> . md for cfs / . github / workflows / uses an image that may not be easily edited . <section> convert the image to <allcaps> svg </allcaps> . <section> keep as is . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
update rc4 tag descriptions to include equivalent dev tags need a mapping between tags and build numbers to reduce confusion <section> include rc information in update history on readme and tag description <section> finish official release and add official numbers <section> raised in stakeholder meeting <section> <user>,1.0
"fix # <number> , updated <allcaps> readme </allcaps> training link - fix # <number> <section> none - documentation only . <section> none <section> na <section> none <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
update cfs training package link new slide package available at <url> <section> update <allcaps> readme </allcaps> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"cfs submodules refer to "" master "" branches it seems the . gitmodules file still lists "" branch = master "" for cfe and osal . should switch to "" main "" . ( surprised "" master "" still works , given that branch is long gone ! guessing git defaults to "" <allcaps> head </allcaps> "" if the branch specified no longer exists . ) <url>",2.0
"fix # <number> , add ci status badge in <allcaps> readme </allcaps> fixes # <number> <section> tested badges locally : <url> <section> adds badges for cfs - build and rtems five . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fixed minor typos in the cfs docs <section> fixed a few minor typos ( misspelling of words ) in <allcaps> readme </allcaps> . md , <allcaps> contributing </allcaps> . md and <allcaps> security </allcaps> . md . <section> none ( non - executable code ) . <section> none ( markdown doc changes only ) . <section> n / a <section> n / a <section> n / a",1.0
add functional tests step to continuous integration the cfe repository has a suite of functional tests . these tests can sometimes fail when introducing new osal dependencies . these failures can be shown to be fixed at the bundle level when combining the right set of submodule references . <section> port the functional test workflow as an extra job to the build test and run workflows . <section> make a separate workflow <section> none,2.0
"fix # <number> , add discussions in the contributing guide fixes # <number> add information on where to submit discussions , questions , and ideas . <section> users should know to submit discussions , questions , and ideas in the discussions tab of the cfs repository instead of creating an issue . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add discussions in contributing guide cfs now uses discussions as a way to ask questions or request information . this is not in the contributing guide . <section> add that users may start discussions or ask questions in the discussions tab of cfs under ways to contribute in the contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , generate documentation in all scenarios fixes # <number> remove <code> from <allcaps> pdf </allcaps> generation installs and <allcaps> pdf </allcaps> generation . add <allcaps> pdf </allcaps> generation installs and <allcaps> pdf </allcaps> generation steps to the previous job , so that deploy is a separate job . <section> n / a <section> pdfs will generate no matter what while deployment is based on if it is pushed on main . <section> may require cache pr for successful deployment : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , no file found documentation workflow fixes # <number> workflow was failing due to files not persisting between jobs . used cache action . <section> tested on fork : <url> <section> pdfs should generate . <section> pdfs will generate when push on main branch . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"generate documentation <allcaps> pdf </allcaps> in all scenarios regardless of whether it will be pushed or not . # # problem we could have caught the latest error <url> in the documentation build and push job if we built the pdfs every time . # # proposed solution only keep this condition in the "" push "" step of the job ; remove it from the dependencies and document generation steps . <code>",1.0
"no file found for documentation and guides workflow the <allcaps> osal </allcaps> and cfe users guide <allcaps> pdf </allcaps> documentation are not generating due to errors in the workflow . <section> see <url> <section> the <allcaps> osal </allcaps> and cfe users guide <allcaps> pdf </allcaps> documentation should generate and upload to gh - pages . <section> <code> <section> github actions workflows <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , exclude <allcaps> lgtm </allcaps> false positives fixes # <number> excludes cpp / string - copy - return - value - as - boolean <section> none <section> no longer run against string - copy - return - value - as - boolean <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"fix # <number> , run documentation and guides on push fixes # <number> pdfs only generates on push for main branch . workflow will run on push rather than pull request . <section> tested on fork . image <img> <section> pdfs will generate . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"run documentation and guides on push for main pdfs are not generating for the documentation and guides workflow . <section> <url> <section> pdfs will generate if the event is pushed to main . <section> <code> <section> > the problem with skipping pull requests is that it will not test the merge commit . need to skip push if it is not to the main branch . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"changelog workflow failing the changelog workflow does not work due to a syntax error . <section> remove total issues as this is not a valid option in the workflow . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add workflow <allcaps> readme </allcaps> fixes # <number> add a <allcaps> readme </allcaps> in . github / workflows <section> users will know what each workflow does . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , documentation duplicate check a clear and concise description of what the contribution is . fixes # <number> . used with <url> skips individual steps for the <allcaps> osal </allcaps> and cfe jobs . does not skip the last three steps that generates the pdfs . <section> tested locally on forked repo . pdfs were updated in gh - pages branch . image <img> <section> the documentation workflow should generate and update the cfe and <allcaps> osal </allcaps> user guides . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"provide <allcaps> readme </allcaps> in . github / workflows users may not know where to find detailed information about the workflows . <section> provide a description of workflows , how to use them , and how to modify them in a <allcaps> readme </allcaps> . md file . provide a link to this file in the contributing guide . <section> do not create a new <allcaps> readme </allcaps> . md file and instead add detailed descriptions of the workflows in the contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"documentation deployment is being skipped as part of duplicate check , documents stale see <url> documents are months stale . <section> always run the <allcaps> pdf </allcaps> generation and deployment on a push to main on github . <section> none <section> # <number> - possible race in deployment <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ping <user> <user>",1.0
"error installing cfs bootes hi , i am trying to install cfs bootes and i am getting an error while installing it . i tried installing the cfs normal version and it installed successfully but , when i try bootes it is giving the error as shown below . <section> steps i followed : git clone - - recursive <url> cd cfs git checkout checksum - bootes - working export <allcaps> simulation </allcaps> = native make prep make install ( the error shows up here ) <section> pi <user> : ~ / cfs $ make install make - - no - print - directory - c "" build "" <allcaps> destdir </allcaps> =""/ home / pi / cfs / build "" mission - install [ <percent> ] building c object tools / elf2cfetbl / cmakefiles / elf2cfetbl . dir / elf2cfetbl . c . o in file included from / home / pi / cfs / cfe / modules / core_api / fsw / inc / cfe_tbl_extern_typedefs . h : <number> , from / home / pi / cfs / cfe / modules / core_api / fsw / inc / cfe_tbl_filedef . h : <number> , from / home / pi / cfs / tools / elf2cfetbl / elf2cfetbl . c : <number> : / home / pi / cfs / cfe / modules / core_api / fsw / inc / cfe_es_extern_typedefs . h : <number> <time> : error : ‘ cfe_mission_es_cds_max_full_name_len ’ undeclared here ( not in a function ) ; did you mean ‘ cfe_mission_es_cds_max_name_len ’ ? char name [ cfe_mission_es_cds_max_full_name_len ] ; /* *< \ brief processor unique name of <allcaps> cds </allcaps> */ ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ cfe_mission_es_cds_max_name_len / home / pi / cfs / cfe / modules / core_api / fsw / inc / cfe_es_extern_typedefs . h : <number> <time> : error : ‘ cfe_mission_es_pool_max_buckets ’ undeclared here ( not in a function ) ; did you mean ‘ cfe_mission_es_perf_max_ids ’ ? cfe_es_blockstats_t blockstats [ cfe_mission_es_pool_max_buckets ] ; /* *< \ cfetlmmnemonic \ es_blkstats ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ cfe_mission_es_perf_max_ids make4 <url> [ tools / elf2cfetbl / cmakefiles / elf2cfetbl . dir / build . make : <number> : tools / elf2cfetbl / cmakefiles / elf2cfetbl . dir / elf2cfetbl . c . o ] error <number> make3 <url> [ cmakefiles / makefile2 : <number> : tools / elf2cfetbl / cmakefiles / elf2cfetbl . dir / all ] error <number> make2 <url> [ cmakefiles / makefile <time> <number> : cmakefiles / mission - install . dir / rule ] error <number> make1 <url> [ makefile : <number> : mission - install ] error <number> make : * * * [ makefile : <number> : install ] error <number> <section> - hardware : raspberry pi <number> - os : raspbian <section> name : kaushik varma rudraraju college : colorado state university",3.0
"add ci workflow / configuration that enables strict type checking the cfs ci scripts currently build with lax / weak type checking , which is the distribution default ( in sample_defs ) as it is more backward compatible . <section> at least one ci build should enable this in <code> to enable strict type checking : set ( mission_resourceid_mode <allcaps> strict </allcaps> ) <section> it ' s easy to add code that will fail w / strict type checks , unless this is enabled in ci to catch it . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , correct links to community mailing list fixes # <number> the mailing list system migrated to a new server resulting in a new subscription process . <section> tested subscription method from separate personal emails . users should receive an email looking like the screenshot below upon subscription . - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - cfs - community_confirmation_email <img> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <section> no behavior changes on cfs codebase <section> n / a <section> streamlined subscription method , new system only requires a single email interaction as opposed to a request / approve / confirm loop <section> none",1.0
"fix # <number> , add workflow descriptions in <allcaps> contributing </allcaps> . md fix # <number> added short descriptions to each of our workflows . <section> users should now know what our workflows are used for . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add description of workflows in contributing guide users may not know the purpose of each workflow we use . <section> provide a short description of each workflow . <section> n / a <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"possible race condition in documentation deploy workflow <section> since the github actions jobs run in parallel there might be a case of two git commits trying to be pushed "" at the same time "" i suggest moving the multiple deploy stages from the separate doc build jobs into a separate deploy job that depends on the successful builds of all docs . could potentially do something fancy by deploying to separate "" local "" git branches and then merging them on the deploy branch . <section> see <url> <section> all documentation can be deployed <section> add any other context about the problem here . <section> full name and company / organization if applicable",0.0
"create separate app and libraries directories <section> having libraries in the apps folder can be confusing especially for beginners . <section> new directory called "" lib "" or "" libs "" where libraries can "" live "" <section> add documentation justifying why it "" makes sense "" to keep libraries in the apps directory",2.0
"update all community email management references for new service community email system is transitioning ( currently <date> target ) , which changes join / leave process . <section> update instructions in sync with system change over : <code> <section> # <number> <section> note a web interface is pending . not clear if it will support review of archives by members . <section> jacob hageman",1.0
"guide to adding new toolchains hi , is there a guide anywhere for adding new toolchains ? i want to add an aarch64 linux toolchain , but i am confused by the example toolchains . for example : - what do these mean ? - cmake_find_root_path_mode_program - cmake_find_root_path_mode_library - cmake_find_root_path_mode_include - cmake_prefix_path - what needs to be added , and what not ? the arm - cortexa8_neon - linux - gnueabi example only specifies the compilers , whereas the i686 - rtems example specifies <code> , <code> , <code> , <code> , <code> , <code> and <code> too . does anyone already have a toolchain script for linux on aarch64 ? many thanks , jack",3.0
"fix # <number> , add instruction on how to use workflows in contributing . md fixes # <number> - added instructions on how to view errors from failed workflows - added instructions on how to view workflow results in the actions tab and in pull requests - added a list of our workflows and the status of them - added information on how to configure workflows and where to find them <section> users should know how to use our workflows . <section> used reference : <url> used example : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add instructions on how to use workflows in contributing . md users may not know how to use our github actions workflows . <section> add instructions on how to use our github actions workflows under writing high quality code . instructions includes where workflows can be found , how to analyze or interpret results , how to run and configure workflows . provide links for additional information on each workflow . <section> this can be added in a new section . <section> reference : <url> example : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , rename getting started in contributing . md fixes # <number> - renamed getting started to quick links to submodules - linked the report bugs and feature requests sections in quick links to submodules - linked quick links to submodules in the report bugs section - linked quick links to submodules in the feature requests sections <section> tested links locally . <section> users should know all the submodules where bugs or feature requests may be reported . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add instructions on how to squash and amend commits fixes # <number> - added how to squash commits . - added how to amend commits . - added that users may use the format <code> for commit messages if necessary . - added to create a commit message per topic and provided an example . - added reference to <url> <section> users should know how to squash and amend commits . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"sb message data hello everyone , sorry for the basic question . i ’ m new to cfs - i ’ ve tried for a few days now and having a some difficulty with sb messages . i ’ ve read through the development guide and <allcaps> api </allcaps> - and i can ’ t figure out how to properly attach data to a sb message . i can send and receive messages , but when i mount the pointer to a variable - all the data assigned in my structs are empty . how do i properly mount custom data to my sb messages ? corey carter - <allcaps> nasa </allcaps> pathways",3.0
"add links or instructions to pull request squash and ammend section <code> <section> add links to instructions of "" how "" to squash a commit using git rebase or how to ammend a commit <section> leave as is and address with users on a one - on - one , per pr basis",1.0
"fix # <number> , add checklist to pull request template <section> fix # <number> added a checklist to the pull request template to enforce users to review the contributing guide and ensure they sign the contributor agreement . <section> the checklist helps enforce our standards when submitting pull requests . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add checklist to feature request template <section> fix # <number> added a checklist to the feature request template to enforce users to review the contributing guide , ensure their feature is not in future work , and ensure that their feature is is relevant , not redundant , nor in conflict with other tickets . <section> the checklist helps prevent redundant or irrelevant feature requests from being submitted . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add checklist to bug report template <section> fix # <number> added a checklist to the bug report template to enforce users to review the contributing guide and ensure that their bug report is is relevant , not redundant , nor in conflict with other tickets . <section> the checklist helps prevent redundant or irrelevant issues from being submitted . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add writing high quality code <section> fix # <number> add writing high quality code to the contributing guide <section> users should know how to write high quality code and how to use the github action workflows . <section> the writing high quality code provides instructions for only the two static code analyzers used in github actions . should we add instructions for both deprecated and omit_deprecated build , test , and run workflows ? they only run when code is pushed to the main branch . if we want to add this , either the workflow needs to change so it is trigger for all branches or additional instructions must be provided for users so they can manually change the workflow files . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , create separate document for code of conduct <section> fix # <number> created a separate document for code of conduct . added a link to code of conduct in the contributing guide . moved the getting started section to the bottom of the page . <section> the contributing guide is not as crowded or long . the code of conduct is in a separate document . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"create separate document for code of conduct <section> the code of conduct takes up a lot of space in the contributing guide . <section> create a separate document for the code of conduct and link to it in the contributing guide . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"provide a checklist for pull requests is your feature request related to a problem ? please describe . to ensure our standard of creating a pull request is enforced , checklists can be used . describe the solution you ' d like implement a checklist feature for pull requests . for example , a checklist can ensure that users follow the naming conventions , tested the code , signed the contributor licenses , etc . additional context references : <url> requester info ariel adams , <allcaps> asrc </allcaps> federal",1.0
"provide a checklist for feature request template <section> to ensure our standard of creating a new issue is enforced , checklists can be used . <section> implement a checklist feature for the feature request template . for example , a checklist can ensure that users checked for similar existing requests before submitting a new issue , ensure users checked that the request is not in our <allcaps> readme </allcaps> . md under major future work , and ensure users are submitting the issue in the correct repo . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"provide a checklist for bug report template <section> to ensure our standard of creating a new issue is enforced , checklists can be used . <section> implement a checklist feature for the bug report template . for example , a checklist can ensure that users checked for similar existing issues before submitting a new issue and ensure users are submitting the issue in the correct repo . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"complete writing high quality code for contributing . md <section> provide instructions to users on how to write high quality code . <section> complete the writing high quality code section to add to the contributing guide . <section> the draft so far : # # writing high - quality code <number> . follow cfs code conventions ( formatting , symbol naming , file naming , etc ) but do *not* change / reformat existing code except to address your changes . <number> . for any new <allcaps> api </allcaps> ' s , add unit tests to cover nominal and off - nominal conditions . <number> . add / edit stubs to the unit test codebase for any new / modified functions . <number> . for any changes to existing <allcaps> api </allcaps> ' s , alter the unit tests to cover the changes ( and remove tests made irrelevant due to your changes ) . <number> . test your code , on a linux platform ( at minimum ) - - _todo : _ specific distros / versions / <allcaps> cpu </allcaps> architectures of linux ? <number> . build your code , including unit tests . _todo : _ need "" standard "" build process . <number> . run the unit tests ( all passed , yes ? ) _todo : _ need "" standard "" test procedure . <number> . run the main cfs executable ( no errors reported , yes ? ) _todo : _ need "" standard "" test procedure , including targets . cmake recommendations . <number> . ? <repeated> do we expect contributors to run coverage ? <repeated> guessing no . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"rpi3 buffer warning / make error . <code> given its just a warning i tried to suppress it with the ol ' <code> and this pops <code> trying to compile on raspberry os with a <allcaps> rpi </allcaps> 3 b works on ubuntu <number> following the same steps . any help is appreciated tried main and integration - candidate new to git sorry if i missed anything , .",3.0
some github actions workflows not running in some branches and forks <section> workflows only run in the <code> branch of a forked repo for submodules ( and maybe the bundle as well ) <section> <number> . create a new branch in nasa repo or fork <number> . push a change to the branch <number> . observe github action workflow dashboard and notice that workflows <allcaps> do not </allcaps> run for your new branch <section> workflows should run for branches in forks and in nasa repo <section> probably due to this section in our workflows <code> <section> ubuntu <number> ( github workflows runner ) <section> can be worked around by creating a pull request on your fork that targets the branch you are working on <section> full name and company / organization if applicable,0.0
"fix # <number> , create changelog github actions workflow <section> fix # <number> created a changelog github actions workflow that is triggered manually . the workflow organizes issues for each release in the sections , closed issues , breaking changes , implemented enhancements , fixed bugs , deprecated , removed , and security fixes . pull requests are not displayed . <section> when the user manually triggers the workflow , a changelog . md file is created . <section> tested on my forked repo . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"document changes across releases <section> create a changelog entry that documents noteworthy differences , often across multiple commits , and communicate them clearly to end users . <section> a github actions workflow that is triggered manually to create a changelog . md file . <section> examples : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , fix contributions spelling error in pr template <section> fix # <number> changed code contibutions to code contributions to fix the spelling error in the pr template . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix spelling error in pull_request_template . md <section> code contibutions is misspelled . <section> change code contibutions to code contributions . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for cfs under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . <section> users should now be aware of the type of testing cfs undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs is tested . by providing this information , transparency is provided to the community which promotes trust . also , when adding a new issue , there are three templates to chose from . one of the templates is report a security vulnerability . when clicking this template , it redirects the user to the security policy which states to use the bug report template . i think this is redundant and making the user do extra unnecessary steps . <section> the security policy should inform users what tools are being used to test cfs while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . for the template issue , an easy solution is to have the bug report state that this includes security vulnerabilities and get rid of the report a security vulnerability template . <section> another option is to allow the report a security vulnerability template to redirect the user to the security policy , but change the policy to say something along the lines of emailing us for security vulnerabilities . then we would have to define what is considered a security vulnerability , which i believe to be a vulnerability dealing with authorization , authentication , and encryption issues . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , create contributing . md <section> fix # <number> the contributing . md file contains a table of contents and instructions on how to report bugs , request features , view security vulnerabilities , create pull requests , participate in discussions and ask questions , and how to write high - quality code . <section> i would like to collaborate as a team on this file . please review my main concerns and questions . feedback is appreciated . code of conduct example : <url> main concerns / questions <number> . i would like to finish the section "" writing high - quality code "" . it was written by <user> and <user> . thoughts / feedback on how it should look like ? <number> . what format do we want to use for commit message convention and pr convention . there are three different formats that were used throughout our documentation . - <code> - <code> - <code> <number> . do we want to enforce a name convention for branches ? i have not seen developers using this . > create a new branch in your fork to work on your fix . please name your branch fix - issue_number - <fix_summary> . <number> . for the discussions and questions section , it would be great to explore how cfs can allow for more discussions from the community . some ideas include using gitter . im , discourse , or a discussions template to submit in the issues along with an appropriate label . thoughts / feedback ? <number> . i would also like to work together to create a code of conduct before publishing this document . thoughts on what it should look like ? <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"create contributing . md <section> create a contributing . md file so users know how to engage with cfs . <section> include instructions on how to report bugs , request a feature , participate in discussions , create pull requests , and view security vulnerabilities . <section> i would like to create a code of conduct for this file . i would also like to explore how cfs could allow more discussions from the community such as using gitter . im , discourse , or a discussions template to use in issues . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"question : getting cfs to communicate with ground station running on different host hey , so this may have a simple solution , but i am new to cfs and i am trying to figure out how to get a ground station running on a vm to communicate with a cfs instance running on a raspberry pi to communicate . i can see the packets being received by the cfs instance but it does not send any data . there are no firewalls blocking anything . i am also running the sample makefile and sample_defs . i know i need to modify the ci_lab and to_lab files , but i am not sure what to modify . ryan",3.0
"solved question : how do i ensure that the ground system sends a command with the correct secondary header ? i have copied my first test app from the sample app in the bundle . i have now been able to add my commands , but <code> always returns <code> because <code> . for the sample app commands , <code> , but of course those commands were already pickled , so i do not know where the problem lies . does the ground station or the <code> script add the headers automatically ? how is this worked out ? i have been just adding three <code> s to my command .",3.0
"add realistic timeouts to workflows <section> workflows could run up to the default <number> minutes <section> add realistic timeouts , avoids delayed reports when there really is an issue ( test hang , etc ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"apply codeql to every branch <section> codeql only scans the main branch on push and pull - request . <section> scan every branch on push and pull - request using codeql . <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"remove "" debug "" build in codeql workflow from comment in # <number> > release test would be sufficient in my mind . <repeated> always with omit_deprecated > _originally posted by <user> in <url>",2.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
documentation has not been pushed since transition to github actions <section> see <url> links are <number> months old <section> publish the guides from github action ( add to the build ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"fork - originated pull requests not running github actions workflows <section> the current setup for the workflow runs on <code> instead of <code> events so the tests are not running on pull requests from forks . <section> create a pull request from a fork . see "" checks "" section for that pull request . you will notice that the "" build and test "" workflows are not activated . <section> "" build and test "" workflows are activated on pull requests and changes to them . <section> if applicable , add references to the software . <section> add any other context about the problem here .",0.0
"main user guide build warnings ( and they were not caught by actions ) <section> warnings generated when building user ' s guide <section> i did standard setup , and <code> but likely exists for any config . then <code> , observe warnings in build / doc / warnings . log : <code> <section> no warnings . also the new github actions should have caught this . <user> note the warnings file at <url> is not empty . <repeated> not clear why this did not trigger a failure . <section> none yet . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
missing cppcheck in github actions workflow <section> cppcheck test is no longer checked in continuous integration after migrating from travisci <section> a step that runs cpp check before compiling <section> none,0.0
"why i could not update cfs dear , i clone the repository using git clone , cd to the directory then git submodule init , but when update it , it could not get the cfe , is there any wrong ? thanks i can update the cfe repository . sincerely",3.0
"fix # <number> , create security policy markdown <section> fix # <number> created a draft of a security policy markdown file . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add a github actions workflow to replace travis ci <section> travis ci billing change is hindering our continuous integration flows <section> a service that does not limit our runs <section> running all tests locally , paying for travis or another service <section> none",2.0
"can not run unit tests <section> i can build and run the application , but when i try to run unit tests i am told "" no tests were found "" . probably i am not following instructions properly , some parts seem a little vague to me . <section> after setup , i followed the instructions in "" build and run "" which were make <allcaps> simulation </allcaps> = native prep make make install cd build / exe / cpu1 / . / core - cpu1 and i got results that looked reasonable . the instructions then said "" unit tests can be added with enable_unit_tests = true , run with make test , and coverage reported with make lcov . "" so , i tried "" make <allcaps> simulation </allcaps> = native enable_unit_tests = true prep "" followed by make make test and also just "" make enable_unit_tests = true prep "" followed by make make test i guess the instructions are not clear to me . ( i tried another few combinations , too , but these seemed the most reasonable ) . <section> a clear and concise description of what you expected to happen . <section> if applicable , add references to the software . <section> - hardware - os : [ e . g . linux <number> ] - versions [ e . g . cfe <number> , <allcaps> osal </allcaps> <number> , <allcaps> psp </allcaps> <number> for mcp750 , any related apps ] <section> add any other context about the problem here . <section> full name and company / organization if applicable",3.0
"help : could not load cfe application file hi , i am working on an app that uses a library for an <allcaps> imu </allcaps> . my app compiles without errors but when i run the core - cpu1 , i get : <code> my app directory is called imu and it contains : / imu - - - fsw ( which contains the usual mission_inc , platofrm_inc . <repeated> etc ) - - - imu_lib - - - - - - build - - - - - - - - - obj - - - - - - - - - - - - vn ( which includes a bunch of . o files ) - - - - - - - - - libvnc . a ( contains the . o files ) - - - - - - include - - - - - - - - - vn ( which includes a bunch of . h files ) - - - cmakelists . txt here is the cmakelists . txt <code> any help is appreciated . thanks",3.0
"sample "" real - life "" implementation of a cfs mission build . <section> from the cfs mailing list : > it would be nice to see a fully completed project to decipher why certain features are used . the how is easy to digest from the documentation but a real - world example would help clarify each feature ’ s intended purpose . > > i know a lot of this code may be internal to <allcaps> nasa </allcaps> / other organizations but it would be really helpful to have a completed demo to reference from time to time . <section> a how - to guide or a complete docker image with a mission - like cfs implementation . <section> the current bundle , partnering with open - sat kit <section> also from the mailing list > i have also been pulling apart the training vm provided by the cfs - <number> repo . it would be incredibly helpful if anyone had any open source projects that i could see , it just always seems that looking through an already completed project is the best way to learn new things and their intricacies . <section> <user>",1.0
"minor spelling edits to <allcaps> readme </allcaps> . md <section> minor spelling edits to <allcaps> readme </allcaps> . md <section> no impact to behavior <section> full name and company / organization / center of all contributors ( "" personal "" if individual work ) kolby heacock ( personal contribution )",1.0
"travis is truncating logs again ( repeat of # <number> ) <section> # <number> repeat . <repeated> the full log does not always get retained for review . <section> observe a travis log . <repeated> for example <url> <section> should not trucate <section> previously was "" resolved "" by adding : <url> <section> - travis - ci . com <section> # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"run - time error on the docker container built with s390x / ubuntu hi , i have built cfs v6 . <number> on my host computer with ubuntu18 . <number> and was able to run it communicating with cosmos . also i was able to build a docker container for cfs v6 . <number> with s390x / ubuntu ( <allcaps> ibm </allcaps> zseries based linux , big endian <allcaps> cpu </allcaps> ) , but i have an error when i build cfs in the docker container and run it . root <user> : ~ / cfs / build / exe / cpu1 # . / core - cpu1 cfe_psp : default reset subtype = <number> cfe_psp : default <allcaps> cpu id </allcaps> = <number> cfe_psp : default spacecraft id = <number> cfe_psp : default <allcaps> cpu </allcaps> name : cpu1 os_posix_tablemutex_init ( <sad> <number> : error : pthread_mutex_init failed : operation not supported os_api_init ( <sad> <number> : os_api_impl_init ( 0x 1 ) failed to initialize : - <number> os_api_init ( <sad> <number> : warning : microsecs per sec value of <number> does not equal <number> ( microsecpertick : <number> tickspersecond : <number> ) cfe_psp : os_api_init ( ) failure aborted ( core dumped ) the error occurs in osal / src / os / posix / src / os - impl - common . c . <allcaps> osal </allcaps> : development build : <number> . <number> + dev247 but if i build the docker container by changing to i686 / ubuntu or i386 / ubuntu ( little endian <allcaps> cpu </allcaps> ) in the same dockerfile , i have no run - time errors and can run cfs with problems . i wonder if anyone had the same problem with s390x and found a way to fix this error . if you know another big endian <allcaps> cpu </allcaps> that i can build a docker container with , please let me know . thank you ! harry kim",0.0
"add information about planned component versions to caelum roadmap <section> the caelum plan does not have information on the component version targetted for inclusion in that release <section> add a list of planned component versions for caleum to the readme . for example <code> <section> have a separate file , roadmap . md , that details the plans <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"reflect ci status in different badges on the readme . <section> the current ci compiles the code , runs unit tests , builds the documentation and executes cfs all in one script . if the script fails at the documentation build the only way to figure out why it fails is to go into the travis dashboard and read through the log which takes time and is not transparent to our users . <section> have at - a - glance information that reflects what specific part of ci failed . <section> none <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"question : do you notify contributors when their contribution first takes flight ? i am thinking of finding something simple to fix for fun , and this would be a huge motivation 😄",3.0
attitude control i am looking for the attitude control system or gn & c . is there any documentation that can point me to where the code is ?,3.0
"document branch / tag / release strategy <section> community not clear on how to get what they want ( latest development version , latest official release , latest release candidate , etc ) . <section> document the current process . especially critical based on new bundle branches that may be showing up soon to track latest named release versions . <section> none . <section> frequent topic on community email list . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"how can i include a prebuilt library as a <allcaps> cfs </allcaps> library ? hi , i would like to include the cubesat space protocol library <url> as a library in <allcaps> cfs </allcaps> . i am new to <allcaps> cfs </allcaps> so i am unsure the correct way to approach this . my goal is to use the <allcaps> csp </allcaps> functionality within the ci / to applications in order to send to / receive from <allcaps> can </allcaps> . i would like to use the waf build system included with <allcaps> csp </allcaps> to build the library , then link the output library to <allcaps> cfs </allcaps> so the ci / to apps can use the <allcaps> csp </allcaps> functionality by including the appropriate headers . as a prereq i have added the libcsp repo to <code> . it is my understanding that adding libcsp to my <code> <code> is not ideal , because that would attempt to build the libcsp code ; however , in this case it would have already been built using the waf build system . i have tried the following : <number> . building libcsp as a shared library using the waf build system <number> . adding an include directive for the <allcaps> csp </allcaps> headers in the to application <number> . adding <code> in <code> <number> . copying the waf - built <code> to the target install directory <code> <number> . adding <code> to my target startup script as a result , the library fails to load at startup . i also tried : <number> . building libcsp as a shared library using the waf build system <number> . adding an include directive for the <allcaps> csp </allcaps> headers in the to application <number> . adding <code> in <code> <number> . adding <code> to <code> before the final executable is installed as a result , the to application fails to load . any help would be appreciated . i am unsure of the feasibility of using two separate build systems to build the code for my target , although i would like to avoid having to convert the waf build script to a cmake build if possible . thanks for your help . stephen",3.0
"add issue template for questions <section> i have been advised to submit questions through the github issue system , but questions do not fit into the feature request or bug report issue template options . it would be nice if there was a third template to capture questions . <section> add a template for users to formulate questions about the software . <section> users could choose not to use any of the templates . <section> n / a <section> keegan moore / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add ut failures to ci log <section> fix # <number> failure now reported and test stops : <code> <section> ran with failure ( and without ) , see output above . <section> just reports failure in ci log <section> - ci with current bundle <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"better failure reporting for unit tests in travis ci log <section> current log is not all that useful , for example : <code> <section> exit the test and record the failure to the log <section> could do more complex storing of results , but just writing out the failure is better than nothing . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add new installation instructions to the readme the following additions were made to improve novice user installation experience in the cfs <allcaps> readme </allcaps> . md . <section> added a brief introductory statement describing cfs to the top of the page . added prerequisite software ( make , cmake , gcc , and git ) instruction to the setup section . added a statement specifying a possible third dependency , libcanberra - gtk - module , for the groundsystem under the send commands receive telemetry section . additionally , some typos were corrected . resolves : # <number> <section> jandlyn bentley , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"add new installation instructions to the <allcaps> readme </allcaps> . md <section> several user experience improvements can be made to the general cfs <allcaps> readme </allcaps> . md to help brand new cfs users ( like interns who have never encountered cfs before ) through the installation process . <section> <number> . add in a brief introductory statement at the very top explaining what cfs is . <number> . under the "" setup and build and run "" sections add a list of prerequisite software that should be preinstalled before cloning cfs ( i . e . make , cmake , gcc , and git ) . <number> . under the "" send commands , receive telemetry section "" add in the specific installation commands for pyqt5 , zmq , and libcanberra - gtk - module from the ground system ' s readme ( i and some of my fellow interns ran into issues with installation because cfs was very picky in how these three were installed ) . <section> submitted by : jandlyn bentley , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"no tests were found <section> <code> on a freshly cloned repository does not find any tests . <section> steps to reproduce the behavior : <number> . <code> <number> . <code> <number> . <code> <number> . <code> <number> . <code> <number> . <code> <number> . <code> <number> . <code> <section> <code> <section> tests run and pass . <section> virtualbox <number> running linux mint <number> , kernel : linux <number> . <number> - <number> - generic , architecture : x86 - <number>",3.0
"where is the "" main loop "" in cfs ? hello everyone , i am trying to calculate the loop time for cfs for future debugging purposes . if anyone could let me know where the main loop for cfs exists , i would appreciate it ! thank you , evan fitzgerald",3.0
ci - add test build / run with elevated privileges <section> ci only builds / runs with user privileges <section> add an elevated privileges build / run <section> none . <section> see # <number> for additional update request <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"publish html version of users guide and leverage github pages <section> the current deploy of the documentation is a pdf that while useful , could be better implemented as a webpage which doxygen already generates . <section> leverage github pages to host a "" live "" version of the users guide . <section> figure out how to get doxygen to generate markdown instead of html and use jekyll or another static site generator <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",1.0
"either fm unit testing is incorrect or an <allcaps> osal </allcaps> enumeration is incorrect <section> i do not know if this an fm bug or an <allcaps> osal </allcaps> bug . i do not know what the intent on either side was . fm is failing unit tests . the first error indicates before <allcaps> osal </allcaps> <number> . <number> - bv , fm determined if a directory entry was a directory by using the s_ifdir macro directly , but had an <hashtag> if def </hashtag> that allowed it to use an <allcaps> osal </allcaps> defined macro instead . <code> with <allcaps> osal </allcaps> <number> . <number> - bv , the os_filestat_isdir macro is defined and fm is using the os_filestat_isdir macro . the unit test sets the filestatus . filemodebits to <number> ( 0x 4 0 0 0 ) , but the os_filestat_isdir tests equality against os_filestat_mode_dir ( 0x 1 0 0 0 0 ) so the unit tests fail . i do not know if the <allcaps> osal </allcaps> developer intended to use the value expected by fm ( 0x 4 0 0 0 ) , or if the fm should be : from : <code> to : <code> making the change above fixes these errors , but so does changing the enumeration from : os_filestat_mode_dir = 0x 1 0 0 0 0 to os_filestat_mode_dir = 0x 4 0 0 0 <section> steps to reproduce the behavior : <number> . build fm unit tests with the ut_assert , hooks , and stubs from cfe <number> . 0 a <number> . run fm unit tests <section> fm unit tests should pass . <section> - virtualbox - ubuntu <number> - fm <number> . <number> , <allcaps> osal </allcaps> <number> . <number> - bv , app ut_assert , hooks , and stubs from cfe <number> . 0 a <section> mathew benson windhover labs , <allcaps> llc </allcaps> <email>",0.0
"update pyqt4 to pyqt5 in <allcaps> readme </allcaps> <section> updates documentation to match implementation <section> n / a <section> docs - only change <section> web browser <section> none <section> none <section> evan fitzgerald , canadian space agency - note clas <allcaps> only </allcaps> apply to software contributions .",1.0
"fix # <number> , add a reference to skeleton_app in <allcaps> readme </allcaps> . md <section> added a reference to the skeleton_app ( <url> in the cfs bundle ' s <allcaps> readme </allcaps> . md . in this reference i provided a short description of the skeleton app with a link to its repository . this reference was placed under the "" other cfs related elements / tools / apps / distributions "" section , under the "" other apps "" category . resolves : # <number> <section> n / a <section> n / a <section> n / a <section> this is a simple documentation enhancement . <section> n / a <section> contribution by : jandlyn bentley , <allcaps> nasa gsfc </allcaps>",1.0
"fix # <number> , added the references ( links ) to the cfe and <allcaps> osal </allcaps> user guides from the … <section> added the cfe and <allcaps> osal </allcaps> user guides ' references ( links ) from the gh - pages branch to the cfs bundle <allcaps> readme </allcaps> . md . resolves : # <number> <section> contributed by jandlyn bentley , <allcaps> nasa gsfc </allcaps>",1.0
"boolean type not defined ? i am new to cfs and trying to slowly add the applications i will need for my mission . i am trying to add the to , <allcaps> sch </allcaps> , and hk apps but keep running into the same problem . it appears that in many app codes such as sch_msg . h , sch_app . h , etc . there is use of ' boolean ' . it does not appear that the boolean type has been defined anywhere in the cfs code . am i missing something or does it have to be manually added in ? <section> - vm running ubuntu <number> . <number> 6 4 bit - versions running all the current versions of cfs bundle , cfs apps , and cfe / osal / psp paula",3.0
ci - build multiple targets <section> the build process becomes increasingly more complex when building for multiple targets . ci should build for at least two targets to ensure that the build system is functioning properly . <section> have ci create relevant build configuration to build for multiple targets . <section> <email>,2.0
"fix # <number> - update lgtm . yml to exclude ui files <section> fixes # <number> to exclude files in cfs - groundsystem with the <code> prefix <section> steps taken to test the contribution : pending lgtm run <section> lgtm analysis should not include <code> files <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> leor bleier , <allcaps> nasa gsfc </allcaps> \ code <number>",2.0
"small hiccup when installing the cfs bundle in following the steps laid out in the cfs bundle ' s readme , everything up through the "" build and run "" section worked fine . however , there was a small hiccup that occurred in the "" send commands , receive telemetry "" section after installing pyqt5 ( instead of the prescribed pyqt4 ) and pyzmq . i changed directory back to the main cfs location , and tried to follow the next insruction : cd tools / cfs - groundsystem / subsystems / cmdutil , but i got this error message : no such file or directory . i tried installing cmdutils via pip3 , then re - tried the cd tools / cfs - groundsystem / subsystems / cmdutil command again and still the same error occurred . skipping to the next line : python3 groundsystem . py was unsurprisingly met with : pythons3 : can ’ t open file ‘ groundsystem . py ’ : [ errno <number> ] no such file or directory . i tried closing out the terminal and opening a new one , and re - tried cd tools / cfs - groundsystem / subsystems / cmdutil , but still no luck . later after trying a new terminal again , i thought maybe pyqt5 instead of pyqt4 was a problem ( but nothing changed ) . and finally , trying a new terminal window one last time , i was able to get cd tools / cfs - groundsystem / subsystems / cmdutil and all of the subsequent commands to work , and launch the ground system gui . i am not sure why , after changing nothing from the last attempt , it would work this time . this was attempted on a linux vm with ubuntu <number> .",3.0
"fix # <number> , only inline empty functions <section> fix # <number> <section> ran against related repos , confirmed style update . <section> none - whitespace <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : master bundle + this commit . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"code style update - only inline empty functions <section> complaints about single line functions being inline <section> do not . <section> ignore complaints . <section> none , whitespace . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> , per <url>",2.0
create directory structure for pushing <allcaps> ctf </allcaps> scripts <section> need to create a location to push <allcaps> ctf </allcaps> scripts and plugins to . <section> dan knutsen <allcaps> nasa </allcaps> goddard,2.0
"fix # <number> , add <allcaps> git sha </allcaps> <section> adds <allcaps> git sha </allcaps> ' s to travis log . <section> checked the travis log for this branch . <section> <email>",2.0
"report submodule <allcaps> sha </allcaps> in travis job log <section> it would be helpful to know exactly what versions of everything travis is doing a ci against . <section> adding "" git submodule "" and "" git rev - parse <allcaps> head </allcaps> "" to the travis script . <section> <email>",2.0
"consider using "" <allcaps> reuse </allcaps> "" for license / copyright banner management currently copyright headers and the like are all over the map , this software would help automatically check that all of our copyright and license information is correct in every file in the cfs tree . see : <url> <section> <email>",2.0
"fix # <number> , add sleep after script to avoid truncated log <section> added after_script sleep to ci fix # <number> <section> ci - see <url> <section> full job log now available on travis <section> - hardware : ci - os : ubuntu <number> - versions : master bundle + this commit <section> none <section> the cfs repository is provided to bundle the cfs framework . it is utilized for bundling submodules , continuous integration testing , and version management and does not contain any software . code contributions should be directed to the appropriate submodule . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"travis truncating job logs <section> likely related to <url> and similar reports the job log output gets truncated , often around the final documentation warning checks <section> see build logs , for example <url> <section> full log should be shown to debug errors <section> n / a <section> ci <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"cfs header definition version <number> ci <section> certification configuration is <allcaps> ccsds </allcaps> extended header , 3 2 bit . default config is currently <allcaps> ccsds </allcaps> primary only , <number> bit . <section> ci with cfs header definition v2 , and any other minor tweaks for cert config . <section> leaning towards adding a v2 config that maps to the cert configuration to ci will not be the full ci until related issues get resolved . <section> will need to resolve any related v2 issues ( cmdutil does not support it , etc ) , issues in implicit packet padding differences , etc . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , <allcaps> lgtm </allcaps> build now omits deprecated code <section> added omit_deprecated = true to <allcaps> lgtm </allcaps> script fix # <number> <section> ci <section> should clear up some errors related to shell , decompress , etc . <section> - ci <section> built on latest ic <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
update <allcaps> lgtm </allcaps> build to omit_deprecated <section> deprecated elements included in analysis <section> remove deprecated elements from analysis <section> none . <section> will address some of the open <allcaps> lgtm </allcaps> issues . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"gui / menu / wizard configuration <section> for noobs , it can be daunting to configure a cfs environment , or to find "" that one parameter that changes the size of the pipe tables "" , for example . <section> it would be nice to have a configuration . <repeated> generator ? . <repeated> that a user could use to quickly run through the configuration options ( conditional code options , platform selection , sizing options ) and generates the appropriate cmake files , . h files , startup scripts , etc . <section> menuconfig / kconfig ( <url> is a popular option and provides a menu - based configuration system . alternatively , a "" wizard "" style configuration ( like perl ' s configure script ) that steps through all of the configuration options , asking questions and providing default answers . whatever option is chosen , it should *not* replace the existing build process but should be a front - end to it , and provide human - readable / editable files as output that are equivalent to the current files . <section> <email>",2.0
"add pc - linux toolchain "" cross - compile "" to ci <section> current ci uses <allcaps> simulation </allcaps> = native for all builds <section> add one non - simulation build , consider matrix model as used in osal <section> none <section> nasa / cfe # <number> - failure that wasn ' t caught <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add reference to skeleton_app in <allcaps> readme </allcaps> <section> skeleton app added , missing reference in readme <section> add reference <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"document deprecation process <section> process not documented <section> document process and reference . - issue requesting deprecation gets reviewed by <allcaps> ccb </allcaps> , accepted / assigned or rejected - evaluate requirements / documentation / operational impacts - pull request ( s ) wraps deprecated elements in * _omit_deprecated ifndef and removes any internal dependencies - default sample configuration does not remove this code - make omit_deprecated = true prep will compile without it to check code for compliance - ideally any deprecated elements address dependency fix ( use new element , no longer supported , etc ) - elements can be deprecated in any build / release - ci tests with and without deprecated elements removed to ensure no internal dependencies - issue requesting removal of deprecated code - pull request removes deprecated elements - typically done end of cycle prior to a major release <section> wing it . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
reference autogenerated docs <section> see # <number> no current references to the generated documents <section> once the docs are deployed the first time ( after push of # <number> to master and ci completes ) add references from at least <allcaps> readme </allcaps> . md . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update ci for deploy docs , warnings , and simplify <section> fix # <number> , deploy documentation fix # <number> , config warnings except for the new ones introduced by using the latest deployment version fix # <number> , removes permissive mode hack and updates <allcaps> readme </allcaps> . md adds enforce of no doxygen warnings for osal and users guide <section> steps taken to test the contribution : <number> . ci test <section> old ci script warnings resolved ( <number> remain based on using development version ) now enforces no doxygen warnings for user guides will deploy documentation to gh_pages branch on push to master <section> - ci system <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix travis - ci config warnings <section> build config validation ( from travis - ci ) - root : deprecated key sudo ( the key <code> has no effect anymore . ) language : unexpected sequence , using the first value ( c ) root : missing os , using the default linux env : key matrix is an alias for jobs , using jobs <section> see <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"exclude lgtm false positives <section> sample_lib triggers a lgtm error based on checking strncpy return ( false alarm ) <section> exclude string - copy - return - value - as - boolean ( triggered by sample_lib , which is doing this on purpose ) <section> could clutter code to exclude this specific call from triggering the warning . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add positive check to cfs execution in ci <section> ci in # <number> only checks for warn / err / fail in cfs output <section> enforce the existence of the following message : "" cfe_es_main entering <allcaps> operational </allcaps> state "" <section> any other positive check would work , above was the simplest i could think of . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update lgtm to include python <section> update lgtm . yml file to include python <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"cfe_time_gettime ( ) information seems incorrect ? a question related to the use of the time service provided by cfe . i am trying to get time information using the <allcaps> api </allcaps> provided by cfe as follows : <code> and i print it as follows : <code> but the printed year and time information seems to be incorrect . it indicates some value in <number> as : <code> . also , when i launch cfe ( core - cpu1 ) , i see the following output which indicates the time starting in <number> and then changing to some value in <number> . <code> could someone please explain how i could obtain the correct current time information using the cfe apis without having to resort to using functions in time . h ? thanks !",3.0
"add a mechanism to push app configurations to the mission definitions folder . after working with some of the pre - made utility apps provided by the <allcaps> cfe </allcaps> , i have noticed that at some point ( relatively early ) developers must abandon reuse in favor of clone / own which , in my opinion , is partly due to the <allcaps> cfs </allcaps> cmake build system not providing a clean method to push build configurations into the top level definitions folder . an example of an app that could benefit from additional configuration would be the ci and to lab apps . the current implementation of these apps use a hard coded port value for <allcaps> udp </allcaps> communication with only a means to change the ip listened to via a command in to lab . my solution would most likely take the form of changing . <repeated> <code> to . <repeated> <code> and having a <code> located within the missions definitions directory that contains the definition from a cmake instruction . <repeated> <code> it would be nice for the cmake build system to provide the ability to have a companion configuration folder for each app in the definitions folder . this folder could contain headers and additional . cmake files used to specify certain details about the app being built . it ' s currently possible to hijack the behavior of the <code> file and add additional instructions like <code> to inject files into the app before it attempts to build but this would clobber the files currently present in the app directory .",2.0
update <allcaps> readme </allcaps> and ci based on permissive update <section> will need to update process when <url> gets merged . this issue is to track getting the related cfs repo work done . <section> update based on new process <section> none . <section> also update # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update cfs - groundsystem instructions in <allcaps> readme </allcaps> <section> send commands , receive telemetry section is out of date in <allcaps> readme </allcaps> for python3 <section> update instructions or link to submodule instructions ? <section> n / a <section> see also <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , improve ci testing <section> fixes # <number> <section> see ci results <section> better ci testing coverage <section> ci <section> jobs will fail until issues are resolved . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"improve travis ci testing <section> travis ci currently just does cppcheck and default build on the bundle <section> parallel test the following : - <allcaps> buildtype </allcaps> = release omit_deprecated = true strict_no_warnings = true - <allcaps> buildtype </allcaps> = release omit_deprecated = false ( default ) strict_no_warnings = true - <allcaps> buildtype </allcaps> = debug ( default ) omit_deprecated = true strict_no_warnings = true - <allcaps> buildtype </allcaps> = debug ( default ) omit_deprecated = false ( default ) strict_no_warnings = true and do the following tests : - add document generation ( eventually enforce no warnings ) - make doc - make usersguide - make osalguide ( dependent on <url> - build with enable_unit_tests = <allcaps> true simulation </allcaps> = native - run unit tests ( eventually enforce coverage ) - execute cfe and pipe output to file - send reset cmd from cmdutil - confirm execution output lacks error / warning / fail messages <section> none <section> eventually add nightly or triggered local builds for other environments ( pc - <allcaps> rtems </allcaps> , vxworks on a modern platform ) eventually add automated build verification ( trade ci vs local ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add style configuration <section> fixes # <number> <section> see as applied in <url> enforced in <url> <section> - no impact to software behavior - allows for application and enforcement of standard style <section> - cfs dev server <number> - os : ubuntu <number> ( with clang - format - <number> installed ) - versions : see related pull requests in ci_lab <url> <url> <section> to use , requires installation of clang - format - <number> ( minimum version needed for define alignment ) see . travis . yml in ci_lab pull request <url> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add lgtm badge to readme <section> add lgtm badge to readme <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
"adding . lgtm . yml file <section> add lgtm . yml file . <section> anh van , <allcaps> nasa </allcaps> goddard",2.0
automate a deployment of docs to github pages having to build and open the documentation locally adds an extra step that could be mitigated by pushing the documentation of the current master commit to github pages . the process of uploading to github pages is documented here <url>,2.0
update release document links in <allcaps> readme </allcaps> . md <section> all references in <code> are broken . <section> fix links - relate to <number> release when available . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> email from <user>,2.0
cfe_es_gettaskinfo : task id not valid : <number> i get the following message when i try to publish a message on the software bus from within a call back function that is called by a timer . cfe_es_gettaskinfo : task id not valid : <number> steps to reproduce the behavior : sample_app . txt <url> - download the attached sample_app . txt - rename . txt to . c - replace apps / sample_app / fsw / src / sample_app . c with the renamed sample_app . c file - compile and run core - cpu1 . <section> please note that the time call back function in the attached sample_app is at the very end of the file . the timer is initialized within the app ' s initialization function . <section> - x86_64 - os : [ e . g . linux <number> ] - versions [ cfs repository at commit hash : 0 4 4 4 7 6 b ( current master branch as on <number> / <number> ) ] <section> <allcaps> nasa </allcaps> langley / <allcaps> nia </allcaps> any thoughts on how to resolve this is greatly appreciated .,3.0
add preferred style configuration <section> inconsistent style used throughout cfs <section> automated way to apply style that can be enforced by ci if desired <section> none <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"syntax for table dump command when attempting to dump a table the format for the python groundsystem is unclear . image <img> my attempt syntax is as follows . it appears to concatenate the table and the table file name , making it hard to discern any proper convention for the arguments of the command . image <img>",3.0
"syntax issue for groundsystem python table validate command i am trying to get the syntax right for the validation command . i have been running gdb to look at the contents of the message . all i get is a cryptic invalid msg length error . with the following from the cfs - groundsystem / guid , instructions , i know i am not interpreting it right . image <img> image <img> image <img> _originally posted by <user> in <url>",3.0
"add automated revision increment on merge to master <section> from <allcaps> ccb </allcaps> discussions , should increment master revision on merges ( except on * _version . h file ) <section> automate via github actions , template started on branch in ci_lab that triggers - still need to do update ( via script , something like attached ) - still need to figure out how to commit ( some key ? ) - may need to be done remotely , triggered by github and use a key to check back in <section> update by hand ( error prone ) <section> na <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"table load failures my app , named cnt_app starts running and while there are tables in the app , it appears that cfe_tbl attempts to load those tables and fails , causing cnt_app to error out . is there a missing step that i need to perform ( load tables ? ) or is this indicative of a bug or misconfiguration ? image <img>",3.0
contributor license agreement template <section> unable to quickly find the contributor license agreement ( <allcaps> cla </allcaps> ) . recommend adding to <allcaps> readme </allcaps> of each repository . <section> john p . lucas - <allcaps> nasa gsfc </allcaps>,2.0
"improve version control , reporting , and integrity support to enhance security <section> elements could be modified between original generation and use without easily being noticed . a holistic design approach to version control , reporting , integrity should be considered to support the various use cases . currently state : <number> . repo information ( git describe in a subset of repos ) is gathered during build and reported on execution for top branch , cfe and <allcaps> osal </allcaps> - need to expand this to include all the elements ( apps , libs , psp , etc ) <number> . build information is gathered during build and reported on execution - user name and date for last full build covering cfe ( does not cover uploaded apps or elements built separately / after the original full build ) <number> . version information updated by hand and reported at execution time for most of cfs - elf2cfetbl and tblcrctool do not report version information , has not been consistently updated <number> . checksums are typically just calculated and reported at load / execution , does not cover libs , really should employ digital signatures that can be verified <section> see above suggestions <section> none , but should discuss with security experts and come up with a complete , well vetted solution . <section> likely very beneficial to community requiring a more robust security approach <section> jacob hageman / <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"use appid with perfid for apps <section> currently apps define their perfid when using the performance logging framework , but there ' s no mechanism currently to ensure that the perfid is unique to that application and could result in confused perf logs . <section> one option would be to use the appid generated when the application is registered ( but will need to be reported somehow so that a performance analysis tool can crosswalk from runtime - generated perfid ' s to the applications . ) <section> three alternatives : <number> ) a separate perfid registry / table in memory , <number> ) some sort of compile - time tool to generate id ' s , <number> ) a textual identifier ( that can be "" namespaced "" . ) <section> discussed at <allcaps> ccb </allcaps> <number> - <number> - <number> <section> chris knight , <email> , <allcaps> nasa </allcaps> ames research center",2.0
"remove gen_sch_tbl submodule from framework this tool is specifically for the <allcaps> gsfc </allcaps> scheduler ( a <allcaps> gsfc </allcaps> app ) , and is maintained by <allcaps> gsfc </allcaps> not the cfs framework community .",2.0
"examples for application testing since the release of cfe <number> , there has not been apps that give an example of the way tests should be defined in the cmakelists file . previously , when utassert was part of the tools directory rather than being part of the <allcaps> osal </allcaps> , this definition would exist inside of the fsw / for_build / makefile but this does not cleanly translate to cfe <number> ' s cmake build system . the arch_build . cmake file located in the cmake directory seems to have a function add_unit_test_exe <url> but i could not get this to work when calling it from the simple app ' s cmakelist . txt . an explanation of what needs to be done in either the target . cmake or cmakelists file for an app or an example of an app using ut for it ' s testing would be appreciated .",2.0
"suggestion : documentation rework i have started working on markdown - izing documentation on my fork of this repository so it ' s easier to navigate via github ' s interface . i plan to convert all plain - text , <allcaps> pdf </allcaps> , and word documents to markdown , but leave doxygen docs intact since they are generated ( however , on that subject , on the <allcaps> cactus </allcaps> fork of cfe <url> . i can open a pr here once the conversion is complete if the cfe team would like to integrate that change in the main repo .",1.0
"use generated stubs hk unit testing currently uses a set of stubs for its internal units that are not generated by the tool <section> use the generated stubs directly whenever possible , as this makes future maintenance easier - when an <allcaps> api </allcaps> changes , just re - run the generator tool to update the stubs . <section> this requires some additional separation of items - global variable stubs should be in a separate compilation unit , as the tool does not generate these . <section> joseph hickey , vantage systems , inc .",2.0
"uninitialized variable in unit tests compiling the latest hk app with the latest <allcaps> gcc </allcaps> version ( <number> . x) produces a warning about uninitialized variable in the unit test : <code> <section> add hk to latest <allcaps> cfs </allcaps> bundle , build using default config . <section> should build cleanly <section> debian ( latest version , with <allcaps> gcc </allcaps> <number> ) <section> joseph hickey , vantage systems , inc .",0.0
simplify hk_sendcombinedhkcmd and remove stray printfs unnecessary variable : <url> stray printfs ( leftover debugging ? <sad> <url> <url> <section> clean / remove . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old hk clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template . md and contributing . md - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset use for addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
static analysis workflow style warnings style warnings in strict cppcheck static analysis workflow causing workflow failure : <code> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
hk count track times packet is not found in file hk_utils . c function hk_sendcombinedhkpacket recommendation : hk app hk packet could keep track of number of times packet is not found . hk_appdata . missingdatactr could be repurposed for this . finding from code review imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"mempoolhandle should be of type cfe_es_memhandle_t , not uint32 see <url> this causes hk to exit while running on a <number> bit platform , as an 8 byte pointer is written to this and overwrites the adjacent runstatus field .",0.0
registration of events with 0x0 0 0 0 filters is not all that helpful <section> registration of all events with <code> filters just loads the system without actually filtering anything . also fills the event filter buffer for the app and likely drops some since default limit is <number> . <section> remove zero entries from initialization and add a filter when / if needed ( or operationally via command ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"overrun warning false alarms in to_lab_app . c <section> out - of - bounds access ( <allcaps> overrun </allcaps> ) in to_lab_app . c <section> fix overruns <section> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 2 0 ul . <url> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 8 0 ul . <url> overrunning array pipename of <number> bytes by passing it to a function which accesses it at byte offset <number> . <url> overrunning array totlmpipename of <number> bytes by passing it to a function which accesses it at byte offset <number> . <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"update cfe_msg_message_t conversions to use cfe_msg_ptr macro <section> in nasa / cfe # <number> introduces a <code> macro which converts a cmd / tlm header object to a <code> pointer , which is intended to be used rather than assuming a specific member name ( e . g . <code> ) . <section> use the macro instead of assuming <code> member name . <section> required when using generated headers , as the member name may not be "" msg "" or may be further encapsulated . <section> joseph hickey , vantage systems , inc .",2.0
"improve consistency in application of cfe_sb_msgidtovalue / valuetomsgid conversions <section> a <code> value , like other ids , is supposed to be a unique type / opaque value that identifies a message within the sb application context . although it is currently implemented using an integer ( <code> specifically ) application should not assume this . instead , a set of macros and inline conversion functions ( cfe_sb_msgidtovalue and cfe_sb_valuetomsgid ) are provided for when the application needs to interpret the value as an integer for a valid purpose . <section> add conversions where they are currently missing <section> see nasa / cfe # <number> for full info . a separate issue + pr will be submitted for each framework app . <section> joseph hickey , vantage systems , inc .",2.0
"remove references to cfe_es_registerapp <section> as part of nasa / osal # <number> and nasa / cfe # <number> the registration apis are getting fully deprecated and removed . applications no longer need to call os_taskregister , cfe_es_registerapp , or cfe_es_registerchildtask . <section> remove references to these functions . <section> will be required with nasa / osal # <number> and nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the to_lab repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the to_lab repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"applications should use all - inclusive "" cfe . h "" header <section> the <allcaps> cfe </allcaps> documentation recommends that applications use the supplied <code> header which in turn provides all <allcaps> cfe </allcaps> core , <allcaps> psp </allcaps> , and <allcaps> osal </allcaps> apis as well as mission config . because some header names are getting changed in nasa / cfe # <number> , including the headers individually becomes a problem . <section> change to using the <code> all - inclusive header , which makes ci_lab work with the new directory structure , and should avoid future issues , and it matches what the documentation recommends . <section> change <code> - > <code> <section> needed for nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for to_lab or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing to_lab or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / to_lab is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / to_lab while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for to_lab . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
remove pktsize from add packet command <section> pktsize is unused <section> remove from command <section> none <section> observed in testing # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"mark empty slots with invalid msgid , and do not try to unsubscribe all on them <section> unsubscribe all currently loops through the entire table unsubscribing , including the <allcaps> msgid </allcaps> 0x0 ' s ( which is a valid <allcaps> msgid </allcaps> ) . this causes numerous errors : <code> <section> mark as invalid , skip invalid <section> keep a count <section> observed in fixing # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove all packet command causes to_lab to break <section> sending the to_remove_all_pkt command to to_lab causes to_lab to unsubscribe from its own message id . this means that to_lab will no longer respond to any commands and has to be restarted for it to function properly again . we ran into this problem at <allcaps> nasa </allcaps> ames and figured that it was not intended behavior . when testing for this bug be aware that it can be semi obscured by the fact that any commands for to_lab already on the software bus will still be processed by to_lab . this means that whether or not commands to to_lab sent after a to_remove_all_pkt command succeed is highly timing dependent . <section> steps to reproduce the behavior : <number> . send to_remove_pkt command to to_lab <number> . send any other command to to_lab <number> . observe that the command has no effect <section> you should not be able to send to_lab a command that puts it into a non functional state <section> / / this line in to_lab_app . c line <number> is the source of the problem status = cfe_sb_unsubscribe ( to_lab_cmd_mid , to_lab_global . cmd_pipe ) ; <section> this bug is independent of the environment cfs is run in <section> james roach - <allcaps> nasa </allcaps> research scientist <email>",0.0
"remove obsolete comments <section> end of function comments historically poorly maintained , so not really worth keeping around . name of a function in comments also frequently gets out of date . example of differences ( needs full scrub ) : <url> <url> <section> remove obsolete comments <section> none <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
apply standard naming convention ( to_lab . <repeated> ) <section> <url> <url> <url> <section> apply standard pattern ( to_lab . <repeated> ) <section> none . <section> requires update to entry point in startup script ( nasa / cfe ) <section> jacob hageman,2.0
"update for suggested alignment enforcement pattern ( nasa / cfe # <number> ) <section> see nasa / cfe # <number> , inconsistent pattern <section> match suggestion in nasa / cfe # <number> , use the "" raw "" message cmd / tlm types in definition . <section> none <section> nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove dependencies on deprecated sb apis <section> sb apis deprecated in nasa / cfe # <number> <section> update to use <allcaps> msg </allcaps> module . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"update to_lab to use osal_id_t typedef <section> to_lab is using <code> type to hold its <allcaps> osal </allcaps> socket id . <section> should use the <code> typedef instead . <section> part of ongoing effort to update all framework code to use the typedef for <allcaps> osal </allcaps> ids . <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add header guard to to_lab_sub_table . h <section> fix # <number> - add header guard to to_lab_sub_table . h <section> build and run - no issues <section> no impact to behavior , good design practice <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + this change <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
<allcaps> lgtm </allcaps> warning - no header guard in to_lab_sub_table . h <section> missing header guard in to_lab_sub_table . h <section> add header guard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix # <number> , mark end of valid msgid subscriptions <section> fix # <number> - added a to_unused entry at the end of the subscription list - added break in subscription loop when to_unused found <section> normal run , confirmed no 0x0 duplicate subscription message , confirmed nominal hk telemetry still works with groundsystem <section> no more subscriptions on the unused table slots ( no msgid <number> subscriptions ) . <section> - hardware : cfs dev <number> - os : ubuntu <number> - versions : bundle <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"subscribes to msgid 0x0 <number> - actual_msgids times <section> loops through the entire table of subscriptions and subscribes , any unset values in the table are <number> so subscribes to msgid <number> over <number> times . shows up multiple times on startup : <code> <section> any normal run . <section> only subscribe to requested message ids . <section> <url> <section> - hardware : cfs dev <number> - os : ubuntu <number> - versions : current bundle <section> likely due to subscription table conversion to a cfs table . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"add build name and build number to version . h <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"previous pr # <number> broke some platforms due to type mismatch <section> a recent change in pull request # <number> changed the <code> function prototype to return an <code> type here : <url> however the function is actually defined later here : <url> this results in error if <code> and <code> are not actually the same type . <section> build on any platform where <code> and <code> are not the same type ( e . g . <number> bit <allcaps> rtems </allcaps> , for example ) . <section> declaration should match definition , and it should build cleanly . <section> <allcaps> rtems </allcaps> <number> . <number> ( cross ) <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , make the to table a proper table <section> makes the to table ( "" to_lab_subs "" ) into a cfe_tbl - managed table . <section> built and run . <section> debian <number> <section> <email>",2.0
"fix # <number> , remove dependencies on <allcaps> ccsds </allcaps> types <section> replace references to <code> types with the <code> - provided type . fixes # <number> <section> build and sanity check <allcaps> cfe </allcaps> , run all unit tests <section> no impact to behavior <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"remove references to "" <allcaps> ccsds </allcaps> "" structures <section> applications should <allcaps> not </allcaps> refer to the "" <allcaps> ccsds </allcaps> "" data types and macros , as there should be no assumption of a particular message framing type at this level . <section> use the abstract types provided in <code> rather than directly using <code> types . <section> related to nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , apply standard code style <section> whitespace changes only . fix # <number> <section> ci - <url> <section> none <section> - hardware : ci - os : ubuntu <number> - versions : bundle w / all whitespace change commits <section> note - not enforcing , just a single cleanup since there ' s no pending activity in this repo . <allcaps> note </allcaps> - applied on top of ic . <repeated> just last commit is the subject of this change <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"hardcoded queue depth of <number> <section> to_lab creates a queue depth of <number> , which is beyond the limit of some queue implementations . <section> run to_lab on a system that does not allow a queue depth of <number> . <section> should not hard code a large queue depth that could be beyond the implementation limit . <section> <url> <section> ubuntu <number> , after enabling max depth enforcement in <allcaps> osal </allcaps> . <section> if the goal is to create a deep queue , then use os_max_queue_depth . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , deprecate shell tlm subscription <section> fix # <number> deprecates shell tlm subscription <section> just build and unit test per nasa / cfe # <number> <section> no shell output telemetry <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : see nasa / cfe # <number> <section> see nasa / cfe # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"to_lab app only receiving <allcaps> noop </allcaps> commands <section> after updating to the most recent cfs packages ( git pull ) and recursively updating the submodules , all commands from groundsystem . py to to_lab are being interpreted as <allcaps> noops </allcaps> . first saw this with requesting output enabled but then verified that all commands are being seen as <allcaps> noops </allcaps> . outputs of git pull are below capturing groundsystem . py output : host : <number> . <number> port : <number> pkt id : 0x 1 8 8 0 sending data to ' <number> . <number> ' ( ip : <number> . <number> ); port <number> data to send : 0x 1 8 0x 8 0 0 xc0 0x0 0 0x0 0 0x0 1 0x0 0 0x0 6 <allcaps> cfe </allcaps> output <allcaps> evs </allcaps> port1 <number> / <number> / cfe_time <number> : stop <allcaps> flywheel </allcaps> <allcaps> evs </allcaps> port1 <number> / <number> / to_lab_app <number> : no - op command same command with previous build yields the below and telemetry beings to flow . <allcaps> evs </allcaps> port1 <number> / <number> / cfe_time <number> : stop <allcaps> flywheel </allcaps> <allcaps> evs </allcaps> port1 <number> / <number> / to_lab_app <number> : to telemetry output enabled for ip <section> git pull to latest and run both cfe and groundsystem . py <section> expected a to_output_enable <section> allen <user> - home - lt : ~ / repos / cfs / missionxyz $ git pull remote : enumerating objects : <number> , done . remote : counting objects : <percent> ( <number> / <number> ) , done . remote : compressing objects : <percent> ( <number> / <number> ) , done . remote : total <number> ( delta <number> ) , reused <number> ( delta <number> ) , pack - reused <number> unpacking objects : <percent> ( <number> / <number> ) , done . from <url> 6 9 e18e5 . <repeated> 7 8 8 b8d6 master - > origin / master * [ new branch ] gh - pages - > origin / gh - pages * [ new branch ] integration - candidate - > origin / integration - candidate fetching submodule apps / ci_lab from <url> * [ new branch ] integration - candidate - > origin / integration - candidate 3 ad9a10 . <repeated> fe9e3ef master - > origin / master fetching submodule apps / sample_app from <url> * [ new branch ] integration - candidate - > origin / integration - candidate 1 f84f20 . <repeated> b956292 master - > origin / master fetching submodule apps / sample_lib from <url> * [ new branch ] integration - candidate - > origin / integration - candidate f499730 . <repeated> 3 3 efec3 master - > origin / master fetching submodule cfe from <url> * [ new branch ] integration - candidate - > origin / integration - candidate d6d944c . <repeated> 6 0 a5f65 master - > origin / master fetching submodule osal from <url> * [ new branch ] integration - candidate - > origin / integration - candidate 2 2 8 4 a6f . <repeated> 7 d9c4c8 master - > origin / master fetching submodule psp from <url> * [ new branch ] integration - candidate - > origin / integration - candidate 6 2 1 abba . <repeated> 1 2 e2607 master - > origin / master fetching submodule tools / cfs - groundsystem from <url> * [ new branch ] integration - candidate - > origin / integration - candidate c982339 . <repeated> 9 d4b155 master - > origin / master updating 6 9 e18e5 . <repeated> 7 8 8 b8d6 fast - forward . lgtm . yml | <number> + + + + + + + + + + + + + + + + - - - - - - - - - - - - - - - . travis . yml | <number> + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + - - - - - - - <allcaps> readme </allcaps> . md | <number> + + + + - - - - - - apps / ci_lab | <number> + - apps / sample_app | <number> + - apps / sample_lib | <number> + - cfe | <number> + - osal | <number> + - psp | <number> + - tools / cfs - groundsystem | <number> + - <number> files changed , <number> insertions ( + ) , <number> deletions ( - ) <section> - docker build - os : ubuntu <section> n / a <section> allen kummer - self",3.0
"data instantiated in to_lab_sub_table . h is a standards violation <section> headers define , c code instantiates per coding standard <section> move and change to a c file . also confuses "" table "" concept , since this is not a real table . maybe make it one ? <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , resolve doxygen warning <section> fix # <number> resolve doxygen warnings <section> steps taken to test the contribution : <number> . corrected line ( s ) that generated warnings <number> . rebuilt documentation with <code> <number> . observed no warnings generated <number> . viewed relevant page ( s ) to verify correctness <section> changes to documentation only ; no code impact <section> leor bleier , <allcaps> nasa </allcaps> \ <allcaps> gsfc </allcaps>",1.0
"app should treat cfe_sb_msgid_t values as opaque <section> for compatibility going forward , code should not assume that <code> is an integer . <section> when dealing with an integer , such as when printing in events / messages or for backward compatibility with <allcaps> mid </allcaps> <code> ' s , the code may use <code> and <code> conversion routines . <section> architecturally , the <code> is supposed to be an opaque / abstract value that identifies an endpoint on the software bus routing domain . the specific meaning of integer values is already different in an "" extended header "" ( <allcaps> ccsds </allcaps> v2 ) build vs . the standard header build . therefore apps should never make assumptions regarding the specific integer values , and all introspection of <code> values should be through the <allcaps> cfe sb api </allcaps> only . <section> joseph hickey , vantage systems , inc .",2.0
apply standard code style <section> inconstant style <section> see <url> and <url> <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
update to use <allcaps> osal </allcaps> socket <allcaps> api </allcaps> is your feature request related to a problem ? please describe . currently uses cfe supplied network_includes . h and not the abstracted <allcaps> osal </allcaps> calls describe the solution you ' d like update to use <allcaps> osal </allcaps> describe alternatives you have considered none additional context see osapi - os - net . h and / or <allcaps> osal api </allcaps> . requester info jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"replace deprecated cfe refs , # <number> fixes # <number> submitted by <user> , <allcaps> cla </allcaps> on file testing : - make enable_unit_tests = <allcaps> true simulation </allcaps> = native prep - built on linux with - dcfe_omit_deprecated_6_6 with no build errors",2.0
remove dependencies on deprecated cfe elements with : <code> build errors : <code>,2.0
"enhanced version reporting use ci_lab_version from cfecfs_version_info . h if available and report on <allcaps> noop </allcaps> and startup ( along with classic version numbering ) classic version numbering can then just be updated on release , vs for every commit .",2.0
remove classic build support only supporting cmake build going forward,2.0
"remove <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",2.0
"to_subsciption_t typo originated by kseywald ( <number> on babelfish ) : it looks like "" to_subsciption "" ought to be "" to_subscription "" . the typo occurs in the following locations : apps / to_lab / fsw / platform_inc / to_lab_sub_table . h : <number> : static to_subsciption_t to_subtable [ ] = apps / to_lab / fsw / platform_inc / to_lab_sub_table . h : <number> : /* cfe core subsciptions */ apps / to_lab / fsw / src / to_lab_app . c : <number> : for ( i = <number> ; ( i < ( sizeof ( to_subtable ) / sizeof ( to_subsciption_t ) )); i + + ) apps / to_lab / fsw / src / to_lab_app . c : <number> : for ( i = <number> ; ( i < ( sizeof ( to_subtable ) / sizeof ( to_subsciption_t ) )); i + + ) apps / to_lab / fsw / src / to_lab_msg . h : <number> : } to_subsciption_t ;",0.0
"split out to_lab platform config from app header originated by abrown4 ( <number> on babelfish ) : the platform - specific config ( that i need to change for a deployment ) is in the to_lab_app . h , and thus common to all to_lab builds . however , i want to build and deploy multiple cfs instances , each with a to_lab . [ it _is_ simple and handy . ] propose moving the platform - specific info into to_lab_platform_cfg . h , like the other apps .",2.0
confirm valid perf_id use originated by abrown4 ( <number> on babelfish ) : cfe reserves <number> - <number> perf - ids . need to confirm ci_lab does not use these .,0.0
"cf invokes cfe_msg_init with size of <number> the 3 rd parameter of <code> is supposed to indicate the actual size of the structure / buffer being initialized . in general , this must be _at least_ the size of the primary header in order to be valid . cf ( at first ) passes this as <number> , then overwrites this with the real size later on . the problem is , a size of <number> is totally invalid , and to be correct , <code> should not be writing any values into a structure that is smaller than the size of a primary header , as this is an error . writing any value into a struct of size <number> is a write - beyond - bounds error , and thus the fact that the default cfe_msg_init ( ) even allows this is a bug . <section> run cf with a proper implementation of <code> - i . e . one that verifies the size is valid . when passed a size of <number> , none of the header fields will be set ( correct behavior ) . this results in the buffer being in an indeterminate state , and the msgid will not be set . <section> the msgid needs to be set by the call to <code> <section> <url> <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , update minor out - of - family naming / consistency issues in cf note : * * cf does not verify length for non - command mids received in the app pipe ( <code> and <code> ) - it would be worthwhile to rectify this at some point . cfe and the other apps are generally inconsistent on this - some do not check non - command mids , some use a single verifylength function to check all mids arriving , some use separate verifylength functions for command and non - command mids . <repeated> <section> github ci actions all passing successfully ( incl . build + run , unit / functional tests etc . ) . <section> minor changes as noted above , no significant changes to behavior . aligning aberrant naming to the predominant patterns in cfs improves usability and eases future maintenance . <section> avi weiss <user>",2.0
"some minor out - of - family naming / consistency issues in cf could be updated expected behavior * * align with cfs where appropriate - consistency makes maintenance easier , and improves usability for consumers of cfs and the open - source apps . <section> avi weiss <user>",2.0
"cf draco rc4 : many fiile uploads caus cf to hang or have "" gap errors "" on <allcaps> rst wfi fsw </allcaps> , when uploading many files ( <number> - <number> files ) , the cf application either stops responding ang hangs or it responds with ' gap errors ' . this is most easily seen when uploading a large number of table files . on <allcaps> rst wfi fsw </allcaps> , this bug can be tracked under <url> <section> this bug was originally seen by the <allcaps> wfi </allcaps> simulator team when trying to upload large numbers of <allcaps> ald </allcaps> files to the <allcaps> wfi fsw </allcaps> . this bug was reproduced in the <allcaps> wfi fsw </allcaps> lab <allcaps> cots </allcaps> gr740 string by uploading <number> to <number> sets of <number> table files . from <allcaps> wfi </allcaps> - <number> : "" the script wfif_fgs_table_dump_and_load_test . prc dumps and reloads all <allcaps> fgs </allcaps> tables ( <number> ) total in sequence . once in a while the script will hang because a table was not able to upload . <allcaps> cfdp </allcaps> page will sometimes show a "" gap "" error . "" <section> the cf application should be able to handle "" large "" numbers of file uploads without hanging or producing errors . <section> - roman <allcaps> rst wpc </allcaps> , and leon4 gr740 <allcaps> cots </allcaps> - <allcaps> rtems </allcaps> <number> - cf draco rc4 ( and draco rc2 ) , <allcaps> wfi fsw </allcaps> <number> <section> add any other context about the problem here . <section> nicholas yanchik , <allcaps> nasa </allcaps> goddard space flight center , <allcaps> wfi fsw pdl </allcaps> <email>",0.0
"support polling with no delay polling has a timer that does not support zero delay , limiting performance : <url> <url> <url> <section> there ' s already a channel enable , no need to use interval to disable the channel . update to support <number> delay to maximize throughput when using the polling directory . <section> none <section> i can not say i really understand why <number> timeout wasn ' t supported to begin with . if anyone knows i ' d be interested to hear it . in rate constrained situations unnecessary delays on file transfers are a big impact . sending small files on a fast link could waste significant bandwidth by waiting a second between polling . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"silence logic around error event broken on semaphore timeout if the semaphore times out there ' s no attempt to allocate a buffer . if a buffer is not allocated and silent is false , an error event is sent claiming there was no buffer available . <url> this silent logic does not make any sense to me , since it ' s passed in as <number> from all the non - file data pdus but <number> for data . if it was intended for the allocate buffer why only non - data pdus ? i doubt it was ever intended for the semaphore timeout . <section> i saw it when waiting for the semaphore to send an eof <allcaps> pdu </allcaps> . could probably see it on the metadata send , but i initialize w / a nonzero sem count . <section> no event on semaphore timeout , this is nominal behavior for flow control . <allcaps> tbh i </allcaps> ' m not a huge fan of a possible flooding event on the failure to get a buffer . i ' d rather see a combined approach of a counter and probably a single event sent at the maximum rate of each hk cycle only when the counter increments . <section> see above . <section> ubuntu <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , remove local error return codes in cf_validateconfigtable ( ) testing performed * * github ci actions all passing successfully . <section> <code> will now return a relevant error code that is intelligible to outside functions , if they want to take action on it . the function is noticeably simpler / cleaner now . <section> avi weiss <user>",2.0
"decoding segments using incorrect macro ( cf_pdu_max_tlv ) while checking out the most recent version of the cf repository to test with a custom file sending application , i ran into this line while trying to figure out why <allcaps> nak </allcaps> ' s were acting strangely : <url> should not it look moreso like this ? there are other lines referencing the <code> macro , but those compare against the <code> struct member . when i modified it to this in my instance of cfs , all <allcaps> cfdp </allcaps> functions worked as expected : <code>",0.0
"add option for padding bytes / trailer at end of <allcaps> cf pdu </allcaps> some deployment scenarios for cf may require some extra platform - specific trailing data to be appended to the end of the pdus , for example a custom <allcaps> crc </allcaps> or error check / correction code . <section> to facilitate this , cf should offer an option to add extra padding bytes to the end of the <allcaps> pdu </allcaps> so that the platform may fill these bytes with the desired trailing data . <section> joseph hickey , vantage systems , inc .",2.0
cf backwards compatibility it possible to simply update cf app ( <number> . 4 xx ) and have that new version of cf be backwards compatible with all the other apps <allcaps> cfe </allcaps> etc ?,3.0
double semicolon in <hashtag> define </hashtag> macro ? reporter info * * avi weiss <user>,0.0
"coding style : braces around single - line statements in if / for blocks ? <section> most single - line statements ( > <percent> ) in if / for blocks are surrounded by braces , but not all . <section> if not contrary to the coding standard , no change is required , although consistency is always nice . <repeated> <section> most safety - focused coding standards require braces in call blocks , even for single - line statements ( and often even for empty statements ) . i am not sure where the cfs ( <allcaps> gsfc </allcaps> ) standard stands on this . this is due to the perceived improvement in readability and maintainability ( i . e . with braces , there is a lower risk of messing up the scope of a statement when something is either added or removed in the future ) . <section> <url> <url> a few further examples from around cfs to illustrate : <url> <url> <url> <section> avi weiss <user>",3.0
"<allcaps> pdu </allcaps> processing when crc_flag true the issue involves a difference in interpretation of the <allcaps> cfdp </allcaps> specification . in particular , the format and processing of <allcaps> cfdp </allcaps> pdus when the <allcaps> pdu </allcaps> header indicates <allcaps> crc </allcaps> present . for fd pdus , the code ignores <number> bytes instead of <number> bytes for the <allcaps> crc </allcaps> at the end of the <allcaps> pdu </allcaps> ( see context ) . that will result in ignoring the last <number> bytes of file data from fd pdus encoded with a <allcaps> crc </allcaps> . if an <allcaps> eof </allcaps> or <allcaps> fin pdu </allcaps> is received with <allcaps> crc </allcaps> present , the <allcaps> crc </allcaps> at the end will ( almost always ) cause a decoding error in cf_cfdp_decodealltlv called by cf_cfdp_decodeeof / cf_cfdp_decodefin . <section> unknown . if helpful , i could provide what i believe to be valid <allcaps> cfdp </allcaps> pdus and show how their processing differs from my expectation . <section> the software could refuse pdus with crc_flag true , or , preferably , it could decrement the data_len of ( all ) pdus with crc_flag true by <number> ( bytes ) . <section> this code has the per <allcaps> pdu crc </allcaps> declaration : <url> the comments on lines <number> - <number> do not match my understanding . file data processing excerpt : <url> <section> n / a <section> unfortunately , the <allcaps> cfdp </allcaps> standard <number> <allcaps> crc procedures </allcaps> has an external reference for the <allcaps> crc </allcaps> and the reference is wrong : <number> . <number> the <allcaps> crc </allcaps> computation algorithm shall be the standard <allcaps> ccsds </allcaps> telecommand <allcaps> crc </allcaps> algorithm specified in <number> . <number> of the <allcaps> ccsds </allcaps> telecommand recommendation ( reference [ <number> ] ) . and <number> - b - <number> section <number> . <number> does not specify a <allcaps> crc </allcaps> . however , the only <allcaps> crc </allcaps> in <number> - b - <number> is defined in <number> . <number> frame error control word as a <number> octet field . <section> bob wiegand , <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"' <allcaps> eid </allcaps> ' should be at the end of the event id names code snips * * screenshot <number> - <number> - <number> <number> <number> <number> <img> <section> i think it is worth moving ' <allcaps> eid </allcaps> ' to the end of the cf event id names to improve consistency across the cfs apps and ease the identification of eids from cf in general . at the same time , it is probably worth moving the additional type parameter in the event id names ( <code> , <code> etc . ) to the end as well , which is also the predominant convention in cfs . <section> avi weiss <user>",2.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
"temporary files possible filename conflict the temporary filenames are created based on the sequence number in the <allcaps> pdu </allcaps> ( in the cf_cfdp_r_init ( ) ) . imagine that two different <allcaps> cfdp </allcaps> entities are sending a <allcaps> pdu </allcaps> with the same sequence number ( which can happen since this number is managed by each <allcaps> cfdp </allcaps> entity and it can be the same ) to the same <allcaps> cfdp </allcaps> destination entity . for instance , the sequence number in this case is ' x'. for the first <allcaps> pdu </allcaps> the cf app would create the x . tmp file and store it in the temporary folder . upon arriving the second <allcaps> pdu </allcaps> the cf app would also create a x . tmp file and then would store it in the temporary folder . this would create a conflict . would not it be better if the temporary filename is the concatenation of the source entity id and the sequence number ? this would guarantee that each temporary file would be unique since each sequence number is unique for each entity id .",0.0
"cf_cfdp_sendeotpkt sent with incorrect cc value a call to cf_cfdp_sendeotpkt ( ) was added to the cf_cfdp_resettransaction ( ) function to give feedback on successful file transmission . however , it is sent every time the transaction is discarded regardless of the cause . i believe it was the intent that the t - > history - > cc could then be used to determine if it was successful . however , it is unclear if t - > history - > cc is being correctly set on on every possible condition that calls cf_cfdp_resettransaction ( ) . particularly with the <allcaps> cfdp </allcaps> send control loop , it appears that there are cases where the the sending transaction is reset without setting t - > history - > cc which is used by cf_cfdp_sendeotpkt ( ) . i . e . the cf_eotpacket telemetry would indicate success when it in fact did not complete successfully . before cf_cfdp_sendeotpkt ( ) was added to cf_cfdp_resettransaction ( ) , it did not matter if t - > history - > cc was set before calling cf_cfdp_resettransaction ( ) since it wasn ' t used in the function before freeing the transaction . <section> steps to reproduce the behavior : example - let <allcaps> cfpd </allcaps> send t - > inactivity_timer timeout before completing the transaction . <section> t - > history - > cc must be set correctly for all possible cases before calling cf_cfdp_resettransaction ( ) . canceling a transaction or an error condition that leads to resetting the transaction must set t - > history - > cc to a value other than cf_cfdp_conditioncode_no_error . unit tests for function that have an error condition that leads to resetting the transaction should verify that t - > history - > cc is also set to an error condition . <section> void cf_cfdp_sendeotpkt ( cf_transaction_t * t ) { . <repeated> pktbuf - > eot . cc = t - > history - > cc ; . <repeated> } <section> - hardware n / a - os : centos - versions <number> <section> add any other context about the problem here . <section> nathan lynch <allcaps> jsc </allcaps> - er611",0.0
resolve issues building users guide with ubuntu <number> / doxygen <date> doxygen <code> <section> remove unnecessary documentation <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"directory polling does not clean up open directory file descriptors cf_cfdp_playbackdir is called by cf_cfdp_processingpollingdirectories when the interval for the cf_poll_t structure has expired . this function will attempt to reopen the directory . if the polling directory does not continuously receive new files to process , then the os_directoryopen call happens without a corresponding os_directoryclose call , exhausting the amount of available file descriptors and causing this error . <code> <section> steps to reproduce the behavior : <number> . launch cf with a configured polling directory <number> . let ticker expire and attempt to reopen directory <number> . wait until fds are exhausted and error appears <section> i expect the directory file descriptor to be cleaned up before each os_directoryopen call . <section> configuration table used : <code> <section> - sc3m , microblaze - os : linux <number> - cfs <number> , cf commit bff67f87 <section> i added a check in cf_cfdp_playbackdir <url> that looks to see if the fd is <number> . if it is not , i close the directory and reopen it . this gets rid of the problem . <section> dennis afanasev , <allcaps> nasa </allcaps> goddard code <number>",0.0
"disable directory polling in default configuration table the default configuration table cf_def_config . c enables channel <number> directory polling on / cf / poll_dir at app startup . unless that directory already exists on the target filesystem , cf will periodically emit the error event <number> message "" cf : failed to open playback directory / cf / poll_dir , error = - <number> "" . when testing and validating the cf app running defaults , it is not ideal to have unnecessary error events being periodically reported . <section> disable all directory polling in the default configuration table . because this feature requires foreknowledge of specific directories resident on the target filesystem , it should only be configured and enabled by end users . all channels should have polling disabled and no polling settings in the cf_polldir_t structure . <section> n / a <section> n / a <section> sergio maldonado , <allcaps> nasa gsfc </allcaps> , arctic slope technical services",2.0
"cf build failure on systems where int32 is "" long "" on a system where the <code> type is defined as <code> ( rather than <code> ) , the cf unit tests fail to build with the following error : <code> <section> build on any system where <code> is not equivalent to <code> <section> should build successfully <section> <allcaps> rtems </allcaps> <section> this is using utassert_true - problem would not exist if the <code> were used as intended . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , removes cf_config_tlm_mid from cf_msgids . h - fixes # <number> <section> searched all cf child directories for <code> and found no uses of the variable . <percent> unit test coverage . <section> remove unused <code> from cf_msgids . h . <section> - ubuntu <number> <section> none <section> if included , identify any third party code and provide text file of license <section> justin figueroa , <allcaps> asrc </allcaps> federal",2.0
"remove config tlm packet <allcaps> mid </allcaps> the cf_config_tlm_mid constant is still defined in cf_msgids . h . the corresponding packet was removed in # <number> and is no longer used . <section> remove cf_config_tlm_mid from cf_msgids . h <section> n / a <section> n / a <section> sergio maldonado , <allcaps> nasa gsfc </allcaps> , arctic slope technical services",2.0
enums should not be used in tlm ( portability ) the end of transaction tlm message <code> uses enums which we tend to avoid due to portability issues : <url> <section> replace with fixed size types <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> reported / requested by stakeholder .,2.0
"numerous bugs in cf chunk processing edge cases as part of resolving # <number> , numerous bugs were discovered in cf_chunk . c both with adding to the list w / <code> and computing gaps with <code> . observed chunk add errors ( covers described with non - inclusive end ) : <number> ) adding a chunk that would completely replace chunks <number> and <number> ( a combinenext case ) . starting list { offset , size } : { <number> } , { <number> , <number> } , { <number> } , { <number> } , { <number> } so it covers <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> - <number> cf_chunklistadd with { <number> } so it should completely replace chunk <number> <sad> <number> } and <number> <sad> <number> } results in { <number> } , { <number> } , { <number> } , { <number> } ( note erroneous overlap of <number> and <number> ) , expected : { <number> } , { <number> } , { <number> } , { <number> } covering <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> ) adding a chunk that combines with chunk <number> , <number> , and <number> ( prev , next , next ) . starting list { offset , size } : { <number> } , { <number> , <number> } , { <number> } , { <number> } , { <number> } so it covers <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> - <number> cf_chunklistadd with { <number> } so it should combine with chunk <number> - <number> results in { <number> } , { <number> } , { <number> } , { <number> } ( note erroneous overlap of <number> and <number> ) , expected : { <number> } , { <number> } , { <number> } covering <number> - <number> <number> - <number> <number> - <number> <number> ) adding a chunk that is a subset of chunk <number> starting list { offset , size } : { <number> } , { <number> , <number> } , { <number> } , { <number> } , { <number> } so it covers <number> - <number> <number> - <number> <number> - <number> <number> - <number> <number> - <number> cf_chunklistadd with { <number> } so it should just drop since it ' s a subset of <number> results in { <number> , <number> } , { <number> } , { <number> } , { <number> } , { <number> } ( note numerous issues ) , expected no change observed chunk gap errors ( gaps and covers described with non - inclusive end ) : <number> ) misses a leading gap . starting list { offset , size } : { <number> } , { <number> } , { <number> } covers <number> - <number> <number> - <number> <number> - <number> so gaps <number> - <number> , <number> - <number> , <number> - <number> and anything after <number> cf_chunklist_computegaps with start <number> , total <number> results in { <number> } , so it missed the <number> - <number> gap <section> see scenarios above . <section> see scenarios above . <section> cf_chunks_eraserange has problems if start = = end and the memmove size is wrong : <url> cf_chunks_combineprevious should combine whenever the offset is less than previous range ( move ret = <number> out of inner if ) : <url> cf_chunks_combinenext is overly complex and broken . <repeated> ended up refactoring completely to get it to work : <url> cf_chunks_computegaps start logic is broken . <repeated> again just refactored to straighten it out : <url> <section> ci with # <number> incorporated <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"clarify cmd processing success event text for cases that just initialize action playback , transfer , and cancel commands just initiate the action which is then handled by the engine . event text implies otherwise : <url> <url> <url> <section> update text to indicate the action was successfully initiated <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"use generic "" cf_msgids . h "" file that uses offsets from base <allcaps> mid </allcaps> currently , the example <code> file supplied with cf ( under platform_inc ) is hardcoded , e . g . : <url> this presents some challenges for the user : - at a minimum the user needs to modify this file in place ( because the build script just points to this dir , there is no selection / override currently ) - it is not really possible to use different mids on multiple instances of cf running on a multi - <allcaps> cpu </allcaps> deployment . <section> use offsets from <code> and <code> like <allcaps> cfe </allcaps> framework does . for example : <url> thus the user only needs to specify the offset from the base ( aka the "" topic id "" ) in the mission_cfg . h file ( which has global scope , not processor scope ) and each <allcaps> cpu </allcaps> will automatically get non - overlapping <allcaps> mid </allcaps> numbers . <section> the alternative is to employ the <code> cmake function to allow the user to specify this file per arch , but <allcaps> imo </allcaps> the topicid / offset approach is simpler and more logical . <section> joseph hickey , vantage systems , inc .",2.0
"cf_unionargs_payload_t elements dword and hword not used , union not necessary dword and hword are not used in the <code> union , only byte : <url> <section> remove unnecessary union <section> <code> is somewhat out of family in that it specifies unnecessary payload elements for some of the commands . the only common benefit seems to be byte <number> which is channel , supporting all channels generically with <number> . consider untangling all the layers of abstraction and go back to simple command processing . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"cf_delete_queue_node_cc not used , expected command length for cc <number> filled in command code <code> not used : <url> cc <number> expected length is set but not used : <url> <section> remove unused elements , also clean up comments when done : <url> <section> none <section> add any other context about the feature request here . <section> full name and company / organization if applicable",2.0
"<code> refactor broke engine initialization , blank sem_name is not an error semaphore name being blank is not an error condition , it should simply skip the semaphore get by name call . the recent refactor changed this behavior which causes the engine to crash . error introduced here : <url> old code : <url> <section> initialize engine without a semaphore name defined <section> still initialize the transactions if the semaphore name is blank <section> observed from <allcaps> ctf </allcaps> testing ( on linux i assume ) <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"follow temporary file + rename pattern for all files currently , there is a special case to handle situations where the <allcaps> md pdu </allcaps> arrives out of order . a temporary file is opened , and then renamed once the md packet does arrive . however , because this is only done for off - nominal cases , it is likely not as well tested as other paths ( see bug # <number> ) . <section> this pattern of using a temp file should be standard operating procedure , not just something for special cases . reasons / advantages for always doing it this way described in my comment here : <url> this improves atomicity of file updates , prevents clobbering files and avoids cases where other apps might see partial files or other bad content . <section> n / a <section> as the fix for # <number> strictly only fixed the issue described , this is a more general enhancement that would improve cf . <section> joseph hickey , vantage systems , inc .",2.0
"possible silent truncations of entity id and transaction sequence number the types for entity id and transaction sequence number are sort of configurable ( they are in the config . h but impact packet dfns ) : <url> <url> if they are set to anything smaller than uint64 allowed by the spec , then they could get truncated silently when decoding packet headers in cf_cfdp_decodeheader : <url> although the impacts do not seem all that critical . sequence will roll over locally ( should still locally match up ) , masking off high order eid bits and still getting a match / conflict for destination or source seems unlikely , although possible . <section> check that the encoded value will fit , otherwise send an event and drop the transaction . up to <number> extra checks per header decode . <section> make these all support the spec allowed <number> bit , no longer configurable . would impact memory footprint and cmd / tlm packets . leave as is seems like an option also . avoids the extra checks on every header that would be needed to avoid something that likely has minimal impact / likelihood . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",0.0
"cf parameter configuration file reference incorrect in doxygen documentation doxygen references non - existent file cf_def_cfg . c <url> <section> update , file name is cf_def_config . c , and probably should clarify that this is a table and that there are get / set commands . <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"remove design and obsolete <allcaps> vdd </allcaps> from codebase ( these are release assets ) design ppt and <allcaps> vdd </allcaps> doc are binary and challenging to manage within actual codebase with little benefit . updates to either should not impact codebase hash . <section> remove from codebase , provide as release assets <section> transition design material to markdown would support better text - based management , and possibly create a pdf from it to provide as the release asset ( and that <allcaps> pdf </allcaps> could still be updated without impacting codebase hash ) . or integrate the design material into the doxygen users - guide ( or both , since doxygen can reference markdown ) , which generates a pdf as a release asset . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"generate diagnostics / info packet on transaction closure difficult to automate follow - on actions based on transaction completion ( history queue is not automation friendly ) or maintain a record of all transactions without dumping queues . <section> send a diagnostics / info packet whenever a transaction is closed for any reason including all the relevant info ( rx / tx , channel , file source / target , status , class , etc ) <section> event could be an alternative , but harder to base automation on <section> stakeholder request <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <user>",2.0
"abandon and cancel commands with invalid transaction ids are silently dropped ( not rejected ) cf requirements cf5006 . <number> and cf5007 . <number> state that , if the command - specified transaction is not in progress , cf shall reject the command . requirements cf5015 . <number> and cf5017 . <number> cover "" all "" transactions and state that , if there are no transactions in progress , cf shall reject the command . cf does not reject such a command by either issuing an event message or incrementing the command failure counter . cf does not take any action other than incrementing the command counter . <section> steps to reproduce the behavior : issue the abandon or cancel command with a transaction id that is invalid and / or not currently in progress . issue the abandon or cancel command with the "" all "" specifier when no transactions are currently in progress . <section> to be consistent with other transaction based commands , cf should provide operator feedback if it fails to find the active transaction id . at the minimum , it should issue an event message and increment the command failure counter . <section> ubuntu <number> linux <number> <section> sergio maldonado , <allcaps> nasa gsfc </allcaps> , arctic slope technical services",0.0
cf_processmsg ( ) function incorrect description the cf_processmsg ( cfe_sb_buffer_t * msg ) description in the cf_app . h header file is incorrect . it is a duplicate of the cf_init ( void ) function . <section> n / a <section> n / a <section> n / a <section> n / a <section> n / a <section> n / a,1.0
"new <allcaps> rx pdu </allcaps> dropped due to max rx transactions reached on channel not counted there ' s a strange comment about "" no known channel "" as justification for dropping a new <allcaps> rx pdu </allcaps> without incrementing the channel dropped receive counter , yet the channel number is known since it ' s received on the channel pipe and the local <allcaps> eid </allcaps> matches . <url> <section> i ' d expect the dropped counter to increment as a way to track this condition per channel . there is not a transaction set up or a cf_cfdp_dispatchrecv called , but all the cf_cfdp_recvdrop call does is increment the dropped counter anyways . <section> maybe the received "" dropped "" counter is only intended for rx transactions that have been started . <repeated> seems like useful information though . probably also useful to track with a counter if the event gets filtered . <section> i could not find a requirement so likely derived . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"noncompliance with the concept of informative variable names a style thing , but pretty obscure one character names all over . good practice to use useful names that a new reader can easily pick up on and / or easier to maintain . example use of c , q , p , and t all in one line : <url> <section> c - > chan t - > txn q - > queue_idx / q_index or whatever . p - > priority ( or whatever it is ) and so on . <section> may just be another one for the lesson ' s learned bucket . not sure how this got through code review . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"local <hashtag> defines </hashtag> in cf_cmd . c used as special values in command processing ( w / repeat dfn in tests ) <code> , <code> , <code> used in command processing should not be defined in a * . c where it ' s inaccessible and somewhat hidden . the names are not great either , better to prefix w / app . <url> <section> move into cfe_msg . h and rename as <code> and similar , which would allow removal from cf_test_utils . h : <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"event id name does not match use <code> is used for reporting invalid <allcaps> mid </allcaps> received , note <code> and <code> are used for actual ground command processing : <url> <section> event id names should make sense , maybe <code> or similar . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"registering <number> + event filters w / 0x0 0 0 0 values serves no purpose ( and overflows a typical filter buffer ) registering event filters just to register event filters does not do anything but load the system . if an event needs to be filtered operationally , just use the add filter command . note default <code> is <number> , so the rest would get discarded and cause a filter buffer overflow event . <section> remove filter registration for those set to 0x0 0 0 0 ( all of them ! ) add operationally if / when needed , or if eventually an actual filter needs to be applied then add it . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove config tlm packet and associated command all the configuration information is in the table ( and maintained there ) , the config packet is redundant and actually is missing all the channel data so it ' s not all that useful anyways . <url> <section> remove this functionality along with requirement cf5004 <section> none <section> as part of making more configuration channel based , this redundancy was noted . not worth the effort to maintain a tlm packet that ' s basically a repeat of the table . - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> adds link to new clas in pull_request_template and contributing . md - fixes # <number> - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [x ] update the instructions in each app ' s contributing . md - [x ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
"typo in <allcaps> readme </allcaps> . md first section header lacks space between <code> and <code> <section> observe that "" <hashtag> core </hashtag> flight system ( cfs ) <allcaps> cfdp </allcaps> application ( cf ) "" is literal and does not look like a section header <section> "" core flight system ( cfs ) <allcaps> cfdp </allcaps> application ( cf ) "" looks like a section header <section> <url> <section> n / a <section> n / a <section> john n pham , northrop grumman",1.0
updating ut to work with cmake build system i am looking for a methodology or guide to build and run or convert unit tests which are based on gcov for apps which have not been updated such as : * <url> * <url> etc . the only app updated is : * <url> i have viewed the diffs between 2 a292d041a <phone> cc10344abbf0c4ecccc2 and 7 a48a8b2e8f4f5b103748685f076d9dc8b3b66fb but it is still not clear why things were shifted around . can anyone clarify,3.0
"<allcaps> cfdp </allcaps> backwards compatibility i have a system that is running <allcaps> cfdp </allcaps> version <number> and want to interface it with a system that is running the older version of <allcaps> cfdp </allcaps> <number> . are the two versions compatible for file transfers ? <section> i would like to know if <allcaps> cfdp </allcaps> version <number> and <number> are compatible for file transfers . <section> i have looked at the documentation for <allcaps> cfdp </allcaps> available on the github page and have not seen anything suggesting they are compatible / incompatible with each other . <section> i know certain things have changed across the two versions , such as the hk telemetry messages having a different format . <section> jeff anderson",3.0
resolve static analysis warnings in unit tests various static analysis warnings observed in unit tests ( license restricts publishing ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
resolve static analysis warnings in fsw various static analysis warnings observed ( license restricts publishing ) <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"add documentation build / deploy workflow build / deploy documentation not in workflow <section> add workflow to build and deploy documentation , see nasa / cfs # <number> <section> none <section> nasa / cfs # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"replace codec code - compatibility macros with direct calls to the new functions these were used to help transition the code from old endian dependent macros , but they obscure the fact values are being modified by taking address of the input . they also cause static analysis warnings on occasion as identified in # <number> . example : <url> <section> convert the code to use the functions directly , remove offending macros . <section> none <section> - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"replace use of <code> , coding standard violation <code> violates power of ten and <allcaps> jpl </allcaps> coding standards , typically avoided in cfs code . <section> refactor <section> none <section> static analysis warning that showed up in # <number> but wasn ' t resolved as part of that issue fix <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"dynamically choose <allcaps> tlm </allcaps> or <allcaps> cmd </allcaps> message type for <allcaps> pdu </allcaps> currently , the cf application uses the software bus for <allcaps> pdu </allcaps> transfer . ( this is an issue in itself , see # <number> ) . however , in the meantime , when using sb it must make the <allcaps> pdu </allcaps> messages look like the <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> messages that sb typically deals with . cf currently assumes / requires that all ingress / rx direction pdus will have a <allcaps> cmd </allcaps> header , and all egress / tx direction pdus will have a <allcaps> tlm </allcaps> header . this assumption is a barrier to configuration of having two instances of cf potentially send files to each other - in such a configuration , there must be an intermediate entity to forward the "" <allcaps> tlm </allcaps> "" - style egress <allcaps> pdu </allcaps> messages and convert them to "" <allcaps> cmd </allcaps> "" - style ingress <allcaps> pdu </allcaps> messages on the other node , in both directions . <section> to potentially make this configuration a bit easier , cf could dynamically choose which type of message header to use based on the configured msgid values . that is , if the user has configured cf to output on a msgid which ( per the <allcaps> msg </allcaps> module ) is identified as a <allcaps> cmd </allcaps> type , it should use a <allcaps> cmd </allcaps> header when assembling those egress pdus . likewise , if the user has configured cf to input on a msgid which is identified as a <allcaps> tlm </allcaps> type , then cf should strip a <allcaps> tlm </allcaps> header from that message . <section> currently if cf - cf transfer is required , an intermediate transfer agent must fulfill this role to forward the <allcaps> pdu </allcaps> to the other entity and also convert to the other type ( <allcaps> tlm </allcaps> - > <allcaps> cmd </allcaps> ) for ingest by cf . <section> while this would address one pain point of this type of configuration , it still leaves two major ones : - sb pipes have inherent buffering limits - sb pipes cannot provide backpressure to sender ( they just hit msglim and drop ) as a result the backpressure still needs to be implemented separately ( via a sync sem ) to avoid overflowing pipes . i ' d still rather fix # <number> to address all the issues inherent with using sb as a bulk data transfer mechanism - it is not designed to be that . <section> joseph hickey , vantage systems , inc .",2.0
"<code> in platform_inc directory <code> in platform_inc directory instead of with source , causing tables to use the non - overridden cf_platform_cfg . h file instead of the one in * _defs at the top level , since the compiler prefers includes relative to the current file over include paths specified on the command line . this is also different than most other apps which define their table structs in fsw / src . workaround would be to also override cf_tbldefs . h , but the table struct is not really something that one needs to customize in the first place . <section> steps to reproduce the behavior : alter cf_num_channels in platform_cfg by copying to [ mission ] _defs / , modifying and using generate_config_includefile to override . <section> cf config table uses the updated cf_platform_cfg . h instead of the original one . <section> if applicable , add references to the software . <section> - sp0 - s - os : vxworks <number> <section> using snippets from <allcaps> jsc </allcaps> ' s modified arch_custom . cmake to override platform_cfg : <code> <section> john n pham , northrop grumman",0.0
"apply latest contributor license agreement links applies links to the latest contributor license agreements . <section> working links <section> depends on <url> <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"resolve additional internal static analysis warnings in fsw <number> "" red "" errors reported by internal static analysis ( license restricts publishing results ) <section> resolve the warnings ( uninit variable * <number> and one non - distinct identifier ) <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
report mission rev in startup and noop event string <code> every other app reports major . minor . rev . mission_rev ( mission_rev missing above ) <section> add mission rev to version reporting both for startup and noop . may actually need to add <code> define ( not found during quick inspection ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
resolve cppcheck issues ( and confirm they are getting flagged correctly ) style warnings when running strict cppcheck : <code> <section> confirm these are getting flagged in ci . <section> none <section> - # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"potential acceptance of commands with invalid <allcaps> cfdp </allcaps> class the check for <allcaps> cfdp </allcaps> class could let a "" class <number> "" or negative class message through the code that checks if the class is valid looks like <code> if <code> is zero or negative this check might pass and let through an invalid command . <section> n / a , have not tested yet . <section> only accept class - <number> or class - <number> . all other values should be rejected . <section> <url> <url> <section> code - only check <section> n / a <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps>",0.0
"apply clang - format - <number> formatting was formatted w / clang - format - <number> , rest of the repos ( and ci ) still use clang - format - <number> <section> apply clang - format - <number> so ci will pass . <section> none , we can bulk update to <number> in the future . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , doxygen frontpage refactor and cleanup - fix # <number> <section> documentation change only , but still built and ran unit tests <section> none <section> - hardware : i5 / wsl - os : ubuntu <number> - versions : bundle main + this commit <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
clean up old license headers old headers still exist in the codebase . <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"add event , command code , command structure , and telemetry structure documentation missing user ' s guide documentation . also some inlines in cf_utils . h missing documentation . <section> add descriptions . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"implement doxygen front page concept , clean up documentation , resolve doxygen warnings - apply frontpage concept / documentation framework ( mainpage can not be included in larger document ) - clean up / clarify sections and apply suggested patterns - resolve warnings from building doxygen documentation <section> see above . <section> none <section> - nasa / cfe # <number> - nasa / cfe # <number> - nasa / osal # <number> - nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
add apache <number> <allcaps> license </allcaps> file and update copyright headers missing license file and out of date copyright info in file headers <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
fix common_types . h include not following standard : <url> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
use <code> instead of <code> <code> has been abstracted by <code> to avoid internal dependencies on cfe_msg_message_t <code> <section> use <code> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
add fixed size <allcaps> ccsds </allcaps> packet option some systems can not handle variable sized telemetry packets . <section> add an option to zero - fill the related <allcaps> ccsds </allcaps> packets . <section> none . <section> none <section> jacob hageman,2.0
apply header guard standard formatting <section> nonstandard guard used <section> apply standard <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"cf table updates - default to cf app name to match <allcaps> gsfc </allcaps> apps , disable polling by default current table name follows lab app pattern w / * _app , but <allcaps> gsfc </allcaps> apps do not have the _app . polling directory enabled by default means the warnings / errors about no polling directory existing will show up unless created by the user . prefer default behavior to not see these . <section> change cf_app to cf in table , set polling to disabled <section> users can override , so not a big deal but nice to stay consistent with apps . if we want to add * _app everywhere probably makes more sense as a bulk update . note may run into name length issues on other apps by using up the extra <number> chars . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"possible race condition with creation of throttle sem ( needs to exist before cf initializes ) <section> <allcaps> cfe es </allcaps> starts all applications in their own thread . therefore , conceptually at least , all apps are starting at the same time . if configured to use a throttle sem , the cf app expects that semaphore to be created _before_ it starts . during startup , it will attempt to bind to that semaphore during cf_cfdp_initengine ( ) , and if that fails , cf aborts ( see # <number> ) . problem is , if the semaphore is created by another app , whether it be ci / to or some other dedicated i / o app , there is no guarantee that the semaphore has been created before cf attempts to use it . secondary problem exists if the i / o app that owns the sem gets restarted or reloaded , the semaphore id will likely change too . this may be recoverable by disabling the engine and re - enabling it ( but have not tested that ) . <section> its a race condition , so not readily reproducible . start cf _before_ the app that creates the sem ( still not guaranteed , but increases the chance the race will be lost ) add an artificial delay during startup for the app that creates the sem ( just further increases the chance the race will be lost ) <section> should be guaranteed via sync mechanisms , or should not be a hard error ( e . g . maybe retry to bind later ? ) suggestion that cf might still start up but with the engine in a disabled state , so at least someone can correct the condition and enable the engine , rather than having cf abort / exit . adding a call to cfe_es_waitforstartupsync ( ) before starting the engine might help too . <repeated> <section> <url> <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"change default configuration to not use throttling semaphore <section> the default / example table source files include a semaphore name - cf_1_sem and cf_2_sem - for throttling on channel <number> and <number> , respectively . however , cf does not actually create the throttling semaphores , it expects the semaphore to be created before cf starts . if a new user is starting cf by itself with no other support apps running , this semaphore will not exist . <section> to make it simpler to build and run cf with a default configuration , the example table should have an empty string for the semaphore name - this means no throttle . <section> this will make cf at least boot up and load "" out of the box "" . <repeated> but probably any real deployment will need a throttle , so this means that we do not have an example of a throttling semaphore anymore . <section> joseph hickey , vantage systems , inc .",2.0
"write queue data does not truncate existing files <section> discovered when testing cf_write_queue_cc command . my test issued the command more than once , with the same target file name , but different type / queue parameters , to get the different content . noted that in cases where the second output was shorter than the first output , the old output remained in the file ( stale data ) at the end . this is because the call to os_fileopen ( ) does not use the os_file_flag_truncate flag , so the old data remains in the file , until it is actually overwritten . <section> run cf , run some transactions to get some history , then run cf_write_queue_cc with all types / all queues . then run cf_write_queue_cc again with the same output file , but a more specific type / queue parameter , so the output is smaller . observe that the old data from the first call is still at the end of the file , after the new entries - it was not truncated . <section> in general any time a write file request is done , it should truncate the file , unless the requirement is specifically to preserve old data ( i . e . append ) . this is not an append , so it should truncate , and write the file from a clean slate . <section> problematic call to os_opencreate is here ( via wrapper ) : <url> however there may be other occurrences . all calls to this function should be checked . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",0.0
"cf no longer processes nak pdu packets <section> a recent cf change removed the decoding of received <allcaps> nak </allcaps> pdus . in cf_cfdp_s . c , function cf_cfdp_s2_nak , there should be a call to cf_cfdp_recvnak which decodes the <allcaps> pdu </allcaps> prior to processing . otherwise , the packet is not decoded , the <allcaps> pdu </allcaps> is rejected as invalid , and the event report with "" received invalid nak pdu "" is issued . <section> execute cf tests in linux that exercise receipt of <allcaps> nak </allcaps> pdus . <section> tests should pass and <allcaps> nak </allcaps> pdus should be accepted . <section> linux x86_64",0.0
"improve ut coverage on cf_cmdgetsetparam ( ) <section> the unit test does not individually validate all of the values that "" param_id "" may have . this did not show up in the <allcaps> lcov </allcaps> reports previously . however a recent pr changed the table lookup to a <code> block , the <allcaps> lcov </allcaps> branch coverage now shows these param_id values as untested cases in the switch . <section> should add test cases to get back to <percent> line and branch coverage . <section> note this was always the case , but it just did not show up in the <allcaps> lcov </allcaps> because of the code structure . now it does . <section> joseph hickey , vantage systems , inc .",2.0
"test_cf_chunks_init_setgiven_chunks_max_chunks_togiven_max_chunks creates object too large , crashes <allcaps> rtems </allcaps> <section> the "" test_cf_chunks_init_setgiven_chunks_max_chunks_togiven_max_chunks "" test fails on <allcaps> rtems </allcaps> and crashes the kernel , because it creates an absurdly large structure on the stack and then memset ( ) ' s it to <number> . this appears to blow out the stack and probably overwrites some important structures . <section> execute cf tests on <allcaps> rtems </allcaps> <section> tests should pass <section> <url> <section> <allcaps> rtems </allcaps> <number> . <number> via <allcaps> qemu </allcaps> / pc686 <section> once again , appears to be related to use of random numbers . <repeated> when using a random number to indicate the size of an object , nothing good comes from that ( see # <number> ) <section> joseph hickey , vantage systems , inc .",0.0
"cf_cfdp_disableengine no longer disables the engine <section> the line which actually disables the engine got mistakenly deleted in a recent pr . ( got swept up because it was grouped with the variable declarations with no whitespace between ) . <section> issue disable engine command , it does not actually disable <section> should disable the engine <section> <url> <section> n / a <section> sergio maldonado ( <user> )",0.0
"implementation of cf_cmdcond takes address of inline function <section> while the compiler does not complain about this , it totally defeats the purpose of making these "" inline "" functions to begin with , as by definition they will need to be compiled out - of - line in order to be able to call them via a function pointer . <section> this complexity of using a function pointer is not necessary and counterproductive . make it simple and boring : <code> not fancy , but pretty clear what the above is doing . what ' s there now just obfuscates . note that the "" cond "" is not a boolean , its the return value of a command function that returns <number> on success . so the logic is inverted . <section> existing function <url> <section> joseph hickey , vantage systems , inc .",2.0
"a uint16 is used for defining the input / output apids in the config table , does not support full sized message ids cf defines apid inputs / outputs as uint16 ' s , then uses these with the cfe_msg_init <allcaps> api </allcaps> which expects message id ' s of type <code> . <url>",0.0
"mixture of different return types , and many use "" int "" cf has a variety of different return types from its internal functions , and many are just <code> , and return <number> on success , or - <number> on failure : <url> but some , for example the "" send "" routines , have a dedicated enum : <url> these can be tricky because it is still fundamentally an <code> ( enum ) but while the success is still a value of "" <number> "" , the error codes are in positive values , not negative like the others . sometimes the return type is <code> but it indicates a size : <url> and in other cases the return type is <code> but it indicates a boolean value , where <number> is false and <number> is true : <url> this latter case is also easy to confuse with the first case , where <number> is success on many functions but a logical "" false "" here . <section> : cf should have a return code paradigm that is more consistent with <allcaps> cfe </allcaps> and other apps . - if the return value is a boolean true / false then use <code> - if the return value is a size , then use <code> - general helper functions should return a type based on <code> ( may be a typedef like <code> ) and have a set of predefined constants for use as return values , and use them consistently throughout the code .",2.0
remove use of message storage in cf_appdata global should this be a follow - on cleanup issue ( if it is not already ) ? _originally posted by <user> in <url> related to <url> might depend on # <number>,2.0
"cf updates its destination file "" in - place "" the cf application , when receiving files , will open the destination file as indicated in the metadata <allcaps> pdu </allcaps> and immediately start writing data to it , thereby overwriting any data that was previously in the file at that position . this can be dangerous , because the file transfer may not ultimately succeed . for instance , <allcaps> crc </allcaps> errors may occur , or part of the transfer might get lost . but once data has been clobbered , there is no way to "" undo "" and restore the original data - - its gone . so now the user has a situation where neither the new file nor the original file are valid - the file is just corrupt now . it is often desirable to write data to a temporary file first , let the transfer run to completion ( storing <allcaps> all </allcaps> data in the temporary file ) , and then rename the file to its final / correct filename only after the final <allcaps> crc </allcaps> and size checks have passed and the data is known to be good ( or at least to the extent that cf can verify it ) . in fact , this is the _only_ way to safely update application binary object ( . so files ) on many targets , since the text / rodata memory pages may be mmap ' ed directly to the file on disk . if these are updated in place , and the file is an actively - running application , then the running code will immediately "" see "" the modifications , and likely crash / segfault depending on what it was doing at the time . recommendation here is to <allcaps> always </allcaps> use a temporary file to store incoming data , never overwrite existing files until final validations have occurred . this will also avoid some of the special logic that only handled corner cases ( see issue # <number> ) by making that more the norm than the exception .",2.0
"likely issues in processing of deferred / reordered "" md "" packets there appears to be logic within cf to support a case where the metadata <allcaps> pdu </allcaps> arrives late - that is , after file data has already started . basically , the logic is as follows : - if the receiver gets <allcaps> pdu </allcaps> type is file data ( not metadata ) in the idle state ( which is for a new / unknown transaction ) , it assumes the initial metadata <allcaps> pdu </allcaps> may have been lost , and it jumps directly to the file data state . - the <allcaps> pdu </allcaps> is then re - dispatched in the context of a class <number> file data state - the cf_cfdp_r_init ( ) function , will see that this is initializing a transaction for which no metadata is known , and it will : - generate a <allcaps> nak </allcaps> for the md ( looks like this is an attempt to get the sender to regenerate it ) - populates the transaction with a generated temporary file name for the destination - if the <allcaps> md pdu </allcaps> subsequently arrives , it then kicks off the following sequence : - temporary file is closed - <code> from temporary file to file name in metadata <allcaps> pdu </allcaps> - re - open the file under its new name the problem that is immediately visible here is that this close + reopen will reset the file position , but does not reset the cached position within the state object ( <code> ) that is used during writes to determine if an "" lseek "" is necessary . so now the file pointer is back to the beginning , but the <code> likely reflects the end of the file , and as a result new data will clobber existing content . but the bigger issue is that this code is essentially duplicate / specialized logic that only handles a corner case / exception so it is unlikely to be adequately tested .",0.0
"cf should not require / hard - code use of the software bus for <allcaps> pdu </allcaps> transport the cf application creates a stream of data pdus during operation , which are intended to be ( somehow ) transported to the remote node . it is a point - to - point data flow . currently , cf assumes that the software bus will be used for this purpose . although this is the existing / de - facto data transport mechanism provided by the framework , it is not an ideal fit at all . ( analogy of "" when all you have is a hammer , everything looks like a nail "" applies here ) . - software bus is broadcast ( <number> : n ) where cf data flows are <number> : <number> in nature - software bus has relatively small buffers , and is designed for minimizing latency and memory efficiency , not designed for bulk throughput - software bus does not provide any sort of back - pressure capability ( e . g . if a sender like cf is sending pdus faster than the receiver can process them ) . also note that it is not really practical for it to do so either , given it is a multicast design ( <number> : n ) - in a multicast , one would not stop sending just because one subscriber is not able to keep up . - similarly , by forwarding / bridging data pdus from the os network buffers to software bus buffers , it effectively defeats any backpressure capabilities of the underlying network protocol . for example , if a <allcaps> tcp </allcaps> connection were used for node - to - node transport over the physical network , this protocol will effectively throttle the sender to the rate that the receiver actually accepts the data through the use of ack ' s and sliding windows . this is determined on the receive side by how deep the buffer is , inside the network stack . by bridging the data to sb it essentially keeps this empty , and this gives a green - light for the sender to keep blasting data in . this makes it difficult , if not impossible , to tune the system for good throughput - it means the sender must be artificially held off without any real feedback . - software bus is designed for commands and telemetry data , and all messages are assumed to be either a command or telemetry message . therefore , cf must add a fake telemetry header on the pdus it generates , and other entities must add a fake command header on the pdus it generates , in order to maintain this pattern ( or else it will break software bus apis ) . this extra header is just unnecessary baggage , because sb is not designed for bulk data ( i . e . this is where it is really contorting the problem domain to look more like a nail so the sb hammer will be able work with it ) . while there may be valid reasons to use the software bus as a backhaul , it is certainly less than ideal and should not be the only ( hard - coded , forced ) option . there should be mode to use an i / o layer and go direct to network , which will solve many of the throughput and performance tuning issues , as well as just being a far cleaner design . if anything using sb for bulk data backhaul should be the undesirable fallback option ( if nothing else better exists ) rather than the primary / only option .",2.0
"support for segment metadata on file data <allcaps> pdu </allcaps> according to <allcaps> ccsds </allcaps> <number> - b - <number> , table <number> - <number> , a file data <allcaps> pdu </allcaps> may have segment metadata included . this is indicated by a flag being set in the main <allcaps> pdu </allcaps> header , which means the data <allcaps> pdu </allcaps> has two extra fields as well as the specified number of segment metadata information blocks . currently cf does not even check for this bit or the presence of these fields . while it may not be required to support it , on the receive side cf should be required to check for and actively discard / reject packets for which these bits are set ( and therefore it does not understand ) . instead , as it stands right now , it will read the extra fields as part of the offset , and generally corrupt the entire file , if this flag is set by a sender . hopefully the <allcaps> crc </allcaps> check would detect the corruption , but it should not do that to begin with . current code that receives the file data header only reads a single offset field , there is no provision to check for and handle the extra fields here , just the offset : <url>",0.0
"command valid and rejected counters do not increment correctly for certain invalid commands cf will increment the valid counter . for certain valid commands cf will increment the invalid counter . the cf_tsnchanaction function does not appear to correctly interpret the return status from certain sub - functions that return the count of matched transactions . it assumes a non - zero return value is failure , but actually it is the count of transaction matches . this can be seen with the following command opcodes : <allcaps> abandon </allcaps> , <allcaps> cancel </allcaps> , <allcaps> suspend </allcaps> , <allcaps> resume </allcaps>",0.0
"<allcaps> tx file </allcaps> command does not validate channel parameter the <allcaps> tx file </allcaps> command does not validate the channel parameter value prior to execution . when specifying a channel value other than <number> or <number> , the system crashes .",0.0
"<allcaps> cfdp </allcaps> protocol timer configuration is not per channel ( cf5002 and cf4000 . <number> failure ) per requirement cf5002 , protocol timer configuration should be per channel . currently the values are applied to all channels .",0.0
"not all invalid commands send an error event message per requirement cf1004 , all invalid commands should issue an error event message . for example , the tx_file command does not send the event message when certain parameters in the command are invalid . there are several other commands that need to be dispositioned for compliance .",0.0
"not all validated commands send an info event message per requirement cf1003 , validated commands should issue an info event message . this is not the case for most of the cf commands . the command counter increments but no event message is sent . this applies to the following command codes but there could be more : <allcaps> abandon </allcaps> , <allcaps> cancel </allcaps> , <allcaps> enable </allcaps> / <allcaps> disable dequeue </allcaps> , <allcaps> enable </allcaps> / <allcaps> disable engine </allcaps> , <allcaps> enable </allcaps> / <allcaps> disable polldir </allcaps> , <allcaps> freeze </allcaps> , <allcaps> thaw </allcaps> , <allcaps> suspend </allcaps> , <allcaps> resume </allcaps> , <allcaps> purge </allcaps> , <allcaps> write queue </allcaps>",0.0
"decode procedures read header fields without checking length cf uses many variable - length fields in its header structure . this requires aggressive buffer bounds checking at each point during decode , since a bad value ( such as a bad "" length "" on an lv parameter ) can throw off the decoder which may end up reading past the end of data and into undefined behavior territory . cf really only sanity checks the length at a couple points here in the initial header receive : headers alone : <url> full <allcaps> pdu </allcaps> length field : <url> however , note that even for the first check above ( line <number> ) the code has already invoked cf_headersize here : <url> notably , the <code> function reads data from the packet header to compute header size . therefore this has already read some packet data before the length is even initially sanity checked . if the input data was very short ( such as from a <allcaps> mid </allcaps> misconfiguration ) this would potentially segfault by immediately reading beyond the buffer . furthermore , every packet type that utilizes an lv or <allcaps> tlv </allcaps> style sub - fields ( e . g . <allcaps> eof </allcaps> , <allcaps> fin </allcaps> , md ) needs to re - check the bounds at each of these entries . for example in recvmd it only confirms that the size is sufficient for fixed - size fields here : <url> but later on when copying the lv data at these places , there is no check : <url> <url> these functions only check that the length is less than <code> . <repeated> it does not check if the length has gone beyond the end of the input buffer . __recommendation__ : each and every step of encode + decode should confirm that the process is not reading or writing past the end of the buffer . particularly for variable length fields .",0.0
"variables declared mid - function according to many coding standards ( <allcaps> gsfc fsw </allcaps> included , <allcaps> afaik </allcaps> ) , variables should not be declared only at the top of functions , not in the middle . however , cf has many cases of this . any variables declared mid - function should be moved to the top of the function to correct this .",2.0
"identify cases where value is computed and only used in assert call in pr # <number> , rather than completely removing assertions in the code , this including a no - op function such that the condition is still evaluated , but not acted upon . this was done because there are a few instances where a value was computed and used only for the assert , and no other reason . if the assert is removed , then the value becomes unused and is flagged as such ( i . e . compiler warning ) . the fix in # <number> was only an interim in order to get the code to compile and run . the preferred fix would be to identify cases where a value is computed and only used in an assert , and remove them . this is likely just a matter of removing the no - op function and fixing the warnings that come up .",2.0
"support for alternate checksum type indicated in metadata <allcaps> pdu </allcaps> per the <allcaps> ccsds </allcaps> blue book <number> - b - <number> , section <number> . <number> - the metadata <allcaps> pdu </allcaps> has a <number> - bit "" checksum type "" field . the description says : > checksum algorithm identifier as registered in the <allcaps> sana </allcaps> checksum types registry . > value zero indicates use of the legacy modular checksum . it looks like cf only supports the legacy checksum , because it does not check this field at all , and there appears to be only one algorithm implemented . however , this is not as significant as the large file size issue (# <number> ) because it does not otherwise change the format , here the result will be a simple failure of the validation check if there is a mismatch between peers . this is an interoperability concern . if the intent is to only support legacy checksum , this should probably be documented in the release notes / version description document . if the intent is for full compliance with <allcaps> ccsds </allcaps> book <number> - b - <number> , then this is missing . interim recommendation for <allcaps> fsw </allcaps> is to at least check this field on receipt of a metadata <allcaps> pdu </allcaps> , and reject if the checksum type field is set to anything other than ' <number> ' .",2.0
"instantiating globals in header files ( <allcaps> fsw </allcaps> version ) the <allcaps> fsw </allcaps> has a macro called "" declare_field "" which creates a constant at global scope : <url> the constant is scoped as "" static "" so it does not create a linker error , but it still creates a _separate_ instance of this global variable for each time the header is included . confirmed by checking <code> and observing that _each_ of these <number> fields occur in the binary file <number> times : <url>",0.0
add format check and static - analysis workflows add format check workflow to continuous integration to ensure new commits meet style guide see <url>,2.0
"should not use "" hk "" packet data elements as active / runtime control values the <code> values should be used strictly for reporting housekeeping status of cf out to external entities . however , cf uses some values within this structure for some active control purposes as well . for example , the <code> member is used for checking whether the soft limit is reached yet : <url> note that these hk structures are currently marked as "" packed "" ( see # <number> ) so reading / writing from these structs is more costly than normal structures . furthermore , tracking depth using a single integer can be somewhat error prone ( it is possible to "" miss "" an increment / decrement , and it will never self - correct ) .",2.0
"use of globals to store ephemeral / in - transit data cf stores its current working pointers in a global variable called <code> : in particular : <code> has a pointer to the buffer last received from sb <code> has the size of that buffer ( and is actually updated during the course of processing ) <code> and <code> have the data extracted from the header of the most recent message . and so forth . <repeated> importantly : __none of these values are supposed to be carried across wakeups__ . all values are reset in their entirety on every wakeup , and in fact with each channel . all data is ephemeral and is only valid while the <allcaps> cfdp </allcaps> app is actively processing that packet . as soon as processing of the current packet completes , the data is no longer valid . when the wakeup cycle completes , only the <code> is actively cleared . all other fields will be left with whatever data was in them . also notable - there is a mixture of <allcaps> api </allcaps> calls where sometimes the pointer to the packet data is passed in directly , as it is here via the <code> argument : <url> the call to <code> also needs the packet data , but it does not pass it along . instead , this function grabs it from the global ( theoretically the same packet ) : <url> this inconsistency should be addressed . if the intent is to _always_ store the current packet in a global , then code needing to access it should _always_ retrieve it from the global . there should not be some apis which pass a pointer to the structure , mixed with others that get it directly from the global ( where they are supposed to be acting on the same data ) , as this creates the opportunity that they could diverge . for ephemeral data , it is fine to pre - allocate a buffer in a global to avoid dynamic allocation , but the pointer to this data should be passed consistently down through the <allcaps> api </allcaps> where needed . this design allows for safer evolution , permitting the use of multiple buffers or even multiple threads should that become a requirement ( e . g . create a child task per <allcaps> cfdp </allcaps> channel to make them more independent ) .",2.0
"inconsistent parameter passing ( chan_num vs . channel pointer ) there does not seem to be any consistency in cf as to whether identifiers passed to functions are done in the form of a number ( such as a channel number ) where the function then gets the channel pointer internally by doing a table lookup , or by passing a pointer to the structure . the cf contains both forms , and sometimes passes a pointer when the implementation really needed the number . example : <url> in this case the cf_receivemessage was ( for some reason ) declared as accepting a pointer to the channel structure , but it really needs the channel number , so it does a bit of pointer arithmetic <code> to get the number . this type of pointer manipulation can be error prone , particularly if the code evolves in such a way where the <code> pointer might not be pointing to an entry in the table , this might produce an out - of - range channel number . this can also happen during unit test where its common to pass in test values - - even if <allcaps> fsw </allcaps> never expects a value not within the table , its still possible to happen . recommendation : if channel numbers are generally always needed , pass only the channel number around . it is safer because it can be more easily range - checked if necessary . alternative : store the channel number inside the channel structure , so the <allcaps> fsw </allcaps> can more simply look it up and does not need to recompute it ( avoids assumption that the pointer is pointing to a chan table entry ) . this can avoid repetitiously looking up a chan_num to get the pointer , allowing direct pointers to be passed around . but does cost a little memory and introduces the risk that something ( e . g . a bug somewhere else ) can overwrite or change the chan_num and make it wrong .",2.0
"target name inconsistencies - "" cf "" vs . "" cf_app "" the name patterns used by other <allcaps> cfs </allcaps> applications do not have an "" app "" suffix . the "" sample_app "" is the only exception here , it only has this suffix to differentiate from the "" sample_lib "" . the build scripts do rely on some naming conventions - in particular the name of the directory should match the name of the main application target . since this repository is called "" cf "" ( not cf_app ) and is cloned into a directory called "" cf "" , the target name should also be "" cf "" . on the other hand , if the target is named "" cf_app "" this may problems with things like table builds and app installation , because the names in scripts will not match . recommendation is to change the cmake files to build this as a target named only <code> and drop any <code> suffix .",0.0
"incorrect check of status from cfe_sb_receivebuffer ( ) checking of the status return from this <allcaps> cfe api </allcaps> call is not correct / sufficient : <url> this function may fail for a number of reasons , not limited to <code> . the preferred check should be : if ( status ! = cfe_success )",0.0
"size is insufficient in call to cfe_sb_allocatemessagebuffer ( ) the invocation of cfe_sb_allocatemessagebuffer ( ) here only allocates for <allcaps> cf pdu </allcaps> maximum size : <url> the returned buffer is only guaranteed to be large enough for a <allcaps> cfdp pdu </allcaps> itself , not the extra sb headers / encapsulation . this needs to be a little larger to account the <allcaps> cfe sb </allcaps> headers . preferred call should be something more like : cf_appdata . engine . out . msg = cfe_sb_allocatemessagebuffer ( offsetof ( pdu_s_msg_t , ph ) + cf_max_pdu_size ) ;",0.0
"recieved software bus buffers must be treated as "" const "" the software bus is a broadcast mechanism and sends the same memory buffers to all subscribed applications / pipes . the intent is that the data buffer should be <code> but for backward compatibility reasons the <allcaps> api </allcaps> does not enforce this . however , cf actively writes to and modifies its received buffers , basically treating it as its own temporary storage location . if this is combined in a system with another app that subscribes to cf traffic ( e . g . data store , <allcaps> dtn </allcaps> , or some other traffic monitor ) then all other apps will see the same modifications to the data buffer , and this effectively creates a race condition / unpredictable behavior . all received software bus buffers should be qualified as <code> in application code , and they should not be written to . apps should create their own buffers for temporary storage .",0.0
"cf should not use bitfields use of bitfields is discouraged by many coding standards ( including <allcaps> gsfc </allcaps> ) because the c standard does not specifically dictate how they are packed into the underlying integer type . cf uses them in several internal structures , for example : <url> if these truly need to be bit fields , then they should be implemented explicitly using shifts and masks . however , initial inspection of the code would suggest they do not need to be bit fields , they can be made into separate fields . while this may increase the memory footprint somewhat ( struct is likely to be <number> bytes in the example instead of <number> ) this is probably a reasonable trade , because separate fields can be simply read / written directly rather than requiring a read - modify - write etc . note that when using bit fields , the assembly instructions to do shifts and masks will still be generated by compiler , even though the c syntax "" looks "" simple - it is hiding it all . so it may be considerably less efficient than accessing separate memory locations . this of course depends on hardware architecture , caching , optimization by the compiler , etc but in general bitfields will always be less efficient , due to the extra shifting and masking .",0.0
"cf should use unions to simplify code and avoid improper casting <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf should use unions to simplify code and avoid improper casting _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on wed <date> <time> <number> _original description_ : in particular this applies to the "" msg "" member of the global , in the following structs : cf \ _appdata . engine . out . msg cf \ _appdata . engine . in . msg they are currently defined as a "" <allcaps> cfe </allcaps> \ _sb \ _buffer \ _t * "" type , which is what comes to / from sb calls . however , locally it is either a "" pdu \ _s \ _msg \ _t "" or "" pdu \ _r \ _msg \ _t "" ( an extension ) depending on direction . this is then cast inline at the point of use whenever the local type is required , e . g . ret = & ( ( pdu \ _s \ _msg \ _t <wink> cf \ _appdata . engine . out . msg ) - > ph ; this is not only inelegant , but casting permits almost any type conversion , and offers no protection against a programmer mistake , such as if it was cast to a "" pdu \ _r \ _msg \ _t * "" instead of "" pdu \ _s \ _msg \ _t * "" . <repeated> that would compile just fine but cause odd memory corruption at runtime . recommend to use a union for the "" msg "" member data type , i . e . union { <allcaps> cfe </allcaps> \ _sb \ _buffer \ _t sb \ _buf ; pdu \ _r \ _msg \ _t pdu \ _r \ _msg ; }; then by taking the address of either the "" sb \ _buf "" or "" msg "" union member depending on what is being called and what it requires . in addition to being easier to read , this offers a layer of protection in that the data can only be converted into a limited set of types ( union members ) .",2.0
"cf use of "" static const int32 "" for return codes , not used anywhere <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf use of "" static const int32 "" for return codes , not used anywhere _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on wed <date> <time> <number> _original description_ : in the table validation function "" cf \ _validateconfigtable "" it has return values declared locally as a set of "" static const int32 "" values : static const int32 no \ _ticks \ _per \ _second = - <number> ; static const int32 crc \ _alignment = - <number> ; static const int32 outgoing \ _chunk \ _size = - <number> ; because they are local , these values are not available to code outside this function , so nothing can ever check for these status codes ( and nothing ever does ) . the validation function caller only ever checks if the value is negative , and cf only checks if the <allcaps> tbl </allcaps> call returns something other than <allcaps> cfe </allcaps> \ _success . since cf is already sending an event with the validation failure details , this error code is not necessary and not relevant . it should be remove and replaced with one of the generic cfe \ _error constants .",2.0
"cf code style - use of side - effects statements within "" if "" <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf code style - use of side - effects statements within "" if "" _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on wed <date> <time> <number> _original description_ : cf uses many statements such as this to check the status of a call and store in a local variable : if ( ( status = <allcaps> cfe </allcaps> \ _sb \ _createpipe ( & cf \ _appdata . cmd \ _pipe , cf \ _pipe \ _depth , cf \ _pipe \ _name ) ) ! = <allcaps> cfe </allcaps> \ _success ) most other <allcaps> cfs </allcaps> code break this out into separate statements , i . e . status = <allcaps> cfe </allcaps> \ _sb \ _createpipe ( & cf \ _appdata . cmd \ _pipe , cf \ _pipe \ _depth , cf \ _pipe \ _name ) if ( status ! = <allcaps> cfe </allcaps> \ _success ) i believe <allcaps> gsfc </allcaps> coding standards also prefer the latter form . recommend updating these statements for readability .",2.0
"cf tests assume "" assert "" is available but do not include assert . h <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf tests assume "" assert "" is available but do not include assert . h _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on tue <date> <time> <number> _original description_ : some cf test utility functions call "" assert "" on various items ( e . g . any \ _file \ _directive \ _t \ _except ) . several issues with this : - the "" assert . h "" system header was not included - the condition "" <allcaps> error </allcaps> \ _retrieving \ _any \ _value "" is a constant that is not even <number> , so the assert will generally pass ( it is boolean true ) . recommendation is to use the utassert \ _abort ( ) function instead .",0.0
"cf assertions should not be compiled in when using "" release "" buildtype <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf assertions should not be compiled in when using "" release "" buildtype _originally submitted by_ : hickey , joseph p . ( <allcaps> gsfc </allcaps> - <number> ) [ <allcaps> vantage systems inc </allcaps> ] on tue <date> <time> <number> _original description_ : see also # <number> regarding the use of "" unlikely "" in this macro . when building with <allcaps> buildtype </allcaps> = release , the <allcaps> ndebug </allcaps> macro will be set . typically this turns off assertions in the code , but in cf this is not the case , it redefines cf \ _assert to a local handler instead . typically code will disable / compile - out assertion statements when in release mode , as they should never be triggered , so they just waste cycles .",0.0
"cf purge queue command opcode not defined <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf purge queue command opcode not defined _originally submitted by_ : maldonado , sergio e . ( <allcaps> gsfc </allcaps> - <number> ) [ arctic slope technical services , inc . ] on fri <date> <time> <number> _original description_ : the command opcode for purge queue is not present in the cf \ _cmds enumeration in cf \ _msg . h . it should be present with a value of <number> . the command dispatch table in cf \ _cmd . c does have an entry for the command , as well as the implementation . without the opcode defined , the command cannot be verified at the functional level .",0.0
"cf function cf_cfdp_processplaybackdirectory has an oddly bracketed block <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf function cf_cfdp_processplaybackdirectory has an oddly bracketed block _originally submitted by_ : gibson , alan s . ( <allcaps> gsfc </allcaps> - <number> ) on wed <date> <time> <number> _original description_ : in cfdp . c the function cf \ _cfdp \ _processplaybackdirectory has a block of code with no if / while et . just a bracketed block of code that does not seem to have a reason to be bracketed .",2.0
"cf function cf_cfdp_issender ( transaction_t * ti ) is odd one out because it uses ti <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf function cf_cfdp_issender ( transaction_t * ti ) is odd one out because it uses ti _originally submitted by_ : gibson , alan s . ( <allcaps> gsfc </allcaps> - <number> ) on tue <date> <time> <number> _original description_ : every other function in cfdp . c that uses a transaction \ _t * as an argument names it ' t ' , but cf \ _cfdp \ _issender uses ti .",2.0
"cf method cf_clist_remove appears to accept bad arguments <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf method cf_clist_remove appears to accept bad arguments _originally submitted by_ : gibson , alan s . ( <allcaps> gsfc </allcaps> - <number> ) on thu <date> <time> <number> _original description_ : a bad node is passed to cf \ _clist \ _remove , but it carries on unaware . this was found because branch <number> of <code> can only be covered by a test that passes this situation , node - > next = = node , node - > prev ! = node . the issue : should a single node enter , that has a node - > next = = node ( meaning : pointing to itself ) , but a node - > prev ! = node ( meaning : <allcaps> not </allcaps> pointing to itself ) , the code continues as if this is a valid state . it may be impossible for a bad node to enter here , but that is not apparent at the unit test level for cf \ _clist \ _remove nor is the doxygen brief clear on that assumption .",2.0
"unused event id <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] unused event id _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on tue <date> <time> <number> _original description_ : the event <allcaps> id cf </allcaps> \ _eid \ _err \ _pdu \ _bad \ _rx \ _msg \ _size appears to be unused .",2.0
"cf purge command does not appear to be hooked in <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cf purge command does not appear to be hooked in _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on tue <date> <time> <number> _original description_ : cf comments make reference to a purge command , and functions exist for that command . however , the command code referenced in the comments ( cf \ _purge \ _queue \ _cc ) does not appear to exist and there does not appear to be an equivalent one . _ ( link removed ) _ _ ( link removed ) _",2.0
"add transaction watchpoint concept for transaction complete notification <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] transaction watchpoint _originally submitted by_ : seeger , steven d . ( <allcaps> gsfc </allcaps> - <number> ) [ embedded flight systems , inc ] on thu <date> <time> <number> _original description_ : it might be useful for operators to have a concept of transaction watchpoints . this could be implemented with the spare <number> - bit per - channel register ( or the spare <number> - bit per - channel ) coupled with a ground command specifying a bit in that register to be set when a transaction is complete . the benefit here is a proc could request a watchpoint and wait for the bit to be set when the file is done . this is more useful than a file counter because polling directories being active could skew the file counter .",2.0
"investigate whether tx and <allcaps> rx pdu </allcaps> sizes need to be different <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] investigate whether tx and <allcaps> rx pdu </allcaps> sizes need to be different _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on mon <date> <time> <number> _original description_ : need to investigate uses cases where tx and <allcaps> rx pdu </allcaps> sizes need to be different . need to investigate the impact of making a change to allow that .",2.0
"improve commenting throughout cf v3 . <number> <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] improve commenting throughout cf v3 . <number> _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on mon <date> <time> <number> _original description_ : cf v3 . <number> needs improved commenting throughout . specifically : - file comments in every file describing the purpose of the file - explanations and limits for all configuration parameters - ensure that all comments are accurate",1.0
"cleanup cf v3 . <number> perf id handling <section> _imported from_ : [ <allcaps> gsfccfs </allcaps> - <number> ] cleanup cf v3 . <number> perf id handling _originally submitted by_ : timmons , elizabeth j . ( <allcaps> gsfc </allcaps> - <number> ) on fri <date> <time> <number> _original description_ : encompasses several findings from the cf v3 . <number> code review : - remove unused perf id cf \ _dirread \ _perf \ _id - determine whether perf ids cf \ _pdu \ _rcvd \ _perf \ _id and cf \ _vcxpdusent \ _perf \ _id should be added ( currently used in stakeholder ) - ensure that <allcaps> cfe </allcaps> \ _es \ _perflogexit is called when the app exits",2.0
"playback directory command - timing bug related to issue # <number> the playback queue is starting to process a new file after the end - of - file ( <allcaps> eof </allcaps> ) <allcaps> pdu </allcaps> is sent for an old transaction , while the old transaction isn ’ t truly finished ( and the ‘ active transactions ’ count decremented ) until the <allcaps> ack </allcaps> - <allcaps> fin pdu </allcaps> is received . due to this , one or more transactions can still be active waiting for their <allcaps> ack </allcaps> - <allcaps> fin pdu </allcaps> to be received while the playback queue starts a new transaction . if i had to guess , this is a relic of class1 ( unacknowledged ) transactions which end after the <allcaps> eof pdu </allcaps> is sent . this issue must have gone unnoticed for so long because in most cases it is hidden , as long as your files are reasonably large and your maximum number of simultaneous transactions is greater than <number> ( ours is <number> ) . this is because as long as the file is reasonably large , it will take more time to downlink the new file than it will take for the <allcaps> ack </allcaps> - <allcaps> fin </allcaps> from the old transaction to be received and fully closed out . since the playback queue only transfers one file at a time , you ’ ll only have a maximum of two transactions active at once . with maximum number of simultaneous transactions set to <number> , if you try to download <number> small files via the playback directory command we encounter the issue ( and is the case which found this bug in the first place ) . this is because the files are so small that <number> separate files can send all of their data and hit the ‘ <allcaps> eof </allcaps> ’ phase before the first transaction receives its ‘ <allcaps> ack </allcaps> - <allcaps> fin </allcaps> ’ and fully closes out . even if the files are quite large , if i set the maximum number of simultaneous transactions to <number> the issue is encountered every time and the second file will fail to download . this is because a new transaction always attempts to start while the old transaction was between the ‘ <allcaps> eof </allcaps> sent ’ and ‘ <allcaps> ack </allcaps> - <allcaps> fin </allcaps> received ’ phases . would it be valuable for me to submit a bug fix to this repository ? unsure if this repository is monitored .",0.0
"use of playback directory command i ' d expect the playback directory command to function like the following . assume <number> is the maximum number of transactions that can be occurring simultaneously and that the directory we are attempting to playback has <number> files in it : - all of the files in the directory get queued . - transactions are started for <number> files , at which point the maximum number of transactions is reached . - once <number> transaction finishes , cf reads from the queue and starts a transaction for the 8 th file . - continue until the entire directory has been downlinked . however , during our testing the command is functioning like the following : - all of the files in the directory get queued . - transactions are successfully started for <number> files , at which point the maximum number of transactions is reached . - cf also attempts to start transactions for the remaining <number> files at the same time , but they error out since we are at the maximum number of transactions . the remaining files are never downlinked . i am not sure if we are misunderstanding how the command is intended to be used or if there is a bug .",1.0
"request for configurable transaction packet <allcaps> mid </allcaps> in our use case , we want to use <allcaps> cfdp </allcaps> to send files from cpu1 to cpu2 and from cpu1 to ground . the two cpus are connected via <allcaps> sbn </allcaps> , and the connection between cpu1 and the ground station is through to and ci . i had thought to use the <allcaps> mid </allcaps> of <allcaps> cfdp </allcaps> packets to filter which packets are let through to and <allcaps> sbn </allcaps> . by setting up cf with two input channels and two output channels , each using separate mids , i could set to to only listen for packets from one channel and <allcaps> sbn </allcaps> to listen for packets on the other cf channel . it looks like all <allcaps> cfdp </allcaps> transfer packets use the cf_trans_tlm_mid , and that ’ s not configurable . would it be possible to add a configuration value in cf_cfgtable to set <allcaps> mid </allcaps> for output channels , similar to what is done for the input channels ? alternatively , is there a more standard way to do what i am attempting ?",2.0
does not work by default with <allcaps> osal </allcaps> <number> . <number> official release i am using the rc - <number> . <number> branch with cfe <number> and <allcaps> osal </allcaps> <number> . <number> . it does not build without the following changes : <number> . fsw / src / cf_callbacks . c : <number> - st_size should be filesize <number> . fsw / src / cf_playback . c - all references to os_dirent_t ' s d_name entry should be changed to filename .,3.0
"missing newline at end of sample_lib . c <section> clang throws an error about the missing newline at the end of sample_lib . c <section> add a new line , they are pretty cheap these days . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"remove explicit file name references in doxygen file comments to avoid warnings <section> file comment without a filename implies the comments apply to the current file . adding the file name makes doxygen try to match that file . the issue is there ' s multiple files with the same name , so doxygen gets confused unless you add full path . really it ' s just overhead since the point is to comment the current file . sample warning if you <code> from the bundle : ` ` <code> os - impl - binsem . c ' supplied as the second argument in the \ file statement matches the following input files : / home / jhageman / cfs / cfs - github / osal / src / os / posix / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / rtems / src / os - impl - binsem . c / home / jhageman / cfs / cfs - github / osal / src / os / vxworks / src / os - impl - binsem . c please use a more specific name by including a ( larger ) part of the path ! ` ` ` <section> easiest to just remove the name since for every case the comment applies to the current file <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",1.0
"fix # <number> , correct minor markdown and comment typos <section> - fix # <number> fixed a few minor typos in the text of <allcaps> security </allcaps> . md , and in the comments of : - unit - test / cmakelists . txt - libc_string_stubs . c <section> none ( non - executable code ) . <section> none ( minor markdown doc and comments changes only ) . <section> n / a <section> n / a <section> n / a",1.0
fix non - compliant header guards <section> leading <code> is reserved : <url> <url> <url> <url> <section> match cfs standard pattern : <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add a functional test example <section> apis should have functional tests that verify implementation within operational context ( full stack , not stubs ) . coverage tests can not fully exercise intended functionality since they utilize stubs . <section> add example use of the cfe functional test framework <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add input and output parameters to sample_lib_function to show more advanced generic stubs / hooks <section> sample_lib_function takes no parameters , so can not show example of registering them and using a hook . <section> add parameters ( both pass by value and reference ) , update stubs to use suggested pattern : <code> follow on add a hook ( likely from sample_app ) , register and show use of <code> . <section> there are plenty of implementations in core already , but hard to tell what the "" gold standard "" is . need to trade complexity / simplicity though . <repeated> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the sample_lib repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the sample_lib repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"scrub for include < > vs "" "" use ( < > should be system only ) <section> < > used on non - system header includes . example : <url> <section> full scrub / fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for sample_lib or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing sample_lib or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / sample_lib is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / sample_lib while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add static analysis and format check <section> fix # <number> - adds static analysis and format check into github workflow , includes badges in readme <section> ci <section> basic ci works again <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for sample_lib . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
refactor ut_setforcefail describe the bug ut_setforcefail was refactored to ut_setdefaultreturnvalue for <url> it needs to have its name changed here as well . expected behavior change ut_setforcefail to ut_setdefaultreturnvalue additional context part of <url> reporter info alex campbell,2.0
"rename files , functions , and variables to match libname_ * pattern <section> naming convention in sample_lib is not entirely consistent - some names start with <code> , others just <code> . <section> all variables , functions , and other identifiers should use a <code> prefix . <section> a clear and concise description of any alternative solutions or features you have considered . <section> see nasa / sample_app # <number> . when fixing that , noted some issues in here too . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , install unit test to target directory <section> fix # <number> , install unit test to target directory <section> make unit tests , install , observe they install in correct directory <section> correct install directory <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"coverage test not installed in correct directory <section> coverage test not installed in correct directory - see nasa / cfe # <number> <section> make unit tests , make install , observe unit test in build directory . <section> should go in target directory ( build / exe / cpu1 for sample config ) <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , install unit test <section> fix # <number> - install unit test as part of cmake recipe <section> normal build with enable_unit_tests = true , with make install , and ran sample lib unit test from install dir ( passed ) <section> sample lib test runner now shows up in expected install dir <section> - hardware : cfs dev vm - os : ubuntu <number> - versions : current bundle development branch <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
unit test does not get installed <section> missing unit test from install directory <section> install <section> n / a <section> same as nasa / sample_app # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"add build name and build number to version . h <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"fix # <number> , apply standard style <section> whitespace changes only . fix # <number> <section> ci - <url> <section> none <section> - hardware : ci - os : ubuntu <number> - versions : bundle w / all whitespace change commits <section> note - not enforcing , just a single cleanup since there ' s no pending activity in this repo . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , update coverage compile / link flag options <section> <allcaps> osal </allcaps> now sets these as ut_coverage_compile_flags , ut_coverage_link_flags . building and linking the ut executable needs a corresponding update . fixes # <number> <section> build with <code> and confirm that all unit tests are building <section> coverage data ( <code> ) now includes the sample_lib code again <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> joseph hickey , vantage systems , inc .",0.0
"unit tests need to link with ut_coverage_compile_flags / ut_coverage_link_flags <section> nasa / osal # <number> cleans up the compiler flag management , and as part of this it exports two variables , ut_coverage_compile_flags and ut_coverage_link_flags , rather than a single ut_c_flags value . <section> the unit tests need to use these variables , not ut_c_flags . <section> needs to be included with the nasa / osal # <number> merge . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , fix doxygen warnings <section> fixes # <number> to resolve doxygen warnings <section> steps taken to test the contribution : <number> . corrected lines that generated warnings <number> . rebuilt documentation with <code> <number> . observed no warnings generated <number> . viewed relevant page ( s ) to verify correctness <section> changes to documentation only ; no code impact <section> leor bleier , <allcaps> nasa </allcaps> \ <allcaps> gsfc </allcaps>",1.0
fix doxygen warnings <section> warnings are generated when building the documentation . <section> steps to reproduce the behavior : <number> . do <code> from the cfs directory <number> . observe the warnings in <code> <section> no warnings should be generated <section> leor bleier <allcaps> gsfc </allcaps> \ <number>,0.0
apply standard code style <section> inconstant style <section> see <url> and <url> <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , release prep <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release <number> . <number> prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , unit test for <allcaps> sample </allcaps> lib <section> fixes # <number> implements a coverage test for sample_lib code as well as a stub library to facilitate unit test of external code that calls functions within sample_lib . <section> build with <allcaps> simulation </allcaps> = native enable_unit_tests = <allcaps> true </allcaps> confirm normal <allcaps> cfe </allcaps> operation is unaffected confirm unit tests all pass , including new test of "" sample_lib "" confirm "" lcov "" report now includes sample_lib , and coverage is <percent> <section> this adds a new test for "" sample_lib "" which is part of the make test target , and the line coverage reports now include sample_lib . <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> the coverage test cases are written assuming that previous pull request # <number> is already merged . that is , they exercise / test the logic that was added in this . therefore this commit is a child of the commit for the previous pull request . <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"add unit test example for sample_lib <section> the <allcaps> sample </allcaps> library does not implement any unit test . actual <allcaps> cfe </allcaps> libraries would typically need to do this . <section> a unit test should be implemented to provide a template for implementing a library unit test ( code coverage ) using the current framework . <section> the unit test for an application ( e . g . in sample_app , as in nasa / sample_app # <number> ) is slightly different , as the application typically would not need to expose stubs but a library would . therefore both sample_app and sample_lib should implement unit tests . <section> joseph hickey , vantage systems , inc .",2.0
"add at least one conditional for unit testing <section> in the process of providing useful examples for unit testing , the sample lib should contain at least one "" if "" statement to demonstrate how the alternate paths can be exercised in ut . <section> add a call to a simple c library function during <code> , and have an alternate return code ( not cfe_success ) as based off the result . unit test can then force the alternate path to execute . <section> n / a <section> this will add considerable value to the ut examples <section> joseph hickey , vantage systems , inc .",2.0
"enhanced version reporting use ci_lab_version from cfecfs_version_info . h if available and report on <allcaps> noop </allcaps> and startup ( along with classic version numbering ) classic version numbering can then just be updated on release , vs for every commit .",2.0
remove classic build support only supporting cmake build going forward .,2.0
"remove old <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",2.0
"fix # <number> , update command code underscores for consistency testing performed * * github ci actions all passing successfully ( incl . unit tests and build + run ) . <section> no change to behavior . improved consistency and clarity . <section> avi weiss <user>",2.0
"fix # <number> , convert <code> return codes and variables to <code> testing performed * * github ci actions all passing successfully . <section> no change to behavior ( no types have actually changed with this pr ) . <code> is more expressive and improves consistency with cfe / cfs . <section> avi weiss <user>",2.0
cs <code> return codes and variables should be converted to <code> expected behavior * * use the more expressive <code> and improve consistency with cfs . <section> avi weiss <user>,2.0
"fix # <number> , move function prototypes out of <code> testing performed * * github ci actions all passing successfully . <section> no change to app behavior . cs now more consistent with the other cfs apps . <section> avi weiss <user>",2.0
"function prototypes can be moved out of <code> expected behavior * * unless these are specifically being kept private , it seems better to keep cs consistent with the other apps and move these to the header file . <section> avi weiss <user>",2.0
"all <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> messages should put content in a "" payload "" sub - structure to match the patterns used in <allcaps> cfe </allcaps> and other modules , all <allcaps> cmd </allcaps> / <allcaps> tlm </allcaps> message definitions should put the content ( non - header ) parts into a separate struct called "" payload "" . <section> separate message content into a sub structure called "" payload "" . <section> this is benefit to tooling that can use the presence of this field to identify where the actual content starts ( e . g . something like <code> would work and be correct , as opposed to checking <code> which may not actually reflect where the content starts due to possible compiler - added padding between them ) . <section> joseph hickey , vantage systems , inc .",2.0
"incorrect size passed to "" strncmp "" the size passed to <code> here is not correct : <url> the <code> string being compared here is sized on <code> , not <code> , as declared here : <url> <section> build with <allcaps> gcc </allcaps> <number> and full warnings enabled , this is reported . <section> use <code> to avoid this possibility <section> debian <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , adds null termination to table name processing - fixes # <number> <section> make build and lcov <section> no impact to behavior <section> - os : ubuntu <number> <section> n / a <section> n / a <section> justin figueroa , vantage systems",2.0
"cs_tableinit - cyclomatic complexity of <number> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . cs_table_processing . c : : cs_tableinit <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up cs_tableinit such that it has a cyclomatic complexity of <number> or less . <section> justin figueroa , vantage systems",2.0
"cs_processnewtablesdefinitiontable - cyclomatic complexity of <number> <allcaps> nasa </allcaps> guidelines in <allcaps> npr </allcaps> <number> . 2 d recommends maintaining a cyclomatic complexity in software , in particular flight software of <number> . cs_table_processing . c : : cs_processnewtablesdefinitiontable <url> unnecessarily violates the recommendation with a cyclomatic complexity of <number> . <section> clean up cs_processnewtablesdefinitiontable such that it has a cyclomatic complexity of <number> or less . <section> justin figueroa , vantage systems",2.0
"improper null termination of table names it is not guaranteed that the source or destination arguments of <code> for table entry names assure null - termination . many standard functions such as strcpy , strlen , strcmp among others rely on arrays of characters to be null terminated . <section> <code> <url> alternatively considered : fm strncpy approach <url> however , this approach will not necessarily handle non - terminated sources properly . <section> <url> <url> <section> imported from <allcaps> jsc </allcaps> static analysis audit <section> the source table data was loaded via <code> so yes it came from a file which should be considered "" untrusted input "" . therefore , there is no guarantee that defentry - > name ( the source here ) is null - terminated . however , the current implementation is relying on the assumption that the source and dest are the same length , and thus the function will not read more than it writes , so it ' s safe - ish . <section> justin figueroa , vantage systems",2.0
"table processing : strncmp incorrect size argument ( cfe_tbl_max_full_name_len ) while compiling the latest version of cs , my build environment gave me the following error : <code> <section> the bug relates to this line : <url> based on checking the types for both table entries ( <code> ) , it seems that it would make sense to instead do the strncmp like so : <code> after changing to this locally , my build works fine .",0.0
"requirement verification failure <section> the following requirements fail verification testing because for each - an event message is sent , but checksumming is not disabled : <number> ( user memory ) cs shall send an event message and disable checksumming of the user - defined memory , if the state is not one of the following : a ) enabled b ) disabled c ) empty <number> ( user memory ) if the address range for any of the user - defined memory is invalid , cs shall send an event message and disable user - defined memory checksumming <number> ( tables ) cs shall send an event message and disable table checksumming , if the state is not one of the following : a ) enabled b ) disabled c ) empty <number> ( apps ) cs shall send an event message and disable application code segment checksumming , if the state is not one of the following : a ) enabled b ) disabled c ) empty <number> ( non - volatile ) cs shall send an event message and disable non - volatile checksumming , if the state is not one of the following : a ) enabled b ) disabled c ) empty <number> ( non - volatile ) if the address range for any of the non - volatile segments is invalid , cs shall send an event message and disable non - volatile checksumming <section> checksumming will need to be disabled in each case or the requirements will need to be updated <section> example from cs_table_processing . c : if ( result ! = cs_table_error ) { cfe_evs_sendevent ( cs_val_eeprom_state_err_eid , cfe_evs_eventtype_error , "" eeprom table validate : illegal state field ( 0x % 0 4 x) found in entry id % d "" , ( unsigned short ) statefield , ( int ) outerloop ) ; result = cs_table_error ; } <section> dan knutsen <allcaps> nasa </allcaps> goddard",0.0
"fix # <number> , apply consistent event id names to common events testing performed * * only github ci actions . <section> no impact on code behavior ( no logic changes ) . consistent event id names for the events which are common to all / most cfs components and apps will improve consistency and ease make code review / debugging easier . <section> avi weiss <user>",2.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
resolve issues building users guide with ubuntu <number> / doxygen <date> doxygen warnings for <code> <section> resove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"remove stray <allcaps> todo </allcaps> and empty else condition <url> <section> there ' s no action for the else case , remove ( along with the <allcaps> todo </allcaps> note ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
remove stray terminators <url> <section> remove <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old cs clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template - fixes # <number> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset and cfe_psp_memcpy use on addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"add scrubbing support for libraries cs currently does not support scrubbing libraries . this could be implemented now that ticket <url> is implemented . <section> add a field in the app table to specify whether or not an entry belongs to an app or a lib and call the appropriate <allcaps> api </allcaps> functions accordingly <section> add a separate dedicated lib table , or perhaps call cfe_es_getappidbyname first and if that fails , call cfe_es_getlibidbyname , then call cfe_es_getmoduleinfo ( ) to get the addresses to scrub <section> john n pham , northrop grumman",2.0
"use fixed size types for addresses and address offsets in tables / tlm / cmd changing telemetry and table sizes depending on platform ( <number> vs <number> bit ) when using the cpuaddr type in structures . <section> use cfe_es_memaddress and cfe_es_offset types for tables and telemetry and define those types as <number> bits . if space is an issue , users can redefine these types as <number> - bit . from <allcaps> ccb </allcaps> : <number> - <number> - <number> <url> > > - cpuaddress type will "" change size "" . use cfe_es_memaddress and cfe_es_offset types for tables and telemetry > - open new issue to address and discuss with customers > _originally posted by <user> in <url> <allcaps> edit </allcaps> : <code> and <code> are the actual types that should be used <section> leave as is , redefine telemetry sizes based on platform in the "" ground system "" <section> none <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps>",2.0
"add child task name to platform config file stakeholder suggestion - not all platforms support all task naming conventions , make configurable . unfortunately the platforms w / issues were not mentioned in the original issue so it ' s not clear if this is really relevant / necessary anymore . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"<allcaps> cs crc </allcaps> values may lead to confusion the cs application relies on the cfe_es_calculatecrc function to report the crcs that it calculates . however , this function calculates the <allcaps> crc </allcaps> as an int16 value and returns that value as a uint32 value . this causes the sign bit of the int16 ( bit <number> ) to be propagated to the upper <number> bits of the uint32 . if this bit is set , it can cause confusion since a <allcaps> crc </allcaps> of 0x 8 4 5 e would result in the cs application having a value of 0 xffff845e . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"es - registeredtasks counter does not decrement when child tasks are exited stakeholder reported that the es "" registeredtasks "" counter was not decrementing when a child task exited . the cs code was examined to ensure the needed <allcaps> es api </allcaps> calls were being made . it was confirmed the cs child tasks make the <allcaps> es api </allcaps> call to cfe_es_exitchildtask . the cfe_es_exitchildtask <allcaps> api </allcaps> function does decrement the registeredtasks counter on line <number> however , this step is performed only if conditional checks are passed . really cs should not dynamically be creating / exiting child tasks per a separate issue , but noted here still since it was an observed issue ( although no steps provided to recreate ) . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"checksum errors after restarting app summary scenario <number> . application gets an exception <number> . es restarts the application <number> . there is a high probability that the application checksum has changed due to the restart . <number> . checksum is not notified to recompute the application checksum . when it finds the checksum has changed , it puts out an event message to that effect . <number> . hs is monitoring for application checksum messages , and does a processor reset as a consequence . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
cs child tasks are dynamically created cs creates child tasks dynamically in several command functions : - - cs_recomputebaselinecfecorecmd - - cs_recomputebaselineoscmd - - cs_oneshotcmd is there any risk of cleanup issues if these commands are run too frequently ? cs could be modified to create the child tasks just once and then kick them off when a command is received ( perhaps using a semaphore mechanism like fm ) . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"configuration parameters could exist in configuration table some parameters in cs_platform_cfg . h could be made part of a configuration table to provide more on - orbit flexibility . for instance , number of bytes per wakeup or child task delay time . finding from code review . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
consolidate similar commands several command handler functions are nearly identical . could be consolidated . cs_disableappcmd / cs_enableappcmd cs_disablenameappcmd / cs_enablenameappcmd cs_disableeepromcmd / cs_enableeepromcmd cs_disablememorycmd / cs_enablememorycmd cs_disableentryidmemorycmd / cs_enableentryidmemorycmd cs_disabletablescmd / cs_enabletablescmd cs_disablenametablescmd / cs_enablenametablescmd imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
consider replacing switch statement with jump table in cs_backgroundcheckcmd finding from code review imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
consider making the <allcaps> crc </allcaps> size configurable there are two <allcaps> crc </allcaps> algorithm types specified in the platform config . are both of these using <number> - bit <allcaps> crc </allcaps> ? what if we add another <allcaps> crc </allcaps> algo later that is not <number> - bit ? it might make sense to define the type that holds a <allcaps> crc </allcaps> result in platform config as well . comment is on the cs_computeeeprommemory function regarding the uint32 computedcsvalue parameter . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"unable to functionally test app <allcaps> crc </allcaps> miscompare description : if the application ' s code segment <allcaps> crc </allcaps> is not equal to the corresponding application ' s baseline code segment <allcaps> crc </allcaps> , cs shall increment the application code segment <allcaps> crc </allcaps> miscompare counter and send an event message . was not able to generate a miscompare when reloading a different version of the reqval_app . loaded reqval_v500 which should have incremented the following error counter : appcserrcounter and also generated an event <number> - likely resolution will be to verify via "" analysis "" , aka unit test if reloading an app can not cause the miscompare . future work might support getting the module address , use mm to "" corrupt "" the memory to cause the miscompare . imported from <allcaps> gsfccfs </allcaps> - <number>",3.0
"resolve static analysis issues relative to unit tests many actual code issues ( uninitialized variables , buffer overruns , etc ) identified via static analysis in the unit tests . all actual "" bugs "" should be resolved . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"static analysis issues relative to flight code handful of static analysis issues in the "" red "" identified ( non - style issues ) . need to resolve these . filter : - file : elf - file : ut - file : cfe - file : os - file : cf_ - file : _lab_app . c ! ( significance : style ) should resolve and / or disposition the higher ranked ones at minimum . note license restricts publishing issues . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
cs : implicit padding being added to definition and results tables implicit padding is being added to multiple data structures in cs_tbldefs . h . this creates a problem because we would need to maintain different definition files for decomming the data between our linux and sp0 systems . affected data structures : cs_res_app_table_entry_t cs_res_tables_table_entry_t cs_res_eeprommemory_table_entry_t cs_def_eeprommemory_table_entry_t imported from <allcaps> gsfccfs </allcaps> - <number>,0.0
"fix # <number> , refactor <code> to reduce <code> duplication testing performed * * github ci actions all passing successfully ( incl . build + run , unit / coverage tests etc . ) . <section> no change to behavior . <section> avi weiss <user>",2.0
"fix # <number> , refactor lc_tableinit to remove multiple returns testing performed * * github ci build + run , unit tests all passing successfully . <section> essentially no change to logic . previous early <code> exit points will now fail all the following tests for <code> and fall through to the end of the function , where <code> is returned . <section> avi weiss <user>",2.0
"buffer overflow in unit tests when using default config the unit test code sets the <code> member with a call to strncpy and a hardcoded size here : <url> however in the default platform config the size is only <number> : <url> <section> build and run using default / out - of - box config . <section> example configuration should not trigger buffer overflow <section> consider using <code> operator here , to adapt the <code> call to the real size of the target buffer . <section> joseph hickey , vantage systems , inc .",0.0
"lc "" isnan "" check relies on platform - defined behavior ( non - standard ) with floating point watchpoints , the watch point checking code looks for the ieee754 not - a - number ( nan ) value before doing other comparisons . however , the method used for checking this involves accessing the <code> value as a <code> , and checking the bits per ieee754 . this type of action is not standardized by the c language , and results of doing this are platform - defined . <section> n / a ( it does work as intended on most compilers , it is just not standard or portable "" by the book "" ) <section> should only rely on behavior that is specified by <allcaps> iso c </allcaps> . regarding nan , the c standard does guarantee that a nan is never equal to any other value , even itself . therefore , the generally recommended , portable way to check for nan is by checking that , e . g . : <code> <section> code at issue is here : <url> <section> code inspection when doing <allcaps> eds </allcaps> implementation <section> joseph hickey , vantage systems , inc .",0.0
remove remaining stray references to old event types expected behavior * * update to new event type constants or remove these commented - out tests . <section> <url> <url> <section> avi weiss <user>,2.0
"items instantiated in header causes duplicate definitions and link errors the unit test header file <code> instantiates objects directly in the header file , which breaks if it is ever included in more than one c file . <section> build lc with unit tests enabled , get lots of linker errors : ` ` <code> wdtable ' ; cmakefiles / coverage - lc - lc_action - testrunner . dir / lc_action_tests . c . <surprise> / home / joe / code / cfecfs / github / apps / lc / unit - test / utilities / lc_test_utils . h : <number> : first defined here / usr / bin / ld : libcoverage - lc_internal - stubs . a ( lc_test_utils . c . o ) <annoyed> home / joe / code / cfecfs / github / apps / lc / unit - test / utilities / lc_test_utils . h : <number> : multiple definition of <code> ` ` <section> build should work ? <section> <url> <section> ubuntu <section> i was just trying to build lc "" out of the box "" - not modified in any way - and it failed badly . not sure how this ever built or passed any validation testing with this the way it was . <section> joseph hickey , vantage systems , inc .",0.0
variables declared mid - function expected behavior * * all variables should be declared at the top of the function . <section> avi weiss <user>,2.0
"fix # <number> , refactor lc_sampleaps to remove extraneous if statement testing performed * * github ci actions ( incl . build + run , unit tests etc . ) all passing successfully . <section> intent of the code remains basically unchanged , although the logic has changed slightly . main change is that <code> is checked as valid before any sampling of action points , whereas previously this was only checked in the single action point sample condition - i . e . <code> <section> avi <user>",2.0
inconsistent event id naming expected behavior * * apply consistent event id names to the events which are common to all / most components and apps . <section> invalid message id : <code> <code> <code> <code> <code> <code> <code> <code> <code> initialization : <code> <code> <code> <code> <code> <code> <code> <allcaps> noop </allcaps> : <code> <code> <code> <code> <code> <code> reset counters : <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> <code> etc . <section> avi weiss <user>,2.0
"multiple return statements in lc_createtaskcds and lc_tableinit multiple returns are a coding style violation , and the implementation is challenging to follow ( see # <number> and others ) . <url> <url> <section> single entry / exit point from functions . refactor to simplify flow . <section> none <section> could group w / multiple issues or tackle by file . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , updates <allcaps> cla </allcaps> information for apache <number> deletes old lc clas , removes language in contributing . md of app - specific <allcaps> cla </allcaps> , adds link to new clas in pull_request_template . md and contributing . md - fixes # <number> - fixes <url> <section> visually inspected links in fork and in pr template . <section> all references to clas should be updated to the cfs app <allcaps> cla </allcaps> . <section> google chrome browser <section> none <section> justin figueroa , <allcaps> asrc </allcaps> federal",1.0
"update <allcaps> cla </allcaps> information have new clas given the change in <url> with the combined <allcaps> cla </allcaps> , <section> - [ ] update the instructions in each app ' s contributing . md - [ ] delete old <allcaps> cla </allcaps> pdfs - [ ] update pr and issue templates as needed <section> none <section> none <section> gerardo e . cruz - ortiz",1.0
remove cfe_psp_memset use for addresses in <allcaps> ram </allcaps> should just use memset / memcpy for addresses in <allcaps> ram </allcaps> . the <allcaps> psp </allcaps> functions serve no use in this context . <section> replace with memset / memcpy . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"static analysis workflow failure due to style warnings strict cppcheck warnings cause static analysis workflow to fail , see <url> <code> <section> fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"static analysis issues relative to flight code handful of static analysis issues in the "" red "" identified ( non - style issues ) . need to resolve these . filter : - file : elf - file : ut - file : cfe - file : os - file : cf_ - file : _lab_app . c ! ( significance : style ) should resolve and / or disposition the higher ranked ones at minimum . note license restricts publishing issues . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
remove all mentions of <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts from documentation some of our doxygen docs still reference <allcaps> asist </allcaps> or <allcaps> itos </allcaps> artifacts . see cfs_mm repo : fsw / src / mm_msgdefs . h : l28 imported from <allcaps> gsfccfs </allcaps> - <number>,1.0
apps should use cfe_msg_ptr macro instead of cast or local unwrapping apps typically cast to a cfe_msg_message_t or use * . msg . better to use abstracted cfe_msg_ptr . <allcaps> note </allcaps> - not backwards compatible with caelum so recommend not addressing in draco . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"lc hash logic comments only applicable to v1 message ids if the v1 message id is not used , theoretically the hash could collide up to the entire length of the linked list . at minimum the comments should reflect the possibility for more hash collisions , but might be worth reconsidering implementation or reporting collision depth . imported from <allcaps> gsfccfs </allcaps> - <number>",1.0
"lc : consider making states into enums in lc_msgdefs . h , lc states could be made into enums imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
refactor lc_sampleapreq and lc_housekeepingreq the functions lc_sampleapreq and lc_housekeeping req could be refactored to use a loop instead of the multiple switch statements . the final if condition in lc_sampleapreq could also be refactored to reduce the nesting . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"refactor lc_sampleaps the function lc_sampleaps can be refactored - the "" if ( startindex = = endindex ) "" condition can be removed . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"suggest reversing order in which ap / wp telemetry is stored lc builds ap / wp status / results starting with most significant bits first . i . e . ap <number> state in most significant <number> bits , then ap <number> results , then ap <number> state , and ap <number> results in least significant bits . when doing an array of bit fields , would be nice to have ap <number> in the most significant bits . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
should results tables be critical tables instead of stored to <allcaps> cds </allcaps> the watchpoint results table and actionpoint results table are currently saved to the <allcaps> cds </allcaps> on the housekeeping request interval ( see functions lc_updatetaskcds and lc_housekeepingreq ) . should these tables be critical tables instead ? imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
lc_tableinit helper functions should be moved to their own file lc_tableinit has several helper functions that it calls while running . these calls have many different variations and effects upon what happens in lc_tableinit . this makes it very difficult to unit test because there is too much variation in the helper functions to attempt to keep adequate track of what may or may not be happening . if these helper functions were moved to their own . c file they could be wrapped and stubbed for testing lc_tableinit . this would simplify the unit testing process . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"lc sets the ttofvalue when it transitions from <allcaps> stale </allcaps> to <allcaps> false </allcaps> while testing lc against cfe <number> , the lc_noaction test procedure failed because values were contained in the ttofvalue when they were not expected . the transition from <allcaps> stale </allcaps> to <allcaps> false </allcaps> seemed to set these values . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"support platform - endian byte order in <allcaps> wdt lc </allcaps> should support numerical telemetry data types that are platform - endian . while it would be possible to get the same effect with an <hashtag> if </hashtag> macro block , it would make the table very hard to read . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
"lc - more deterministic behavior currently lc will process messages when they are received , which is fine , generally . also , currently , lc uses a single pipe for commands and for watchpoint telemetry . lc does not process action points until it receives a command message . but in deterministic environments it may be better to have lc be commanded to read telemetry as well as be commanded to process action points . this will necessitate having a separate message pipe for commanding ( which the main loop would block on ) and a telemetry pipe ( which would accumulate telemetry until the command to read . ) the default lc behavior should remain the same ( process messages as they arrive . ) this should be a compile - time option , or perhaps run - time command - able . imported from <allcaps> gsfccfs </allcaps> - <number>",2.0
lc : support <number> - bit types lc currently does not support <number> - bit integers or floats ( doubles ) . imported from <allcaps> gsfccfs </allcaps> - <number>,2.0
"lc transitions active action points to passive when application is in passive mode during a stakeholder rehearsal there were several aps that were commanded "" active "" while the lc application state was in "" passive "" mode . before operations could command the application state to "" active "" mode , some of the aps that were activated and had "" tripped "" causing the ap to transition back to passive mode . the purpose of changing a "" tripped "" aps state from active to passive is to prevent an <allcaps> rts </allcaps> from getting initiated more than once . in "" passive "" mode , lc performs all limit tests as in "" active "" mode , but no stored command sequences are invoked as the result of ap failures . having the ap ' s state transition while the application is in passive mode will make enabling aps with a low threshold while lc is in passive mode very difficult . the rational for this design feature needs to be clearly understood and documented . the lc user ' s guides ( both doxygen and word / pdf ) do not make this design feature clear . if no rational exists this design feature should be removed from lc . imported from <allcaps> gsfccfs </allcaps> - <number>",0.0
"<allcaps> adt </allcaps> table size limit hello , i would like to know if it is possible to increase the <allcaps> wdt </allcaps> table size ( lc_max_actionpoints ) . how much i can extend the size of <allcaps> wdt </allcaps> table ? how many <allcaps> ap i </allcaps> can define ? is there any limit ? thanks .",3.0
update ci pipeline to use github actions the existing travis ci pipeline is out of date and no longer functional . we should migrate to using github actions to get the pipeline working again .,0.0
"support for multiple user - defined commands the current way the <allcaps> eci </allcaps> handles commands by using the eci_cmd_mid does not support any more than <number> custom command . this problem has to do with the limitation that when declaring the buffer / object to store the received command data , the <allcaps> eci </allcaps> can not determine which object to use by only using the eci_cmd_mid . in particular , the problem can be isolated to the behavior for non - eci_cmd_mid values in the default of the switch statement processing commands <url> <code> rcv_msg ` function , the same checks for the length and updates to the cmderrorcounter still happen so no other changes should be needed .",0.0
"broken links to example code in documentation at some point the links to the example code have been broken and now appear empty . this problem , on first glance , only seems to affect the <code> file referenced for the creating eci interface <url> but we should probably check to make sure this did not affect anything else .",0.0
<number> fix <allcaps> cds </allcaps> implementation * update name of <allcaps> cds </allcaps> table in <allcaps> eci </allcaps> code ( expected to be provided by eci_interface . h ) * add <allcaps> cds </allcaps> table to example as test case * fix undeclared status variable in <allcaps> cds </allcaps> handling * update spec to reflect new <allcaps> cds </allcaps> variable name,0.0
"fix <code> undefined the <allcaps> sil </allcaps> is currently in the process of implementing the <allcaps> eci </allcaps> ' s <allcaps> cds </allcaps> interface and currently cannot compile with <allcaps> eci </allcaps> because it does not define <code> , which is the structure <allcaps> eci </allcaps> expects to contain the definition of the <allcaps> cds </allcaps> elements . it defines that structure as <code> . normally the <allcaps> sil </allcaps> would need to align with <allcaps> eci </allcaps> definitions , however , the <allcaps> sil </allcaps> ' s name is better ( does not look like a macro , is clear that its a table ) , and so in this case the <allcaps> eci </allcaps> should be updated . i do not believe there are currently any test cases using <allcaps> cds </allcaps> in the <allcaps> eci </allcaps> repo , so this update should only require modification to the <allcaps> eci </allcaps> source code .",0.0
"fix <code> undefined <code> includes all <allcaps> eci </allcaps> header files after including <code> because some defines in <code> influence the code implemented in <code> . this is intended , however , <code> used <code> ( defined in <code> ) if commands are defined , which causes compilation to fail . need to update include order . also need to ensure an test suite includes and example of an app with a command to catch this in the future .",0.0
"add check for command <allcaps> apid </allcaps> when command queue defined the segfault in issue # <number> was caused by specifying a command <allcaps> mid </allcaps> with a message not defined as a command ( and which thus had no queue defined for it ) . the <allcaps> eci </allcaps> code blindly attempted to utilize the queue which did not exist , causing the segfault . during the course of resolving that issue it was determined that a check can be done here <url> to confirm the that there ' s a queue allocated if the <allcaps> mid </allcaps> indicates the message is a command . that check would look something like if <code> , issue an error event message warning the user about a misconfiguration , and either * skip the configuration of the queue for that message ( if we can establish that the app will still work without it ) * exit the app , if its going to be too broken to function work needs to be done to determine the correct course of action and implement this check .",2.0
"add support for custom <allcaps> ccsds </allcaps> commands through the <allcaps> eci </allcaps> header it ' s been a commonly requested internal feature to add support for custom commands as part of the <allcaps> eci </allcaps> . currently , the only commands supported are housekeeping and noop but these are standard across apps . this feature should not impact the performance of any other parts of the <allcaps> eci </allcaps> and can be included as part of the eci_interface header file . the structure exposed should look like : <code> where function code is a <number> byte value to identify the command and the function pointer is a c style function pointer to the function to execute once the command is received . to reduce the boiler plate code needed to be written , we also include an extra field containing the structure to fill with command information . more information on the <allcaps> ccsds </allcaps> packet protocol can be found here <url> under section <number> . <number> : "" packet secondary header "" . the <allcaps> cfs </allcaps> uses only the ancillary field of the secondary packet header and the relevant portion for this issue will be 0x 7 f00 > > <number> defined as the function code of the command message .",2.0
"add a tutorial on how to build the docs locally even though the new documentation automatically gets pushed into github pages , we still need instructions to build locally .",1.0
alter the sample app compiler flag to satisfy the cfs - groundsystem the latest commit of the cfs - groundsystem includes glibc specific features specifically the inclusion of the <code> . the addrinfo struct definition is only exposed in gcc when passed a gnu compliant standard ( the current test cmake definition uses <code> ) . more information on the topic of c standard compliance vs the <allcaps> gnu </allcaps> libraries can be found on this stack overflow post : <url>,0.0
fix the spelling error in to_lab for testing a recent commit to the master branch of to_lab fixed a spelling mistake <url> which needs to be reflected in the to_lab sub table header in the testing files .,0.0
no examples of using <allcaps> eci </allcaps> for <allcaps> cds </allcaps> management none of the examples provided give any insight on how to manage the <allcaps> cds </allcaps> using the internal <allcaps> eci </allcaps> mechanisms .,2.0
"add checks to make sure each required macro is set in addition to the documentation mentioning what macros need to be set in the interface file for an app , there should be a compile time warning alerting the user to undefined values . it might also be prudent to add validity checks against the entered values ( for example when a bad <allcaps> mid </allcaps> was provided or a name exceeds a max value for the cfe ) .",2.0
"add an explanation of the message id ' s used by <allcaps> eci </allcaps> since <allcaps> eci </allcaps> expects certain macro ' s to be defined for the system to work , these macro names should be added to the documentation . currently , there is a reference that needs to link to this page in the doxy branch .",1.0
"update the documentation for each of the <allcaps> eci </allcaps> structures even though everything was converted into auto - doc comments for doxygen , the content has been lacking . specifically , we need to document the members of the structures provided for use in the <code> file since it ' s more user facing . for maintainability , each structure should have a good explanation of it ' s intended use and a brief explanation of it ' s members .",1.0
"provide a tutorial describing what ' s needed to build an app with <allcaps> eci </allcaps> the previous approach of directing people to the automated build system leaves some holes when trying to explain how to integrate an app with <allcaps> eci </allcaps> . to combat this , we should provide an explanation of how to build an <allcaps> eci </allcaps> app in both the cfe make and cmake build systems . information for building a <number> <allcaps> eci </allcaps> app can be found here <url> but there is not any explanation of how to build with cmake .",1.0
provide a walk through of the main components of the <allcaps> eci </allcaps> we have had a large amount of questions asking for an introduction to how to configure the <allcaps> eci </allcaps> . this should be part of a larger scale effort to document <allcaps> eci </allcaps> up to a standard of basic usability .,1.0
"build and run existing <allcaps> eci </allcaps> unit tests under <allcaps> cfe </allcaps> <number> since the cfe <number> removed the for_build directory in it ' s cmake build system , we are kind of lost on how to add unit tests for the cfs <number> apps using ut assert . effort needs to be made to figure out what unit test looks like for <allcaps> eci </allcaps> <number> and document it accordingly .",2.0
"make the sgp4 example more noisy although this seems like a strange issue , it ' s not very obvious to a user whether or not the example sgp4 app works . it would be a nice addition to sgp4 to add some sort of periodic event message to show that the app has initialized and the main loop is executing . edit : the simple app could benefit from this as well .",2.0
"add ci tests to start <allcaps> cfs </allcaps> and verify no errors in many cases , verifying that code compiles is not sufficient to ensure that it runs as expected . as an extra level of verification , it would be nice to add some ci tests to actually startup the <allcaps> cfs </allcaps> system and verify that the intended apps start and no initialization errors occur . this would be good to have for both <allcaps> cfe </allcaps> <number> and <number> on the master and cfe - <number> branches respectively .",2.0
"improve cmake function naming / documentation for cfe <number> branch some new users are reporting that its hard to figure out how to build a <allcaps> cfs </allcaps> app with <allcaps> eci </allcaps> ( example # <number> ) . i think this can be partially addressed by pointing them at the ci pipeline as a "" recipe "" , but i think it would be helpful to add some better breadcrumbs for them to follow . as a couple examples , i ' d suggest perhaps : * renaming <code> to <code> or something similar , to reflect that there are functions in there for doing more than just setting up cfe ( sets up <allcaps> cfs </allcaps> system , also some helper functions for integrating <allcaps> eci </allcaps> apps , etc ) . * add docstrings for each function in that file explaining the result of each and perhaps at what point in the integration process its useful . * ensure that the function names reflect their purpose . for example , i think <code> might be more aptly called <code> or <code> ( though that ' s a little verbose ) . <code> i think performs multiple operations ( integrates to / sch / ci files , install eci source , etc ) but from the name i ' d think it only puts the <allcaps> eci </allcaps> source files into the <allcaps> cfs </allcaps> tree . * ensure that functions output messages to track their progress , which can also help document the functions . let me know if this makes sense and we can discuss any specific changes here as well .",2.0
"fixed the test builds for cfe <number> this commit makes multiple changes to return the tests to a working state . for whatever reason , the simple app never worked when ran in a cfs context even though it built . close # <number>",0.0
"suggest enhanced version information reporting ( at init and noop ) at build put the response from <code> ( similar to version . cmake in cfe / cmake ) into a define and report by the code if defined in addition to the manual version number . can do it at build - d_enhanced_v_name_ = response from git , or generate a header file on the fly and poke in the <hashtag> define </hashtag> , and include from the code . cfs app guide will eventually say something like this , it ' s the direction we are going with version reporting to eliminate all the manual changes to the version header ( only required at release with this update ) , or the confusion it causes when it ' s not updated . since before every merge to master really was a new version but not tracked well .",2.0
"<allcaps> eci </allcaps> strip headers from incoming packets for prior uses of <allcaps> eci </allcaps> , keeping the header of ingested packets was desirable because it contained information used in the processing of the packet . for some applications that header is unneeded or burdensome to the external code , which has to allocate space for it in its data structures . to maintain compatibility its likely that keeping the header will continue to be the default <allcaps> eci </allcaps> behavior , but adding the ability for the <allcaps> eci </allcaps> to strip the header off an incoming packet and a configuration setting so that the user could enable this functionality might be a good improvement . for the envisioned use case , a global setting ( applying to all incoming packets ) is sufficient but not sure if there are use - cases where the ability to set this per - packet would be needed .",2.0
"<allcaps> eci </allcaps> not updating outgoing packet headers properly in past usage , the external code allocated space for the <allcaps> ccsds </allcaps> header in the output messages , but expected the <allcaps> eci </allcaps> to manage the header ( which is generally out - of - scope for the external code ) . this was implemented by having the <allcaps> eci </allcaps> initialize the header at startup ( using cfe_sb_initmsg ) and then filling the messageid ( via cfe_sb_setmsgid ) , packet length ( via cfe_sb_settotalmsglength ) , and timestamp ( via cfe_sb_timestampmsg ) after each step function . this implementation works so long as the external code does not modify the header . it was discovered that if the external code overwrote the secondary header flag to indicate no secondary header , cfe_sb_timestampmsg , which checks that flag , did not update the time as intended . to remedy this situation and better define the intent of the external code , i intend to update the <allcaps> eci </allcaps> such that it overwrite the entire header ( using cfe_sb_initmsg ) after the execution of the step function and then update the timestamp ( using cfe_sb_timestampmsg ) , which ensures a correct header regardless of what the step function may have done during execution . the external code may disable this functionality by defining <code> , in which case the external code takes full responsibility for managing the header ( including setting the messageid , packet length , and timestamps or checksum ) . this change preserves the current output message definition , but does not allow packet - by - packet control of this behavior . that could be investigated if that ' s a desired feature .",0.0
registration of events with 0x0 0 0 0 filters is not all that helpful <section> registration of all events with <code> filters just loads the system without actually filtering anything . also fills the event filter buffer for the app and likely drops some since default limit is <number> . <section> remove zero entries from initialization and add a filter when / if needed ( or operationally via command ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
apply latest copyright header <section> updated copyright header <section> update <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,1.0
"recommend using fcncode ( instead of commandcode ) terminology in the code the current implementation of the sample app mixes terminology , calling the field which identifies a command a <code> <url> whereas the <allcaps> cfe </allcaps> apis call it a <code> . since this app is the starting point for many people , it might make sense to use consistent terminology . since the <allcaps> cfe </allcaps> apis call it a <code> , it seems like the code should too .",2.0
update to preferred unit test patterns <section> uses lower level macros where generic output is preferred . <section> use macros with default outputs . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"return value of cfe_msg_getmsgid is not checked during processcommandpacket or verifycmdlength <section> cfe_msg_getmsgid returns a status value to indicate success or failure of the call , but neither of the usages in the sample app check if it is successful nor do they state that the return value is ignored by design . <section> n / a <section> sample app should either make use of the return value to verify success or should note the reason why this is not being done . <section> <url> <url> <section> n / a <section> alan gibson <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> <number>",2.0
"overrun warning false alarm for cfe_msg_message_t <section> overrunning struct type cfe_msg_message_t of <number> bytes by passing it to a function which accesses it at byte offset <number> using argument 2 0 ul . <section> fix overrun <section> <url> <section> coverity : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",2.0
"update cfe_msg_message_t conversions to use cfe_msg_ptr macro <section> in nasa / cfe # <number> introduces a <code> macro which converts a cmd / tlm header object to a <code> pointer , which is intended to be used rather than assuming a specific member name ( e . g . <code> ) . <section> use the macro instead of assuming <code> member name . <section> required when using generated headers , as the member name may not be "" msg "" or may be further encapsulated . <section> joseph hickey , vantage systems , inc .",2.0
"improve consistency in application of cfe_sb_msgidtovalue / valuetomsgid conversions <section> a <code> value , like other ids , is supposed to be a unique type / opaque value that identifies a message within the sb application context . although it is currently implemented using an integer ( <code> specifically ) application should not assume this . instead , a set of macros and inline conversion functions ( cfe_sb_msgidtovalue and cfe_sb_valuetomsgid ) are provided for when the application needs to interpret the value as an integer for a valid purpose . <section> add conversions where they are currently missing <section> see nasa / cfe # <number> for full info . a separate issue + pr will be submitted for each framework app . <section> joseph hickey , vantage systems , inc .",2.0
"need to check the status of cfe_tbl_load ( ) call <section> sample_app does not actually check the status returned by the call to <code> . as a result , if the filename is wrong or missing , it is not obvious that the app has not initialized itself fully , because it still prints the "" <allcaps> sample </allcaps> app initialized "" message as usual . <section> start <allcaps> cfe </allcaps> framework as normal but without the sample app table file present in the / cf directory . the sample app still starts "" successfully "" as reported in the message but the table is not loaded . <section> the app should not report that it initialized if the table did not load . <section> the status is saved to a local variable here , but nothing is done with it : <url> <section> ubuntu <number> <section> surprising that this is not reported by static analysis , as it seems to be a case of variable assignment without use . also worth noting that table services itself _does_ send an event about the failure to load the table , but it does not have much detail : <code> if <allcaps> osal </allcaps> debug is enabled ( osal_config_debug_printf ) then the user does get a message on the console , at least on linux , with more detail ( "" no such file or directory "" ) . <section> joseph hickey , vantage systems , inc .",2.0
fix non - compliant header guards <section> leading <code> is reserved <section> replace with pattern used in <allcaps> osal </allcaps> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"should zero global data structure at initialization <section> fragile initialization touches individual elements , no memset <number> <section> memset the global to zero , only initialize non - zero elements <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add generate_config_includefile pattern for perfids and msgids <section> currently just includes the local mission_inc / platform_inc directories . really these are examples / defaults , and should be easily overridden from the target defs . <section> use generate_config_includefile ( example : <url> <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove references to cfe_es_registerapp <section> as part of nasa / osal # <number> and nasa / cfe # <number> the registration apis are getting fully deprecated and removed . applications no longer need to call os_taskregister , cfe_es_registerapp , or cfe_es_registerchildtask . <section> remove references to these functions . <section> will be required with nasa / osal # <number> and nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add contributing guide <section> fix # <number> added a contributing guide that links to the main cfs contributing guide . <section> users should be able to view the contributing guide contents easily from the sample_app repo . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add contributing guide <section> add a contributing guide for the sample_app repo . <section> create a contributing guide markdown file . in the guide , add a link to the cfs contributing guide . <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"scrub for include < > vs "" "" use ( < > should be system only ) <section> < > used on non - system header includes . example : <url> <section> full scrub / fix <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add testing tools to the security policy <section> fix # <number> updated the security policy to include the type of testing done for sample_app or the cfs bundle under a new section titled "" testing "" . provided a disclaimer that under the apache license , liability is not provided . added that security reports should be emailed . <section> users should now be aware of the type of testing sample_app or the cfs bundle undergoes . <section> references : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add testing tools to the security policy <section> users are unaware of how cfs / sample_app is tested . by providing this information , transparency is provided to the community which promotes trust . <section> the security policy should inform users what tools are being used to test cfs / sample_app while being cautious of liability issues . to do so , we can state explicitly that our software does not provide liability under the apache license . the security policy should inform users that they may view the <allcaps> lgtm </allcaps> results . the policy would state that the alerts from <allcaps> lgtm </allcaps> may not be accurate , since they cannot be dismissed . add that security report should be emailed . <section> references : <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"add codeql analysis to workflow <section> codeql analysis not implemented in submodules <section> add so alerts are generated on pull requests to submodules <section> none <section> codeql is run at the bundle ( nasa / cfs ) level , but link to code in submodules does not work . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , add static analysis and format check <section> fix # <number> - adds static analysis and format check into github workflow , includes badges in readme <section> ci <section> basic ci works again <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
ci updates - add static analysis and format in workflow <section> travis - ci not transitioned to github actions <section> transition ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"fix # <number> , create security policy <section> fix # <number> created a draft of a security policy markdown file for sample_app . the purpose of a security policy is to inform users on how to submit bugs or vulnerabilities . it is ideal to include a section for supported versions . <section> optional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"implement a security policy <section> create a security policy for users on how to report security vulnerabilities . <section> the security policy should instruct users on how to report security vulnerabilities and provide them additional contact information for questions and concerns . <section> additional sections that may be included : - what to expect security - wise such as what type of testing is done - address privacy concerns - supported versions - license - known vulnerabilities references to public security policies : <url> <url> <url> <section> ariel adams , <allcaps> asrc </allcaps> federal",1.0
"fix # <number> , apply message alignment pattern <section> fix # <number> - replace cfe_sb_rcvmsg with cfe_sb_receivebuffer - use cfe_sb_buffer_t for receiving and casting to command types - use cfe_msg_commandheader_t and cfe_msg_telemetryheader_t in command and telemetry type definitions - use cfe_sb_transmitmsg to copy the command and telemetry into a cfe_sb_buffer_t and send it where needed - avoids need to create send buffers within the app ( or union the packet types with cfe_sb_buffer_t ) - eliminates references to cfe_sb_cmdhdr_t and cfe_sb_tlmhdr_t that formerly enforced alignment since these had potential to change the actual packet sizes - no need to cast to cfe_msg_message_t anywhere since it ' s available in the cfe_sb_buffer_t union - replaced cfe_msg_size_t with size_t <section> bundle ci , unit tests , spot checked cmd / tlm <section> none , pattern applied only <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle ( integration - candidate ) + nasa / cfe # <number> , and this commit <section> depends on nasa / cfe # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"remove function names from comments ( where not useful ) <section> function names in comments ( end of function comment , function header comment ) historically have been poorly maintained . example : <url> <url> <section> remove redundant information ( these end of function comments and name from the header ) . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"update for suggested alignment enforcement pattern ( nasa / cfe # <number> ) <section> see nasa / cfe # <number> , inconsistent pattern <section> match suggestion in nasa / cfe # <number> , use the "" raw "" message cmd / tlm types in definition . <section> none <section> nasa / cfe # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
refactor ut_setforcefail describe the bug ut_setforcefail was refactored to ut_setdefaultreturnvalue for <url> it needs to have its name changed here as well . expected behavior change ut_setforcefail to ut_setdefaultreturnvalue additional context part of <url> reporter info alex campbell,2.0
remove use of os_pack <section> os_pack should not be used . <section> remove it . <section> none <section> nasa / osal # <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
remove dependencies on deprecated sb apis <section> sb apis deprecated in nasa / cfe # <number> <section> update to use <allcaps> msg </allcaps> module . <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"not correctly checking return code of cfe_tbl_getaddress <section> the <code> routine is one of the apis that have multiple "" success "" codes . although the intent / hope is to deprecate this ( see nasa / cfe # <number> ) - the current implementation still returns values other than <code> . in particular the first time it is called after loading , one gets <code> . <section> run <allcaps> cfe </allcaps> with sample app and issue the "" process "" command ( <number> ) and observe one gets an "" error "" message e . g . : <number> - <number> - <time> . <number> sample app : fail to get table address : 0x 4 c00000e but that error code is actually a "" success "" response . if the same command is repeated , it works ok because it returns <code> this time . a bigger issue , however , is that the address acquired from the first invocation is not released . <section> should get address and release address correctly . <section> ubuntu <number> <section> this is an <section> example of why multiple success responses are a bad idea . it is really a bug in the cfe_tbl <allcaps> api </allcaps> - - we did not as if a table was updated , we only asked to get its pointer . if <allcaps> tbl </allcaps> services gives back a buffer pointer as requested , the response should be <code> . the unnecessary over - complexity of the <allcaps> tbl api </allcaps> definitely causes usability problems . but in the meantime one can change the check from <code> to <code> and it should resolve the resource leak issue here . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , check only format string in ut event test <section> for example "" sendevent "" tests in sample_app , do not pass the test string through <code> to get a fully rendered output . instead test only that the format string matches . this is my recommended approach . note that the "" fully - rendered "" output is affected my many external variables and is not necessarily going to be consistent . the most recent example is in # <number> /# <number> which is the reason for this change , but it also can be affected by things totally outside of <allcaps> cfe </allcaps> like the user ' s locale settings in the os . fixes # <number> <section> build and run sample_app unit tests <section> fixes current failure in integration candidate <number> - <number> - <number> . <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"string checks in ut should check only the spec / format string , not the fully rendered text . <section> as the comment in the code suggests , the "" fully - rendered "" text is really a derived output that depends on a lot of external factors . it is not a direct output of the unit under test . as an example , the unit test is currently getting thrashed around due to a message id check due to the fact that there is no specific text that is always "" correct "" here . it broke when updated to <number> bit (# <number> ) , attempted to fix in # <number> , which only broke the original case ( v1 header ) . <section> run unit test using v1 ( <number> - bit ) message ids . <section> <section> tests should pass . <section> ubuntu <number> and travis - ci ( current integration candidate ) . <section> recommendation is to only check the <allcaps> spec string </allcaps> ( <code> ) which will be the same regardless of what the "" invalid msgid "" value actually is . that ' s all that really matters . <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , install unit test to target directory <section> fix # <number> , install unit test to target directory <section> make unit tests , install , observe they install in correct directory <section> correct install directory <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + this commit <section> none . <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"coverage test not installed in correct directory <section> coverage test not installed in correct directory - see nasa / cfe # <number> <section> make unit tests , make install , observe unit test in build directory . <section> should go in target directory ( build / exe / cpu1 for sample config ) <section> <url> <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , unit test <allcaps> mid </allcaps> string format now 3 2 bit <section> fix # <number> with nasa / cfe # <number> , the format is now consistently <number> bit , fixed event string check to match . <section> built unit tests with nasa / cfe # <number> , now passes <section> unit test pass <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main + nasa / cfe # <number> + this commit <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"fix # <number> , remove cfe_sb_initmsg use in coverage test <section> fix # <number> - removes test code call of cfe_sb_initmsg and sets the <allcaps> api </allcaps> / stub buffers directly . <section> built and ran tests , passed - depends on nasa / cfe # <number> <section> none , just improved test . <section> - hardware : cfs dev server - os : ubuntu <number> - versions : bundle main ( + cfe / osal main ) + nasa / cfe # <number> and this commit <section> nasa / cfe # <number> <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"fix # <number> , apply style <section> fix # <number> - applies standard coding style <section> ci only , whitespace . <section> none <section> ci <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"unit test fails when ver_2 headers are used <section> event test strings are different when the msgid size changes , but test looks for explict message : <url> <url> <url> ! ver_2 = <code> , ver_2 =< code > ( or capitalized based on the format string ) <section> set message_format_is_ccsds_ver_2 , build and run unit tests . <section> unit tests should pass with either configuration <section> see above . <section> - hardware : cfs dev vm - os : ubuntu <number> - versions : main bundle <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"cmakelists . txt not c + + friendly <section> this might be out of scope of this project but when baselining off of sample_app to make other apps i have been able to write c + + code and extern "" c "" functions to run in the sample_app . c main file ( or equivalent ) . now that the cmakelists . txt file does not have the "" aux_source_directory ( fsw / src app_src_files ) "" and "" add_cfe_app ( sample_app app_src_files ) "" lines , the c + + externed functions are not linked by the cmake build system . by explicitly saying "" add_cfe_app ( sample_app fsw / src / sample_app . c ) "" the link command will not pick up the necessary c + + symbols . <section> steps to reproduce the behavior : <number> . create a c + + file in app src directory and make a function called "" extern "" c "" void test ( ) { printf ( "" test \ n "" ) } "" <number> . forward declare this test function in sample_app . c at the top by writing "" void test ( ) "" <number> . add "" <allcaps> cxx </allcaps> "" to the project ( ) line in cmakelists . txt <number> . call test ( ) in sample_app . c somewhere where you know it will be called ( init or main run loop ) <number> . build and run on target <section> target should have an error similar to "" undefined symbol "" when dynamically loading / linking the sample_app during cfs startup / initialization <section> - linux ubuntu <number> , intel i7 vxworks <number> target - os : ubuntu <number> and vxworks <number> <section> joe mahoney - <allcaps> lta </allcaps> research",3.0
"fix # <number> , install unit test <section> fix # <number> - install unit test as part of cmake recipe <section> normal build with enable_unit_tests = true , with make install , and ran sample app unit test from install dir ( passed ) <section> sample app test runner now shows up in expected install dir <section> - hardware : cfs dev vm - os : ubuntu <number> - versions : current bundle development branch <section> none . <section> none . <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"add build name and build number to version . h <section> need a better way to describe versions during development <section> add build name and build number to version . h as discussed , we will add a a build name string and a continuously incrementing build number to <code> <section> see notes from <allcaps> ccb </allcaps> : < <url> <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"inconsistent use of <allcaps> tbl </allcaps> vs <allcaps> table </allcaps> <section> it seems we use <allcaps> tbl </allcaps> and <allcaps> table </allcaps> interchangeably . for example <code> has both uses . <section> search the sample_app directory for uses of * <allcaps> tbl </allcaps> * and * <allcaps> table </allcaps> * both upper and lower case combinations exist . <section> a single mnemonic for tables . <allcaps> tbl </allcaps> seems to be the default used in cfs . <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",2.0
"rename files , functions , and variables to match appname_ * pattern <section> pr # <number> shed light on inconsistencies in naming conventions . there are multiple items named sample_itemname as opposed to sample_app_itemname . <section> one relevant example is <code> in <code> <section> all item names should use the prefix <code> as opposed to <code> . in the example above the correct name should then be <code> . <section> source code <section> gerardo e . cruz - ortiz , <allcaps> nasa </allcaps> - <allcaps> gsfc </allcaps>",0.0
"fix # <number> , reorg the table file <section> fix # <number> - move the table to fsw / tables and renames "" sample_table "" to "" sample_app_table "" . <section> built and run . <section> debian <number> <section> <email>",2.0
"should sample_app be writing to syslog ? <section> i thought that , generally , apps should be generating events on errors , not writing to syslog . however , if you look at , say sample_appinit ( ) , it writes to syslog for a number of error conditions . <section> re - write to generate events . <section> <email>",3.0
"sample_table . c - - relocate ? <section> tables are a component of applications that are expected to be customized by the user . the cfs build process supports this customization ( for example , by creating <code> ) . currently <code> is in <code> but everything else in <code> is not expected to be customized by the user . i consider sample_app to be the "" style template "" for applications , so this should be clear not just for users of the sample_app but for folks who model their code on sample_app . <section> i would like to see a clearer indication that <code> is expected to be customized - - whether it be relocated to a different folder ( <code> ? ) or possibly rename it to <code> ? <section> <email>",3.0
"fix # <number> , remove references to <allcaps> ccsds </allcaps> types <section> replace references to <code> types with the <code> - provided type . fixes # <number> <section> build and sanity check <allcaps> cfe </allcaps> , run all unit tests <section> no impact to behavior <section> ubuntu <number> <section> joseph hickey , vantage systems , inc .",2.0
"remove references to "" <allcaps> ccsds </allcaps> "" structures <section> applications should <allcaps> not </allcaps> refer to the "" <allcaps> ccsds </allcaps> "" data types and macros , as there should be no assumption of a particular message framing type at this level . <section> use the abstract types provided in <code> rather than directly using <code> types . <section> related to nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add extended context information to event hook <section> add a string validation to the sample event hook as an example of how to use the context information supplied to the hook to perform this type of validation . fixes # <number> <section> execute unit tests and confirm correct operation . all passing . <section> test cases now compare an expected event string with a string derived from the spec string and arguments that were output by the unit under test . <section> ubuntu <number> <section> depends on prerequisites / related tickets : - nasa / osal # <number> - nasa / cfe # <number> these are necessary to pass the full cfe_evs_sendevent context through to the hook function . <section> joseph hickey , vantage systems , inc .",2.0
"provide example of extended context arguments in unit test <section> unit test stubs are being updated to pass - through a more complete context information , currently for <allcaps> evs </allcaps> events such that the full spec string and argument set can be checked / manipulated . <section> sample unit tests should include an example of how to obtain the context arguments in a hook function . <section> see nasa / cfe # <number> <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , refactor code to fit suggested app model <section> this is # <number> , resubmitted for fixes : addresses ticket # <number> . specifically adds new sample_app_cmds . c / . h and sample_app_utils . c / . h files , moves functions out of sample_app . c into the new cmds and utils files . updates unit tests . this change makes sample_app a better reference application - structure more closely matches other apps . fix # <number> <section> <allcaps> tbd </allcaps> <section> none <section> - hardware : [ e . g . pc , sp0 , mcp750 ] - os : [ e . g . ubuntu <number> , <allcaps> rtems </allcaps> <number> , vxworks <number> ] - versions : [ e . g . cfe <number> , <allcaps> osal </allcaps> <number> , <allcaps> psp </allcaps> <number> for mcp750 , any related apps or tools ] <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps> ( resubmit ) elizabeth timmons / <allcaps> nasa </allcaps> ( implemented )",2.0
"sample_reporthousekeeping fails , likely due to nasa / cfe # <number> <section> ut failure , likely related to nasa / cfe # <number> : <code> <section> build and run unit tests at bundle level with nasa / cfe # <number> included <section> tests pass <section> n / a <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions bundle with nasa / cfe # <number> included <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"sample app test does not end up in exe dir after make install <section> sample_app - sample_app - testrunner does not get "" installed "" <section> steps to reproduce the behavior : <number> . make <allcaps> simulation </allcaps> = native enable_unit_test = true prep ; make ; make install <number> . ls build / exe / cpu1 <number> . find / . - name "" sample_app_sample_app - testrunner "" <section> install should move all tests to install directory <section> n / a <section> - hardware : cfs dev <number> - os : ubuntu <number> - versions : observed in refactored ic at skliper / ic - <number> - jh <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"format conversion error in coverage test <section> when compiling the coverage test on <allcaps> rtems </allcaps> , a format conversion error is triggered : <code> <section> build with enable_unit_tests = <allcaps> true </allcaps> for i686 - rtems4 . <number> platform <section> should build clean <section> i686 - rtems4 . <number> cross build <section> joseph hickey , vantage systems , inc .",0.0
"fix # <number> , reference skeleton_app in readme <section> adds a doc update with a link to <url> <section> <email>",1.0
"fix # <number> , update coverage compile / link flag options <section> <allcaps> osal </allcaps> now sets these as ut_coverage_compile_flags , ut_coverage_link_flags . building and linking the ut executable needs a corresponding update . fixes # <number> <section> build with <code> and confirm that all unit tests are building <section> coverage data ( <code> ) now includes the sample_app code again <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> joseph hickey , vantage systems , inc .",0.0
"apps should not pend forever on software bus the sample_app , which is supposed to exemplify the current best practices , should not be pending forever on a software bus message as it does here : <url> the problem with pending forever is that the app also needs to perform an orderly exit if a restart / reload / delete command is sent to es , which is checked by <code> . if an app is pending forever for software bus messages but none are sent , then the shutdown request will remain pending indefinitely .",2.0
"app should treat cfe_sb_msgid_t values as opaque <section> for compatibility going forward , code should not assume that <code> is an integer . <section> when dealing with an integer , such as when printing in events / messages or for backward compatibility with <allcaps> mid </allcaps> <code> ' s , the code may use <code> and <code> conversion routines . <section> architecturally , the <code> is supposed to be an opaque / abstract value that identifies an endpoint on the software bus routing domain . the specific meaning of integer values is already different in an "" extended header "" ( <allcaps> ccsds </allcaps> v2 ) build vs . the standard header build . therefore apps should never make assumptions regarding the specific integer values , and all introspection of <code> values should be through the <allcaps> cfe sb api </allcaps> only . <section> joseph hickey , vantage systems , inc .",2.0
"skeleton app <section> sample_app is great for showing a variety of capabilities that cfs provides to an application , but folks will likely come to sample_app thinking it ' s a good starting place for them to develop their new apps . i suggest we also have a "" skeleton_app "" either as a separate <allcaps> git </allcaps> repository ( and referenced in the sample_app docs ) or contained in the sample_app folder . <section> a skeleton_app which has the barest of minimums to make it a valid cfs application . <section> add any other context about the feature request here . <section> <email>",1.0
"suggest adding a child task to sample_app <section> not related to a problem . <section> a simple child task could be added to sample_app to demonstrate how a child task is created . if sample_app is intended to be a fully featured example / template , child tasks are a key thing that is not represented in the sample . <section> none <section> none <section> elizabeth timmons - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"suggest refactoring sample_app to more closely match "" real "" apps . <section> this ticket is not related to a problem . this is a feature request to reorganize the sample app to more closely match "" real "" apps ( namely the <allcaps> gsfc </allcaps> open source apps ) . this would increase sample_app ' s value as a template . in addition to providing a more realistic example , the organization of functions into files has implications for unit testing . <section> <number> . move command functions into a separate sample_app_cmds . c file . <number> . move utility functions into a separate sample_app_utils . c file <section> none <section> none <section> elizabeth timmons - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
"avoid using aux_source_directory <section> the example build script should __not__ use <code> as it is not well defined / controlled behavior - it depends on files that existed at the time "" prep "" was run . <section> <code> should list the app source files explicitly . this is recommended cmake practice for most normal build cases . <section> this is a prime example of why <code> is discouraged , because in this case it incorrectly pulled in the "" sample_table . c "" source file into the app binary . this is incorrect ; the table file is built separately by the table generator script . <section> joseph hickey , vantage systems , inc .",0.0
"sample_app should have a clearly - defined "" publish telemetry "" function <section> i ' d venture most folks who look at the sample_app code are looking to read some data from a sensor / instrument and publish the telemetry onto the software bus . the current code does not make it clear where such code would go . <repeated> i ' d venture it ' d go in "" processcc ( ) "" ? in fact , the only call to cfe_sb_sendmsg ( ) is in reporthousekeeping ( ) function . <section> the sample app demonstrates reading from a table and calling a library , perhaps a call to a library function that iterates through an array ( provided by a table ) of values and publishes the next one on each command received ? needless to say , a big comment block stating "" add your code here "" would be appropriate . the processcc ( ) function really has no documentation in the comments as to what it does . <section> i think some folks on the <allcaps> ccb </allcaps> consider the sample app to *not* be a skeleton for a real application . if that is the intent , it should be made more clear in the sample_app . c file and the <allcaps> readme </allcaps> . md , and it would be appropriate to have a separate skeleton app for folks to start developing from . ( in fact , such a skeleton would be a nice source for developers to fork from , and any major framework changes could be made in the skeleton and folks would see the change when they fetch from their upstreams . ) <section> add any other context about the feature request here . <section> <email>",2.0
"fails to build under raspbian - alignment of pointers <section> trying to build under raspbian , sample_app fails with "" cast increases required alignment of target type "" errors . <code> <section> build on raspbian . <section> should not cause warnings / errors . <section> <section> raspberry pi zero w <section> add any other context about the problem here . <section> <email>",0.0
apply code style <section> inconstant style <section> see <url> and <url> <section> n / a <section> n / a <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
build fails with deprecated cfe / <allcaps> osal </allcaps> elements removed <section> build fails on <number> undeclared errors : errors . txt <url> <section> make omit_deprecated = true prep ( requires <url> <section> clean build <section> - cfs dev server <number> - os : ubuntu <number> - versions : mostly <number> ( + commit above ) <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,0.0
"fix <number> - release updates <section> fix # <number> - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> <number> . standard build , unit test and execute <section> - no impact to behavior <section> - hardware : cfs dev server <number> - os : ubuntu <number> - versions : cfe <number> . <number> related versions and <allcaps> osal </allcaps> <number> . <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",2.0
release <number> . <number> prep <section> updates for release : - updated <allcaps> readme </allcaps> - removed custom license document - added standard apache <number> - updated copyright release version cfe <number> - > <number> <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>,2.0
"compiler warning on <allcaps> rtems </allcaps> <section> when compiling on <allcaps> rtems </allcaps> this application now has multiple warnings : <code> <section> build on <allcaps> rtems </allcaps> per the readme / howto and with <code> switches <section> should build clean <section> ubuntu <number> ( build host ) when cross compiling for <allcaps> rtems </allcaps> <number> <section> appears the problem calls were introduced in # <number> as a rule of thumb , whenever "" printf "" style conversions are used in conjunction with the fixed - width types ( int32 , uint32 , etc ) these need an explicit cast because the actual type definitions vary by platform . <section> joseph hickey , vantage systems , inc .",0.0
"sample_processcc needs to check return code of cfe_tbl_getaddress call <section> the <code> example calls <code> and then immediately proceeds to dereference the pointer , without checking its return code . <section> this is primarily evident in unit test , where the <code> call can be forced to fail . it outputs a <allcaps> null </allcaps> pointer in this case and subsequently segfaults . <section> the <code> should not attempt to dereference the pointer output of <code> unless that function actually returns cfe_success <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit ( when running ut ) <section> joseph hickey , vantage systems , inc .",2.0
"fix # <number> , add sample app tests <section> fixes # <number> adds a complete example unit test to the sample application . uses the ut assert framework with common stubs provided by <allcaps> cfe </allcaps> and other modules . obtains <percent> line coverage on the current app implementation . <section> build with <allcaps> simulation </allcaps> = native enable_unit_tests = <allcaps> true </allcaps> execute the unit tests per "" make test "" and confirm correct output execute "" make lcov "" to collect coverage statistics verified that the sample application is included in results and achieves <percent> line coverage . <section> no changes to <allcaps> fsw </allcaps> . <section> ubuntu <number> <allcaps> lts </allcaps> <number> bit <section> there is a bug in the application implementation , described in # <number> . the unit tests actually will fail until this is fixed . <section> joseph hickey , vantage systems , inc . <section> you must attach a signed <allcaps> cla </allcaps> ( required for acceptance ) or reference one already submitted",2.0
"sample app has error counter and command counter reversed <section> the sample_reporthousekeeping function reports the error count and command count values reversed . <section> send a <allcaps> noop </allcaps> command , then report housekeeping , and see that the error count is in place of the the command count . <section> the error count and command count should not be reversed . <section> inside <code> , it has : <code> <section> ubuntu <number> <allcaps> lts </allcaps> <number> - bit <section> actually discovered this when writing the unit test for the reporthousekeeping function (# <number> ) , and the test case failed because the counters were backwards . <section> joseph hickey , vantage systems , inc .",0.0
"the "" sample_app "" should call into "" sample_lib "" <section> the sample_app only calls <allcaps> cfe </allcaps> functions ; it does not call any <allcaps> osal </allcaps> , <allcaps> psp </allcaps> , or additional library functions like a real app might do . this makes a difference for unit testing . the framework should contain a useful example of ut for apps and libs ( related to # <number> ) and the example would be more useful if it called something other than <allcaps> cfe </allcaps> . <section> the sample_app should invoke the <code> as provided in the example <code> library . <section> n / a <section> this change would demonstrate two things : - demonstrate at runtime that the dynamic linking worked correctly for the libraries ( i . e . an app can successfully call into a lib like it is supposed to ) - demonstrate linking to the stubs provided by the library for unit testing <section> joseph hickey , vantage systems , inc .",2.0
"sample app needs to release table to allow management <section> table not released after use <section> did not test it , but likely will not be able to load a new table after sending the sample_processcc command . <section> add cfe_tbl_releaseaddress after access of table data <section> <url> <section> - versions : current bundle <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"table type should be defined once in table header file <section> sampletable_t is defined in both sample_app_msg . h and sample_table . c <section> define sample_table . h , and include where needed . <section> none <section> none <section> jacob hageman - <allcaps> nasa </allcaps> / <allcaps> gsfc </allcaps>",0.0
"add unit test example the sample app should include an example of how to use the ut_assert , and link / build / run .",2.0
"replace deprecated cfe refs , # <number> fixes # <number> submitted by <user> , <allcaps> cla </allcaps> on file testing : - make enable_unit_tests = <allcaps> true simulation </allcaps> = native prep - built on linux with - dcfe_omit_deprecated_6_6 with no build errors - make test passed ( except osal_timer_ut which occasionally fails on linux ) - cfs executes and loads apps with no issues",2.0
remove dependencies on deprecated cfe elements with : <code> build errors : <code>,2.0
"enhanced version numbering use ci_lab_version from cfecfs_version_info . h if available and report on <allcaps> noop </allcaps> and startup ( along with classic version numbering "" classic version numbering can then just be updated on release , vs for every commit .",2.0
remove classic build support only supporting cmake build going forward .,2.0
"remove old <allcaps> mks </allcaps> flags from comments $ id , $ date , $ revision , $ log , etc all no longer useful and slightly misleading since they do not get updated .",2.0
systematic naming convention ? can all the the core flight system ( cfs ) repositories follow a systematic naming convention with cfs - <name> ? just ' sample_app ' seems to pollute the namespace . thank you .,3.0
"sample app should be consistent with app developer ' s guide originated by dave ( <number> on babelfish ) the sample_app provided with the cfe is not consistent with the example app documented in the application developer ' s guide . the app developer ' s guide should documented recommended styles and practices . similarly the sample_app should implement them . i do not think sample app needs to cover all of the potential app features like critical data stores , child tasks , etc . just the basics to get someone started .",2.0
